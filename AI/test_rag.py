import os
from pathlib import Path  # ê²½ë¡œ ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

def test_rag(query_text):
    # 1. ê²½ë¡œ ë° ì„¤ì •
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸(test_rag.py)ì˜ ìœ„ì¹˜ë¥¼ êµ¬í•¨ (ì˜ˆ: .../kau_generative_ai/AI)
    current_dir = Path(__file__).resolve().parent
    
    # ìƒìœ„ í´ë”(../)ë¡œ ë‚˜ê°„ ë’¤ 'Data' í´ë” ì•ˆì˜ 'chroma_db'ë¥¼ ì§€ì •
    # ì‹¤ì œ ê²½ë¡œ: .../kau_generative_ai/Data/chroma_db
    db_path_obj = current_dir.parent / "Data" / "chroma_db"
    DB_PATH = str(db_path_obj) # ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„±ì„ ìœ„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜

    MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    
    # â˜… ì¤‘ìš”: paper_indexer.pyì—ì„œ ì„¤ì •í•œ ì»¬ë ‰ì…˜ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•¨
    COLLECTION_NAME = "paper_abstracts"  

    print(f"ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘: '{query_text}'")
    print(f"ğŸ“‚ DB ê²½ë¡œ í™•ì¸: {DB_PATH}") # ê²½ë¡œê°€ ë§ê²Œ ì¡í˜”ëŠ”ì§€ ì¶œë ¥ í™•ì¸
    
    # DB í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(DB_PATH):
        print(f"âŒ ì˜¤ë¥˜: '{DB_PATH}' ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   1. 'paper_indexer.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì„œ DBë¥¼ ë§Œë“¤ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("   2. 'Data' í´ë” ì•ˆì— 'chroma_db' í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 2. DB ë¡œë“œ (ì½ê¸° ì „ìš©)
    print("ğŸ“‚ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”© ì¤‘...")
    embeddings = HuggingFaceEmbeddings(model_name=MODEL_NAME)
    
    try:
        vector_store = Chroma(
            persist_directory=DB_PATH,
            embedding_function=embeddings,
            collection_name=COLLECTION_NAME
        )

        # 3. ì‹¤ì œ ê²€ìƒ‰ ìˆ˜í–‰ (ìƒìœ„ 3ê°œ)
        results = vector_store.similarity_search(query_text, k=3)

        # 4. ê²°ê³¼ ì¶œë ¥
        if not results:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤.")
            print("   - DBì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜, Collection ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\nâœ… ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê±´):")
            for i, doc in enumerate(results):
                print("-" * 50)
                source = doc.metadata.get('source', 'Unknown')
                print(f"[{i+1}] ì¶œì²˜: {source}")
                # ê°€ë…ì„±ì„ ìœ„í•´ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì¶œë ¥
                content_preview = doc.page_content[:200].replace('\n', ' ')
                print(f"ë‚´ìš©: {content_preview}...") 
                print("-" * 50)
                
    except Exception as e:
        print(f"\nâŒ ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        print("   DB íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ë²„ì „ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ì›í•˜ëŠ” ê²€ìƒ‰ì–´ë¡œ í…ŒìŠ¤íŠ¸
    test_rag("ê¸ˆìœµ ê´€ë ¨ ë…¼ë¬¸ ì°¾ì•„ì¤˜")