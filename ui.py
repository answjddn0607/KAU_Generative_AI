from fastapi import FastAPI
import gradio as gr
import uvicorn
import uuid
import time 
from graph.runner import run_with_stream

# FastAPI ì•± ìƒì„±
app = FastAPI()

with gr.Blocks(title="Transporter", fill_height=True) as demo:
    
    # ì‚¬ì´ë“œë°”: ë¡œê·¸ì°½
    with gr.Sidebar(label="Agent Status"):
        log_view = gr.Markdown("")

    gr.Markdown(
        """
        # Transporter
        ### KAU Generative AI
        """
    )
    
    chatbot = gr.Chatbot(label="ëŒ€í™”ì°½", height=450)
    msg = gr.Textbox(label="ì§ˆë¬¸ ì…ë ¥")
    session_id_state = gr.State(lambda: str(uuid.uuid4()))
    log_history_state = gr.State(value="") 

    def respond(user_message, history, session_id, log_accumulated):
        if not user_message:
            return "", history, "ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", log_accumulated

        if history is None:
            history = []
        
        history.append({"role": "user", "content": user_message})

        # ë‹µë³€ ì¶œë ¥ ëŒ€ê¸°
        history.append({"role": "assistant", "content": "..."}) 
        
        prefix = ""
        if log_accumulated:
            prefix = log_accumulated + "\n\n---\n\n"
            
        current_header = f"### ğŸ” ì§ˆë¬¸: {user_message}\n"

        yield "", history, prefix + current_header + "ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤...", log_accumulated
        
        for output in run_with_stream(user_message, session_id=session_id):
            if "**ìµœì¢… ë‹µë³€:**" in output:
                parts = output.split("**ìµœì¢… ë‹µë³€:**")
                logs = parts[0].strip()
                full_answer = parts[1].strip()
                
                new_log_entry = prefix + current_header + logs
                
                # ë‹µë³€ì„ ì¶œë ¥í•˜ê¸° ì§ì „ì— "..."ì„ ì§€ì›€
                history[-1]['content'] = ""
                
                for char in full_answer:
                    history[-1]['content'] += char
                    yield "", history, new_log_entry, new_log_entry
                    time.sleep(0.005) 

            else:
                # ë¡œê·¸ë§Œ ì—…ë°ì´íŠ¸ (í™”ë©´ì—” ì—¬ì „íˆ "..." í‘œì‹œë¨)
                current_view = prefix + current_header + output
                yield "", history, current_view, log_accumulated

    msg.submit(
        respond, 
        [msg, chatbot, session_id_state, log_history_state], 
        [msg, chatbot, log_view, log_history_state]
    )

app = gr.mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)