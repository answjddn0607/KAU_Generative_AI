from .graph import create_graph
from .state import AgentState
from memory.reflection import extract_and_save_memory
from langchain_core.messages import HumanMessage


def run_with_stream(user_input: str, session_id: str = "default"):
    """Stream + Interrupt ëª¨ë“œ"""
    
    graph = create_graph(interrupt=True)
    config = {"configurable": {"thread_id": session_id}}
    
    # ê¸°ì¡´ ìƒíƒœ í™•ì¸ (ì¬ê°œì¸ì§€ ì²´í¬)
    snapshot = graph.get_state(config)
    
    if snapshot.next:  # interrupt ìƒíƒœë©´ ì¬ê°œ
        print(f"[RESUME] ì¬ê°œ - next: {snapshot.next}")
        graph.update_state(config, {"query": user_input})
        initial_state = None
    else:
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "tool_result": None,
            "iteration": 0,
            "max_iterations": 5,
            "query": "",
            "status": "",
            "rag_result": None,
            "api_result": None,
            "google_result": None,
            "target_paper": None,
            "related_papers": None,
            "user_interests": None,
            "recommendations": None,
            "final_result": None
        }
    
    print("ğŸš€ Agent ì‹œì‘ (Stream Mode)...\n")
    logs = "ğŸš€ **Agent ì‹œì‘** (LangGraph Running...)\n"
    yield logs
    
    for event in graph.stream(initial_state, config, stream_mode="updates"):
        for node_name, node_output in event.items():
            
            # 1. ì—ì´ì „íŠ¸ê°€ ë§í•˜ê±°ë‚˜ ë„êµ¬ë¥¼ í˜¸ì¶œí–ˆì„ ë•Œ
            if node_name == "agent":
                messages = node_output.get("messages", [])
                if messages:
                    last_msg = messages[-1]
                    
                    # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš°ì—ë§Œ
                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                        
                        logs += f"\n\nğŸ› ï¸ **ë„êµ¬ í˜¸ì¶œ** ({len(last_msg.tool_calls)}ê°œ):\n"
                        for tc in last_msg.tool_calls:
                            func_name = tc['name']
                            func_args = tc['args']
                            logs += f"- âš™ï¸ **Running:** `{func_name}`\n"
                            logs += f"  - ğŸ“¥ **Input:** `{str(func_args)}`\n"
                        logs += "\n"
                        yield logs
                    
                    # ìµœì¢… ë‹µë³€ ìƒì„±
                    else:
                        pass

            # 2. Tools ì‹¤í–‰ì„ ë§ˆì¹˜ê³  ê²°ê³¼ë¥¼ ë±‰ì—ˆì„ ë•Œ
            elif node_name == "tools": 
                messages = node_output.get("messages", [])
                if messages:
                    last_msg = messages[-1]
                    result_preview = last_msg.content[:200]
                    
                    logs += f"\n\nâœ… **ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ!**\n"
                    logs += f"> ğŸ“¤ **Output:** {result_preview}...\n"
                    yield logs

            # 3. ê·¸ ì™¸ ì»¤ìŠ¤í…€ ë…¸ë“œ 
            else:
                logs += f"\n\nğŸ”„ **ì‘ì—… ì¤‘:** `{node_name}` ë‹¨ê³„ ìˆ˜í–‰ ì¤‘...\n"
                yield logs
    
    final_state = graph.get_state(config)
    final_msg = final_state.values["messages"][-1]
    answer = final_msg.content if hasattr(final_msg, 'content') else "ë‹µë³€ ìƒì„± ì‹¤íŒ¨"

    extract_and_save_memory(user_input, answer)
    
    logs += "\n\nâœ… **ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.**"
    yield logs + f"\n\n**ìµœì¢… ë‹µë³€:**\n\n{answer}"