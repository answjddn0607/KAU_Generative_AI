from .graph import create_graph
from .state import AgentState
from memory.reflection import extract_and_save_memory
from langchain_core.messages import HumanMessage


def run_with_stream(user_input: str, session_id: str = "default"):
    """Stream + Interrupt ëª¨ë“œ"""
    
    graph = create_graph(interrupt=True)
    config = {"configurable": {"thread_id": session_id}}
    
    # ê¸°ì¡´ ìƒíƒœ í™•ì¸ (ì¬ê°œì¸ì§€ ì²´í¬)
    snapshot = graph.get_state(config)
    
    if snapshot.next:  # interrupt ìƒíƒœë©´ ì¬ê°œ
        print(f"[RESUME] ì¬ê°œ - next: {snapshot.next}")
        graph.update_state(config, {"query": user_input})
        initial_state = None
    else:
        initial_state = {
            "messages": [HumanMessage(content=user_input)],
            "tool_result": None,
            "iteration": 0,
            "max_iterations": 5,
            "query": "",
            "status": "",
            "rag_result": None,
            "api_result": None,
            "google_result": None,
            "target_paper": None,
            "related_papers": None,
            "user_interests": None,
            "recommendations": None,
            "final_result": None
        }
    
    print("ğŸš€ Agent ì‹œì‘ (Stream Mode)...\n")
    logs = "ğŸš€ **Agent ì‹œì‘** (LangGraph Running...)\n"
    yield logs
    
    for event in graph.stream(initial_state, config, stream_mode="updates"):
        for node_name, node_output in event.items():
            # interrupt ì²˜ë¦¬
            if node_name == "__interrupt__":
                print("[INTERRUPT] ê°ì§€!")
                snap = graph.get_state(config)
                if snap.next and "pa_ask_user" in snap.next:
                    query = snap.values.get("query", "")
                    answer = f"'{query}' ê´€ë ¨ ë…¼ë¬¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì •í™•í•œ ë…¼ë¬¸ ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
                    yield logs + f"\n\nâ¸ï¸ **ì…ë ¥ ëŒ€ê¸°:**\n\n{answer}"
                    return
                continue
            
            if not isinstance(node_output, dict):
                continue
            
            iteration = node_output.get("iteration", 0)
            print(f"[{node_name.upper()}] Iteration {iteration}")
            
            if node_name == "agent":
                messages = node_output.get("messages", [])
                if messages:
                    last_msg = messages[-1]
                    if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                        tool_calls = last_msg.tool_calls
                        print(f"  ğŸ”§ Tool Call ({len(tool_calls)}ê°œ):")
                        logs += f"ğŸ› ï¸ **Tool Call** ({len(tool_calls)}ê°œ):\n"
                        for tc in tool_calls:
                            print(f"    - {tc['name']}")
                            logs += f"  - `{tc['name']}`\n"
                        yield logs
                    elif hasattr(last_msg, 'content') and last_msg.content:
                        print(f"  ğŸ’¬ Response: {last_msg.content[:100]}...")
    
    final_state = graph.get_state(config)
    final_msg = final_state.values["messages"][-1]
    answer = final_msg.content if hasattr(final_msg, 'content') else "ë‹µë³€ ìƒì„± ì‹¤íŒ¨"

    extract_and_save_memory(user_input, answer)
    
    yield logs + f"\n\nâœ… **ìµœì¢… ë‹µë³€:**\n\n{answer}"