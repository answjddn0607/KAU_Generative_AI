{
  "ceb2ebef0b41e31c1a21b28c2734123900c005e2": {
    "paperId": "ceb2ebef0b41e31c1a21b28c2734123900c005e2",
    "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
    "year": 2018,
    "authors": "Tero Karras, S. Laine, Timo Aila",
    "abstract": "We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.",
    "citationCount": 11900,
    "pdf_filename": "2018_A_Style_Based_Generator_Architecture_for_ceb2ebef.pdf"
  },
  "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3": {
    "paperId": "df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3",
    "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
    "year": 2016,
    "authors": "C. Ledig, Lucas Theis, Ferenc Huszár, Jose Caballero, Andrew P. Aitken",
    "abstract": "Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image super-resolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4x upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.",
    "citationCount": 11527,
    "pdf_filename": "2016_Photo_Realistic_Single_Image_Super_Resol_df0c54fe.pdf"
  },
  "14fdc18d9c164e5b0d6d946b3238c04e81921358": {
    "paperId": "14fdc18d9c164e5b0d6d946b3238c04e81921358",
    "title": "Analyzing and Improving the Image Quality of StyleGAN",
    "year": 2019,
    "authors": "Tero Karras, S. Laine, M. Aittala, Janne Hellsten, J. Lehtinen",
    "abstract": "The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.",
    "citationCount": 6501,
    "pdf_filename": "2019_Analyzing_and_Improving_the_Image_Qualit_14fdc18d.pdf"
  },
  "2dcef55a07f8607a819c21fe84131ea269cc2e3c": {
    "paperId": "2dcef55a07f8607a819c21fe84131ea269cc2e3c",
    "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
    "year": 2015,
    "authors": "Jascha Narain Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, S. Ganguli",
    "abstract": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.",
    "citationCount": 8586,
    "pdf_filename": "2015_Deep_Unsupervised_Learning_using_Nonequi_2dcef55a.pdf"
  },
  "744fe47157477235032f7bb3777800f9f2f45e52": {
    "paperId": "744fe47157477235032f7bb3777800f9f2f45e52",
    "title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation",
    "year": 2017,
    "authors": "Tero Karras, Timo Aila, S. Laine, J. Lehtinen",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.",
    "citationCount": 8054,
    "pdf_filename": "2017_Progressive_Growing_of_GANs_for_Improved_744fe471.pdf"
  },
  "df0402517a7338ae28bc54acaac400de6b456a46": {
    "paperId": "df0402517a7338ae28bc54acaac400de6b456a46",
    "title": "WaveNet: A Generative Model for Raw Audio",
    "year": 2016,
    "authors": "Aäron van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals",
    "abstract": "This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.",
    "citationCount": 7870,
    "pdf_filename": "2016_WaveNet__A_Generative_Model_for_Raw_Audi_df040251.pdf"
  },
  "8388f1be26329fa45e5807e968a641ce170ea078": {
    "paperId": "8388f1be26329fa45e5807e968a641ce170ea078",
    "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
    "year": 2015,
    "authors": "Alec Radford, Luke Metz, Soumith Chintala",
    "abstract": "In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.",
    "citationCount": 14708,
    "pdf_filename": "2015_Unsupervised_Representation_Learning_wit_8388f1be.pdf"
  },
  "353ecf7b66b3e9ff5e9f41145a147e899a2eea5c": {
    "paperId": "353ecf7b66b3e9ff5e9f41145a147e899a2eea5c",
    "title": "Conditional Generative Adversarial Nets",
    "year": 2014,
    "authors": "Mehdi Mirza, Simon Osindero",
    "abstract": "Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.",
    "citationCount": 11148,
    "pdf_filename": "2014_Conditional_Generative_Adversarial_Nets_353ecf7b.pdf"
  },
  "3813b88a4ec3c63919df47e9694b577f4691f7e5": {
    "paperId": "3813b88a4ec3c63919df47e9694b577f4691f7e5",
    "title": "A survey on Image Data Augmentation for Deep Learning",
    "year": 2019,
    "authors": "Connor Shorten, T. Khoshgoftaar",
    "abstract": "Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.",
    "citationCount": 10265,
    "pdf_filename": "2019_A_survey_on_Image_Data_Augmentation_for__3813b88a.pdf"
  },
  "f466157848d1a7772fb6d02cdac9a7a5e7ef982e": {
    "paperId": "f466157848d1a7772fb6d02cdac9a7a5e7ef982e",
    "title": "Neural Discrete Representation Learning",
    "year": 2017,
    "authors": "Aäron van den Oord, O. Vinyals, K. Kavukcuoglu",
    "abstract": "Learning useful representations without supervision remains a key challenge in machine learning. In this paper, we propose a simple yet powerful generative model that learns such discrete representations. Our model, the Vector Quantised-Variational AutoEncoder (VQ-VAE), differs from VAEs in two key ways: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static. In order to learn a discrete latent representation, we incorporate ideas from vector quantisation (VQ). Using the VQ method allows the model to circumvent issues of \"posterior collapse\" -- where the latents are ignored when they are paired with a powerful autoregressive decoder -- typically observed in the VAE framework. Pairing these representations with an autoregressive prior, the model can generate high quality images, videos, and speech as well as doing high quality speaker conversion and unsupervised learning of phonemes, providing further evidence of the utility of the learnt representations.",
    "citationCount": 6185,
    "pdf_filename": "2017_Neural_Discrete_Representation_Learning_f4661578.pdf"
  },
  "345afa0e85cb2f5cb438ae44027499ff2c392409": {
    "paperId": "345afa0e85cb2f5cb438ae44027499ff2c392409",
    "title": "Adversarial Discriminative Domain Adaptation",
    "year": 2017,
    "authors": "Eric Tzeng, Judy Hoffman, Kate Saenko, Trevor Darrell",
    "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
    "citationCount": 5000,
    "pdf_filename": "2017_Adversarial_Discriminative_Domain_Adapta_345afa0e.pdf"
  },
  "edf73ab12595c6709f646f542a0d2b33eb20a3f4": {
    "paperId": "edf73ab12595c6709f646f542a0d2b33eb20a3f4",
    "title": "Improved Training of Wasserstein GANs",
    "year": 2017,
    "authors": "Ishaan Gulrajani, Faruk Ahmed, Martín Arjovsky, Vincent Dumoulin, Aaron C. Courville",
    "abstract": "Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.",
    "citationCount": 10281,
    "pdf_filename": "2017_Improved_Training_of_Wasserstein_GANs_edf73ab1.pdf"
  },
  "22aab110058ebbd198edb1f1e7b4f69fb13c0613": {
    "paperId": "22aab110058ebbd198edb1f1e7b4f69fb13c0613",
    "title": "Large Scale GAN Training for High Fidelity Natural Image Synthesis",
    "year": 2018,
    "authors": "Andrew Brock, Jeff Donahue, K. Simonyan",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128x128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Frechet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.6.",
    "citationCount": 5838,
    "pdf_filename": "2018_Large_Scale_GAN_Training_for_High_Fideli_22aab110.pdf"
  },
  "4feef0fd284feb1233399b400eb897f59ec92755": {
    "paperId": "4feef0fd284feb1233399b400eb897f59ec92755",
    "title": "mixup: Beyond Empirical Risk Minimization",
    "year": 2017,
    "authors": "Hongyi Zhang, Moustapha Cissé, Yann Dauphin, David Lopez-Paz",
    "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.",
    "citationCount": 10950,
    "pdf_filename": "2017_mixup__Beyond_Empirical_Risk_Minimizatio_4feef0fd.pdf"
  },
  "449310e3538b08b43227d660227dfd2875c3c3c1": {
    "paperId": "449310e3538b08b43227d660227dfd2875c3c3c1",
    "title": "Neural Ordinary Differential Equations",
    "year": 2018,
    "authors": "T. Chen, Yulia Rubanova, J. Bettencourt, D. Duvenaud",
    "abstract": "We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.",
    "citationCount": 6053,
    "pdf_filename": "2018_Neural_Ordinary_Differential_Equations_449310e3.pdf"
  },
  "29e944711a354c396fad71936f536e83025b6ce0": {
    "paperId": "29e944711a354c396fad71936f536e83025b6ce0",
    "title": "Categorical Reparameterization with Gumbel-Softmax",
    "year": 2016,
    "authors": "Eric Jang, S. Gu, Ben Poole",
    "abstract": "Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.",
    "citationCount": 5859,
    "pdf_filename": "2016_Categorical_Reparameterization_with_Gumb_29e94471.pdf"
  },
  "571b0750085ae3d939525e62af510ee2cee9d5ea": {
    "paperId": "571b0750085ae3d939525e62af510ee2cee9d5ea",
    "title": "Improved Techniques for Training GANs",
    "year": 2016,
    "authors": "Tim Salimans, I. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford",
    "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
    "citationCount": 9741,
    "pdf_filename": "2016_Improved_Techniques_for_Training_GANs_571b0750.pdf"
  },
  "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0": {
    "paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
    "title": "Show and tell: A neural image caption generator",
    "year": 2014,
    "authors": "O. Vinyals, Alexander Toshev, Samy Bengio, D. Erhan",
    "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.",
    "citationCount": 6327,
    "pdf_filename": "2014_Show_and_tell__A_neural_image_caption_ge_d4dc1012.pdf"
  },
  "0090023afc66cd2741568599057f4e82b566137c": {
    "paperId": "0090023afc66cd2741568599057f4e82b566137c",
    "title": "A Survey on Bias and Fairness in Machine Learning",
    "year": 2019,
    "authors": "Ninareh Mehrabi, Fred Morstatter, N. Saxena, Kristina Lerman, A. Galstyan",
    "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
    "citationCount": 5106,
    "pdf_filename": "2019_A_Survey_on_Bias_and_Fairness_in_Machine_0090023a.pdf"
  },
  "fb7aa89a499a0c3736a1b73594d073d48b287b51": {
    "paperId": "fb7aa89a499a0c3736a1b73594d073d48b287b51",
    "title": "The Fourth Industrial Revolution",
    "year": 2016,
    "authors": "Johann Walters, J. M. Vorster",
    "abstract": "The Fourth Industrial Revolution | Essay by Klaus Schwab Global Lighthouse Network: Unlocking Sustainability What Is The Fourth Industrial Revolution?Preparing the Philippines for the Fourth Industrial Thrive in the Fourth Industrial Revolution Unit What is the Fourth Industrial Revolution and its The Fourth Industrial Revolution: what it means and how to Instapundit » Blog Archive » DAVID GOLDMAN: How America The Impact of the Fourth Industrial Revolution on Public Meet the Three Industrial Revolutions Unit | Salesforce News Releases | About VerizonBardsFM, The Fourth Industrial Revolution 20211206What is the Fourth Industrial Revolution? | Industrial (PDF) THE FOURTH INDUSTRIAL REVOLUTION -ITS IMPACT ON ...The evolution of Artificial Intelligence (AI) – A new dawn IMPACT OF THE FOURTH INDUSTRIAL REVOLUTIONThe Fourth Industrial Revolution and digitization will The Fourth Industrial Revolution by Klaus Schwab What Is the Fourth Industrial Revolution? | SalesforceRegulation for the Fourth Industrial Revolution GOV.UKWhat is the Fourth Industrial Revolution Davos 2019What is Fourth Industrial Revolution? Definition from The Fourth Industrial Revolution: Challenges, Risks and Fourth Industrial Revolution WikipediaAmazon.com: The Fourth Industrial Revolution (PDF) The Fourth Industrial Revolution Klaus Schwab How America Can Lose the Fourth Industrial Revolution Preparing tomorrow’s workforce for the Fourth Industrial How 5G Is Making the Fourth Industrial Revolution a RealityFourth Industrial Revolution | World Economic ForumTechnology in 2025: Prepare for the fourth industrial The Fourth Industrial Revolution GOV.UKTHE FOURTH INDUSTRIAL REVOLUTION Essay TypingThe Fourth Industrial Revolution DeloitteThe ‘fourth industrial revolution’: potential and risks",
    "citationCount": 5242,
    "pdf_filename": "2016_The_Fourth_Industrial_Revolution_fb7aa89a.pdf"
  },
  "184ac0766262312ba76bbdece4e7ffad0aa8180b": {
    "paperId": "184ac0766262312ba76bbdece4e7ffad0aa8180b",
    "title": "Representation Learning: A Review and New Perspectives",
    "year": 2012,
    "authors": "Yoshua Bengio, Aaron C. Courville, Pascal Vincent",
    "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.",
    "citationCount": 13143,
    "pdf_filename": "2012_Representation_Learning__A_Review_and_Ne_184ac076.pdf"
  },
  "5120f65919f77859a974fcc1ad08f72b2918b8ec": {
    "paperId": "5120f65919f77859a974fcc1ad08f72b2918b8ec",
    "title": "A translation approach to portable ontology specifications",
    "year": 1993,
    "authors": "T. Gruber",
    "abstract": "Abstract To support the sharing and reuse of formally represented knowledge among AI systems, it is useful to define the common vocabulary in which shared knowledge is represented. A specification of a representational vocabulary for a shared domain of discourse—definitions of classes, relations, functions, and other objects—is called an ontology. This paper describes a mechanism for defining ontologies that are portable over representation systems. Definitions written in a standard format for predicate calculus are translated by a system called Ontolingua into specialized representations, including frame-based systems as well as relational languages. This allows researchers to share and reuse ontologies, while retaining the computational benefits of specialized implementations. We discuss how the translation approach to portability addresses several technical problems. One problem is how to accommodate the stylistic and organizational differences among representations while preserving declarative content. Another is how to translate from a very expressive language into restricted languages, remaining system-independent while preserving the computational efficiency of implemented systems. We describe how these problems are addressed by basing Ontolingua itself on an ontology of domain-independent, representational idioms.",
    "citationCount": 14029,
    "pdf_filename": "1993_A_translation_approach_to_portable_ontol_5120f659.pdf"
  },
  "6296aa7cab06eaf058f7291040b320b5a83c0091": {
    "paperId": "6296aa7cab06eaf058f7291040b320b5a83c0091",
    "title": "Generative Adversarial Networks",
    "year": 2021,
    "authors": "I. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley",
    "abstract": "Generative Adversarial Networks (GANs) are a type of deep learning techniques that have shown remarkable success in generating realistic images, videos, and other types of data. This paper provides a comprehensive guide to GANs, covering their architecture, loss functions, training methods, applications, evaluation metrics, challenges, and future directions. We begin with an introduction to GANs and their historical development, followed by a review of the background and related work. We then provide a detailed overview of the GAN architecture, including the generator and discriminator networks, and discuss the key design choices and variations. Next, we review the loss functions utilized in GANs, including the original minimax objective, as well as more recent approaches s.a. Wasserstein distance and gradient penalty. We then delve into the training of GANs, discussing common techniques s.a. alternating optimization, minibatch discrimination, and spectral normalization. We also provide a survey of the various applications of GANs across domains. In addition, we review the evaluation metrics utilized to assess the diversity and quality of GAN-produced data. Furthermore, we discuss the challenges and open issues in GANs, including mode collapse, training instability, and ethical considerations. Finally, we provide a glimpse into the future directions of GAN research, including improving scalability, developing new architectures, incorporating domain knowledge, and exploring new applications. Overall, this paper serves as a comprehensive guide to GANs, providing both theoretical and practical insights for researchers and practitioners in the field.",
    "citationCount": 30247,
    "pdf_filename": "2021_Generative_Adversarial_Networks_6296aa7c.pdf"
  },
  "633e2fbfc0b21e959a244100937c5853afca4853": {
    "paperId": "633e2fbfc0b21e959a244100937c5853afca4853",
    "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
    "year": 2020,
    "authors": "Yang Song, Jascha Narain Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\\aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.",
    "citationCount": 8494,
    "pdf_filename": "2020_Score_Based_Generative_Modeling_through__633e2fbf.pdf"
  },
  "2f4c451922e227cbbd4f090b74298445bbd900d0": {
    "paperId": "2f4c451922e227cbbd4f090b74298445bbd900d0",
    "title": "Elucidating the Design Space of Diffusion-Based Generative Models",
    "year": 2022,
    "authors": "Tero Karras, M. Aittala, Timo Aila, S. Laine",
    "abstract": "We argue that the theory and practice of diffusion-based generative models are currently unnecessarily convoluted and seek to remedy the situation by presenting a design space that clearly separates the concrete design choices. This lets us identify several changes to both the sampling and training processes, as well as preconditioning of the score networks. Together, our improvements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a class-conditional setting and 1.97 in an unconditional setting, with much faster sampling (35 network evaluations per image) than prior designs. To further demonstrate their modular nature, we show that our design changes dramatically improve both the efficiency and quality obtainable with pre-trained score networks from previous work, including improving the FID of a previously trained ImageNet-64 model from 2.07 to near-SOTA 1.55, and after re-training with our proposed improvements to a new SOTA of 1.36.",
    "citationCount": 2637,
    "pdf_filename": "2022_Elucidating_the_Design_Space_of_Diffusio_2f4c4519.pdf"
  },
  "5278a8eb2ba2429d4029745caf4e661080073c81": {
    "paperId": "5278a8eb2ba2429d4029745caf4e661080073c81",
    "title": "Generative Agents: Interactive Simulacra of Human Behavior",
    "year": 2023,
    "authors": "J. Park, Joseph C. O’Brien, Carrie J. Cai, M. Morris, Percy Liang",
    "abstract": "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.",
    "citationCount": 2811,
    "pdf_filename": "2023_Generative_Agents__Interactive_Simulacra_5278a8eb.pdf"
  },
  "29858b40a15704398aecdca6bd2820f2fcc99891": {
    "paperId": "29858b40a15704398aecdca6bd2820f2fcc99891",
    "title": "Training Generative Adversarial Networks with Limited Data",
    "year": 2020,
    "authors": "Tero Karras, M. Aittala, Janne Hellsten, S. Laine, J. Lehtinen",
    "abstract": "Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.42.",
    "citationCount": 2084,
    "pdf_filename": "2020_Training_Generative_Adversarial_Networks_29858b40.pdf"
  },
  "c1ff08b59f00c44f34dfdde55cd53370733a2c19": {
    "paperId": "c1ff08b59f00c44f34dfdde55cd53370733a2c19",
    "title": "Alias-Free Generative Adversarial Networks",
    "year": 2021,
    "authors": "Tero Karras, M. Aittala, S. Laine, Erik Härkönen, Janne Hellsten",
    "abstract": "We observe that despite their hierarchical convolutional nature, the synthesis process of typical generative adversarial networks depends on absolute pixel coordinates in an unhealthy manner. This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. We trace the root cause to careless signal processing that causes aliasing in the generator network. Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes that guarantee that unwanted information cannot leak into the hierarchical synthesis process. The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, and they are fully equivariant to translation and rotation even at subpixel scales. Our results pave the way for generative models better suited for video and animation.",
    "citationCount": 1829,
    "pdf_filename": "2021_Alias_Free_Generative_Adversarial_Networ_c1ff08b5.pdf"
  },
  "44279244407a64431810f982be6d0c7da4429dd7": {
    "paperId": "44279244407a64431810f982be6d0c7da4429dd7",
    "title": "BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining",
    "year": 2022,
    "authors": "Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang",
    "abstract": "Pre-trained language models have attracted increasing attention in the biomedical domain, inspired by their great success in the general natural language domain. Among the two main branches of pre-trained language models in the general language domain, i.e. BERT (and its variants) and GPT (and its variants), the first one has been extensively studied in the biomedical domain, such as BioBERT and PubMedBERT. While they have achieved great success on a variety of discriminative downstream biomedical tasks, the lack of generation ability constrains their application scope. In this paper, we propose BioGPT, a domain-specific generative Transformer language model pre-trained on large-scale biomedical literature. We evaluate BioGPT on six biomedical natural language processing tasks and demonstrate that our model outperforms previous models on most tasks. Especially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI end-to-end relation extraction tasks, respectively, and 78.2% accuracy on PubMedQA, creating a new record. Our case study on text generation further demonstrates the advantage of BioGPT on biomedical literature to generate fluent descriptions for biomedical terms.",
    "citationCount": 1089,
    "pdf_filename": "2022_BioGPT__Generative_Pre_trained_Transform_44279244.pdf"
  },
  "41a66997ce0a366bba3becf7c3f37c9aebb13fbd": {
    "paperId": "41a66997ce0a366bba3becf7c3f37c9aebb13fbd",
    "title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis",
    "year": 2024,
    "authors": "Patrick Esser, Sumith Kulal, A. Blattmann, Rahim Entezari, Jonas Muller",
    "abstract": "Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models, and we will make our experimental data, code, and model weights publicly available.",
    "citationCount": 2502,
    "pdf_filename": "2024_Scaling_Rectified_Flow_Transformers_for__41a66997.pdf"
  },
  "cd4d112f3f9120d0715f22a9de2ce4720822368c": {
    "paperId": "cd4d112f3f9120d0715f22a9de2ce4720822368c",
    "title": "How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment",
    "year": 2023,
    "authors": "Aidan Gilson, Conrad W. Safranek, Thomas Huang, V. Socrates, Ling Chi",
    "abstract": "Background Chat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input. Objective This study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as to analyze responses for user interpretability. Methods We used 2 sets of multiple-choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT’s performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question. Results Of the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT’s answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively. Conclusions ChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT’s capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning.",
    "citationCount": 1441,
    "pdf_filename": "2023_How_Does_ChatGPT_Perform_on_the_United_S_cd4d112f.pdf"
  },
  "7be169a70f5db74f40adfd2790021aa3fbf3cb87": {
    "paperId": "7be169a70f5db74f40adfd2790021aa3fbf3cb87",
    "title": "Artificial Hallucinations in ChatGPT: Implications in Scientific Writing",
    "year": 2023,
    "authors": "H. Alkaissi, Samy I McFarlane",
    "abstract": "While still in its infancy, ChatGPT (Generative Pretrained Transformer), introduced in November 2022, is bound to hugely impact many industries, including healthcare, medical education, biomedical research, and scientific writing. Implications of ChatGPT, that new chatbot introduced by OpenAI on academic writing, is largely unknown. In response to the Journal of Medical Science (Cureus) Turing Test - call for case reports written with the assistance of ChatGPT, we present two cases one of homocystinuria-associated osteoporosis, and the other is on late-onset Pompe disease (LOPD), a rare metabolic disorder. We tested ChatGPT to write about the pathogenesis of these conditions. We documented the positive, negative, and rather troubling aspects of our newly introduced chatbot’s performance.",
    "citationCount": 1187,
    "pdf_filename": "2023_Artificial_Hallucinations_in_ChatGPT__Im_7be169a7.pdf"
  },
  "0adec918885dff698acf359988ed79a543157f80": {
    "paperId": "0adec918885dff698acf359988ed79a543157f80",
    "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    "year": 2021,
    "authors": "Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp",
    "abstract": "When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, fine-tuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are “fantastic” and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true few-shot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13% relative improvement for GPT-family models across eleven different established text classification tasks.",
    "citationCount": 1343,
    "pdf_filename": "2021_Fantastically_Ordered_Prompts_and_Where__0adec918.pdf"
  },
  "49b66b980c91f989637b089c2e8284af443aaa25": {
    "paperId": "49b66b980c91f989637b089c2e8284af443aaa25",
    "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education",
    "year": 2023,
    "authors": "C. Chan, Wenjie Hu",
    "abstract": "This study explores university students’ perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs’ 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students’ perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning outcomes. Insights from this study can inform policy development around the integration of GenAI technologies into higher education. By understanding students’ perceptions and addressing their concerns, policymakers can create well-informed guidelines and strategies for the responsible and effective implementation of GenAI tools, ultimately enhancing teaching and learning experiences in higher education. This study focuses on the integration of generative AI (GenAI) technologies, like ChatGPT, into higher education settings. University students’ perceptions of generative AI technologies in higher education were explored, including familiarity, potential benefits, and challenges. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Insights from this study can inform policy development around the integration of GenAI technologies into higher education, helping to create well-informed guidelines and strategies for responsible and effective implementation. This study focuses on the integration of generative AI (GenAI) technologies, like ChatGPT, into higher education settings. University students’ perceptions of generative AI technologies in higher education were explored, including familiarity, potential benefits, and challenges. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Insights from this study can inform policy development around the integration of GenAI technologies into higher education, helping to create well-informed guidelines and strategies for responsible and effective implementation.",
    "citationCount": 1147,
    "pdf_filename": "2023_Students__voices_on_generative_AI__perce_49b66b98.pdf"
  },
  "7b6a8c6d44e0f77bf930484e438d77b7465a69fb": {
    "paperId": "7b6a8c6d44e0f77bf930484e438d77b7465a69fb",
    "title": "Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning",
    "year": 2023,
    "authors": "David Baidoo-Anu, Leticia Owusu Ansah",
    "abstract": "Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.",
    "citationCount": 1912,
    "pdf_filename": "2023_Education_in_the_Era_of_Generative_Artif_7b6a8c6d.pdf"
  },
  "d7890d1906d95c4ae4c430b350455156d6d8aed9": {
    "paperId": "d7890d1906d95c4ae4c430b350455156d6d8aed9",
    "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis",
    "year": 2023,
    "authors": "Dustin Podell, Zion English, Kyle Lacey, A. Blattmann, Tim Dockhorn",
    "abstract": "We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. In the spirit of promoting open research and fostering transparency in large model training and evaluation, we provide access to code and model weights at https://github.com/Stability-AI/generative-models",
    "citationCount": 3596,
    "pdf_filename": "2023_SDXL__Improving_Latent_Diffusion_Models__d7890d19.pdf"
  },
  "f22d71c7ce9720ba1f717a4f1181488200e78198": {
    "paperId": "f22d71c7ce9720ba1f717a4f1181488200e78198",
    "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day",
    "year": 2023,
    "authors": "Chunyuan Li, Cliff Wong, Sheng Zhang, N. Usuyama, Haotian Liu",
    "abstract": "Conversational generative AI has demonstrated remarkable promise for empowering biomedical practitioners, but current investigations focus on unimodal text. Multimodal conversational AI has seen rapid progress by leveraging billions of image-text pairs from the public web, but such general-domain vision-language models still lack sophistication in understanding and conversing about biomedical images. In this paper, we propose a cost-efficient approach for training a vision-language conversational assistant that can answer open-ended research questions of biomedical images. The key idea is to leverage a large-scale, broad-coverage biomedical figure-caption dataset extracted from PubMed Central, use GPT-4 to self-instruct open-ended instruction-following data from the captions, and then fine-tune a large general-domain vision-language model using a novel curriculum learning method. Specifically, the model first learns to align biomedical vocabulary using the figure-caption pairs as is, then learns to master open-ended conversational semantics using GPT-4 generated instruction-following data, broadly mimicking how a layperson gradually acquires biomedical knowledge. This enables us to train a Large Language and Vision Assistant for BioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med exhibits excellent multimodal conversational capability and can follow open-ended instruction to assist with inquiries about a biomedical image. On three standard biomedical visual question answering datasets, LLaVA-Med outperforms previous supervised state-of-the-art on certain metrics. To facilitate biomedical multimodal research, we will release our instruction-following data and the LLaVA-Med model.",
    "citationCount": 1219,
    "pdf_filename": "2023_LLaVA_Med__Training_a_Large_Language_and_f22d71c7.pdf"
  },
  "eddfb9be78cfe94193766e3722eb0e56c3d24cef": {
    "paperId": "eddfb9be78cfe94193766e3722eb0e56c3d24cef",
    "title": "ChatGPT is fun, but not an author",
    "year": 2023,
    "authors": "H. Thorp",
    "abstract": "In less than 2 months, the artificial intelligence (AI) program ChatGPT has become a cultural sensation. It is freely accessible through a web portal created by the tool’s developer, OpenAI. The program—which automatically creates text based on written prompts—is so popular that it’s likely to be “at capacity right now” if you attempt to use it. When you do get through, ChatGPT provides endless entertainment. I asked it to rewrite the first scene of the classic American play Death of a Salesman, but to feature Princess Elsa from the animated movie Frozen as the main character instead of Willy Loman. The output was an amusing conversation in which Elsa—who has come home from a tough day of selling—is told by her son Happy, “Come on, Mom. You’re Elsa from Frozen. You have ice powers and you’re a queen. You’re unstoppable.” Mash-ups like this are certainly fun, but there are serious implications for generative AI programs like ChatGPT in science and academia.",
    "citationCount": 1077,
    "pdf_filename": "2023_ChatGPT_is_fun__but_not_an_author_eddfb9be.pdf"
  },
  "1b31dbf44e68b698120552366df03e6e35a1e428": {
    "paperId": "1b31dbf44e68b698120552366df03e6e35a1e428",
    "title": "Objaverse: A Universe of Annotated 3D Objects",
    "year": 2022,
    "authors": "Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel",
    "abstract": "Massive data corpora like WebText, Wikipedia, Conceptual Captions, WebImageText, and LAION have propelled recent dramatic progress in AI. Large neural models trained on such datasets produce impressive results and top many of today's benchmarks. A notable omisslion within this family of large-scale datasets is 3D data. Despite considerable interest and potential applications in 3D vision, datasets of high-fidelity 3D models continue to be mid-sized with limited diversity of object categories. Addressing this gap, we present Objaverse 1.0, a large dataset of objects with 800K + (and growing) 3D models with descriptive captions, tags, and animations. Objaverse improves upon present day 3D repositories in terms of scale, number of categories, and in the visual diversity of instances within a category. We demonstrate the large potential of Objaverse via four diverse applications: training generative 3D models, improving tail category segmentation on the LVIS benchmark, training open-vocabulary object-navigation models for Embodied AI, and creating a new benchmark for robustness analysis of vision models. Objaverse can open new directions for research and enable new applications across the field of AI.",
    "citationCount": 1303,
    "pdf_filename": "2022_Objaverse__A_Universe_of_Annotated_3D_Ob_1b31dbf4.pdf"
  },
  "db6ad6ded1cfa26fdc7437f27fb823ec533e96fe": {
    "paperId": "db6ad6ded1cfa26fdc7437f27fb823ec533e96fe",
    "title": "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions",
    "year": 2021,
    "authors": "Iqbal H. Sarker",
    "abstract": "Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of today’s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics, cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals.",
    "citationCount": 1978,
    "pdf_filename": "2021_Deep_Learning__A_Comprehensive_Overview__db6ad6de.pdf"
  },
  "af68f10ab5078bfc519caae377c90ee6d9c504e9": {
    "paperId": "af68f10ab5078bfc519caae377c90ee6d9c504e9",
    "title": "Flow Matching for Generative Modeling",
    "year": 2022,
    "authors": "Y. Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, Matt Le",
    "abstract": "We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.",
    "citationCount": 2592,
    "pdf_filename": "2022_Flow_Matching_for_Generative_Modeling_af68f10a.pdf"
  },
  "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6": {
    "paperId": "7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6",
    "title": "GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers",
    "year": 2022,
    "authors": "Elias Frantar, Saleh Ashkboos, T. Hoefler, Dan Alistarh",
    "abstract": "Generative Pre-trained Transformer models, known as GPT or OPT, set themselves apart through breakthrough performance across complex language modelling tasks, but also by their extremely high computational and storage costs. Specifically, due to their massive size, even inference for large, highly-accurate GPT models may require multiple performant GPUs, which limits the usability of such models. While there is emerging work on relieving this pressure via model compression, the applicability and performance of existing compression techniques is limited by the scale and complexity of GPT models. In this paper, we address this challenge, and propose GPTQ, a new one-shot weight quantization method based on approximate second-order information, that is both highly-accurate and highly-efficient. Specifically, GPTQ can quantize GPT models with 175 billion parameters in approximately four GPU hours, reducing the bitwidth down to 3 or 4 bits per weight, with negligible accuracy degradation relative to the uncompressed baseline. Our method more than doubles the compression gains relative to previously-proposed one-shot quantization methods, preserving accuracy, allowing us for the first time to execute an 175 billion-parameter model inside a single GPU for generative inference. Moreover, we also show that our method can still provide reasonable accuracy in the extreme quantization regime, in which weights are quantized to 2-bit or even ternary quantization levels. We show experimentally that these improvements can be leveraged for end-to-end inference speedups over FP16, of around 3.25x when using high-end GPUs (NVIDIA A100) and 4.5x when using more cost-effective ones (NVIDIA A6000). The implementation is available at https://github.com/IST-DASLab/gptq.",
    "citationCount": 1440,
    "pdf_filename": "2022_GPTQ__Accurate_Post_Training_Quantizatio_7da0f250.pdf"
  },
  "4e468d3da1797d791db8d514d695b183acb027ee": {
    "paperId": "4e468d3da1797d791db8d514d695b183acb027ee",
    "title": "HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis",
    "year": 2020,
    "authors": "Jungil Kong, Jaehyeon Kim, Jaekyoung Bae",
    "abstract": "Several recent work on speech synthesis have employed generative adversarial networks (GANs) to produce raw waveforms. Although such methods improve the sampling efficiency and memory usage, their sample quality has not yet reached that of autoregressive and flow-based generative models. In this work, we propose HiFi-GAN, which achieves both efficient and high-fidelity speech synthesis. As speech audio consists of sinusoidal signals with various periods, we demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality. A subjective human evaluation (mean opinion score, MOS) of a single speaker dataset indicates that our proposed method demonstrates similarity to human quality while generating 22.05 kHz high-fidelity audio 167.9 times faster than real-time on a single V100 GPU. We further show the generality of HiFi-GAN to the mel-spectrogram inversion of unseen speakers and end-to-end speech synthesis. Finally, a small footprint version of HiFi-GAN generates samples 13.4 times faster than real-time on CPU with comparable quality to an autoregressive counterpart.",
    "citationCount": 2369,
    "pdf_filename": "2020_HiFi_GAN__Generative_Adversarial_Network_4e468d3d.pdf"
  },
  "6b0570e66cdf79704461e1f8a07dc761ac10d6b6": {
    "paperId": "6b0570e66cdf79704461e1f8a07dc761ac10d6b6",
    "title": "TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods",
    "year": 2024,
    "authors": "Gary S. Collins, K. Moons, P. Dhiman, R. Riley, A. L. Beam",
    "abstract": "The TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis) statement was published in 2015 to provide the minimum reporting recommendations for studies developing or evaluating the performance of a prediction model. Methodological advances in the field of prediction have since included the widespread use of artificial intelligence (AI) powered by machine learning methods to develop prediction models. An update to the TRIPOD statement is thus needed. TRIPOD+AI provides harmonised guidance for reporting prediction model studies, irrespective of whether regression modelling or machine learning methods have been used. The new checklist supersedes the TRIPOD 2015 checklist, which should no longer be used. This article describes the development of TRIPOD+AI and presents the expanded 27 item checklist with more detailed explanation of each reporting recommendation, and the TRIPOD+AI for Abstracts checklist. TRIPOD+AI aims to promote the complete, accurate, and transparent reporting of studies that develop a prediction model or evaluate its performance. Complete reporting will facilitate study appraisal, model evaluation, and model implementation.",
    "citationCount": 1033,
    "pdf_filename": "2024_TRIPOD_AI_statement__updated_guidance_fo_6b0570e6.pdf"
  },
  "d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43": {
    "paperId": "d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43",
    "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face",
    "year": 2023,
    "authors": "Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu",
    "abstract": "Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence. While there are numerous AI models available for various domains and modalities, they cannot handle complicated AI tasks autonomously. Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this. Based on this philosophy, we present HuggingGPT, an LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards the realization of artificial general intelligence.",
    "citationCount": 1172,
    "pdf_filename": "2023_HuggingGPT__Solving_AI_Tasks_with_ChatGP_d1120d67.pdf"
  },
  "7c0a7419114db2209c2f386bc1537e90417cf9d4": {
    "paperId": "7c0a7419114db2209c2f386bc1537e90417cf9d4",
    "title": "Efficient Geometry-aware 3D Generative Adversarial Networks",
    "year": 2021,
    "authors": "Eric Chan, Connor Z. Lin, Matthew A. Chan, Koki Nagano, Boxiao Pan",
    "abstract": "Unsupervised generation of high-quality multi-view-consistent images and 3D shapes using only collections of single-view 2D photographs has been a long-standing challenge. Existing 3D GANs are either compute intensive or make approximations that are not 3D-consistent; the former limits quality and resolution of the generated images and the latter adversely affects multi-view consistency and shape quality. In this work, we improve the computational efficiency and image quality of 3D GANs without overly relying on these approximations. We introduce an expressive hybrid explicit implicit network architecture that, together with other design choices, synthesizes not only high-resolution multi-view-consistent images in real time but also produces high-quality 3D geometry. By decoupling feature generation and neural rendering, our framework is able to leverage state-of-the-art 2D CNN generators, such as StyleGAN2, and inherit their efficiency and expressiveness. We demonstrate state-of-the-art 3D-aware synthesis with FFHQ and AFHQ Cats, among other experiments.",
    "citationCount": 1363,
    "pdf_filename": "2021_Efficient_Geometry_aware_3D_Generative_A_7c0a7419.pdf"
  },
  "706f756b71f0bf51fc78d98f52c358b1a3aeef8e": {
    "paperId": "706f756b71f0bf51fc78d98f52c358b1a3aeef8e",
    "title": "Self-Supervised Learning: Generative or Contrastive",
    "year": 2020,
    "authors": "Xiao Liu, Fanjin Zhang, Zhenyu Hou, Zhaoyu Wang, Li Mian",
    "abstract": "Deep supervised learning has achieved great success in the last decade. However, its defects of heavy dependence on manual labels and vulnerability to attacks have driven people to find other paradigms. As an alternative, self-supervised learning (SSL) attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further collect related theoretical analysis on self-supervised learning to provide deeper thoughts on why self-supervised learning works. Finally, we briefly discuss open problems and future directions for self-supervised learning. An outline slide for the survey is provided<inline-formula><tex-math notation=\"LaTeX\">$^1$</tex-math><alternatives><mml:math><mml:msup><mml:mrow/><mml:mn>1</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"liu-ieq1-3090866.gif\"/></alternatives></inline-formula>.",
    "citationCount": 1938,
    "pdf_filename": "2020_Self_Supervised_Learning__Generative_or__706f756b.pdf"
  },
  "3936fd3c6187f606c6e4e2e20b196dbc41cc4654": {
    "paperId": "3936fd3c6187f606c6e4e2e20b196dbc41cc4654",
    "title": "Constitutional AI: Harmlessness from AI Feedback",
    "year": 2022,
    "authors": "Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, John Kernion",
    "abstract": "As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.",
    "citationCount": 2185,
    "pdf_filename": "2022_Constitutional_AI__Harmlessness_from_AI__3936fd3c.pdf"
  },
  "ea8c46e193d5121e440daf96edfd15a47151c293": {
    "paperId": "ea8c46e193d5121e440daf96edfd15a47151c293",
    "title": "Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering",
    "year": 2020,
    "authors": "Gautier Izacard, Edouard Grave",
    "abstract": "Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that sequence-to-sequence models offers a flexible framework to efficiently aggregate and combine evidence from multiple passages.",
    "citationCount": 1406,
    "pdf_filename": "2020_Leveraging_Passage_Retrieval_with_Genera_ea8c46e1.pdf"
  },
  "1156e277fa7ec195b043161d3c5c97715da17658": {
    "paperId": "1156e277fa7ec195b043161d3c5c97715da17658",
    "title": "Improved Techniques for Training Score-Based Generative Models",
    "year": 2020,
    "authors": "Yang Song, Stefano Ermon",
    "abstract": "Score-based generative models can produce high quality image samples comparable to GANs, without requiring adversarial optimization. However, existing training procedures are limited to images of low resolution (typically below 32x32), and can be unstable under some settings. We provide a new theoretical analysis of learning and sampling from score models in high dimensional spaces, explaining existing failure modes and motivating new solutions that generalize across datasets. To enhance stability, we also propose to maintain an exponential moving average of model weights. With these improvements, we can effortlessly scale score-based generative models to images with unprecedented resolutions ranging from 64x64 to 256x256. Our score-based models can generate high-fidelity samples that rival best-in-class GANs on various image datasets, including CelebA, FFHQ, and multiple LSUN categories.",
    "citationCount": 1337,
    "pdf_filename": "2020_Improved_Techniques_for_Training_Score_B_1156e277.pdf"
  },
  "cf1f26e7cbed3958b3c2870656568c299fece6e3": {
    "paperId": "cf1f26e7cbed3958b3c2870656568c299fece6e3",
    "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
    "year": 2022,
    "authors": "Tiffany H. Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon",
    "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, even clinical decision-making.",
    "citationCount": 2906,
    "pdf_filename": "2022_Performance_of_ChatGPT_on_USMLE__Potenti_cf1f26e7.pdf"
  },
  "bb8656979f38d95062ba55640c1be65535f57c6a": {
    "paperId": "bb8656979f38d95062ba55640c1be65535f57c6a",
    "title": "GIRAFFE: Representing Scenes as Compositional Generative Neural Feature Fields",
    "year": 2020,
    "authors": "Michael Niemeyer, Andreas Geiger",
    "abstract": "Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications, this is not enough: content creation also needs to be controllable. While several recent works investigate how to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to disentangle one or multiple objects from the background as well as individual objects’ shapes and appearances while learning from unstructured and unposed image collections without any additional supervision. Combining this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and rotating them in the scene as well as changing the camera pose.",
    "citationCount": 1029,
    "pdf_filename": "2020_GIRAFFE__Representing_Scenes_as_Composit_bb865697.pdf"
  },
  "c65897d366831d95e5aaa3332b79c308554e5c49": {
    "paperId": "c65897d366831d95e5aaa3332b79c308554e5c49",
    "title": "DDcGAN: A Dual-Discriminator Conditional Generative Adversarial Network for Multi-Resolution Image Fusion",
    "year": 2020,
    "authors": "Jiayi Ma, Han Xu, Junjun Jiang, Xiaoguang Mei, Xiao-Ping Zhang",
    "abstract": "In this paper, we proposed a new end-to-end model, termed as dual-discriminator conditional generative adversarial network (DDcGAN), for fusing infrared and visible images of different resolutions. Our method establishes an adversarial game between a generator and two discriminators. The generator aims to generate a real-like fused image based on a specifically designed content loss to fool the two discriminators, while the two discriminators aim to distinguish the structure differences between the fused image and two source images, respectively, in addition to the content loss. Consequently, the fused image is forced to simultaneously keep the thermal radiation in the infrared image and the texture details in the visible image. Moreover, to fuse source images of different resolutions, e.g., a low-resolution infrared image and a high-resolution visible image, our DDcGAN constrains the downsampled fused image to have similar property with the infrared image. This can avoid causing thermal radiation information blurring or visible texture detail loss, which typically happens in traditional methods. In addition, we also apply our DDcGAN to fusing multi-modality medical images of different resolutions, e.g., a low-resolution positron emission tomography image and a high-resolution magnetic resonance image. The qualitative and quantitative experiments on publicly available datasets demonstrate the superiority of our DDcGAN over the state-of-the-art, in terms of both visual effect and quantitative metrics. Our code is publicly available at https://github.com/jiayi-ma/DDcGAN.",
    "citationCount": 1024,
    "pdf_filename": "2020_DDcGAN__A_Dual_Discriminator_Conditional_c65897d3.pdf"
  },
  "f156ecbbb9243522275490d698c6825f4d2e01af": {
    "paperId": "f156ecbbb9243522275490d698c6825f4d2e01af",
    "title": "Explainable AI: A Review of Machine Learning Interpretability Methods",
    "year": 2020,
    "authors": "Pantelis Linardatos, Vasilis Papastefanopoulos, S. Kotsiantis",
    "abstract": "Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.",
    "citationCount": 2277,
    "pdf_filename": "2020_Explainable_AI__A_Review_of_Machine_Lear_f156ecbb.pdf"
  },
  "89ab36ae8630f6e4058c926816fe8d9a676c54e3": {
    "paperId": "89ab36ae8630f6e4058c926816fe8d9a676c54e3",
    "title": "What is AI Literacy? Competencies and Design Considerations",
    "year": 2020,
    "authors": "D. Long, Brian Magerko",
    "abstract": "Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology, but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.",
    "citationCount": 1515,
    "pdf_filename": "2020_What_is_AI_Literacy__Competencies_and_De_89ab36ae.pdf"
  },
  "2a0f2a76df5af569a9d85d97d2a81ae10f02fccf": {
    "paperId": "2a0f2a76df5af569a9d85d97d2a81ae10f02fccf",
    "title": "Can AI Help in Screening Viral and COVID-19 Pneumonia?",
    "year": 2020,
    "authors": "M. Chowdhury, Tawsifur Rahman, A. Khandakar, R. Mazhar, M. A. Kadir",
    "abstract": "Coronavirus disease (COVID-19) is a pandemic disease, which has already caused thousands of causalities and infected several millions of people worldwide. Any technological tool enabling rapid screening of the COVID-19 infection with high accuracy can be crucially helpful to the healthcare professionals. The main clinical tool currently in use for the diagnosis of COVID-19 is the Reverse transcription polymerase chain reaction (RT-PCR), which is expensive, less-sensitive and requires specialized medical personnel. X-ray imaging is an easily accessible tool that can be an excellent alternative in the COVID-19 diagnosis. This research was taken to investigate the utility of artificial intelligence (AI) in the rapid and accurate detection of COVID-19 from chest X-ray images. The aim of this paper is to propose a robust technique for automatic detection of COVID-19 pneumonia from digital chest X-ray images applying pre-trained deep-learning algorithms while maximizing the detection accuracy. A public database was created by the authors combining several public databases and also by collecting images from recently published articles. The database contains a mixture of 423 COVID-19, 1485 viral pneumonia, and 1579 normal chest X-ray images. Transfer learning technique was used with the help of image augmentation to train and validate several pre-trained deep Convolutional Neural Networks (CNNs). The networks were trained to classify two different schemes: i) normal and COVID-19 pneumonia; ii) normal, viral and COVID-19 pneumonia with and without image augmentation. The classification accuracy, precision, sensitivity, and specificity for both the schemes were 99.7%, 99.7%, 99.7% and 99.55% and 97.9%, 97.95%, 97.9%, and 98.8%, respectively. The high accuracy of this computer-aided diagnostic tool can significantly improve the speed and accuracy of COVID-19 diagnosis. This would be extremely useful in this pandemic where disease burden and need for preventive measures are at odds with available resources.",
    "citationCount": 1472,
    "pdf_filename": "2020_Can_AI_Help_in_Screening_Viral_and_COVID_2a0f2a76.pdf"
  },
  "9670485f526f2254c0f34e64d9ca06f665a0bd17": {
    "paperId": "9670485f526f2254c0f34e64d9ca06f665a0bd17",
    "title": "Modified SEIR and AI prediction of the epidemics trend of COVID-19 in China under public health interventions",
    "year": 2020,
    "authors": "Zi-feng Yang, Zhiqi Zeng, Ke Wang, Sook-san Wong, W. Liang",
    "abstract": "Background The coronavirus disease 2019 (COVID-19) outbreak originating in Wuhan, Hubei province, China, coincided with chunyun, the period of mass migration for the annual Spring Festival. To contain its spread, China adopted unprecedented nationwide interventions on January 23 2020. These policies included large-scale quarantine, strict controls on travel and extensive monitoring of suspected cases. However, it is unknown whether these policies have had an impact on the epidemic. We sought to show how these control measures impacted the containment of the epidemic. Methods We integrated population migration data before and after January 23 and most updated COVID-19 epidemiological data into the Susceptible-Exposed-Infectious-Removed (SEIR) model to derive the epidemic curve. We also used an artificial intelligence (AI) approach, trained on the 2003 SARS data, to predict the epidemic. Results We found that the epidemic of China should peak by late February, showing gradual decline by end of April. A five-day delay in implementation would have increased epidemic size in mainland China three-fold. Lifting the Hubei quarantine would lead to a second epidemic peak in Hubei province in mid-March and extend the epidemic to late April, a result corroborated by the machine learning prediction. Conclusions Our dynamic SEIR model was effective in predicting the COVID-19 epidemic peaks and sizes. The implementation of control measures on January 23 2020 was indispensable in reducing the eventual COVID-19 epidemic size.",
    "citationCount": 1259,
    "pdf_filename": "2020_Modified_SEIR_and_AI_prediction_of_the_e_9670485f.pdf"
  },
  "406289a706af2e00006a5823f245ef7bcd811681": {
    "paperId": "406289a706af2e00006a5823f245ef7bcd811681",
    "title": "Precision Medicine, AI, and the Future of Personalized Health Care",
    "year": 2020,
    "authors": "Kevin B. Johnson, Wei-Qi Wei, D. Weeraratne, M. Frisse, K. Misulis",
    "abstract": "The convergence of artificial intelligence (AI) and precision medicine promises to revolutionize health care. Precision medicine methods identify phenotypes of patients with less‐common responses to treatment or unique healthcare needs. AI leverages sophisticated computation and inference to generate insights, enables the system to reason and learn, and empowers clinician decision making through augmented intelligence. Recent literature suggests that translational research exploring this convergence will help solve the most difficult challenges facing precision medicine, especially those in which nongenomic and genomic determinants, combined with information from patient symptoms, clinical history, and lifestyles, will facilitate personalized diagnosis and prognostication.",
    "citationCount": 1074,
    "pdf_filename": "2020_Precision_Medicine__AI__and_the_Future_o_406289a7.pdf"
  },
  "7943ec4a67151a559b25cd34369e661c9a7924c8": {
    "paperId": "7943ec4a67151a559b25cd34369e661c9a7924c8",
    "title": "GPT-4o System Card",
    "year": 2024,
    "authors": "OpenAI Aaron Hurst, Adam Lerer, Adam P. Goucher, Adam Perelman, Aditya Ramesh",
    "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities.",
    "citationCount": 2523,
    "pdf_filename": "2024_GPT_4o_System_Card_7943ec4a.pdf"
  },
  "f61cc9b5583c6295d5cd756ec0f34e4c003aab29": {
    "paperId": "f61cc9b5583c6295d5cd756ec0f34e4c003aab29",
    "title": "Qwen2.5-VL Technical Report",
    "year": 2025,
    "authors": "Shuai Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge",
    "abstract": "We introduce Qwen2.5-VL, the latest flagship model of Qwen vision-language series, which demonstrates significant advancements in both foundational capabilities and innovative functionalities. Qwen2.5-VL achieves a major leap forward in understanding and interacting with the world through enhanced visual recognition, precise object localization, robust document parsing, and long-video comprehension. A standout feature of Qwen2.5-VL is its ability to localize objects using bounding boxes or points accurately. It provides robust structured data extraction from invoices, forms, and tables, as well as detailed analysis of charts, diagrams, and layouts. To handle complex inputs, Qwen2.5-VL introduces dynamic resolution processing and absolute time encoding, enabling it to process images of varying sizes and videos of extended durations (up to hours) with second-level event localization. This allows the model to natively perceive spatial scales and temporal dynamics without relying on traditional normalization techniques. By training a native dynamic-resolution Vision Transformer (ViT) from scratch and incorporating Window Attention, we reduce computational overhead while maintaining native resolution. As a result, Qwen2.5-VL excels not only in static image and document understanding but also as an interactive visual agent capable of reasoning, tool usage, and task execution in real-world scenarios such as operating computers and mobile devices. Qwen2.5-VL is available in three sizes, addressing diverse use cases from edge AI to high-performance computing. The flagship Qwen2.5-VL-72B model matches state-of-the-art models like GPT-4o and Claude 3.5 Sonnet, particularly excelling in document and diagram understanding. Additionally, Qwen2.5-VL maintains robust linguistic performance, preserving the core language competencies of the Qwen2.5 LLM.",
    "citationCount": 2459,
    "pdf_filename": "2025_Qwen2_5_VL_Technical_Report_f61cc9b5.pdf"
  },
  "34471a2fa18ea22efad5287cf4aeb18542c98a9b": {
    "paperId": "34471a2fa18ea22efad5287cf4aeb18542c98a9b",
    "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning",
    "year": 2025,
    "authors": "DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Jun-Mei Song",
    "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
    "citationCount": 5069,
    "pdf_filename": "2025_DeepSeek_R1__Incentivizing_Reasoning_Cap_34471a2f.pdf"
  },
  "5f49ec9560ca9e03eff32a607f6caabc08f98926": {
    "paperId": "5f49ec9560ca9e03eff32a607f6caabc08f98926",
    "title": "Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling",
    "year": 2024,
    "authors": "Zhe Chen, Weiyun Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao",
    "abstract": "We introduce InternVL 2.5, an advanced multimodal large language model (MLLM) series that builds upon InternVL 2.0, maintaining its core model architecture while introducing significant enhancements in training and testing strategies as well as data quality. In this work, we delve into the relationship between model scaling and performance, systematically exploring the performance trends in vision encoders, language models, dataset sizes, and test-time configurations. Through extensive evaluations on a wide range of benchmarks, including multi-discipline reasoning, document understanding, multi-image / video understanding, real-world comprehension, multimodal hallucination detection, visual grounding, multilingual capabilities, and pure language processing, InternVL 2.5 exhibits competitive performance, rivaling leading commercial models such as GPT-4o and Claude-3.5-Sonnet. Notably, our model is the first open-source MLLMs to surpass 70% on the MMMU benchmark, achieving a 3.7-point improvement through Chain-of-Thought (CoT) reasoning and showcasing strong potential for test-time scaling. We hope this model contributes to the open-source community by setting new standards for developing and applying multimodal AI systems. HuggingFace demo see https://huggingface.co/spaces/OpenGVLab/InternVL",
    "citationCount": 1035,
    "pdf_filename": "2024_Expanding_Performance_Boundaries_of_Open_5f49ec95.pdf"
  },
  "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb": {
    "paperId": "3f5b31c4f7350dc88002c121aecbdc82f86eb5bb",
    "title": "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
    "year": 2023,
    "authors": "Junnan Li, Dongxu Li, S. Savarese, Steven C. H. Hoi",
    "abstract": "The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.",
    "citationCount": 6351,
    "pdf_filename": "2023_BLIP_2__Bootstrapping_Language_Image_Pre_3f5b31c4.pdf"
  },
  "1206b05eae5a06ba662ae79fb291b50e359c4f42": {
    "paperId": "1206b05eae5a06ba662ae79fb291b50e359c4f42",
    "title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets",
    "year": 2023,
    "authors": "A. Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian",
    "abstract": "We present Stable Video Diffusion - a latent video diffusion model for high-resolution, state-of-the-art text-to-video and image-to-video generation. Recently, latent diffusion models trained for 2D image synthesis have been turned into generative video models by inserting temporal layers and finetuning them on small, high-quality video datasets. However, training methods in the literature vary widely, and the field has yet to agree on a unified strategy for curating video data. In this paper, we identify and evaluate three different stages for successful training of video LDMs: text-to-image pretraining, video pretraining, and high-quality video finetuning. Furthermore, we demonstrate the necessity of a well-curated pretraining dataset for generating high-quality videos and present a systematic curation process to train a strong base model, including captioning and filtering strategies. We then explore the impact of finetuning our base model on high-quality data and train a text-to-video model that is competitive with closed-source video generation. We also show that our base model provides a powerful motion representation for downstream tasks such as image-to-video generation and adaptability to camera motion-specific LoRA modules. Finally, we demonstrate that our model provides a strong multi-view 3D-prior and can serve as a base to finetune a multi-view diffusion model that jointly generates multiple views of objects in a feedforward fashion, outperforming image-based methods at a fraction of their compute budget. We release code and model weights at https://github.com/Stability-AI/generative-models .",
    "citationCount": 1814,
    "pdf_filename": "2023_Stable_Video_Diffusion__Scaling_Latent_V_1206b05e.pdf"
  },
  "2854e5bab8e6f36e54c64456628a9559bf67019e": {
    "paperId": "2854e5bab8e6f36e54c64456628a9559bf67019e",
    "title": "IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models",
    "year": 2023,
    "authors": "Hu Ye, Jun Zhang, Siyi Liu, Xiao Han, Wei Yang",
    "abstract": "Recent years have witnessed the strong power of large text-to-image diffusion models for the impressive generative capability to create high-fidelity images. However, it is very tricky to generate desired images using only text prompt as it often involves complex prompt engineering. An alternative to text prompt is image prompt, as the saying goes:\"an image is worth a thousand words\". Although existing methods of direct fine-tuning from pretrained models are effective, they require large computing resources and are not compatible with other base models, text prompt, and structural controls. In this paper, we present IP-Adapter, an effective and lightweight adapter to achieve image prompt capability for the pretrained text-to-image diffusion models. The key design of our IP-Adapter is decoupled cross-attention mechanism that separates cross-attention layers for text features and image features. Despite the simplicity of our method, an IP-Adapter with only 22M parameters can achieve comparable or even better performance to a fully fine-tuned image prompt model. As we freeze the pretrained diffusion model, the proposed IP-Adapter can be generalized not only to other custom models fine-tuned from the same base model, but also to controllable generation using existing controllable tools. With the benefit of the decoupled cross-attention strategy, the image prompt can also work well with the text prompt to achieve multimodal image generation. The project page is available at \\url{https://ip-adapter.github.io}.",
    "citationCount": 1182,
    "pdf_filename": "2023_IP_Adapter__Text_Compatible_Image_Prompt_2854e5ba.pdf"
  },
  "ac974291d7e3a152067382675524f3e3c2ded11b": {
    "paperId": "ac974291d7e3a152067382675524f3e3c2ded11b",
    "title": "Consistency Models",
    "year": 2023,
    "authors": "Yang Song, Prafulla Dhariwal, Mark Chen, I. Sutskever",
    "abstract": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generation. When trained in isolation, consistency models become a new family of generative models that can outperform existing one-step, non-adversarial generative models on standard benchmarks such as CIFAR-10, ImageNet 64x64 and LSUN 256x256.",
    "citationCount": 1367,
    "pdf_filename": "2023_Consistency_Models_ac974291.pdf"
  },
  "58842cdca3ea68f7b9e638b288fc247a6f26dafc": {
    "paperId": "58842cdca3ea68f7b9e638b288fc247a6f26dafc",
    "title": "T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models",
    "year": 2023,
    "authors": "Chong Mou, Xintao Wang, Liangbin Xie, Jing Zhang, Zhongang Qi",
    "abstract": "The incredible generative ability of large-scale text-to-image (T2I) models has demonstrated strong power of learning complex structures and meaningful semantics. However, relying solely on text prompts cannot fully take advantage of the knowledge learned by the model, especially when flexible and accurate controlling (e.g., structure and color) is needed. In this paper, we aim to ``dig out\" the capabilities that T2I models have implicitly learned, and then explicitly use them to control the generation more granularly. Specifically, we propose to learn low-cost T2I-Adapters to align internal knowledge in T2I models with external control signals, while freezing the original large T2I models. In this way, we can train various adapters according to different conditions, achieving rich control and editing effects in the color and structure of the generation results. Further, the proposed T2I-Adapters have attractive properties of practical value, such as composability and generalization ability. Extensive experiments demonstrate that our T2I-Adapter has promising generation quality and a wide range of applications. Our code is available at https://github.com/TencentARC/T2I-Adapter.",
    "citationCount": 1348,
    "pdf_filename": "2023_T2I_Adapter__Learning_Adapters_to_Dig_ou_58842cdc.pdf"
  },
  "91eb20f923ea3b0246868902aef4e9bea572b800": {
    "paperId": "91eb20f923ea3b0246868902aef4e9bea572b800",
    "title": "Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware",
    "year": 2023,
    "authors": "Tony Zhao, Vikash Kumar, S. Levine, Chelsea Finn",
    "abstract": "Fine manipulation tasks, such as threading cable ties or slotting a battery, are notoriously difficult for robots because they require precision, careful coordination of contact forces, and closed-loop visual feedback. Performing these tasks typically requires high-end robots, accurate sensors, or careful calibration, which can be expensive and difficult to set up. Can learning enable low-cost and imprecise hardware to perform these fine manipulation tasks? We present a low-cost system that performs end-to-end imitation learning directly from real demonstrations, collected with a custom teleoperation interface. Imitation learning, however, presents its own challenges, particularly in high-precision domains: errors in the policy can compound over time, and human demonstrations can be non-stationary. To address these challenges, we develop a simple yet novel algorithm, Action Chunking with Transformers (ACT), which learns a generative model over action sequences. ACT allows the robot to learn 6 difficult tasks in the real world, such as opening a translucent condiment cup and slotting a battery with 80-90% success, with only 10 minutes worth of demonstrations. Project website: https://tonyzhaozh.github.io/aloha/",
    "citationCount": 1103,
    "pdf_filename": "2023_Learning_Fine_Grained_Bimanual_Manipulat_91eb20f9.pdf"
  },
  "40e8af970329135ec95057d73e239dab805ad128": {
    "paperId": "40e8af970329135ec95057d73e239dab805ad128",
    "title": "The Llama 3 Herd of Models",
    "year": 2024,
    "authors": "Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle",
    "abstract": "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.",
    "citationCount": 10810,
    "pdf_filename": "2024_The_Llama_3_Herd_of_Models_40e8af97.pdf"
  },
  "5cde474869cb230a29b3ba0f6f685f5162b1a1a1": {
    "paperId": "5cde474869cb230a29b3ba0f6f685f5162b1a1a1",
    "title": "Revolutionizing healthcare: the role of artificial intelligence in clinical practice",
    "year": 2023,
    "authors": "Shuroug A. Alowais, Sahar S. Alghamdi, Nada Alsuhebany, Tariq Alqahtani, Abdulrahman I. Alshaya",
    "abstract": "Introduction Healthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI’s role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools. Research Significance This review article provides a comprehensive and up-to-date overview of the current state of AI in clinical practice, including its potential applications in disease diagnosis, treatment recommendations, and patient engagement. It also discusses the associated challenges, covering ethical and legal considerations and the need for human expertise. By doing so, it enhances understanding of AI’s significance in healthcare and supports healthcare organizations in effectively adopting AI technologies. Materials and Methods The current investigation analyzed the use of AI in the healthcare system with a comprehensive review of relevant indexed literature, such as PubMed/Medline, Scopus, and EMBASE, with no time constraints but limited to articles published in English. The focused question explores the impact of applying AI in healthcare settings and the potential outcomes of this application. Results Integrating AI into healthcare holds excellent potential for improving disease diagnosis, treatment selection, and clinical laboratory testing. AI tools can leverage large datasets and identify patterns to surpass human performance in several healthcare aspects. AI offers increased accuracy, reduced costs, and time savings while minimizing human errors. It can revolutionize personalized medicine, optimize medication dosages, enhance population health management, establish guidelines, provide virtual health assistants, support mental health care, improve patient education, and influence patient-physician trust. Conclusion AI can be used to diagnose diseases, develop personalized treatment plans, and assist clinicians with decision-making. Rather than simply automating tasks, AI is about developing technologies that can enhance patient care across healthcare settings. However, challenges related to data privacy, bias, and the need for human expertise must be addressed for the responsible and effective implementation of AI in healthcare.",
    "citationCount": 1677,
    "pdf_filename": "2023_Revolutionizing_healthcare__the_role_of__5cde4748.pdf"
  },
  "af9f365ed86614c800f082bd8eb14be76072ad16": {
    "paperId": "af9f365ed86614c800f082bd8eb14be76072ad16",
    "title": "Classifier-Free Diffusion Guidance",
    "year": 2022,
    "authors": "Jonathan Ho",
    "abstract": "Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance.",
    "citationCount": 5102,
    "pdf_filename": "2022_Classifier_Free_Diffusion_Guidance_af9f365e.pdf"
  },
  "3b2a675bb617ae1a920e8e29d535cdf27826e999": {
    "paperId": "3b2a675bb617ae1a920e8e29d535cdf27826e999",
    "title": "Video Diffusion Models",
    "year": 2022,
    "authors": "Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi",
    "abstract": "Generating temporally coherent high fidelity video is an important milestone in generative modeling research. We make progress towards this milestone by proposing a diffusion model for video generation that shows very promising initial results. Our model is a natural extension of the standard image diffusion architecture, and it enables jointly training from image and video data, which we find to reduce the variance of minibatch gradients and speed up optimization. To generate long and higher resolution videos we introduce a new conditional sampling technique for spatial and temporal video extension that performs better than previously proposed methods. We present the first results on a large text-conditioned video generation task, as well as state-of-the-art results on established benchmarks for video prediction and unconditional video generation. Supplementary material is available at https://video-diffusion.github.io/",
    "citationCount": 2124,
    "pdf_filename": "2022_Video_Diffusion_Models_3b2a675b.pdf"
  },
  "04e541391e8dce14d099d00fb2c21dbbd8afe87f": {
    "paperId": "04e541391e8dce14d099d00fb2c21dbbd8afe87f",
    "title": "Prompt-to-Prompt Image Editing with Cross Attention Control",
    "year": 2022,
    "authors": "Amir Hertz, Ron Mokady, J. Tenenbaum, Kfir Aberman, Y. Pritch",
    "abstract": "Recent large-scale text-driven synthesis models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Such text-based synthesis methods are particularly appealing to humans who are used to verbally describe their intent. Therefore, it is only natural to extend the text-driven image synthesis to text-driven image editing. Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. To this end, we analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we present several applications which monitor the image synthesis by editing the textual prompt only. This includes localized editing by replacing a word, global editing by adding a specification, and even delicately controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts, demonstrating high-quality synthesis and fidelity to the edited prompts.",
    "citationCount": 2247,
    "pdf_filename": "2022_Prompt_to_Prompt_Image_Editing_with_Cros_04e54139.pdf"
  },
  "8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c": {
    "paperId": "8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c",
    "title": "Sparks of Artificial General Intelligence: Early experiments with GPT-4",
    "year": 2023,
    "authors": "Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, J. Gehrke, Eric Horvitz",
    "abstract": "Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.",
    "citationCount": 3737,
    "pdf_filename": "2023_Sparks_of_Artificial_General_Intelligenc_8dbd5746.pdf"
  },
  "f9a7175198a2c9f3ab0134a12a7e9e5369428e42": {
    "paperId": "f9a7175198a2c9f3ab0134a12a7e9e5369428e42",
    "title": "A Survey of Large Language Models",
    "year": 2023,
    "authors": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang",
    "abstract": "Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.",
    "citationCount": 3703,
    "pdf_filename": "2023_A_Survey_of_Large_Language_Models_f9a71751.pdf"
  },
  "210b0a3d76e93079cc51b03c4115fde545eea966": {
    "paperId": "210b0a3d76e93079cc51b03c4115fde545eea966",
    "title": "GPQA: A Graduate-Level Google-Proof Q&A Benchmark",
    "year": 2023,
    "authors": "David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang",
    "abstract": "We present GPQA, a challenging dataset of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry. We ensure that the questions are high-quality and extremely difficult: experts who have or are pursuing PhDs in the corresponding domains reach 65% accuracy (74% when discounting clear mistakes the experts identified in retrospect), while highly skilled non-expert validators only reach 34% accuracy, despite spending on average over 30 minutes with unrestricted access to the web (i.e., the questions are\"Google-proof\"). The questions are also difficult for state-of-the-art AI systems, with our strongest GPT-4 based baseline achieving 39% accuracy. If we are to use future AI systems to help us answer very hard questions, for example, when developing new scientific knowledge, we need to develop scalable oversight methods that enable humans to supervise their outputs, which may be difficult even if the supervisors are themselves skilled and knowledgeable. The difficulty of GPQA both for skilled non-experts and frontier AI systems should enable realistic scalable oversight experiments, which we hope can help devise ways for human experts to reliably get truthful information from AI systems that surpass human capabilities.",
    "citationCount": 1528,
    "pdf_filename": "2023_GPQA__A_Graduate_Level_Google_Proof_Q_A__210b0a3d.pdf"
  },
  "dfdf7ff01aa6f691831e663fd29bc71890be39e2": {
    "paperId": "dfdf7ff01aa6f691831e663fd29bc71890be39e2",
    "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns",
    "year": 2023,
    "authors": "Malik Sallam",
    "abstract": "ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.",
    "citationCount": 2131,
    "pdf_filename": "2023_ChatGPT_Utility_in_Healthcare_Education__dfdf7ff0.pdf"
  },
  "a26a7a74f1e5fd562be95c3611a0680759fbdf84": {
    "paperId": "a26a7a74f1e5fd562be95c3611a0680759fbdf84",
    "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
    "year": 2022,
    "authors": "Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini",
    "abstract": "Exploring large-scale pretrained foundation models is of significant interest in computer vision because these models can be quickly transferred to many downstream tasks. This paper presents Contrastive Captioner (CoCa), a minimalist design to pretrain an image-text encoder-decoder foundation model jointly with contrastive loss and captioning loss, thereby subsuming model capabilities from contrastive approaches like CLIP and generative methods like SimVLM. In contrast to standard encoder-decoder transformers where all decoder layers attend to encoder outputs, CoCa omits cross-attention in the first half of decoder layers to encode unimodal text representations, and cascades the remaining decoder layers which cross-attend to the image encoder for multimodal image-text representations. We apply a contrastive loss between unimodal image and text embeddings, in addition to a captioning loss on the multimodal decoder outputs which predicts text tokens autoregressively. By sharing the same computational graph, the two training objectives are computed efficiently with minimal overhead. CoCa is pretrained end-to-end and from scratch on both web-scale alt-text data and annotated images by treating all labels simply as text, seamlessly unifying natural language supervision for representation learning. Empirically, CoCa achieves state-of-the-art performance with zero-shot transfer or minimal task-specific adaptation on a broad range of downstream tasks, spanning visual recognition (ImageNet, Kinetics-400/600/700, Moments-in-Time), crossmodal retrieval (MSCOCO, Flickr30K, MSR-VTT), multimodal understanding (VQA, SNLI-VE, NLVR2), and image captioning (MSCOCO, NoCaps). Notably on ImageNet classification, CoCa obtains 86.3% zero-shot top-1 accuracy, 90.6% with a frozen encoder and learned classification head, and new state-of-the-art 91.0% top-1 accuracy on ImageNet with a finetuned encoder.",
    "citationCount": 1568,
    "pdf_filename": "2022_CoCa__Contrastive_Captioners_are_Image_T_a26a7a74.pdf"
  },
  "244054a4254a2147e43a3dad9c124b9b7eb4a04a": {
    "paperId": "244054a4254a2147e43a3dad9c124b9b7eb4a04a",
    "title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow",
    "year": 2022,
    "authors": "Xingchao Liu, Chengyue Gong, Qiang Liu",
    "abstract": "We present rectified flow, a surprisingly simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions \\pi_0 and \\pi_1, hence providing a unified solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectified flow is to learn the ODE to follow the straight paths connecting the points drawn from \\pi_0 and \\pi_1 as much as possible. This is achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are special and preferred because they are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efficient models. We show that the procedure of learning a rectified flow from data, called rectification, turns an arbitrary coupling of \\pi_0 and \\pi_1 to a new deterministic coupling with provably non-increasing convex transport costs. In addition, recursively applying rectification allows us to obtain a sequence of flows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectified flow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight flows that give high quality results even with a single Euler discretization step.",
    "citationCount": 1821,
    "pdf_filename": "2022_Flow_Straight_and_Fast__Learning_to_Gene_244054a4.pdf"
  },
  "1e91fa21b890a8f5d615578f4ddf46c3cb394691": {
    "paperId": "1e91fa21b890a8f5d615578f4ddf46c3cb394691",
    "title": "RePaint: Inpainting using Denoising Diffusion Probabilistic Models",
    "year": 2022,
    "authors": "Andreas Lugmayr, Martin Danelljan, Andrés Romero, F. Yu, Radu Timofte",
    "abstract": "Free-form inpainting is the task of adding new content to an image in the regions specified by an arbitrary binary mask. Most existing approaches train for a certain distribution of masks, which limits their generalization capabilities to unseen mask types. Furthermore, training with pixel-wise and perceptual losses often leads to simple textural extensions towards the missing areas instead of semantically meaningful generation. In this work, we propose RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting approach that is applicable to even extreme masks. We employ a pretrained unconditional DDPM as the generative prior. To condition the generation process, we only alter the reverse diffusion iterations by sampling the unmasked regions using the given image infor-mation. Since this technique does not modify or condition the original DDPM network itself, the model produces high-quality and diverse output images for any inpainting form. We validate our method for both faces and general-purpose image inpainting using standard and extreme masks. Re-Paint outperforms state-of-the-art Autoregressive, and GAN approaches for at least five out of six mask distributions. Github Repository: git.io/RePaint",
    "citationCount": 1789,
    "pdf_filename": "2022_RePaint__Inpainting_using_Denoising_Diff_1e91fa21.pdf"
  },
  "4530c25da949bb2185c50663158ef19d52e3c6b5": {
    "paperId": "4530c25da949bb2185c50663158ef19d52e3c6b5",
    "title": "DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps",
    "year": 2022,
    "authors": "Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li",
    "abstract": "Diffusion probabilistic models (DPMs) are emerging powerful generative models. Despite their high-quality generation performance, DPMs still suffer from their slow sampling as they generally need hundreds or thousands of sequential function evaluations (steps) of large neural networks to draw a sample. Sampling from DPMs can be viewed alternatively as solving the corresponding diffusion ordinary differential equations (ODEs). In this work, we propose an exact formulation of the solution of diffusion ODEs. The formulation analytically computes the linear part of the solution, rather than leaving all terms to black-box ODE solvers as adopted in previous works. By applying change-of-variable, the solution can be equivalently simplified to an exponentially weighted integral of the neural network. Based on our formulation, we propose DPM-Solver, a fast dedicated high-order solver for diffusion ODEs with the convergence order guarantee. DPM-Solver is suitable for both discrete-time and continuous-time DPMs without any further training. Experimental results show that DPM-Solver can generate high-quality samples in only 10 to 20 function evaluations on various datasets. We achieve 4.70 FID in 10 function evaluations and 2.87 FID in 20 function evaluations on the CIFAR10 dataset, and a $4\\sim 16\\times$ speedup compared with previous state-of-the-art training-free samplers on various datasets.",
    "citationCount": 1880,
    "pdf_filename": "2022_DPM_Solver__A_Fast_ODE_Solver_for_Diffus_4530c25d.pdf"
  },
  "f94c58af515c4c9621762f2276adbe14ac1031d5": {
    "paperId": "f94c58af515c4c9621762f2276adbe14ac1031d5",
    "title": "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT",
    "year": 2023,
    "authors": "Debby R. E. Cotton, Peter A. Cotton, J. Shipway",
    "abstract": "ABSTRACT The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.",
    "citationCount": 1587,
    "pdf_filename": "2023_Chatting_and_cheating__Ensuring_academic_f94c58af.pdf"
  },
  "61e46884567be7cad12e999365b16a8d3414b678": {
    "paperId": "61e46884567be7cad12e999365b16a8d3414b678",
    "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems",
    "year": 2022,
    "authors": "Hyungjin Chung, Jeongsol Kim, Michael T. McCann, M. Klasky, J. C. Ye",
    "abstract": "Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring. Code available at https://github.com/DPS2022/diffusion-posterior-sampling",
    "citationCount": 1175,
    "pdf_filename": "2022_Diffusion_Posterior_Sampling_for_General_61e46884.pdf"
  },
  "144eca44e250cc462f6fc3a172abb865978f66f5": {
    "paperId": "144eca44e250cc462f6fc3a172abb865978f66f5",
    "title": "Multi-Concept Customization of Text-to-Image Diffusion",
    "year": 2022,
    "authors": "Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, Jun-Yan Zhu",
    "abstract": "While generative models produce high-quality images of concepts learned from a large-scale database, a user often wishes to synthesize instantiations of their own concepts (for example, their family, pets, or items). Can we teach a model to quickly acquire a new concept, given a few examples? Furthermore, can we compose multiple new concepts together? We propose Custom Diffusion, an efficient method for augmenting existing text-to-image models. We find that only optimizing a few parameters in the text-to-image conditioning mechanism is sufficiently powerful to represent new concepts while enabling fast tuning (~ 6 minutes). Additionally, we can jointly train for multiple concepts or combine multiple fine-tuned models into one via closed-form constrained optimization. Our fine-tuned model generates variations of multiple new concepts and seamlessly composes them with existing concepts in novel settings. Our method outperforms or performs on par with several baselines and concurrent works in both qualitative and quantitative evaluations, while being memory and computationally efficient.",
    "citationCount": 1117,
    "pdf_filename": "2022_Multi_Concept_Customization_of_Text_to_I_144eca44.pdf"
  },
  "9348656b761f7b76fb65cfe6fac55386b04a3a8a": {
    "paperId": "9348656b761f7b76fb65cfe6fac55386b04a3a8a",
    "title": "A Comprehensive Survey of Continual Learning: Theory, Method and Application",
    "year": 2023,
    "authors": "Liyuan Wang, Xingxing Zhang, Hang Su, Jun Zhu",
    "abstract": "To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance drop of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative strategies address continual learning, and how they are adapted to particular challenges in various applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.",
    "citationCount": 1016,
    "pdf_filename": "2023_A_Comprehensive_Survey_of_Continual_Lear_9348656b.pdf"
  },
  "3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7": {
    "paperId": "3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7",
    "title": "Denoising Diffusion Restoration Models",
    "year": 2022,
    "authors": "Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song",
    "abstract": "Many interesting tasks in image restoration can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion Restoration Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.",
    "citationCount": 1050,
    "pdf_filename": "2022_Denoising_Diffusion_Restoration_Models_3d3c5fcb.pdf"
  },
  "0c72450890a54b68d63baa99376131fda8f06cf9": {
    "paperId": "0c72450890a54b68d63baa99376131fda8f06cf9",
    "title": "The Rise and Potential of Large Language Model Based Agents: A Survey",
    "year": 2023,
    "authors": "Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding",
    "abstract": "For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.",
    "citationCount": 1292,
    "pdf_filename": "2023_The_Rise_and_Potential_of_Large_Language_0c724508.pdf"
  },
  "9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a": {
    "paperId": "9faa2b0e5cb93f20df0555c3c350fab0b2eccf3a",
    "title": "Foundation models for generalist medical artificial intelligence",
    "year": 2023,
    "authors": "Michael Moor, Oishi Banerjee, Zahra F H Abad, H. Krumholz, J. Leskovec",
    "abstract": "The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets. This review discusses generalist medical artificial intelligence, identifying potential applications and setting out specific technical capabilities and training datasets necessary to enable them, as well as highlighting challenges to its implementation.",
    "citationCount": 1318,
    "pdf_filename": "2023_Foundation_models_for_generalist_medical_9faa2b0e.pdf"
  },
  "e342165a614588878ad0f4bc9bacf3905df34d08": {
    "paperId": "e342165a614588878ad0f4bc9bacf3905df34d08",
    "title": "Diffusion Models: A Comprehensive Survey of Methods and Applications",
    "year": 2022,
    "authors": "Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao",
    "abstract": "Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language processing, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy",
    "citationCount": 1804,
    "pdf_filename": "2022_Diffusion_Models__A_Comprehensive_Survey_e342165a.pdf"
  },
  "efa1647594b236361610a20d507127f0586a379b": {
    "paperId": "efa1647594b236361610a20d507127f0586a379b",
    "title": "Diffusion Models in Vision: A Survey",
    "year": 2022,
    "authors": "Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, M. Shah",
    "abstract": "Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In the reverse stage, a model is tasked at recovering the original input data by learning to gradually reverse the diffusion process, step by step. Diffusion models are widely appreciated for the quality and diversity of the generated samples, despite their known computational burdens, i.e., low speeds due to the high number of steps involved during sampling. In this survey, we provide a comprehensive review of articles on denoising diffusion models applied in vision, comprising both theoretical and practical contributions in the field. First, we identify and present three generic diffusion modeling frameworks, which are based on denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations. We further discuss the relations between diffusion models and other deep generative models, including variational auto-encoders, generative adversarial networks, energy-based models, autoregressive models and normalizing flows. Then, we introduce a multi-perspective categorization of diffusion models applied in computer vision. Finally, we illustrate the current limitations of diffusion models and envision some interesting directions for future research.",
    "citationCount": 1699,
    "pdf_filename": "2022_Diffusion_Models_in_Vision__A_Survey_efa16475.pdf"
  },
  "b6d6c33298b852cf63edac233deca70530d69a2a": {
    "paperId": "b6d6c33298b852cf63edac233deca70530d69a2a",
    "title": "PaLM 2 Technical Report",
    "year": 2023,
    "authors": "Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin",
    "abstract": "We introduce PaLM 2, a new state-of-the-art language model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture of objectives. Through extensive evaluations on English and multilingual language, and reasoning tasks, we demonstrate that PaLM 2 has significantly improved quality on downstream tasks across different model sizes, while simultaneously exhibiting faster and more efficient inference compared to PaLM. This improved efficiency enables broader deployment while also allowing the model to respond faster, for a more natural pace of interaction. PaLM 2 demonstrates robust reasoning capabilities exemplified by large improvements over PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable performance on a suite of responsible AI evaluations, and enables inference-time control over toxicity without additional overhead or impact on other capabilities. Overall, PaLM 2 achieves state-of-the-art performance across a diverse set of tasks and capabilities. When discussing the PaLM 2 family, it is important to distinguish between pre-trained models (of various sizes), fine-tuned variants of these models, and the user-facing products that use these models. In particular, user-facing products typically include additional pre- and post-processing steps. Additionally, the underlying models may evolve over time. Therefore, one should not expect the performance of user-facing products to exactly match the results reported in this report.",
    "citationCount": 1376,
    "pdf_filename": "2023_PaLM_2_Technical_Report_b6d6c332.pdf"
  },
  "f6681d526def3a7a5cd7b960d3e60ac69a10dbd7": {
    "paperId": "f6681d526def3a7a5cd7b960d3e60ac69a10dbd7",
    "title": "What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education",
    "year": 2023,
    "authors": "A. Tlili, Boulus Shehata, Michael Agyemang Adarkwah, Aras Bozkurt, D. Hickey",
    "abstract": "Artificial Intelligence (AI) technologies have been progressing constantly and being more visible in different aspects of our lives. One recent phenomenon is ChatGPT, a chatbot with a conversational artificial intelligence interface that was developed by OpenAI. As one of the most advanced artificial intelligence applications, ChatGPT has drawn much public attention across the globe. In this regard, this study examines ChatGPT in education, among early adopters, through a qualitative instrumental case study. Conducted in three stages, the first stage of the study reveals that the public discourse in social media is generally positive and there is enthusiasm regarding its use in educational settings. However, there are also voices who are approaching cautiously using ChatGPT in educational settings. The second stage of the study examines the case of ChatGPT through lenses of educational transformation, response quality, usefulness, personality and emotion, and ethics. In the third and final stage of the study, the investigation of user experiences through ten educational scenarios revealed various issues, including cheating, honesty and truthfulness of ChatGPT, privacy misleading, and manipulation. The findings of this study provide several research directions that should be considered to ensure a safe and responsible adoption of chatbots, specifically ChatGPT, in education.",
    "citationCount": 1160,
    "pdf_filename": "2023_What_if_the_devil_is_my_guardian_angel___f6681d52.pdf"
  },
  "de18baa4964804cf471d85a5a090498242d2e79f": {
    "paperId": "de18baa4964804cf471d85a5a090498242d2e79f",
    "title": "Improved Denoising Diffusion Probabilistic Models",
    "year": 2021,
    "authors": "Alex Nichol, Prafulla Dhariwal",
    "abstract": "Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code at https://github.com/openai/improved-diffusion",
    "citationCount": 4571,
    "pdf_filename": "2021_Improved_Denoising_Diffusion_Probabilist_de18baa4.pdf"
  },
  "64ea8f180d0682e6c18d1eb688afdb2027c02794": {
    "paperId": "64ea8f180d0682e6c18d1eb688afdb2027c02794",
    "title": "Diffusion Models Beat GANs on Image Synthesis",
    "year": 2021,
    "authors": "Prafulla Dhariwal, Alex Nichol",
    "abstract": "We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our code at https://github.com/openai/guided-diffusion",
    "citationCount": 9979,
    "pdf_filename": "2021_Diffusion_Models_Beat_GANs_on_Image_Synt_64ea8f18.pdf"
  },
  "5b19bf6c3f4b25cac96362c98b930cf4b37f6744": {
    "paperId": "5b19bf6c3f4b25cac96362c98b930cf4b37f6744",
    "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation",
    "year": 2022,
    "authors": "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Y. Pritch, Michael Rubinstein",
    "abstract": "Large text-to-image models achieved a remarkable leap in the evolution of AI, enabling high-quality and diverse synthesis of images from a given text prompt. However, these models lack the ability to mimic the appearance of subjects in a given reference set and synthesize novel renditions of them in different contexts. In this work, we present a new approach for “personalization” of text-to-image diffusion models. Given as input just a few images of a subject, we fine-tune a pretrained text-to-image model such that it learns to bind a unique identifier with that specific subject. Once the subject is embedded in the output domain of the model, the unique identifier can be used to synthesize novel photorealistic images of the subject contextualized in different scenes. By leveraging the semantic prior embedded in the model with a new autogenous class-specific prior preservation loss, our technique enables synthesizing the subject in diverse scenes, poses, views and lighting conditions that do not appear in the reference images. We apply our technique to several previously-unassailable tasks, including subject recontextualization, text-guided view synthesis, and artistic rendering, all while preserving the subject's key features. We also provide a new dataset and evaluation protocol for this new task of subject-driven generation. Project page: https://dreambooth.github.io/",
    "citationCount": 3617,
    "pdf_filename": "2022_DreamBooth__Fine_Tuning_Text_to_Image_Di_5b19bf6c.pdf"
  },
  "f671a09e3e5922e6d38cb77dda8d76d5ceac2a27": {
    "paperId": "f671a09e3e5922e6d38cb77dda8d76d5ceac2a27",
    "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations",
    "year": 2021,
    "authors": "Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu",
    "abstract": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user input (e.g., hand-drawn colored strokes) and realism of the synthesized image. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide of any type, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit significantly outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.",
    "citationCount": 1849,
    "pdf_filename": "2021_SDEdit__Guided_Image_Synthesis_and_Editi_f671a09e.pdf"
  },
  "91b32fc0a23f0af53229fceaae9cce43a0406d2e": {
    "paperId": "91b32fc0a23f0af53229fceaae9cce43a0406d2e",
    "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
    "year": 2021,
    "authors": "Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, Rianne van den Berg",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusion-like generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. 2021, by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on LM1B. On the image dataset CIFAR-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space DDPM model.",
    "citationCount": 1292,
    "pdf_filename": "2021_Structured_Denoising_Diffusion_Models_in_91b32fc0.pdf"
  },
  "94bcd712aed610b8eaeccc57136d65ec988356f2": {
    "paperId": "94bcd712aed610b8eaeccc57136d65ec988356f2",
    "title": "Variational Diffusion Models",
    "year": 2021,
    "authors": "Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho",
    "abstract": "Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the variance of the resulting VLB estimator, leading to faster optimization. Combining these advances with architectural improvements, we obtain state-of-the-art likelihoods on image density estimation benchmarks, outperforming autoregressive models that have dominated these benchmarks for many years, with often significantly faster optimization. In addition, we show how to use the model as part of a bits-back compression scheme, and demonstrate lossless compression rates close to the theoretical optimum. Code is available at https://github.com/google-research/vdm .",
    "citationCount": 1324,
    "pdf_filename": "2021_Variational_Diffusion_Models_94bcd712.pdf"
  },
  "92bf1c069747374fbc3efb55e7a916a3e2d736da": {
    "paperId": "92bf1c069747374fbc3efb55e7a916a3e2d736da",
    "title": "Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech",
    "year": 2021,
    "authors": "Jaehyeon Kim, Jungil Kong, Juhee Son",
    "abstract": "Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.",
    "citationCount": 1120,
    "pdf_filename": "2021_Conditional_Variational_Autoencoder_with_92bf1c06.pdf"
  },
  "014576b866078524286802b1d0e18628520aa886": {
    "paperId": "014576b866078524286802b1d0e18628520aa886",
    "title": "Denoising Diffusion Implicit Models",
    "year": 2020,
    "authors": "Jiaming Song, Chenlin Meng, Stefano Ermon",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples $10 \\times$ to $50 \\times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.",
    "citationCount": 9832,
    "pdf_filename": "2020_Denoising_Diffusion_Implicit_Models_014576b8.pdf"
  },
  "74276a37bfa50f90dfae37f767b2b67784bd402a": {
    "paperId": "74276a37bfa50f90dfae37f767b2b67784bd402a",
    "title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer",
    "year": 2020,
    "authors": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou",
    "abstract": "The recent “Text-to-Text Transfer Transformer” (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent “accidental translation” in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.",
    "citationCount": 2865,
    "pdf_filename": "2020_mT5__A_Massively_Multilingual_Pre_traine_74276a37.pdf"
  },
  "c7bbeaef75fa64c7e9cdf1b68bb487b9f8cd9a7d": {
    "paperId": "c7bbeaef75fa64c7e9cdf1b68bb487b9f8cd9a7d",
    "title": "Image Segmentation Using Deep Learning: A Survey",
    "year": 2020,
    "authors": "Shervin Minaee, Yuri Boykov, F. Porikli, A. Plaza, N. Kehtarnavaz",
    "abstract": "Image segmentation is a key task in computer vision and image processing with important applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others, and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of deep learning (DL) has prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation models, examine the widely used datasets, compare performances, and discuss promising research directions.",
    "citationCount": 3390,
    "pdf_filename": "2020_Image_Segmentation_Using_Deep_Learning___c7bbeaef.pdf"
  },
  "ac3cdb50606f7770eef8e4cd951840a4f71287a0": {
    "paperId": "ac3cdb50606f7770eef8e4cd951840a4f71287a0",
    "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm",
    "year": 2021,
    "authors": "Laria Reynolds, Kyle McDonell",
    "abstract": "Prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe models’ novel capabilities. Using GPT-3 as a case study, we show that 0-shot prompts can significantly outperform few-shot prompts. We suggest that the function of few-shot examples in these cases is better described as locating an already learned task rather than meta-learning. This analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models. We discuss methods of prompt programming, emphasizing the usefulness of considering prompts through the lens of natural language. We explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict. Informed by this more encompassing theory of prompt programming, we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks. Finally, we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications.",
    "citationCount": 1129,
    "pdf_filename": "2021_Prompt_Programming_for_Large_Language_Mo_ac3cdb50.pdf"
  },
  "a70c50bff01547f00ce341cd7e42797f11c4cdc7": {
    "paperId": "a70c50bff01547f00ce341cd7e42797f11c4cdc7",
    "title": "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum.",
    "year": 2023,
    "authors": "J. Ayers, Adam Poliak, Mark Dredze, E. Leas, Zechariah Zhu",
    "abstract": "Importance\nThe rapid expansion of virtual health care has caused a surge in patient messages concomitant with more work and burnout among health care professionals. Artificial intelligence (AI) assistants could potentially aid in creating answers to patient questions by drafting responses that could be reviewed by clinicians.\n\n\nObjective\nTo evaluate the ability of an AI chatbot assistant (ChatGPT), released in November 2022, to provide quality and empathetic responses to patient questions.\n\n\nDesign, Setting, and Participants\nIn this cross-sectional study, a public and nonidentifiable database of questions from a public social media forum (Reddit's r/AskDocs) was used to randomly draw 195 exchanges from October 2022 where a verified physician responded to a public question. Chatbot responses were generated by entering the original question into a fresh session (without prior questions having been asked in the session) on December 22 and 23, 2022. The original question along with anonymized and randomly ordered physician and chatbot responses were evaluated in triplicate by a team of licensed health care professionals. Evaluators chose \"which response was better\" and judged both \"the quality of information provided\" (very poor, poor, acceptable, good, or very good) and \"the empathy or bedside manner provided\" (not empathetic, slightly empathetic, moderately empathetic, empathetic, and very empathetic). Mean outcomes were ordered on a 1 to 5 scale and compared between chatbot and physicians.\n\n\nResults\nOf the 195 questions and responses, evaluators preferred chatbot responses to physician responses in 78.6% (95% CI, 75.0%-81.8%) of the 585 evaluations. Mean (IQR) physician responses were significantly shorter than chatbot responses (52 [17-62] words vs 211 [168-245] words; t = 25.4; P < .001). Chatbot responses were rated of significantly higher quality than physician responses (t = 13.3; P < .001). The proportion of responses rated as good or very good quality (≥ 4), for instance, was higher for chatbot than physicians (chatbot: 78.5%, 95% CI, 72.3%-84.1%; physicians: 22.1%, 95% CI, 16.4%-28.2%;). This amounted to 3.6 times higher prevalence of good or very good quality responses for the chatbot. Chatbot responses were also rated significantly more empathetic than physician responses (t = 18.9; P < .001). The proportion of responses rated empathetic or very empathetic (≥4) was higher for chatbot than for physicians (physicians: 4.6%, 95% CI, 2.1%-7.7%; chatbot: 45.1%, 95% CI, 38.5%-51.8%; physicians: 4.6%, 95% CI, 2.1%-7.7%). This amounted to 9.8 times higher prevalence of empathetic or very empathetic responses for the chatbot.\n\n\nConclusions\nIn this cross-sectional study, a chatbot generated quality and empathetic responses to patient questions posed in an online forum. Further exploration of this technology is warranted in clinical settings, such as using chatbot to draft responses that physicians could then edit. Randomized trials could assess further if using AI assistants might improve responses, lower clinician burnout, and improve patient outcomes.",
    "citationCount": 1613,
    "pdf_filename": "2023_Comparing_Physician_and_Artificial_Intel_a70c50bf.pdf"
  },
  "cc22c4e54c0dd381a2ff22881d4fb570cf3761e8": {
    "paperId": "cc22c4e54c0dd381a2ff22881d4fb570cf3761e8",
    "title": "Normalizing Flows: An Introduction and Review of Current Methods",
    "year": 2020,
    "authors": "I. Kobyzev, S. Prince, Marcus A. Brubaker",
    "abstract": "Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.",
    "citationCount": 1366,
    "pdf_filename": "2020_Normalizing_Flows__An_Introduction_and_R_cc22c4e5.pdf"
  },
  "f6d32ed0eee5fb3f6ac518f3aebc8ceff2aae397": {
    "paperId": "f6d32ed0eee5fb3f6ac518f3aebc8ceff2aae397",
    "title": "NVAE: A Deep Hierarchical Variational Autoencoder",
    "year": 2020,
    "authors": "Arash Vahdat, Jan Kautz",
    "abstract": "Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256$\\times$256 pixels. The source code is available at this https URL .",
    "citationCount": 1037,
    "pdf_filename": "2020_NVAE__A_Deep_Hierarchical_Variational_Au_f6d32ed0.pdf"
  },
  "08a80cb34d785258c770acecd302ab41ead46eed": {
    "paperId": "08a80cb34d785258c770acecd302ab41ead46eed",
    "title": "WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions",
    "year": 2023,
    "authors": "Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao",
    "abstract": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM",
    "citationCount": 1137,
    "pdf_filename": "2023_WizardLM__Empowering_Large_Pre_Trained_L_08a80cb3.pdf"
  },
  "8946891e94831adc8cddb0d32311cce2445c96d2": {
    "paperId": "8946891e94831adc8cddb0d32311cce2445c96d2",
    "title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts",
    "year": 2023,
    "authors": "Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chun-yue Li",
    "abstract": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/.",
    "citationCount": 1066,
    "pdf_filename": "2023_MathVista__Evaluating_Mathematical_Reaso_8946891e.pdf"
  },
  "3e4085e5869f1b7959707a1e1d7d273b6057eb4e": {
    "paperId": "3e4085e5869f1b7959707a1e1d7d273b6057eb4e",
    "title": "StarCoder: may the source be with you!",
    "year": 2023,
    "authors": "Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov",
    "abstract": "The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.",
    "citationCount": 1005,
    "pdf_filename": "2023_StarCoder__may_the_source_be_with_you__3e4085e5.pdf"
  },
  "a938303f20b7fcde2bfdb7ca95ff5b69739430d3": {
    "paperId": "a938303f20b7fcde2bfdb7ca95ff5b69739430d3",
    "title": "AlphaFold Protein Structure Database in 2024: providing structure coverage for over 214 million protein sequences",
    "year": 2023,
    "authors": "M. Váradi, Damian Bertoni, Paulyna Magana, Urmila Paramval, Ivanna Pidruchna",
    "abstract": "Abstract The AlphaFold Database Protein Structure Database (AlphaFold DB, https://alphafold.ebi.ac.uk) has significantly impacted structural biology by amassing over 214 million predicted protein structures, expanding from the initial 300k structures released in 2021. Enabled by the groundbreaking AlphaFold2 artificial intelligence (AI) system, the predictions archived in AlphaFold DB have been integrated into primary data resources such as PDB, UniProt, Ensembl, InterPro and MobiDB. Our manuscript details subsequent enhancements in data archiving, covering successive releases encompassing model organisms, global health proteomes, Swiss-Prot integration, and a host of curated protein datasets. We detail the data access mechanisms of AlphaFold DB, from direct file access via FTP to advanced queries using Google Cloud Public Datasets and the programmatic access endpoints of the database. We also discuss the improvements and services added since its initial release, including enhancements to the Predicted Aligned Error viewer, customisation options for the 3D viewer, and improvements in the search engine of AlphaFold DB.",
    "citationCount": 1110,
    "pdf_filename": "2023_AlphaFold_Protein_Structure_Database_in__a938303f.pdf"
  },
  "7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea": {
    "paperId": "7872f34e2a164c5cf3c34a7a7433dc3342b6c7ea",
    "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions",
    "year": 2021,
    "authors": "Iqbal H. Sarker",
    "abstract": "In the current age of the Fourth Industrial Revolution (4IR or Industry 4.0), the digital world has a wealth of data, such as Internet of Things (IoT) data, cybersecurity data, mobile data, business data, social media data, health data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Various types of machine learning algorithms such as supervised, unsupervised, semi-supervised, and reinforcement learning exist in the area. Besides, the deep learning, which is part of a broader family of machine learning methods, can intelligently analyze the data on a large scale. In this paper, we present a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and the capabilities of an application. Thus, this study’s key contribution is explaining the principles of different machine learning techniques and their applicability in various real-world application domains, such as cybersecurity systems, smart cities, healthcare, e-commerce, agriculture, and many more. We also highlight the challenges and potential research directions based on our study. Overall, this paper aims to serve as a reference point for both academia and industry professionals as well as for decision-makers in various real-world situations and application areas, particularly from the technical point of view.",
    "citationCount": 3752,
    "pdf_filename": "2021_Machine_Learning__Algorithms__Real_World_7872f34e.pdf"
  },
  "3803ea42e1fc773db3b1d0fa05f41b5ebf0a61d1": {
    "paperId": "3803ea42e1fc773db3b1d0fa05f41b5ebf0a61d1",
    "title": "Toward Causal Representation Learning",
    "year": 2021,
    "authors": "Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner",
    "abstract": "The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.",
    "citationCount": 1148,
    "pdf_filename": "2021_Toward_Causal_Representation_Learning_3803ea42.pdf"
  },
  "754eef845a1fd33405661e9de4e985f020ea949a": {
    "paperId": "754eef845a1fd33405661e9de4e985f020ea949a",
    "title": "Correlation of Chest CT and RT-PCR Testing in Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases",
    "year": 2020,
    "authors": "T. Ai, Zhenlu Yang, Hongyan Hou, Chenao Zhan, Chong Chen",
    "abstract": "Background Chest CT is used for diagnosis of 2019 novel coronavirus disease (COVID-19), as an important complement to the reverse-transcription polymerase chain reaction (RT-PCR) tests. Purpose To investigate the diagnostic value and consistency of chest CT as compared with comparison to RT-PCR assay in COVID-19. Methods From January 6 to February 6, 2020, 1014 patients in Wuhan, China who underwent both chest CT and RT-PCR tests were included. With RT-PCR as reference standard, the performance of chest CT in diagnosing COVID-19 was assessed. Besides, for patients with multiple RT-PCR assays, the dynamic conversion of RT-PCR results (negative to positive, positive to negative, respectively) was analyzed as compared with serial chest CT scans for those with time-interval of 4 days or more. Results Of 1014 patients, 59% (601/1014) had positive RT-PCR results, and 88% (888/1014) had positive chest CT scans. The sensitivity of chest CT in suggesting COVID-19 was 97% (95%CI, 95-98%, 580/601 patients) based on positive RT-PCR results. In patients with negative RT-PCR results, 75% (308/413) had positive chest CT findings; of 308, 48% were considered as highly likely cases, with 33% as probable cases. By analysis of serial RT-PCR assays and CT scans, the mean interval time between the initial negative to positive RT-PCR results was 5.1 ± 1.5 days; the initial positive to subsequent negative RT-PCR result was 6.9 ± 2.3 days). 60% to 93% of cases had initial positive CT consistent with COVID-19 prior (or parallel) to the initial positive RT-PCR results. 42% (24/57) cases showed improvement in follow-up chest CT scans before the RT-PCR results turning negative. Conclusion Chest CT has a high sensitivity for diagnosis of COVID-19. Chest CT may be considered as a primary tool for the current COVID-19 detection in epidemic areas. A translation of this abstract in Farsi is available in the supplement. - ترجمه چکیده این مقاله به فارسی، در ضمیمه موجود است.",
    "citationCount": 5473,
    "pdf_filename": "2020_Correlation_of_Chest_CT_and_RT_PCR_Testi_754eef84.pdf"
  },
  "d3135733aa39dec20ce72aa138589dda27c8406d": {
    "paperId": "d3135733aa39dec20ce72aa138589dda27c8406d",
    "title": "Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering",
    "year": 2022,
    "authors": "Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang",
    "abstract": "When answering a question, humans utilize the information available across different modalities to synthesize a consistent and complete chain of thought (CoT). This process is normally a black box in the case of deep learning models like large-scale language models. Recently, science question benchmarks have been used to diagnose the multi-hop reasoning ability and interpretability of an AI system. However, existing datasets fail to provide annotations for the answers, or are restricted to the textual-only modality, small scales, and limited domain diversity. To this end, we present Science Question Answering (ScienceQA), a new benchmark that consists of ~21k multimodal multiple choice questions with a diverse set of science topics and annotations of their answers with corresponding lectures and explanations. We further design language models to learn to generate lectures and explanations as the chain of thought (CoT) to mimic the multi-hop reasoning process when answering ScienceQA questions. ScienceQA demonstrates the utility of CoT in language models, as CoT improves the question answering performance by 1.20% in few-shot GPT-3 and 3.99% in fine-tuned UnifiedQA. We also explore the upper bound for models to leverage explanations by feeding those in the input; we observe that it improves the few-shot performance of GPT-3 by 18.96%. Our analysis further shows that language models, similar to humans, benefit from explanations to learn from fewer data and achieve the same performance with just 40% of the data. The data and code are available at https://scienceqa.github.io.",
    "citationCount": 1784,
    "pdf_filename": "2022_Learn_to_Explain__Multimodal_Reasoning_v_d3135733.pdf"
  },
  "964bd39b546f0f6625ff3b9ef1083f797807ef2e": {
    "paperId": "964bd39b546f0f6625ff3b9ef1083f797807ef2e",
    "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model",
    "year": 2022,
    "authors": "Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili'c",
    "abstract": "Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.",
    "citationCount": 2698,
    "pdf_filename": "2022_BLOOM__A_176B_Parameter_Open_Access_Mult_964bd39b.pdf"
  },
  "d7f1a885e32faa2194ccd5f85da4c4fb5d788392": {
    "paperId": "d7f1a885e32faa2194ccd5f85da4c4fb5d788392",
    "title": "Explainability for artificial intelligence in healthcare: a multidisciplinary perspective",
    "year": 2020,
    "authors": "J. Amann, A. Blasimme, E. Vayena, D. Frey, V. Madai",
    "abstract": "Background Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice. Methods Taking AI-based clinical decision support systems as a case in point, we adopted a multidisciplinary approach to analyze the relevance of explainability for medical AI from the technological, legal, medical, and patient perspectives. Drawing on the findings of this conceptual analysis, we then conducted an ethical assessment using the “Principles of Biomedical Ethics” by Beauchamp and Childress (autonomy, beneficence, nonmaleficence, and justice) as an analytical framework to determine the need for explainability in medical AI. Results Each of the domains highlights a different set of core considerations and values that are relevant for understanding the role of explainability in clinical practice. From the technological point of view, explainability has to be considered both in terms how it can be achieved and what is beneficial from a development perspective. When looking at the legal perspective we identified informed consent, certification and approval as medical devices, and liability as core touchpoints for explainability. Both the medical and patient perspectives emphasize the importance of considering the interplay between human actors and medical AI. We conclude that omitting explainability in clinical decision support systems poses a threat to core ethical values in medicine and may have detrimental consequences for individual and public health. Conclusions To ensure that medical AI lives up to its promises, there is a need to sensitize developers, healthcare professionals, and legislators to the challenges and limitations of opaque algorithms in medical AI and to foster multidisciplinary collaboration moving forward.",
    "citationCount": 1207,
    "pdf_filename": "2020_Explainability_for_artificial_intelligen_d7f1a885.pdf"
  },
  "9c145390e6073c96e89cf03d3df3b559f0bb0496": {
    "paperId": "9c145390e6073c96e89cf03d3df3b559f0bb0496",
    "title": "Artificial Intelligence and Management: The Automation–Augmentation Paradox",
    "year": 2020,
    "authors": "Sebastian Raisch, Sebastian Krakowski",
    "abstract": "Taking three recent business books on artificial intelligence (AI) as a starting point, we explore the automation and augmentation concepts in the management domain. Whereas automation implies that...",
    "citationCount": 1105,
    "pdf_filename": "2020_Artificial_Intelligence_and_Management___9c145390.pdf"
  },
  "f03333b06c1b2e356dcc03f6bd3ef3d849d531e5": {
    "paperId": "f03333b06c1b2e356dcc03f6bd3ef3d849d531e5",
    "title": "Federated Learning for Internet of Things: A Comprehensive Survey",
    "year": 2021,
    "authors": "Dinh C. Nguyen, Ming Ding, P. Pathirana, A. Seneviratne, Jun Li",
    "abstract": "The Internet of Things (IoT) is penetrating many facets of our daily life with the proliferation of intelligent services and applications empowered by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may not be feasible in realistic application scenarios due to the high scalability of modern IoT networks and growing data privacy concerns. Federated Learning (FL) has emerged as a distributed collaborative AI approach that can enable many intelligent IoT applications, by allowing for AI training at distributed IoT devices without the need for data sharing. In this article, we provide a comprehensive survey of the emerging applications of FL in IoT networks, beginning from an introduction to the recent advances in FL and IoT to a discussion of their integration. Particularly, we explore and analyze the potential of FL for enabling a wide range of IoT services, including IoT data sharing, data offloading and caching, attack detection, localization, mobile crowdsensing, and IoT privacy and security. We then provide an extensive survey of the use of FL in various key IoT applications such as smart healthcare, smart transportation, Unmanned Aerial Vehicles (UAVs), smart cities, and smart industry. The important lessons learned from this review of the FL-IoT services and applications are also highlighted. We complete this survey by highlighting the current challenges and possible directions for future research in this booming area.",
    "citationCount": 1103,
    "pdf_filename": "2021_Federated_Learning_for_Internet_of_Thing_f03333b0.pdf"
  },
  "481dd25896ac531707870c9b8c179cce20013401": {
    "paperId": "481dd25896ac531707870c9b8c179cce20013401",
    "title": "Towards Personalized Federated Learning",
    "year": 2021,
    "authors": "A. Tan, Han Yu, Li-zhen Cui, Qiang Yang",
    "abstract": "In parallel with the rapid adoption of artificial intelligence (AI) empowered by advances in AI research, there has been growing awareness and concerns of data privacy. Recent significant developments in the data regulation landscape have prompted a seismic shift in interest toward privacy-preserving AI. This has contributed to the popularity of Federated Learning (FL), the leading paradigm for the training of machine learning models on data silos in a privacy-preserving manner. In this survey, we explore the domain of personalized FL (PFL) to address the fundamental challenges of FL on heterogeneous data, a universal characteristic inherent in all real-world datasets. We analyze the key motivations for PFL and present a unique taxonomy of PFL techniques categorized according to the key challenges and personalization strategies in PFL. We highlight their key ideas, challenges, opportunities, and envision promising future trajectories of research toward a new PFL architectural design, realistic PFL benchmarking, and trustworthy PFL approaches.",
    "citationCount": 1072,
    "pdf_filename": "2021_Towards_Personalized_Federated_Learning_481dd258.pdf"
  },
  "a7a407968c13ced804a063259d72315a43b84f29": {
    "paperId": "a7a407968c13ced804a063259d72315a43b84f29",
    "title": "Artificial Intelligence in Education: A Review",
    "year": 2020,
    "authors": "Lijia Chen, Pingping Chen, Zhijian Lin",
    "abstract": "The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors’ duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students’ assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students’ needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning.",
    "citationCount": 1963,
    "pdf_filename": "2020_Artificial_Intelligence_in_Education__A__a7a40796.pdf"
  },
  "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6": {
    "paperId": "020bb2ba5f3923858cd6882ba5c5a44ea8041ab6",
    "title": "Meta-Learning in Neural Networks: A Survey",
    "year": 2020,
    "authors": "Timothy M. Hospedales, Antreas Antoniou, P. Micaelli, A. Storkey",
    "abstract": "The field of meta-learning, or learning-to-learn, has seen a dramatic rise in interest in recent years. Contrary to conventional approaches to AI where tasks are solved from scratch using a fixed learning algorithm, meta-learning aims to improve the learning algorithm itself, given the experience of multiple learning episodes. This paradigm provides an opportunity to tackle many conventional challenges of deep learning, including data and computation bottlenecks, as well as generalization. This survey describes the contemporary meta-learning landscape. We first discuss definitions of meta-learning and position it with respect to related fields, such as transfer learning and hyperparameter optimization. We then propose a new taxonomy that provides a more comprehensive breakdown of the space of meta-learning methods today. We survey promising applications and successes of meta-learning such as few-shot learning and reinforcement learning. Finally, we discuss outstanding challenges and promising areas for future research.",
    "citationCount": 2324,
    "pdf_filename": "2020_Meta_Learning_in_Neural_Networks__A_Surv_020bb2ba.pdf"
  },
  "ef0c62ff070a476f216fe478cc190c773f12a1f6": {
    "paperId": "ef0c62ff070a476f216fe478cc190c773f12a1f6",
    "title": "Human Trust in Artificial Intelligence: Review of Empirical Research",
    "year": 2020,
    "authors": "Ella Glikson, A. Woolley",
    "abstract": "Artificial intelligence (AI) characterizes a new generation of technologies capable of interacting with the environment and aiming to simulate human intelligence. The success of integrating AI into...",
    "citationCount": 1442,
    "pdf_filename": "2020_Human_Trust_in_Artificial_Intelligence___ef0c62ff.pdf"
  },
  "df9b2d432cc3735927d9eb44aec214c07fd4f240": {
    "paperId": "df9b2d432cc3735927d9eb44aec214c07fd4f240",
    "title": "Global, Regional, and National Burden of CKD due to Glomerulonephritis from 1990 to 2019",
    "year": 2022,
    "authors": "Ju-Lan Hu, Runjiang Ke, Wilhem M. S. Teixeira, Yimin Dong, R. Ding",
    "abstract": "Visual Abstract Background CKD is becoming a major human health concern. Limited quantitative assessments of the burden of CKD due to glomerulonephritis have been performed. We performed a comprehensive analysis of the disease burden to update the epidemiology of this disease. Methods Incidence, prevalence, deaths, and disability-adjusted life-years (DALYs) data and percent changes in these indicators were extracted from Global Burden of Disease Study 2019 to analyze the burden of CKD due to glomerulonephritis. Results Globally, there were 606,300 (95% uncertainty interval [UI], 560,100 to 658,100) incident patients, 17,300,000 (95% UI, 16,100,000 to 18,600,000) prevalent patients, 183,700 (95% UI, 146,300 to 228,900) deaths, and 6,900,000 (95% UI, 5,900,000 to 8,100,000) DALYs of CKD due to glomerulonephritis in 2019. Compared with those in 1990, the numbers of incident patients, prevalent patients, deaths, and DALYs increased by 77%, 81%, 100%, and 66%, respectively. Most of the disease burden was concentrated in countries with lower sociodemographic index. In Central Latin America, the disease burden was much higher than expected on the basis of its sociodemographic index. Decomposition analysis showed that population aging and growth were the two major drivers of the increase in DALYs. Frontier analysis revealed considerable opportunities to reduce the age-standardized DALYs in the middle of the sociodemographic-index spectrum. Although middle-aged and elderly individuals accounted for the majority of the disease burden, the highest incidence rate was observed in children aged 1–4 years. Conclusions The disease burden of CKD due to glomerulonephritis has increased worldwide, especially in regions and countries with lower sociodemographic indexes.",
    "citationCount": 2024,
    "pdf_filename": "2022_Global__Regional__and_National_Burden_of_df9b2d43.pdf"
  },
  "3def68bd0f856886d34272840a7f81588f2bc082": {
    "paperId": "3def68bd0f856886d34272840a7f81588f2bc082",
    "title": "Survey of Hallucination in Natural Language Generation",
    "year": 2022,
    "authors": "Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, D. Su",
    "abstract": "Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.",
    "citationCount": 3275,
    "pdf_filename": "2022_Survey_of_Hallucination_in_Natural_Langu_3def68bd.pdf"
  },
  "4e95ce827049a350819c5c87caf992f27f9ff792": {
    "paperId": "4e95ce827049a350819c5c87caf992f27f9ff792",
    "title": "Review of Artificial Intelligence Techniques in Imaging Data Acquisition, Segmentation, and Diagnosis for COVID-19",
    "year": 2020,
    "authors": "Feng Shi, Jun Wang, Jun Shi, Zi-xiang Wu, Qian Wang",
    "abstract": "The pandemic of coronavirus disease 2019 (COVID-19) is spreading all over the world. Medical imaging such as X-ray and computed tomography (CT) plays an essential role in the global fight against COVID-19, whereas the recently emerging artificial intelligence (AI) technologies further strengthen the power of the imaging tools and help medical specialists. We hereby review the rapid responses in the community of medical imaging (empowered by AI) toward COVID-19. For example, AI-empowered image acquisition can significantly help automate the scanning procedure and also reshape the workflow with minimal contact to patients, providing the best protection to the imaging technicians. Also, AI can improve work efficiency by accurate delineation of infections in X-ray and CT images, facilitating subsequent quantification. Moreover, the computer-aided platforms help radiologists make clinical decisions, i.e., for disease diagnosis, tracking, and prognosis. In this review paper, we thus cover the entire pipeline of medical imaging and analysis techniques involved with COVID-19, including image acquisition, segmentation, diagnosis, and follow-up. We particularly focus on the integration of AI with X-ray and CT, both of which are widely used in the frontline hospitals, in order to depict the latest progress of medical imaging and radiology fighting against COVID-19.",
    "citationCount": 1088,
    "pdf_filename": "2020_Review_of_Artificial_Intelligence_Techni_4e95ce82.pdf"
  },
  "68f141724814839d556a989646194be88641b143": {
    "paperId": "68f141724814839d556a989646194be88641b143",
    "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
    "year": 2021,
    "authors": "Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann",
    "abstract": "Language modelling provides a step towards intelligent communication systems by harnessing large repositories of written human knowledge to better predict and understand the world. In this paper, we present an analysis of Transformer-based language model performance across a wide range of model scales -- from models with tens of millions of parameters up to a 280 billion parameter model called Gopher. These models are evaluated on 152 diverse tasks, achieving state-of-the-art performance across the majority. Gains from scale are largest in areas such as reading comprehension, fact-checking, and the identification of toxic language, but logical and mathematical reasoning see less benefit. We provide a holistic analysis of the training dataset and model's behaviour, covering the intersection of model scale with bias and toxicity. Finally we discuss the application of language models to AI safety and the mitigation of downstream harms.",
    "citationCount": 1484,
    "pdf_filename": "2021_Scaling_Language_Models__Methods__Analys_68f14172.pdf"
  },
  "76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2": {
    "paperId": "76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2",
    "title": "On the Opportunities and Risks of Foundation Models",
    "year": 2021,
    "authors": "Rishi Bommasani, Drew A. Hudson, E. Adeli, R. Altman, Simran Arora",
    "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
    "citationCount": 5489,
    "pdf_filename": "2021_On_the_Opportunities_and_Risks_of_Founda_76e9e2ec.pdf"
  },
  "723f06ba33b2fdaabfe5845b0c25568edcffd4e9": {
    "paperId": "723f06ba33b2fdaabfe5845b0c25568edcffd4e9",
    "title": "Coronavirus Disease 2019 Case Surveillance — United States, January 22–May 30, 2020",
    "year": 2020,
    "authors": "Erin K. Stokes, Laura D. Zambrano, Kayla N Anderson, E. Marder, Kala M. Raz",
    "abstract": "The coronavirus disease 2019 (COVID-19) pandemic resulted in 5,817,385 reported cases and 362,705 deaths worldwide through May, 30, 2020,† including 1,761,503 aggregated reported cases and 103,700 deaths in the United States.§ Previous analyses during February-early April 2020 indicated that age ≥65 years and underlying health conditions were associated with a higher risk for severe outcomes, which were less common among children aged <18 years (1-3). This report describes demographic characteristics, underlying health conditions, symptoms, and outcomes among 1,320,488 laboratory-confirmed COVID-19 cases individually reported to CDC during January 22-May 30, 2020. Cumulative incidence, 403.6 cases per 100,000 persons,¶ was similar among males (401.1) and females (406.0) and highest among persons aged ≥80 years (902.0). Among 599,636 (45%) cases with known information, 33% of persons were Hispanic or Latino of any race (Hispanic), 22% were non-Hispanic black (black), and 1.3% were non-Hispanic American Indian or Alaska Native (AI/AN). Among 287,320 (22%) cases with sufficient data on underlying health conditions, the most common were cardiovascular disease (32%), diabetes (30%), and chronic lung disease (18%). Overall, 184,673 (14%) patients were hospitalized, 29,837 (2%) were admitted to an intensive care unit (ICU), and 71,116 (5%) died. Hospitalizations were six times higher among patients with a reported underlying condition (45.4%) than those without reported underlying conditions (7.6%). Deaths were 12 times higher among patients with reported underlying conditions (19.5%) compared with those without reported underlying conditions (1.6%). The COVID-19 pandemic continues to be severe, particularly in certain population groups. These preliminary findings underscore the need to build on current efforts to collect and analyze case data, especially among those with underlying health conditions. These data are used to monitor trends in COVID-19 illness, identify and respond to localized incidence increase, and inform policies and practices designed to reduce transmission in the United States.",
    "citationCount": 1277,
    "pdf_filename": "2020_Coronavirus_Disease_2019_Case_Surveillan_723f06ba.pdf"
  },
  "979a9f247700d00ff2c3f0612d5eb001379f93c8": {
    "paperId": "979a9f247700d00ff2c3f0612d5eb001379f93c8",
    "title": "The Medical Segmentation Decathlon",
    "year": 2021,
    "authors": "M. Antonelli, Annika Reinke, S. Bakas, K. Farahani, AnnetteKopp-Schneider",
    "abstract": "International challenges have become the de facto standard for comparative assessment of image analysis algorithms. Although segmentation is the most widely investigated medical image processing task, the various challenges have been organized to focus only on specific clinical tasks. We organized the Medical Segmentation Decathlon (MSD)—a biomedical image analysis challenge, in which algorithms compete in a multitude of both tasks and modalities to investigate the hypothesis that a method capable of performing well on multiple tasks will generalize well to a previously unseen task and potentially outperform a custom-designed solution. MSD results confirmed this hypothesis, moreover, MSD winner continued generalizing well to a wide range of other clinical problems for the next two years. Three main conclusions can be drawn from this study: (1) state-of-the-art image segmentation algorithms generalize well when retrained on unseen tasks; (2) consistent algorithmic performance across multiple tasks is a strong surrogate of algorithmic generalizability; (3) the training of accurate AI segmentation models is now commoditized to scientists that are not versed in AI model training. International challenges have become the de facto standard for comparative assessment of image analysis algorithms. Here, the authors present the results of a biomedical image segmentation challenge, showing that a method capable of performing well on multiple tasks will generalize well to a previously unseen task.",
    "citationCount": 1209,
    "pdf_filename": "2021_The_Medical_Segmentation_Decathlon_979a9f24.pdf"
  },
  "6737c2627bcad064410a48f8077e3ca455fa0639": {
    "paperId": "6737c2627bcad064410a48f8077e3ca455fa0639",
    "title": "Guidelines for the use and interpretation of assays for monitoring autophagy (4th edition)1",
    "year": 2021,
    "authors": "D. Klionsky, A. K. Abdel-Aziz, Sara Abdelfatah, M. Abdellatif, A. Abdoli",
    "abstract": "ABSTRACT In 2008, we published the first set of guidelines for standardizing research in autophagy. Since then, this topic has received increasing attention, and many scientists have entered the field. Our knowledge base and relevant new technologies have also been expanding. Thus, it is important to formulate on a regular basis updated guidelines for monitoring autophagy in different organisms. Despite numerous reviews, there continues to be confusion regarding acceptable methods to evaluate autophagy, especially in multicellular eukaryotes. Here, we present a set of guidelines for investigators to select and interpret methods to examine autophagy and related processes, and for reviewers to provide realistic and reasonable critiques of reports that are focused on these processes. These guidelines are not meant to be a dogmatic set of rules, because the appropriateness of any assay largely depends on the question being asked and the system being used. Moreover, no individual assay is perfect for every situation, calling for the use of multiple techniques to properly monitor autophagy in each experimental setting. Finally, several core components of the autophagy machinery have been implicated in distinct autophagic processes (canonical and noncanonical autophagy), implying that genetic approaches to block autophagy should rely on targeting two or more autophagy-related genes that ideally participate in distinct steps of the pathway. Along similar lines, because multiple proteins involved in autophagy also regulate other cellular pathways including apoptosis, not all of them can be used as a specific marker for bona fide autophagic responses. Here, we critically discuss current methods of assessing autophagy and the information they can, or cannot, provide. Our ultimate goal is to encourage intellectual and technical innovation in the field.",
    "citationCount": 3644,
    "pdf_filename": "2021_Guidelines_for_the_use_and_interpretatio_6737c262.pdf"
  },
  "5b9d8bcc46b766b47389c912a8e026f81b91b0d8": {
    "paperId": "5b9d8bcc46b766b47389c912a8e026f81b91b0d8",
    "title": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
    "year": 2020,
    "authors": "Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li",
    "abstract": "Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting (LSTF) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efficiently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to LSTF, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efficient transformer-based model for LSTF, named Informer, with three distinctive characteristics: (i) a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences' dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efficiently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer significantly outperforms existing methods and provides a new solution to the LSTF problem.",
    "citationCount": 5779,
    "pdf_filename": "2020_Informer__Beyond_Efficient_Transformer_f_5b9d8bcc.pdf"
  },
  "9073548cdcac4aeb64d767bfbe850f25ffaf9ebd": {
    "paperId": "9073548cdcac4aeb64d767bfbe850f25ffaf9ebd",
    "title": "Global, Regional, and National Levels and Trends in Burden of Oral Conditions from 1990 to 2017: A Systematic Analysis for the Global Burden of Disease 2017 Study",
    "year": 2020,
    "authors": "E. Bernabé, W. Marcenes, C. Hernández, J. Bailey, L. Abreu",
    "abstract": "Government and nongovernmental organizations need national and global estimates on the descriptive epidemiology of common oral conditions for policy planning and evaluation. The aim of this component of the Global Burden of Disease study was to produce estimates on prevalence, incidence, and years lived with disability for oral conditions from 1990 to 2017 by sex, age, and countries. In addition, this study reports the global socioeconomic pattern in burden of oral conditions by the standard World Bank classification of economies as well as the Global Burden of Disease Socio-demographic Index. The findings show that oral conditions remain a substantial population health challenge. Globally, there were 3.5 billion cases (95% uncertainty interval [95% UI], 3.2 to 3.7 billion) of oral conditions, of which 2.3 billion (95% UI, 2.1 to 2.5 billion) had untreated caries in permanent teeth, 796 million (95% UI, 671 to 930 million) had severe periodontitis, 532 million (95% UI, 443 to 622 million) had untreated caries in deciduous teeth, 267 million (95% UI, 235 to 300 million) had total tooth loss, and 139 million (95% UI, 133 to 146 million) had other oral conditions in 2017. Several patterns emerged when the World Bank’s classification of economies and the Socio-demographic Index were used as indicators of economic development. In general, more economically developed countries have the lowest burden of untreated dental caries and severe periodontitis and the highest burden of total tooth loss. The findings offer an opportunity for policy makers to identify successful oral health strategies and strengthen them; introduce and monitor different approaches where oral diseases are increasing; plan integration of oral health in the agenda for prevention of noncommunicable diseases; and estimate the cost of providing universal coverage for dental care.",
    "citationCount": 1022,
    "pdf_filename": "2020_Global__Regional__and_National_Levels_an_9073548c.pdf"
  },
  "f273a5aaf20e7a87a3fedcdded2f693390bd24ef": {
    "paperId": "f273a5aaf20e7a87a3fedcdded2f693390bd24ef",
    "title": "Cancer Incidence, Mortality, Years of Life Lost, Years Lived With Disability, and Disability-Adjusted Life Years for 29 Cancer Groups From 2010 to 2019",
    "year": 2021,
    "authors": "Jonathan M Kocarnik, K. Compton, Frances Dean, Weijia Fu, Brian Gaw",
    "abstract": "Key Points Question What was the burden of cancer globally and across Sociodemographic Index (SDI) groupings in 2019, and how has incidence, morbidity, and mortality changed since 2010? Findings In this systematic analysis, there were 23.6 million new global cancer cases in 2019 (17.2 million when excluding those with nonmelanoma skin cancer), 10.0 million cancer deaths, and an estimated 250 million disability-adjusted life years estimated to be due to cancer; since 2010, these represent increases of 26.3%, 20.9%, and 16.0%, respectively. Absolute cancer burden increased in all SDI quintiles since 2010, but the largest percentage increases occurred in the low and low-middle SDI quintiles. Meanings The study results suggest that increased cancer prevention and control efforts are needed to equitably address the evolving and increasing burden of cancer across the SDI spectrum.",
    "citationCount": 1450,
    "pdf_filename": "2021_Cancer_Incidence__Mortality__Years_of_Li_f273a5aa.pdf"
  },
  "d5fd1dc358316904069275d3b6cbff3141e021e0": {
    "paperId": "d5fd1dc358316904069275d3b6cbff3141e021e0",
    "title": "Towards 6G wireless communication networks: vision, enabling technologies, and new paradigm shifts",
    "year": 2020,
    "authors": "X. You, Cheng-Xiang Wang, Jie Huang, Xiqi Gao, Zaichen Zhang",
    "abstract": "The fifth generation (5G) wireless communication networks are being deployed worldwide from 2020 and more capabilities are in the process of being standardized, such as mass connectivity, ultra-reliability, and guaranteed low latency. However, 5G will not meet all requirements of the future in 2030 and beyond, and sixth generation (6G) wireless communication networks are expected to provide global coverage, enhanced spectral/energy/cost efficiency, better intelligence level and security, etc. To meet these requirements, 6G networks will rely on new enabling technologies, i.e., air interface and transmission technologies and novel network architecture, such as waveform design, multiple access, channel coding schemes, multi-antenna technologies, network slicing, cell-free architecture, and cloud/fog/edge computing. Our vision on 6G is that it will have four new paradigm shifts. First, to satisfy the requirement of global coverage, 6G will not be limited to terrestrial communication networks, which will need to be complemented with non-terrestrial networks such as satellite and unmanned aerial vehicle (UAV) communication networks, thus achieving a space-air-ground-sea integrated communication network. Second, all spectra will be fully explored to further increase data rates and connection density, including the sub-6 GHz, millimeter wave (mmWave), terahertz (THz), and optical frequency bands. Third, facing the big datasets generated by the use of extremely heterogeneous networks, diverse communication scenarios, large numbers of antennas, wide bandwidths, and new service requirements, 6G networks will enable a new range of smart applications with the aid of artificial intelligence (AI) and big data technologies. Fourth, network security will have to be strengthened when developing 6G networks. This article provides a comprehensive survey of recent advances and future trends in these four aspects. Clearly, 6G with additional technical requirements beyond those of 5G will enable faster and further communications to the extent that the boundary between physical and cyber worlds disappears.",
    "citationCount": 1588,
    "pdf_filename": "2020_Towards_6G_wireless_communication_networ_d5fd1dc3.pdf"
  },
  "ca8682aa3ce8cf869dbaed25bc9bb5fe52d92207": {
    "paperId": "ca8682aa3ce8cf869dbaed25bc9bb5fe52d92207",
    "title": "Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective",
    "year": 2022,
    "authors": "",
    "abstract": "The article presents a critical analysis of the theories and practices of scientific objectivity and outlines a promising feminist concept of objectivity. The author begins by criticizing two mainstream approaches to a feminist evaluation of scientific objectivity: a social constructionism combining the techniques of semiology and deconstruction, and a feminist empiricism. The former insists on the rhetorical nature of truth existing in the power field of a textualized world, while the latter legitimizes scientific objectivity adjusted for the results of gender analysis to yield a “successor science.” Rehabilitating the metaphor of vision resolves the dichotomy between the historical contingency of knowledge claims and subjects and the trust in scientific explanations of the “real” world. Any vision is embodied and therefore presupposes a location in the world. Consequently, the objectivity sought is inevitably embodied, and knowledge is situated and local, always associated with some place or position.\nHaraway subscribes to the constructivist critique of disembodied scientific objectivity and adds that it is an example of the “god trick” in which objectivity is a view “from above” or “from nowhere,” from outside the field of particular positions so that the scientist is distanced from the object of research. The point of view — of a human, any living being, or a machine — is an allegory for feminist objectivity. But in contrast to positioning approaches, the objectivity promised does not consist in identification with another position, but rather in a partial connection: to see together with the other, without claiming to be other. Situated knowledge from a partial perspective does not monopolize the truth by ontologizing subjugation but instead opens a way to learn how others see. Thus, only a partial perspective combined with others of the same kind can guarantee objectivity and accountability. However, the shared conversation on which rational knowledge is based should not be limited only to human beings. Any object of knowledge, Haraway argues, even when mediated by technologies for visualization, has agency, is active and is a generative node for meaning. The idea of material-semiotic actors whose boundaries are materialized in social interactions is introduced to conceptualize this kind of agency.",
    "citationCount": 3262,
    "pdf_filename": "2022_Situated_Knowledges__The_Science_Questio_ca8682aa.pdf"
  },
  "bdba3bd30a49ea4c5b20b43dbd8f0eb59e9d80e2": {
    "paperId": "bdba3bd30a49ea4c5b20b43dbd8f0eb59e9d80e2",
    "title": "Diffusion policy: Visuomotor policy learning via action diffusion",
    "year": 2023,
    "authors": "Cheng Chi, S. Feng, Yilun Du, Zhenjia Xu, Eric Cousineau",
    "abstract": "This paper introduces Diffusion Policy, a new way of generating robot behavior by representing a robot’s visuomotor policy as a conditional denoising diffusion process. We benchmark Diffusion Policy across 15 different tasks from 4 different robot manipulation benchmarks and find that it consistently outperforms existing state-of-the-art robot learning methods with an average improvement of 46.9%. Diffusion Policy learns the gradient of the action-distribution score function and iteratively optimizes with respect to this gradient field during inference via a series of stochastic Langevin dynamics steps. We find that the diffusion formulation yields powerful advantages when used for robot policies, including gracefully handling multimodal action distributions, being suitable for high-dimensional action spaces, and exhibiting impressive training stability. To fully unlock the potential of diffusion models for visuomotor policy learning on physical robots, this paper presents a set of key technical contributions including the incorporation of receding horizon control, visual conditioning, and the time-series diffusion transformer. We hope this work will help motivate a new generation of policy learning techniques that are able to leverage the powerful generative modeling capabilities of diffusion models. Code, data, and training details are available (diffusion-policy.cs.columbia.edu).",
    "citationCount": 2067,
    "pdf_filename": "2023_Diffusion_policy__Visuomotor_policy_lear_bdba3bd3.pdf"
  },
  "e632b5e4f2ff99e313f0bf86ac461075412d823b": {
    "paperId": "e632b5e4f2ff99e313f0bf86ac461075412d823b",
    "title": "Prevalence and Characteristics of Autism Spectrum Disorder Among Children Aged 8 Years — Autism and Developmental Disabilities Monitoring Network, 11 Sites, United States, 2020",
    "year": 2023,
    "authors": "M. Maenner, Z. Warren, Ashley Robinson Williams, E. Amoakohene, A. Bakian",
    "abstract": "Problem/Condition Autism spectrum disorder (ASD). Period Covered 2020. Description of System The Autism and Developmental Disabilities Monitoring (ADDM) Network is an active surveillance program that provides estimates of the prevalence of ASD among children aged 8 years. In 2020, there were 11 ADDM Network sites across the United States (Arizona, Arkansas, California, Georgia, Maryland, Minnesota, Missouri, New Jersey, Tennessee, Utah, and Wisconsin). To ascertain ASD among children aged 8 years, ADDM Network staff review and abstract developmental evaluations and records from community medical and educational service providers. A child met the case definition if their record documented 1) an ASD diagnostic statement in an evaluation, 2) a classification of ASD in special education, or 3) an ASD International Classification of Diseases (ICD) code. Results For 2020, across all 11 ADDM sites, ASD prevalence per 1,000 children aged 8 years ranged from 23.1 in Maryland to 44.9 in California. The overall ASD prevalence was 27.6 per 1,000 (one in 36) children aged 8 years and was 3.8 times as prevalent among boys as among girls (43.0 versus 11.4). Overall, ASD prevalence was lower among non-Hispanic White children (24.3) and children of two or more races (22.9) than among non-Hispanic Black or African American (Black), Hispanic, and non-Hispanic Asian or Pacific Islander (A/PI) children (29.3, 31.6, and 33.4 respectively). ASD prevalence among non-Hispanic American Indian or Alaska Native (AI/AN) children (26.5) was similar to that of other racial and ethnic groups. ASD prevalence was associated with lower household income at three sites, with no association at the other sites. Across sites, the ASD prevalence per 1,000 children aged 8 years based exclusively on documented ASD diagnostic statements was 20.6 (range = 17.1 in Wisconsin to 35.4 in California). Of the 6,245 children who met the ASD case definition, 74.7% had a documented diagnostic statement of ASD, 65.2% had a documented ASD special education classification, 71.6% had a documented ASD ICD code, and 37.4% had all three types of ASD indicators. The median age of earliest known ASD diagnosis was 49 months and ranged from 36 months in California to 59 months in Minnesota. Among the 4,165 (66.7%) children with ASD with information on cognitive ability, 37.9% were classified as having an intellectual disability. Intellectual disability was present among 50.8% of Black, 41.5% of A/PI, 37.8% of two or more races, 34.9% of Hispanic, 34.8% of AI/AN, and 31.8% of White children with ASD. Overall, children with intellectual disability had earlier median ages of ASD diagnosis (43 months) than those without intellectual disability (53 months). Interpretation For 2020, one in 36 children aged 8 years (approximately 4% of boys and 1% of girls) was estimated to have ASD. These estimates are higher than previous ADDM Network estimates during 2000–2018. For the first time among children aged 8 years, the prevalence of ASD was lower among White children than among other racial and ethnic groups, reversing the direction of racial and ethnic differences in ASD prevalence observed in the past. Black children with ASD were still more likely than White children with ASD to have a co-occurring intellectual disability. Public Health Action The continued increase among children identified with ASD, particularly among non-White children and girls, highlights the need for enhanced infrastructure to provide equitable diagnostic, treatment, and support services for all children with ASD. Similar to previous reporting periods, findings varied considerably across network sites, indicating the need for additional research to understand the nature of such differences and potentially apply successful identification strategies across states.",
    "citationCount": 1714,
    "pdf_filename": "2023_Prevalence_and_Characteristics_of_Autism_e632b5e4.pdf"
  },
  "16de2006e2960ba410772c6b6d460b83c0a5cc4b": {
    "paperId": "16de2006e2960ba410772c6b6d460b83c0a5cc4b",
    "title": "Reproducible Scaling Laws for Contrastive Language-Image Learning",
    "year": 2022,
    "authors": "Mehdi Cherti, R. Beaumont, Ross Wightman, Mitchell Wortsman, Gabriel Ilharco",
    "abstract": "Scaling up neural networks has led to remarkable performance across a wide range of tasks. Moreover, performance often follows reliable scaling laws as a function of training set size, model size, and compute, which offers valuable guidance as large-scale experiments are becoming increasingly expensive. However, previous work on scaling laws has primarily used private data & models or focused on uni-modal language or vision learning. To address these limitations, we investigate scaling laws for contrastive language-image pre-training (CLIP) with the public LAION dataset and the open-source OpenCLIP repository. Our large-scale experiments involve models trained on up to two billion image-text pairs and identify power law scaling for multiple downstream tasks including zero-shot classification, retrieval, linear probing, and end-to-end fine-tuning. We find that the training distribution plays a key role in scaling laws as the OpenAI and OpenCLIP models exhibit different scaling behavior despite identical model architectures and similar training recipes. We open-source our evaluation workflow and all models, including the largest public CLIP models, to ensure reproducibility and make scaling laws research more accessible. Source code and instructions to reproduce this study is available at https://github.eom/LAION-AI/sealing-laws-openelip.",
    "citationCount": 1107,
    "pdf_filename": "2022_Reproducible_Scaling_Laws_for_Contrastiv_16de2006.pdf"
  },
  "bc7e6165b00f0c39d40ca2c7a4eb33fcc0e3200d": {
    "paperId": "bc7e6165b00f0c39d40ca2c7a4eb33fcc0e3200d",
    "title": "Image Super-Resolution via Iterative Refinement",
    "year": 2021,
    "authors": "Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J. Fleet",
    "abstract": "We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models (Ho et al. 2020), (Sohl-Dickstein et al. 2015) to image-to-image translation, and performs super-resolution through a stochastic iterative denoising process. Output images are initialized with pure Gaussian noise and iteratively refined using a U-Net architecture that is trained on denoising at various noise levels, conditioned on a low-resolution input image. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ for which SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GAN baselines do not exceed a fool rate of 34%. We evaluate SR3 on a 4× super-resolution task on ImageNet, where SR3 outperforms baselines in human evaluation and classification accuracy of a ResNet-50 classifier trained on high-resolution images. We further show the effectiveness of SR3 in cascaded image generation, where a generative model is chained with super-resolution models to synthesize high-resolution images with competitive FID scores on the class-conditional 256×256 ImageNet generation challenge.",
    "citationCount": 2167,
    "pdf_filename": "2021_Image_Super_Resolution_via_Iterative_Ref_bc7e6165.pdf"
  },
  "3a906b77fa218adc171fecb28bb81c24c14dcc7b": {
    "paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b",
    "title": "Transformers in Vision: A Survey",
    "year": 2021,
    "authors": "Salman Hameed Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, F. Khan",
    "abstract": "Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks, e.g., Long short-term memory. Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text, and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers, i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization), and three-dimensional analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges toward the application of transformer models in computer vision.",
    "citationCount": 3033,
    "pdf_filename": "2021_Transformers_in_Vision__A_Survey_3a906b77.pdf"
  },
  "925ad2897d1b5decbea320d07e99afa9110e09b2": {
    "paperId": "925ad2897d1b5decbea320d07e99afa9110e09b2",
    "title": "Longformer: The Long-Document Transformer",
    "year": 2020,
    "authors": "Iz Beltagy, Matthew E. Peters, Arman Cohan",
    "abstract": "Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.",
    "citationCount": 4746,
    "pdf_filename": "2020_Longformer__The_Long_Document_Transforme_925ad289.pdf"
  },
  "1fa298e3f745099d39ca5bd088fcb62f87e8cc2f": {
    "paperId": "1fa298e3f745099d39ca5bd088fcb62f87e8cc2f",
    "title": "HunyuanVideo: A Systematic Framework For Large Video Generative Models",
    "year": 2024,
    "authors": "Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai",
    "abstract": "Recent advancements in video generation have significantly impacted daily life for both individuals and industries. However, the leading video generation models remain closed-source, resulting in a notable performance gap between industry capabilities and those available to the public. In this report, we introduce HunyuanVideo, an innovative open-source video foundation model that demonstrates performance in video generation comparable to, or even surpassing, that of leading closed-source models. HunyuanVideo encompasses a comprehensive framework that integrates several key elements, including data curation, advanced architectural design, progressive model scaling and training, and an efficient infrastructure tailored for large-scale model training and inference. As a result, we successfully trained a video generative model with over 13 billion parameters, making it the largest among all open-source models. We conducted extensive experiments and implemented a series of targeted designs to ensure high visual quality, motion dynamics, text-video alignment, and advanced filming techniques. According to evaluations by professionals, HunyuanVideo outperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6, and three top-performing Chinese video generative models. By releasing the code for the foundation model and its applications, we aim to bridge the gap between closed-source and open-source communities. This initiative will empower individuals within the community to experiment with their ideas, fostering a more dynamic and vibrant video generation ecosystem. The code is publicly available at https://github.com/Tencent/HunyuanVideo.",
    "citationCount": 671,
    "pdf_filename": "2024_HunyuanVideo__A_Systematic_Framework_For_1fa298e3.pdf"
  },
  "8877e9a5bf473404c35b758faa76905c202f0f36": {
    "paperId": "8877e9a5bf473404c35b758faa76905c202f0f36",
    "title": "Wan: Open and Advanced Large-Scale Video Generative Models",
    "year": 2025,
    "authors": "Ang Wang, Baole Ai, Bin Wen, Chaojie Mao, Chen-Wei Xie",
    "abstract": "This report presents Wan, a comprehensive and open suite of video foundation models designed to push the boundaries of video generation. Built upon the mainstream diffusion transformer paradigm, Wan achieves significant advancements in generative capabilities through a series of innovations, including our novel VAE, scalable pre-training strategies, large-scale data curation, and automated evaluation metrics. These contributions collectively enhance the model's performance and versatility. Specifically, Wan is characterized by four key features: Leading Performance: The 14B model of Wan, trained on a vast dataset comprising billions of images and videos, demonstrates the scaling laws of video generation with respect to both data and model size. It consistently outperforms the existing open-source models as well as state-of-the-art commercial solutions across multiple internal and external benchmarks, demonstrating a clear and significant performance superiority. Comprehensiveness: Wan offers two capable models, i.e., 1.3B and 14B parameters, for efficiency and effectiveness respectively. It also covers multiple downstream applications, including image-to-video, instruction-guided video editing, and personal video generation, encompassing up to eight tasks. Consumer-Grade Efficiency: The 1.3B model demonstrates exceptional resource efficiency, requiring only 8.19 GB VRAM, making it compatible with a wide range of consumer-grade GPUs. Openness: We open-source the entire series of Wan, including source code and all models, with the goal of fostering the growth of the video generation community. This openness seeks to significantly expand the creative possibilities of video production in the industry and provide academia with high-quality video foundation models. All the code and models are available at https://github.com/Wan-Video/Wan2.1.",
    "citationCount": 627,
    "pdf_filename": "2025_Wan__Open_and_Advanced_Large_Scale_Video_8877e9a5.pdf"
  },
  "4e9a8141da2a8c603722b07d096109207f8e0b66": {
    "paperId": "4e9a8141da2a8c603722b07d096109207f8e0b66",
    "title": "VBench: Comprehensive Benchmark Suite for Video Generative Models",
    "year": 2023,
    "authors": "Ziqi Huang, Yinan He, Jiashuo Yu, Fan Zhang, Chenyang Si",
    "abstract": "Video generation has witnessed significant advance-ments, yet evaluating these models remains a challenge. A comprehensive evaluation benchmark for video generation is indispensable for two reasons: 1) Existing metrics do not fully align with human perceptions; 2) An ideal eval-uation system should provide insights to inform future de-velopments of video generation. To this end, we present VBench, a comprehensive benchmark suite that dissects “video generation quality” into specific, hierarchical, and disentangled dimensions, each with tailored prompts and evaluation methods. VBench has three appealing proper-ties: 1) Comprehensive Dimensions: VBench comprises 16 dimensions in video generation (e.g., subject identity in-consistency, motion smoothness, temporal flickering, and spatial relationship, etc.). The evaluation metrics with fine-grained levels reveal individual models' strengths and weaknesses. 2) Human Alignment: We also provide a dataset of human preference annotations to validate our benchmarks' alignment with human perception, for each evaluation dimension respectively. 3) Valuable Insights: We look into current models' ability across various evaluation dimensions, and various content types. We also investi-gate the gaps between video and image generation models. We will open-source VBench, including all prompts, evaluation methods, generated videos, and human preference an-notations, and also include more video generation models in VBench to drive forward the field of video generation.",
    "citationCount": 866,
    "pdf_filename": "2023_VBench__Comprehensive_Benchmark_Suite_fo_4e9a8141.pdf"
  },
  "a57d47b762341340656d5b5caa84f370d9d31063": {
    "paperId": "a57d47b762341340656d5b5caa84f370d9d31063",
    "title": "GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images",
    "year": 2022,
    "authors": "Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, K. Yin",
    "abstract": "As several industries are moving towards modeling massive 3D virtual worlds, the need for content creation tools that can scale in terms of the quantity, quality, and diversity of 3D content is becoming evident. In our work, we aim to train performant 3D generative models that synthesize textured meshes which can be directly consumed by 3D rendering engines, thus immediately usable in downstream applications. Prior works on 3D generative modeling either lack geometric details, are limited in the mesh topology they can produce, typically do not support textures, or utilize neural renderers in the synthesis process, which makes their use in common 3D software non-trivial. In this work, we introduce GET3D, a Generative model that directly generates Explicit Textured 3D meshes with complex topology, rich geometric details, and high-fidelity textures. We bridge recent success in the differentiable surface modeling, differentiable rendering as well as 2D Generative Adversarial Networks to train our model from 2D image collections. GET3D is able to generate high-quality 3D textured meshes, ranging from cars, chairs, animals, motorbikes and human characters to buildings, achieving significant improvements over previous methods.",
    "citationCount": 546,
    "pdf_filename": "2022_GET3D__A_Generative_Model_of_High_Qualit_a57d47b7.pdf"
  },
  "7cbc2a7843411a1768ab762930707af0a3c33a19": {
    "paperId": "7cbc2a7843411a1768ab762930707af0a3c33a19",
    "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model",
    "year": 2022,
    "authors": "Shaden Smith, M. Patwary, Brandon Norick, P. LeGresley, Samyam Rajbhandari",
    "abstract": "Pretrained general-purpose language models can achieve state-of-the-art accuracies in various natural language processing domains by adapting to downstream tasks via zero-shot, few-shot and fine-tuning techniques. Because of their success, the size of these models has increased rapidly, requiring high-performance hardware, software, and algorithmic techniques to enable training such large models. As the result of a joint effort between Microsoft and NVIDIA, we present details on the training of the largest monolithic transformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530 billion parameters. In this paper, we first focus on the infrastructure as well as the 3D parallelism methodology used to train this model using DeepSpeed and Megatron. Next, we detail the training process, the design of our training corpus, and our data curation techniques, which we believe is a key ingredient to the success of the model. Finally, we discuss various evaluation results, as well as other interesting observations and new properties exhibited by MT-NLG. We demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning accuracies on several NLP benchmarks and establishes new state-of-the-art results. We believe that our contributions will help further the development of large-scale training infrastructures, large-scale language models, and natural language generations.",
    "citationCount": 803,
    "pdf_filename": "2022_Using_DeepSpeed_and_Megatron_to_Train_Me_7cbc2a78.pdf"
  },
  "0537c62e32299b8e9b4e3cac44d82ffa123cbbe1": {
    "paperId": "0537c62e32299b8e9b4e3cac44d82ffa123cbbe1",
    "title": "Disease variant prediction with deep generative models of evolutionary data",
    "year": 2021,
    "authors": "J. Frazer, Pascal Notin, M. Dias, Aidan N. Gomez, Joseph K. Min",
    "abstract": "Quantifying the pathogenicity of protein variants in human disease-related genes would have a marked effect on clinical decisions, yet the overwhelming majority (over 98%) of these variants still have unknown consequences1–3. In principle, computational methods could support the large-scale interpretation of genetic variants. However, state-of-the-art methods4–10 have relied on training machine learning models on known disease labels. As these labels are sparse, biased and of variable quality, the resulting models have been considered insufficiently reliable11. Here we propose an approach that leverages deep generative models to predict variant pathogenicity without relying on labels. By modelling the distribution of sequence variation across organisms, we implicitly capture constraints on the protein sequences that maintain fitness. Our model EVE (evolutionary model of variant effect) not only outperforms computational approaches that rely on labelled data but also performs on par with, if not better than, predictions from high-throughput experiments, which are increasingly used as evidence for variant classification12–16. We predict the pathogenicity of more than 36 million variants across 3,219 disease genes and provide evidence for the classification of more than 256,000 variants of unknown significance. Our work suggests that models of evolutionary information can provide valuable independent evidence for variant interpretation that will be widely useful in research and clinical settings. A new computational method, EVE, classifies human genetic variants in disease genes using deep generative models trained solely on evolutionary sequences.",
    "citationCount": 624,
    "pdf_filename": "2021_Disease_variant_prediction_with_deep_gen_0537c62e.pdf"
  },
  "f99de990f791799df398fcd38034c4b395d9b7e0": {
    "paperId": "f99de990f791799df398fcd38034c4b395d9b7e0",
    "title": "Skilful precipitation nowcasting using deep generative models of radar",
    "year": 2021,
    "authors": "Suman V. Ravuri, Karel Lenc, M. Willson, D. Kangin, Rémi R. Lam",
    "abstract": "Precipitation nowcasting, the high-resolution forecasting of precipitation up to two hours ahead, supports the real-world socioeconomic needs of many sectors reliant on weather-dependent decision-making1,2. State-of-the-art operational nowcasting methods typically advect precipitation fields with radar-based wind estimates, and struggle to capture important non-linear events such as convective initiations3,4. Recently introduced deep learning methods use radar to directly predict future rain rates, free of physical constraints5,6. While they accurately predict low-intensity rainfall, their operational utility is limited because their lack of constraints produces blurry nowcasts at longer lead times, yielding poor performance on rarer medium-to-heavy rain events. Here we present a deep generative model for the probabilistic nowcasting of precipitation from radar that addresses these challenges. Using statistical, economic and cognitive measures, we show that our method provides improved forecast quality, forecast consistency and forecast value. Our model produces realistic and spatiotemporally consistent predictions over regions up to 1,536 km × 1,280 km and with lead times from 5–90 min ahead. Using a systematic evaluation by more than 50 expert meteorologists, we show that our generative model ranked first for its accuracy and usefulness in 89% of cases against two competitive methods. When verified quantitatively, these nowcasts are skillful without resorting to blurring. We show that generative nowcasting can provide probabilistic predictions that improve forecast value and support operational utility, and at resolutions and lead times where alternative methods struggle. A deep generative model using radar observations is used to create skilful precipitation predictions that are accurate and support real-world utility.",
    "citationCount": 852,
    "pdf_filename": "2021_Skilful_precipitation_nowcasting_using_d_f99de990.pdf"
  },
  "04faf433934486c41d082e8d75ccfe5dc2f69fef": {
    "paperId": "04faf433934486c41d082e8d75ccfe5dc2f69fef",
    "title": "GPT-GNN: Generative Pre-Training of Graph Neural Networks",
    "year": 2020,
    "authors": "Ziniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, Yizhou Sun",
    "abstract": "Graph neural networks (GNNs) have been demonstrated to be powerful in modeling graph-structured data. However, training GNNs requires abundant task-specific labeled data, which is often arduously expensive to obtain. One effective way to reduce the labeling effort is to pre-train an expressive GNN model on unlabelled data with self-supervision and then transfer the learned model to downstream tasks with only a few labels. In this paper, we present the GPT-GNN framework to initialize GNNs by generative pre-training. GPT-GNN introduces a self-supervised attributed graph generation task to pre-train a GNN so that it can capture the structural and semantic properties of the graph. We factorize the likelihood of graph generation into two components: 1) attribute generation and 2) edge generation. By modeling both components, GPT-GNN captures the inherent dependency between node attributes and graph structure during the generative process. Comprehensive experiments on the billion-scale open academic graph and Amazon recommendation data demonstrate that GPT-GNN significantly outperforms state-of-the-art GNN models without pre-training by up to 9.1% across various downstream tasks?",
    "citationCount": 629,
    "pdf_filename": "2020_GPT_GNN__Generative_Pre_Training_of_Grap_04faf433.pdf"
  },
  "a3c0719d847a8cab836500a0ee3b9f4717ed136d": {
    "paperId": "a3c0719d847a8cab836500a0ee3b9f4717ed136d",
    "title": "From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing.",
    "year": 2023,
    "authors": "Ismail Dergaa, K. Chamari, P. Żmijewski, H. Ben Saad",
    "abstract": "Natural language processing (NLP) has been studied in computing for decades. Recent technological advancements have led to the development of sophisticated artificial intelligence (AI) models, such as Chat Generative Pre-trained Transformer (ChatGPT). These models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. This manuscript aims at (i) exploring the potential benefits and threats of ChatGPT and other NLP technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. This study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in Scopus as quartile 1. The search used keywords such as \"ChatGPT,\" \"AI-generated text,\" \"academic writing,\" and \"natural language processing.\" The analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. The study found that ChatGPT and other NLP technologies have the potential to enhance academic writing and research efficiency. However, their use also raises concerns about the impact on the authenticity and credibility of academic work. The study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. This study highlights the need for comprehensive debates and ethical considerations involved in their use. The study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work.",
    "citationCount": 553,
    "pdf_filename": "2023_From_human_writing_to_artificial_intelli_a3c0719d.pdf"
  },
  "3a75ed3e9e81c9db573ef73d20e2c66c12aaedf8": {
    "paperId": "3a75ed3e9e81c9db573ef73d20e2c66c12aaedf8",
    "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model",
    "year": 2022,
    "authors": "Yinhuai Wang, Jiwen Yu, Jian Zhang",
    "abstract": "Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration.",
    "citationCount": 580,
    "pdf_filename": "2022_Zero_Shot_Image_Restoration_Using_Denois_3a75ed3e.pdf"
  },
  "eb2cbd12f749f14716296f7f415e921562c9079b": {
    "paperId": "eb2cbd12f749f14716296f7f415e921562c9079b",
    "title": "LRM: Large Reconstruction Model for Single Image to 3D",
    "year": 2023,
    "authors": "Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou",
    "abstract": "We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs, including real-world in-the-wild captures and images created by generative models. Video demos and interactable 3D meshes can be found on our LRM project webpage: https://yiconghong.me/LRM.",
    "citationCount": 651,
    "pdf_filename": "2023_LRM__Large_Reconstruction_Model_for_Sing_eb2cbd12.pdf"
  },
  "c871d2dc802d276608a6734637f8bc9e6da0d837": {
    "paperId": "c871d2dc802d276608a6734637f8bc9e6da0d837",
    "title": "GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation",
    "year": 2022,
    "authors": "Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon",
    "abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules.",
    "citationCount": 631,
    "pdf_filename": "2022_GeoDiff__a_Geometric_Diffusion_Model_for_c871d2dc.pdf"
  },
  "7ee3ff7e1c8b9f458baa99a27b3a1411fe1ecd64": {
    "paperId": "7ee3ff7e1c8b9f458baa99a27b3a1411fe1ecd64",
    "title": "GANSpace: Discovering Interpretable GAN Controls",
    "year": 2020,
    "authors": "Erik Härkönen, Aaron Hertzmann, J. Lehtinen, Sylvain Paris",
    "abstract": "This paper describes a simple technique to analyze Generative Adversarial Networks (GANs) and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day. We identify important latent directions based on Principal Components Analysis (PCA) applied either in latent space or feature space. Then, we show that a large number of interpretable controls can be defined by layer-wise perturbation along the principal directions. Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. We show results on different GANs trained on various datasets, and demonstrate good qualitative matches to edit directions found through earlier supervised approaches.",
    "citationCount": 969,
    "pdf_filename": "2020_GANSpace__Discovering_Interpretable_GAN__7ee3ff7e.pdf"
  },
  "b000d6865db824af1563708fb7a545ddd65c6b3a": {
    "paperId": "b000d6865db824af1563708fb7a545ddd65c6b3a",
    "title": "Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation",
    "year": 2022,
    "authors": "Narek Tumanyan, Michal Geyer, Shai Bagon, Tali Dekel",
    "abstract": "Large-scale text-to-image generative models have been a revolutionary breakthrough in the evolution of generative AI, synthesizing diverse images with highly complex visual concepts. However, a pivotal challenge in leveraging such models for real-world content creation is providing users with control over the generated content. In this paper, we present a new framework that takes text-to- image synthesis to the realm of image-to-image translation - given a guidance image and a target text prompt as input, our method harnesses the power of a pre-trained text-to-image diffusion model to generate a new image that complies with the target text, while preserving the semantic layout of the guidance image. Specifically, we observe and empirically demonstrate that fine-grained control over the generated structure can be achieved by manipulating spatial features and their self-attention inside the model. This results in a simple and effective approach, where features extracted from the guidance image are directly injected into the generation process of the translated image, requiring no training or fine-tuning. We demonstrate high-quality results on versatile text-guided image translation tasks, including translating sketches, rough drawings and animations into realistic images, changing the class and appearance of objects in a given image, and modifying global qualities such as lighting and color.",
    "citationCount": 862,
    "pdf_filename": "2022_Plug_and_Play_Diffusion_Features_for_Tex_b000d686.pdf"
  },
  "465b0e9fbca264713b5904c3084f8c8c6e1039b1": {
    "paperId": "465b0e9fbca264713b5904c3084f8c8c6e1039b1",
    "title": "ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations",
    "year": 2023,
    "authors": "Tirth Dave, Sai Anirudh Athaluri, Satyam Singh",
    "abstract": "This paper presents an analysis of the advantages, limitations, ethical considerations, future prospects, and practical applications of ChatGPT and artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an advanced language model that uses deep learning techniques to produce human-like responses to natural language inputs. It is part of the family of generative pre-training transformer (GPT) models developed by OpenAI and is currently one of the largest publicly available language models. ChatGPT is capable of capturing the nuances and intricacies of human language, allowing it to generate appropriate and contextually relevant responses across a broad spectrum of prompts. The potential applications of ChatGPT in the medical field range from identifying potential research topics to assisting professionals in clinical and laboratory diagnosis. Additionally, it can be used to help medical students, doctors, nurses, and all members of the healthcare fraternity to know about updates and new developments in their respective fields. The development of virtual assistants to aid patients in managing their health is another important application of ChatGPT in medicine. Despite its potential applications, the use of ChatGPT and other AI tools in medical writing also poses ethical and legal concerns. These include possible infringement of copyright laws, medico-legal complications, and the need for transparency in AI-generated content. In conclusion, ChatGPT has several potential applications in the medical and healthcare fields. However, these applications come with several limitations and ethical considerations which are presented in detail along with future prospects in medicine and healthcare.",
    "citationCount": 882,
    "pdf_filename": "2023_ChatGPT_in_medicine__an_overview_of_its__465b0e9f.pdf"
  },
  "0930fe943d7d9b5bb943613d87c4ca92850dd43a": {
    "paperId": "0930fe943d7d9b5bb943613d87c4ca92850dd43a",
    "title": "Scaling up GANs for Text-to-Image Synthesis",
    "year": 2023,
    "authors": "Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman",
    "abstract": "The recent success of text-to-image synthesis has taken the world by storm and captured the general public's imagination. From a technical standpoint, it also marked a drastic change in the favored architecture to design generative image models. GANs used to be the de facto choice, with techniques like StyleGAN. With DALL.E 2, autoregressive and diffusion models became the new standard for large-scale generative models overnight. This rapid shift raises a fundamental question: can we scale up GANs to benefit from large datasets like LAION? We find that naïvely increasing the capacity of the StyleGan architecture quickly becomes unstable. We introduce GigaGAN, a new GAN architecture that far exceeds this limit, demonstrating GANs as a viable option for text-to-image synthesis. GigaGAN offers three major advantages. First, it is orders of magnitude faster at inference time, taking only 0.13 seconds to synthesize a 512px image. Second, it can synthesize high-resolution images, for example, 16-megapixel images in 3.66 seconds. Finally, GigaGAN supports various latent space editing applications such as latent interpolation, style mixing, and vector arithmetic operations.",
    "citationCount": 573,
    "pdf_filename": "2023_Scaling_up_GANs_for_Text_to_Image_Synthe_0930fe94.pdf"
  },
  "2e32cde6e080f990873638f2e113767a6a19c824": {
    "paperId": "2e32cde6e080f990873638f2e113767a6a19c824",
    "title": "Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech",
    "year": 2021,
    "authors": "Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail Kudinov",
    "abstract": "Recently, denoising diffusion probabilistic models and generative score matching have shown high potential in modelling complex data distributions while stochastic calculus has provided a unified point of view on these techniques allowing for flexible inference schemes. In this paper we introduce Grad-TTS, a novel text-to-speech model with score-based decoder producing mel-spectrograms by gradually transforming noise predicted by encoder and aligned with text input by means of Monotonic Alignment Search. The framework of stochastic differential equations helps us to generalize conventional diffusion probabilistic models to the case of reconstructing data from noise with different parameters and allows to make this reconstruction flexible by explicitly controlling trade-off between sound quality and inference speed. Subjective human evaluation shows that Grad-TTS is competitive with state-of-the-art text-to-speech approaches in terms of Mean Opinion Score. We will make the code publicly available shortly.",
    "citationCount": 647,
    "pdf_filename": "2021_Grad_TTS__A_Diffusion_Probabilistic_Mode_2e32cde6.pdf"
  },
  "5e00596fa946670d894b1bdaeff5a98e3867ef13": {
    "paperId": "5e00596fa946670d894b1bdaeff5a98e3867ef13",
    "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision",
    "year": 2021,
    "authors": "Zirui Wang, Jiahui Yu, Adams Wei Yu, Zihang Dai, Yulia Tsvetkov",
    "abstract": "With recent progress in joint modeling of visual and textual representations, Vision-Language Pretraining (VLP) has achieved impressive performance on many multimodal downstream tasks. However, the requirement for expensive annotations including clean image captions and regional labels limits the scalability of existing approaches, and complicates the pretraining procedure with the introduction of multiple dataset-specific objectives. In this work, we relax these constraints and present a minimalist pretraining framework, named Simple Visual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training complexity by exploiting large-scale weak supervision, and is trained end-to-end with a single prefix language modeling objective. Without utilizing extra data or task-specific customization, the resulting model significantly outperforms previous pretraining methods and achieves new state-of-the-art results on a wide range of discriminative and generative vision-language benchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE (+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score). Furthermore, we demonstrate that SimVLM acquires strong generalization and transfer ability, enabling zero-shot behavior including open-ended visual question answering and cross-modality transfer.",
    "citationCount": 899,
    "pdf_filename": "2021_SimVLM__Simple_Visual_Language_Model_Pre_5e00596f.pdf"
  },
  "e24f4b28167b05fbf7d29000490fc0a4e4c109c7": {
    "paperId": "e24f4b28167b05fbf7d29000490fc0a4e4c109c7",
    "title": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers",
    "year": 2022,
    "authors": "Y. Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song",
    "abstract": "Large-scale diffusion-based generative models have led to breakthroughs in text-conditioned high-resolution image synthesis. Starting from random noise, such text-to-image diffusion models gradually synthesize images in an iterative fashion while conditioning on text prompts. We find that their synthesis behavior qualitatively changes throughout this process: Early in sampling, generation strongly relies on the text prompt to generate text-aligned content, while later, the text conditioning is almost entirely ignored. This suggests that sharing model parameters throughout the entire generation process may not be ideal. Therefore, in contrast to existing works, we propose to train an ensemble of text-to-image diffusion models specialized for different synthesis stages. To maintain training efficiency, we initially train a single model, which is then split into specialized models that are trained for the specific stages of the iterative generation process. Our ensemble of diffusion models, called eDiff-I, results in improved text alignment while maintaining the same inference computation cost and preserving high visual quality, outperforming previous large-scale text-to-image diffusion models on the standard benchmark. In addition, we train our model to exploit a variety of embeddings for conditioning, including the T5 text, CLIP text, and CLIP image embeddings. We show that these different embeddings lead to different behaviors. Notably, the CLIP image embedding allows an intuitive way of transferring the style of a reference image to the target text-to-image output. Lastly, we show a technique that enables eDiff-I's\"paint-with-words\"capability. A user can select the word in the input text and paint it in a canvas to control the output, which is very handy for crafting the desired image in mind. The project page is available at https://deepimagination.cc/eDiff-I/",
    "citationCount": 963,
    "pdf_filename": "2022_eDiff_I__Text_to_Image_Diffusion_Models__e24f4b28.pdf"
  },
  "3599a236f285af48782fc30b1341d13ec7320735": {
    "paperId": "3599a236f285af48782fc30b1341d13ec7320735",
    "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
    "year": 2023,
    "authors": "Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu",
    "abstract": "Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of recent research advancements, challenges, and opportunities for PFMs in text, image, graph, as well as other data modalities. The review covers the basic components and existing pretraining methods used in natural language processing, computer vision, and graph learning. Additionally, it explores advanced PFMs used for different data modalities and unified PFMs that consider data quality and quantity. The review also discusses research related to the fundamentals of PFMs, such as model efficiency and compression, security, and privacy. Finally, the study provides key implications, future research directions, challenges, and open problems in the field of PFMs. Overall, this survey aims to shed light on the research of the PFMs on scalability, security, logical reasoning ability, cross-domain learning ability, and the user-friendly interactive ability for artificial general intelligence.",
    "citationCount": 637,
    "pdf_filename": "2023_A_Comprehensive_Survey_on_Pretrained_Fou_3599a236.pdf"
  },
  "add5f3f820b393e7ce5ed467814253824ecc484b": {
    "paperId": "add5f3f820b393e7ce5ed467814253824ecc484b",
    "title": "Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions",
    "year": 2021,
    "authors": "Emiel Hoogeboom, Didrik Nielsen, P. Jaini, Patrick Forr'e, M. Welling",
    "abstract": "Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood.",
    "citationCount": 544,
    "pdf_filename": "2021_Argmax_Flows_and_Multinomial_Diffusion___add5f3f8.pdf"
  },
  "5206cfd1c806b2bb2ffd7682bc6d5f9d28279fb9": {
    "paperId": "5206cfd1c806b2bb2ffd7682bc6d5f9d28279fb9",
    "title": "Artificial intelligence in the creative industries: a review",
    "year": 2020,
    "authors": "N. Anantrasirichai, D. Bull",
    "abstract": "This paper reviews the current state of the art in artificial intelligence (AI) technologies and applications in the context of the creative industries. A brief background of AI, and specifically machine learning (ML) algorithms, is provided including convolutional neural networks (CNNs), generative adversarial networks (GANs), recurrent neural networks (RNNs) and deep Reinforcement Learning (DRL). We categorize creative applications into five groups, related to how AI technologies are used: (i) content creation, (ii) information analysis, (iii) content enhancement and post production workflows, (iv) information extraction and enhancement, and (v) data compression. We critically examine the successes and limitations of this rapidly advancing technology in each of these areas. We further differentiate between the use of AI as a creative tool and its potential as a creator in its own right. We foresee that, in the near future, ML-based AI will be adopted widely as a tool or collaborative assistant for creativity. In contrast, we observe that the successes of ML in domains with fewer constraints, where AI is the ‘creator’, remain modest. The potential of AI (or its developers) to win awards for its original creations in competition with human creatives is also limited, based on contemporary technologies. We therefore conclude that, in the context of creative industries, maximum benefit from AI will be derived where its focus is human-centric—where it is designed to augment, rather than replace, human creativity.",
    "citationCount": 511,
    "pdf_filename": "2020_Artificial_intelligence_in_the_creative__5206cfd1.pdf"
  },
  "33422275fbb9958f55419620697faf531482699b": {
    "paperId": "33422275fbb9958f55419620697faf531482699b",
    "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering",
    "year": 2020,
    "authors": "Zhengbao Jiang, J. Araki, Haibo Ding, Graham Neubig",
    "abstract": "Abstract Recent works have shown that language models (LM) capture different types of knowledge regarding facts or common sense. However, because no model is perfect, they still fail to provide appropriate answers in many cases. In this paper, we ask the question, “How can we know when language models know, with confidence, the answer to a particular query?” We examine this question from the point of view of calibration, the property of a probabilistic model’s predicted probabilities actually being well correlated with the probabilities of correctness. We examine three strong generative models—T5, BART, and GPT-2—and study whether their probabilities on QA tasks are well calibrated, finding the answer is a relatively emphatic no. We then examine methods to calibrate such models to make their confidence scores correlate better with the likelihood of correctness through fine-tuning, post-hoc probability modification, or adjustment of the predicted outputs or inputs. Experiments on a diverse range of datasets demonstrate the effectiveness of our methods. We also perform analysis to study the strengths and limitations of these methods, shedding light on further improvements that may be made in methods for calibrating LMs. We have released the code at https://github.com/jzbjyb/lm-calibration.",
    "citationCount": 502,
    "pdf_filename": "2020_How_Can_We_Know_When_Language_Models_Kno_33422275.pdf"
  },
  "5aaeb50d8051890e9fbb9b9b8f34d9f3f2d85c1a": {
    "paperId": "5aaeb50d8051890e9fbb9b9b8f34d9f3f2d85c1a",
    "title": "Recent advances and applications of deep learning methods in materials science",
    "year": 2021,
    "authors": "K. Choudhary, Brian L. DeCost, Chi Chen, Anubhav Jain, F. Tavazza",
    "abstract": "Deep learning (DL) is one of the fastest-growing topics in materials data science, with rapidly emerging applications spanning atomistic, image-based, spectral, and textual data modalities. DL allows analysis of unstructured data and automated identification of features. The recent development of large materials databases has fueled the application of DL methods in atomistic prediction in particular. In contrast, advances in image and spectral data have largely leveraged synthetic data enabled by high-quality forward models as well as by generative unsupervised DL methods. In this article, we present a high-level overview of deep learning methods followed by a detailed discussion of recent developments of deep learning in atomistic simulation, materials imaging, spectral analysis, and natural language processing. For each modality we discuss applications involving both theoretical and experimental data, typical modeling approaches with their strengths and limitations, and relevant publicly available software and datasets. We conclude the review with a discussion of recent cross-cutting work related to uncertainty quantification in this field and a brief perspective on limitations, challenges, and potential growth areas for DL methods in materials science.",
    "citationCount": 793,
    "pdf_filename": "2021_Recent_advances_and_applications_of_deep_5aaeb50d.pdf"
  },
  "13dc81fce2c73de67dbe3829a32ec23d663cec89": {
    "paperId": "13dc81fce2c73de67dbe3829a32ec23d663cec89",
    "title": "scGPT: toward building a foundation model for single-cell multi-omics using generative AI",
    "year": 2024,
    "authors": "Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo",
    "abstract": "Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference. Pretrained using over 33 million single-cell RNA-sequencing profiles, scGPT is a foundation model facilitating a broad spectrum of downstream single-cell analysis tasks by transfer learning.",
    "citationCount": 662,
    "pdf_filename": "2024_scGPT__toward_building_a_foundation_mode_13dc81fc.pdf"
  },
  "9472e198f790cb396c088c8e98bd4c5f5134cf62": {
    "paperId": "9472e198f790cb396c088c8e98bd4c5f5134cf62",
    "title": "Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation",
    "year": 2024,
    "authors": "Anjanava Biswas, Wrick Talukdar",
    "abstract": "Comprehensive clinical documentation is crucial for effective healthcare delivery, yet it poses a significant burden on healthcare professionals, leading to burnout, increased medical errors, and compromised patient safety. This paper explores the potential of generative AI (Artificial Intelligence) to streamline the clinical documentation process, specifically focusing on generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior, Intervention, Response, Plan) notes. We present a case study demonstrating the application of natural language processing (NLP) and automatic speech recognition (ASR) technologies to transcribe patient-clinician interactions, coupled with advanced prompting techniques to generate draft clinical notes using large language models (LLMs). The study highlights the benefits of this approach, including time savings, improved documentation quality, and enhanced patient-centered care. Additionally, we discuss ethical considerations, such as maintaining patient confidentiality and addressing model biases, underscoring the need for responsible deployment of generative AI in healthcare settings. The findings suggest that generative AI has the potential to revolutionize clinical documentation practices, alleviating administrative burdens and enabling healthcare professionals to focus more on direct patient care.",
    "citationCount": 969,
    "pdf_filename": "2024_Intelligent_Clinical_Documentation__Harn_9472e198.pdf"
  },
  "ac675900f7c6c14c8488e09a2a6e8525bcf9d45a": {
    "paperId": "ac675900f7c6c14c8488e09a2a6e8525bcf9d45a",
    "title": "Generative AI",
    "year": 2023,
    "authors": "Stefan Feuerriegel, Jochen Hartmann, Christian Janiesch, Patrick Zschech",
    "abstract": "Recent advancements in generative artificial intelligence (AI) have made it possible for machines to independently produce a variety of creative content. In the context of producing creative content, this essay examines the developments, difficulties, and ethical issues relating to generative AI. It looks into how generative models, such Generative Adversarial Networks (GANs) and Variational Auto encoders (VAEs), can produce realistic artwork like music, literature, and visuals. However, it is frequently discovered that GAN training is extremely unstable and frequently experiences non-convergence, mode collapse, and hyperparameter sensitivity [1]. The technical details of developing and optimizing generative models to produce desired results are covered in detail in this work. It also looks at the difficulties in guaranteeing the variety, creativity, and coherence of generated content. Additionally, the use of generative AI in the creation of original material raises ethical questions. Included in this are concerns about intellectual property, plagiarism, and possible effects on the creative industries. In specifically, the article explores the consequences of employing generative AI for content production in terms of authorship, human creativity, and the possible disruption of traditional creative practices. It also covers issues with fairness, bias, and appropriate application of generative models.",
    "citationCount": 960,
    "pdf_filename": "2023_Generative_AI_ac675900.pdf"
  },
  "a7b3a868a80dbe97689135c99b1a6b6e10dcdfe5": {
    "paperId": "a7b3a868a80dbe97689135c99b1a6b6e10dcdfe5",
    "title": "A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT",
    "year": 2023,
    "authors": "Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai",
    "abstract": "Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant attention from society. As a result, many individuals have become interested in related resources and are seeking to uncover the background and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI) techniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the creation of digital content, such as images, music, and natural language, through AI models. The goal of AIGC is to make the content creation process more efficient and accessible, allowing for the production of high-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information from instructions provided by human, and generating the content according to its knowledge and the intent information. In recent years, large-scale models have become increasingly important in AIGC as they provide better intent extraction and thus, improved generation results. With the growth of data and the size of the models, the distribution that the model can learn becomes more comprehensive and closer to reality, leading to more realistic and high-quality content generation. This survey provides a comprehensive review on the history of generative models, and basic components, recent advances in AIGC from unimodal interaction and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.",
    "citationCount": 695,
    "pdf_filename": "2023_A_Comprehensive_Survey_of_AI_Generated_C_a7b3a868.pdf"
  },
  "d553d008f643622e87e3ac061226865cad3b2928": {
    "paperId": "d553d008f643622e87e3ac061226865cad3b2928",
    "title": "Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education",
    "year": 2023,
    "authors": "Junaid Qadir",
    "abstract": "Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.",
    "citationCount": 619,
    "pdf_filename": "2023_Engineering_Education_in_the_Era_of_Chat_d553d008.pdf"
  },
  "5a23a489bb9e742edacc8b8e778b06e1594365d3": {
    "paperId": "5a23a489bb9e742edacc8b8e778b06e1594365d3",
    "title": "Generative AI at Work",
    "year": 2023,
    "authors": "Erik Brynjolfsson, Danielle Li, Lindsey Raymond",
    "abstract": "\n We study the staggered introduction of a generative AI–based conversational assistant using data from 5,172 customer-support agents. Access to AI assistance increases worker productivity, as measured by issues resolved per hour, by 15% on average, with substantial heterogeneity across workers. The effects vary significantly across different agents. Less experienced and lower-skilled workers improve both the speed and quality of their output, while the most experienced and highest-skilled workers see small gains in speed and small declines in quality. We also find evidence that AI assistance facilitates worker learning and improves English fluency, particularly among international agents. While AI systems improve with more training data, we find that the gains from AI adoption are largest for moderately rare problems, where human agents have less baseline experience but the system still has adequate training data. Finally, we provide evidence that AI assistance improves the experience of work along several dimensions: customers are more polite and less likely to ask to speak to a manager.",
    "citationCount": 702,
    "pdf_filename": "2023_Generative_AI_at_Work_5a23a489.pdf"
  },
  "317ad53bea6fb603c20f692bb2f1a01e2dc86161": {
    "paperId": "317ad53bea6fb603c20f692bb2f1a01e2dc86161",
    "title": "From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy",
    "year": 2023,
    "authors": "Maanak Gupta, Charankumar Akiri, Kshitiz Aryal, Elisabeth Parker, Lopamudra Praharaj",
    "abstract": "Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.",
    "citationCount": 523,
    "pdf_filename": "2023_From_ChatGPT_to_ThreatGPT__Impact_of_Gen_317ad53b.pdf"
  },
  "0893549771094fac547432cb4f84e9605c911a86": {
    "paperId": "0893549771094fac547432cb4f84e9605c911a86",
    "title": "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
    "year": 2023,
    "authors": "B. Meskó, E. Topol",
    "abstract": "The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
    "citationCount": 675,
    "pdf_filename": "2023_The_imperative_for_regulatory_oversight__08935497.pdf"
  },
  "6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab": {
    "paperId": "6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab",
    "title": "Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence",
    "year": 2023,
    "authors": "G. Cooper",
    "abstract": "The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.",
    "citationCount": 811,
    "pdf_filename": "2023_Examining_Science_Education_in_ChatGPT___6f4486c3.pdf"
  },
  "8d020275181c69e5e768c6ffc40e09710a6f54f1": {
    "paperId": "8d020275181c69e5e768c6ffc40e09710a6f54f1",
    "title": "Experimental evidence on the productivity effects of generative artificial intelligence",
    "year": 2023,
    "authors": "Shakked Noy, Whitney Zhang",
    "abstract": "We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making educated professionals obsolete, or will these tools complement their skills and enhance productivity? Noy and Zhang examined this issue in an experiment that recruited college-educated professionals to complete incentivized writing tasks. Participants assigned to use ChatGPT were more productive, efficient, and enjoyed the tasks more. Participants with weaker skills benefited the most from ChatGPT, which carries policy implications for efforts to reduce productivity inequality through AI. —EEU The assistive chatbot ChatGPT raises productivity in professional writing tasks and reduces productivity inequality.",
    "citationCount": 936,
    "pdf_filename": "2023_Experimental_evidence_on_the_productivit_8d020275.pdf"
  },
  "9dafa6c5c609348b46734fc8997b93b3587fec6e": {
    "paperId": "9dafa6c5c609348b46734fc8997b93b3587fec6e",
    "title": "Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education",
    "year": 2023,
    "authors": "J. Pavlik",
    "abstract": "Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.",
    "citationCount": 724,
    "pdf_filename": "2023_Collaborating_With_ChatGPT__Considering__9dafa6c5.pdf"
  },
  "781cfd3b72b3bc690b15433cbbc012487d5553dd": {
    "paperId": "781cfd3b72b3bc690b15433cbbc012487d5553dd",
    "title": "A comprehensive AI policy education framework for university teaching and learning",
    "year": 2023,
    "authors": "C. Chan",
    "abstract": "This study aims to develop an AI education policy for higher education by examining the perceptions and implications of text generative AI technologies. Data was collected from 457 students and 180 teachers and staff across various disciplines in Hong Kong universities, using both quantitative and qualitative research methods. Based on the findings, the study proposes an AI Ecological Education Policy Framework to address the multifaceted implications of AI integration in university teaching and learning. This framework is organized into three dimensions: Pedagogical, Governance, and Operational. The Pedagogical dimension concentrates on using AI to improve teaching and learning outcomes, while the Governance dimension tackles issues related to privacy, security, and accountability. The Operational dimension addresses matters concerning infrastructure and training. The framework fosters a nuanced understanding of the implications of AI integration in academic settings, ensuring that stakeholders are aware of their responsibilities and can take appropriate actions accordingly. Proposed AI Ecological Education Policy Framework for university teaching and learning. Three dimensions: Pedagogical, Governance, and Operational AI Policy Framework. Qualitative and quantitative data collected from students, teachers, and staff. Ten key areas identified for planning an AI policy in universities. Students should play an active role in drafting and implementing the policy. Proposed AI Ecological Education Policy Framework for university teaching and learning. Three dimensions: Pedagogical, Governance, and Operational AI Policy Framework. Qualitative and quantitative data collected from students, teachers, and staff. Ten key areas identified for planning an AI policy in universities. Students should play an active role in drafting and implementing the policy.",
    "citationCount": 777,
    "pdf_filename": "2023_A_comprehensive_AI_policy_education_fram_781cfd3b.pdf"
  },
  "f27dd152582b9da3c3a879025eceaebbf2a50752": {
    "paperId": "f27dd152582b9da3c3a879025eceaebbf2a50752",
    "title": "Chatting about ChatGPT: How May AI and GPT Impact Academia and Libraries?",
    "year": 2023,
    "authors": "Brady D. Lund, Wang Ting",
    "abstract": "\nPurpose\nThis paper aims to provide an overview of key definitions related to ChatGPT, a public tool developed by OpenAI, and its underlying technology, Generative Pretrained Transformer (GPT).\n\n\nDesign/methodology/approach\nThis paper includes an interview with ChatGPT on its potential impact on academia and libraries. The interview discusses the benefits of ChatGPT such as improving search and discovery, reference and information services; cataloging and metadata generation; and content creation, as well as the ethical considerations that need to be taken into account, such as privacy and bias.\n\n\nFindings\nChatGPT has considerable power to advance academia and librarianship in both anxiety-provoking and exciting new ways. However, it is important to consider how to use this technology responsibly and ethically, and to uncover how we, as professionals, can work alongside this technology to improve our work, rather than to abuse it or allow it to abuse us in the race to create new scholarly knowledge and educate future professionals.\n\n\nOriginality/value\nThis paper discusses the history and technology of GPT, including its generative pretrained transformer model, its ability to perform a wide range of language-based tasks and how ChatGPT uses this technology to function as a sophisticated chatbot.\n",
    "citationCount": 908,
    "pdf_filename": "2023_Chatting_about_ChatGPT__How_May_AI_and_G_f27dd152.pdf"
  },
  "d41e8815732f9644270ec4ff5eea5841e6275acb": {
    "paperId": "d41e8815732f9644270ec4ff5eea5841e6275acb",
    "title": "Shaping the Future of Education: Exploring the Potential and Consequences of AI and ChatGPT in Educational Settings",
    "year": 2023,
    "authors": "Simone Grassini",
    "abstract": "Over the last decade, technological advancements, especially artificial intelligence (AI), have significantly transformed educational practices. Recently, the development and adoption of Generative Pre-trained Transformers (GPT), particularly OpenAI’s ChatGPT, has sparked considerable interest. The unprecedented capabilities of these models, such as generating humanlike text and facilitating automated conversations, have broad implications in various sectors, including education and health. Despite their immense potential, concerns regarding their widespread use and opacity have been raised within the scientific community. ChatGPT, the latest version of the GPT series, has displayed remarkable proficiency, passed the US bar law exam, and amassed over a million subscribers shortly after its launch. However, its impact on the education sector has elicited mixed reactions, with some educators heralding it as a progressive step and others raising alarms over its potential to reduce analytical skills and promote misconduct. This paper aims to delve into these discussions, exploring the potential and problems associated with applying advanced AI models in education. It builds on extant literature and contributes to understanding how these technologies reshape educational norms in the “new AI gold rush” era.",
    "citationCount": 661,
    "pdf_filename": "2023_Shaping_the_Future_of_Education__Explori_d41e8815.pdf"
  },
  "eb9c4a07a336e8deefe7b399c550d3af0241238e": {
    "paperId": "eb9c4a07a336e8deefe7b399c550d3af0241238e",
    "title": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
    "year": 2024,
    "authors": "Wenqi Fan, Yujuan Ding, Liang-bo Ning, Shijie Wang, Hengyun Li",
    "abstract": "As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/",
    "citationCount": 546,
    "pdf_filename": "2024_A_Survey_on_RAG_Meeting_LLMs__Towards_Re_eb9c4a07.pdf"
  },
  "e41482f4ee984f17382f6cdd900df094d928be06": {
    "paperId": "e41482f4ee984f17382f6cdd900df094d928be06",
    "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
    "year": 2023,
    "authors": "Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo",
    "abstract": "With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
    "citationCount": 780,
    "pdf_filename": "2023_WebArena__A_Realistic_Web_Environment_fo_e41482f4.pdf"
  },
  "c68a13e60aca40e2cee71818c6791ec04ea5a580": {
    "paperId": "c68a13e60aca40e2cee71818c6791ec04ea5a580",
    "title": "ChatGPT for Language Teaching and Learning",
    "year": 2023,
    "authors": "Lucas Kohnke, Benjamin Luke Moorhouse, D. Zou",
    "abstract": "In this technology review, we explore the affordances of the generative AI chatbot ChatGPT for language teaching and learning. In addition to this, we also present debates and drawbacks of ChatGPT. Finally, we present the digital competencies teachers and learners require to use this chatbot ethically and effectively to support language learning.",
    "citationCount": 697,
    "pdf_filename": "2023_ChatGPT_for_Language_Teaching_and_Learni_c68a13e6.pdf"
  },
  "d730d42bb655b3b44727d71c147f9758612043a8": {
    "paperId": "d730d42bb655b3b44727d71c147f9758612043a8",
    "title": "Adversarial Diffusion Distillation",
    "year": 2023,
    "authors": "Axel Sauer, Dominik Lorenz, A. Blattmann, Robin Rombach",
    "abstract": "We introduce Adversarial Diffusion Distillation (ADD), a novel training approach that efficiently samples large-scale foundational image diffusion models in just 1-4 steps while maintaining high image quality. We use score distillation to leverage large-scale off-the-shelf image diffusion models as a teacher signal in combination with an adversarial loss to ensure high image fidelity even in the low-step regime of one or two sampling steps. Our analyses show that our model clearly outperforms existing few-step methods (GANs, Latent Consistency Models) in a single step and reaches the performance of state-of-the-art diffusion models (SDXL) in only four steps. ADD is the first method to unlock single-step, real-time image synthesis with foundation models. Code and weights available under https://github.com/Stability-AI/generative-models and https://huggingface.co/stabilityai/ .",
    "citationCount": 572,
    "pdf_filename": "2023_Adversarial_Diffusion_Distillation_d730d42b.pdf"
  },
  "8d984ee2eeabb630014f31fc759d4980830c4bdb": {
    "paperId": "8d984ee2eeabb630014f31fc759d4980830c4bdb",
    "title": "Can artificial intelligence help for scientific writing?",
    "year": 2023,
    "authors": "Michele Salvagno, F. Taccone, A. Gerli",
    "abstract": "This paper discusses the use of Artificial Intelligence Chatbot in scientific writing. ChatGPT is a type of chatbot, developed by OpenAI, that uses the Generative Pre-trained Transformer (GPT) language model to understand and respond to natural language inputs. AI chatbot and ChatGPT in particular appear to be useful tools in scientific writing, assisting researchers and scientists in organizing material, generating an initial draft and/or in proofreading. There is no publication in the field of critical care medicine prepared using this approach; however, this will be a possibility in the next future. ChatGPT work should not be used as a replacement for human judgment and the output should always be reviewed by experts before being used in any critical decision-making or application. Moreover, several ethical issues arise about using these tools, such as the risk of plagiarism and inaccuracies, as well as a potential imbalance in its accessibility between high- and low-income countries, if the software becomes paying. For this reason, a consensus on how to regulate the use of chatbots in scientific writing will soon be required.",
    "citationCount": 613,
    "pdf_filename": "2023_Can_artificial_intelligence_help_for_sci_8d984ee2.pdf"
  },
  "8a9f05cdfd0ea7411e83f95b39647167ee82c087": {
    "paperId": "8a9f05cdfd0ea7411e83f95b39647167ee82c087",
    "title": "ChatGPT in higher education: Considerations for academic integrity and student learning",
    "year": 2023,
    "authors": "Articles Info, Miriam Sullivan, Andrew Kelly, Paul Mclaughlan",
    "abstract": "The release of ChatGPT has sparked significant academic integrity concerns in higher education. However, some commentators have pointed out that generative artificial intelligence (AI) tools such as ChatGPT can enhance student learning, and consequently, academics should adapt their teaching and assessment practices to embrace the new reality of living, working, and studying in a world where AI is freely available. Despite this important debate, there has been very little academic literature published on ChatGPT and other generative AI tools. This article uses content analysis to examine news articles (N=100) about how ChatGPT is disrupting higher education, concentrating specifically on Australia, New Zealand, the United States",
    "citationCount": 550,
    "pdf_filename": "2023_ChatGPT_in_higher_education__Considerati_8a9f05cd.pdf"
  },
  "cbdb45fc16b0885905b91d84281c310e6cb49e9c": {
    "paperId": "cbdb45fc16b0885905b91d84281c310e6cb49e9c",
    "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
    "year": 2021,
    "authors": "Swaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi",
    "abstract": "Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19% better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.",
    "citationCount": 836,
    "pdf_filename": "2021_Cross_Task_Generalization_via_Natural_La_cbdb45fc.pdf"
  },
  "e51d38bbabca719cd9c845d1e004c724e9cbdfa4": {
    "paperId": "e51d38bbabca719cd9c845d1e004c724e9cbdfa4",
    "title": "How is ChatGPT's behavior changing over time?",
    "year": 2023,
    "authors": "Lingjiao Chen, Matei Zaharia, James Y. Zou",
    "abstract": "GPT-3.5 and GPT-4 are the two most widely used large language model (LLM) services. However, when and how these models are updated over time is opaque. Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on several diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3) opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating code, 6) US Medical License tests, and 7) visual reasoning. We find that the performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time. For example, GPT-4 (March 2023) was reasonable at identifying prime vs. composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same questions (51% accuracy). This is partly explained by a drop in GPT-4's amenity to follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in June than in March in this task. GPT-4 became less willing to answer sensitive questions and opinion survey questions in June than in March. GPT-4 performed better at multi-hop questions in June than in March, while GPT-3.5's performance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting mistakes in code generation in June than in March. We provide evidence that GPT-4's ability to follow user instructions has decreased over time, which is one common factor behind the many behavior drifts. Overall, our findings show that the behavior of the\"same\"LLM service can change substantially in a relatively short amount of time, highlighting the need for continuous monitoring of LLMs.",
    "citationCount": 529,
    "pdf_filename": "2023_How_is_ChatGPT_s_behavior_changing_over__e51d38bb.pdf"
  },
  "cc1a674bb164d09a060cf5b26fe518c02fae0ddc": {
    "paperId": "cc1a674bb164d09a060cf5b26fe518c02fae0ddc",
    "title": "DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation",
    "year": 2023,
    "authors": "Jiaxiang Tang, Jiawei Ren, Hang Zhou, Ziwei Liu, Gang Zeng",
    "abstract": "Recent advances in 3D content creation mostly leverage optimization-based 3D generation via score distillation sampling (SDS). Though promising results have been exhibited, these methods often suffer from slow per-sample optimization, limiting their practical usage. In this paper, we propose DreamGaussian, a novel 3D content generation framework that achieves both efficiency and quality simultaneously. Our key insight is to design a generative 3D Gaussian Splatting model with companioned mesh extraction and texture refinement in UV space. In contrast to the occupancy pruning used in Neural Radiance Fields, we demonstrate that the progressive densification of 3D Gaussians converges significantly faster for 3D generative tasks. To further enhance the texture quality and facilitate downstream applications, we introduce an efficient algorithm to convert 3D Gaussians into textured meshes and apply a fine-tuning stage to refine the details. Extensive experiments demonstrate the superior efficiency and competitive generation quality of our proposed approach. Notably, DreamGaussian produces high-quality textured meshes in just 2 minutes from a single-view image, achieving approximately 10 times acceleration compared to existing methods.",
    "citationCount": 837,
    "pdf_filename": "2023_DreamGaussian__Generative_Gaussian_Splat_cc1a674b.pdf"
  },
  "4309d572a37d655779f9dce6a2c98c66334132de": {
    "paperId": "4309d572a37d655779f9dce6a2c98c66334132de",
    "title": "SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension",
    "year": 2023,
    "authors": "Bohao Li, Rui Wang, Guangzhi Wang, Yuying Ge, Yixiao Ge",
    "abstract": "Based on powerful Large Language Models (LLMs), recent generative Multimodal Large Language Models (MLLMs) have gained prominence as a pivotal research area, exhibiting remarkable capability for both comprehension and generation. In this work, we address the evaluation of generative comprehension in MLLMs as a preliminary step towards a comprehensive assessment of generative models, by introducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple choice questions with accurate human annotations (x 6 larger than existing benchmarks), which spans 12 evaluation dimensions including the comprehension of both the image and video modality. We develop an advanced pipeline for generating multiple-choice questions that target specific evaluation dimensions, integrating both automatic filtering and manual verification processes. Multiple-choice questions with groundtruth options derived from human annotation enables an objective and efficient assessment of model performance, eliminating the need for human or GPT intervention during evaluation. We further evaluate the performance of 18 models across all 12 dimensions, covering both the spatial and temporal understanding. By revealing the limitations of existing MLLMs through evaluation results, we aim for SEED-Bench to provide insights for motivating future research. We will launch and consistently maintain a leaderboard to provide a platform for the community to assess and investigate model capability.",
    "citationCount": 754,
    "pdf_filename": "2023_SEED_Bench__Benchmarking_Multimodal_LLMs_4309d572.pdf"
  },
  "7c1707db9aafd209aa93db3251e7ebd593d55876": {
    "paperId": "7c1707db9aafd209aa93db3251e7ebd593d55876",
    "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
    "year": 2023,
    "authors": "Potsawee Manakul, Adian Liusie, M. Gales",
    "abstract": "Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to the output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose\"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check the responses of black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if an LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several baselines and show that our approach has considerably higher AUC-PR scores in sentence-level hallucination detection and higher correlation scores in passage-level factuality assessment compared to grey-box methods.",
    "citationCount": 631,
    "pdf_filename": "2023_SelfCheckGPT__Zero_Resource_Black_Box_Ha_7c1707db.pdf"
  },
  "3ab661db57d924f4ff1706e05ac807873ca00e0a": {
    "paperId": "3ab661db57d924f4ff1706e05ac807873ca00e0a",
    "title": "RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment",
    "year": 2023,
    "authors": "Hanze Dong, Wei Xiong, Deepanshu Goyal, Rui Pan, Shizhe Diao",
    "abstract": "Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially serious consequences. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) to address this problem, where generative models are fine-tuned with RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generative models effectively. Utilizing a reward model and a sufficient number of samples, our approach selects the high-quality samples, discarding those that exhibit undesired behavior, and subsequently enhancing the model by fine-tuning on these filtered samples. Our studies show that RAFT can effectively improve the model performance in both reward learning and other automated metrics in both large language models and diffusion models.",
    "citationCount": 619,
    "pdf_filename": "2023_RAFT__Reward_rAnked_FineTuning_for_Gener_3ab661db.pdf"
  },
  "5396c55bee2a2abf2207e1cc5e5ae72c9edef9fa": {
    "paperId": "5396c55bee2a2abf2207e1cc5e5ae72c9edef9fa",
    "title": "Improving and generalizing flow-based generative models with minibatch optimal transport",
    "year": 2023,
    "authors": "Alexander Tong, Nikolay Malkin, G. Huguet, Yanlei Zhang, Jarrid Rector-Brooks",
    "abstract": "Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, we show that when the true OT plan is available, our OT-CFM method approximates dynamic OT. Training CNFs with CFM improves results on a variety of conditional and unconditional generation tasks, such as inferring single cell dynamics, unsupervised image translation, and Schr\\\"odinger bridge inference.",
    "citationCount": 528,
    "pdf_filename": "2023_Improving_and_generalizing_flow_based_ge_5396c55b.pdf"
  },
  "2a3213cb3c755f036d5dfec7261d726a819c78c1": {
    "paperId": "2a3213cb3c755f036d5dfec7261d726a819c78c1",
    "title": "Muse: Text-To-Image Generation via Masked Generative Transformers",
    "year": 2023,
    "authors": "Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, José Lezama",
    "abstract": "We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse is trained to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requiring fewer sampling iterations; compared to autoregressive models, such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, translating to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results are available at https://muse-model.github.io",
    "citationCount": 677,
    "pdf_filename": "2023_Muse__Text_To_Image_Generation_via_Maske_2a3213cb.pdf"
  },
  "42a14d824caa3348046eb34c37e2ab7985faa7a3": {
    "paperId": "42a14d824caa3348046eb34c37e2ab7985faa7a3",
    "title": "High-throughput Generative Inference of Large Language Models with a Single GPU",
    "year": 2023,
    "authors": "Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin",
    "abstract": "The high computational and memory requirements of large language model (LLM) inference make it feasible only with multiple high-end accelerators. Motivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU. We present FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly configured under various hardware resource constraints by aggregating memory and computation from the GPU, CPU, and disk. By solving a linear programming problem, it searches for efficient patterns to store and access tensors. FlexGen further compresses the weights and the attention cache to 4 bits with negligible accuracy loss. These techniques enable FlexGen to have a larger space of batch size choices and thus significantly increase maximum throughput. As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144. On the HELM benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21 hours. The code is available at https://github.com/FMInference/FlexGen",
    "citationCount": 536,
    "pdf_filename": "2023_High_throughput_Generative_Inference_of__42a14d82.pdf"
  },
  "8cf01c76b506f6bca5258071ed309fc4430c24d3": {
    "paperId": "8cf01c76b506f6bca5258071ed309fc4430c24d3",
    "title": "The Role of ChatGPT, Generative Language Models, and Artificial Intelligence in Medical Education: A Conversation With ChatGPT and a Call for Papers",
    "year": 2023,
    "authors": "G. Eysenbach",
    "abstract": "ChatGPT is a generative language model tool launched by OpenAI on November 30, 2022, enabling the public to converse with a machine on a broad range of topics. In January 2023, ChatGPT reached over 100 million users, making it the fastest-growing consumer application to date. This interview with ChatGPT is part 2 of a larger interview with ChatGPT. It provides a snapshot of the current capabilities of ChatGPT and illustrates the vast potential for medical education, research, and practice but also hints at current problems and limitations. In this conversation with Gunther Eysenbach, the founder and publisher of JMIR Publications, ChatGPT generated some ideas on how to use chatbots in medical education. It also illustrated its capabilities to generate a virtual patient simulation and quizzes for medical students; critiqued a simulated doctor-patient communication and attempts to summarize a research article (which turned out to be fabricated); commented on methods to detect machine-generated text to ensure academic integrity; generated a curriculum for health professionals to learn about artificial intelligence (AI); and helped to draft a call for papers for a new theme issue to be launched in JMIR Medical Education on ChatGPT. The conversation also highlighted the importance of proper “prompting.” Although the language generator does make occasional mistakes, it admits these when challenged. The well-known disturbing tendency of large language models to hallucinate became evident when ChatGPT fabricated references. The interview provides a glimpse into the capabilities and limitations of ChatGPT and the future of AI-supported medical education. Due to the impact of this new technology on medical education, JMIR Medical Education is launching a call for papers for a new e-collection and theme issue. The initial draft of the call for papers was entirely machine generated by ChatGPT, but will be edited by the human guest editors of the theme issue.",
    "citationCount": 612,
    "pdf_filename": "2023_The_Role_of_ChatGPT__Generative_Language_8cf01c76.pdf"
  },
  "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba": {
    "paperId": "c0b454e0a6aa51ff3ba56778787d0c43932ef6ba",
    "title": "Yi: Open Foundation Models by 01.AI",
    "year": 2024,
    "authors": "01.AI Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang",
    "abstract": "We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less than 10K) instruction dataset over multiple iterations such that every single instance has been verified directly by our machine learning engineers. For vision-language, we combine the chat language model with a vision transformer encoder and train the model to align visual representations to the semantic space of the language model. We further extend the context length to 200K through lightweight continual pretraining and demonstrate strong needle-in-a-haystack retrieval performance. We show that extending the depth of the pretrained checkpoint through continual pretraining further improves performance. We believe that given our current results, continuing to scale up model parameters using thoroughly optimized data will lead to even stronger frontier models.",
    "citationCount": 747,
    "pdf_filename": "2024_Yi__Open_Foundation_Models_by_01_AI_c0b454e0.pdf"
  },
  "7c597874535c1537d7ddff3b3723015b4dc79d30": {
    "paperId": "7c597874535c1537d7ddff3b3723015b4dc79d30",
    "title": "MaskGIT: Masked Generative Image Transformer",
    "year": 2022,
    "authors": "Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, W. Freeman",
    "abstract": "Generative transformers have experienced rapid popularity growth in the computer vision community in synthesizing high-fidelity and high-resolution images. The best generative transformer models so far, however, still treat an image naively as a sequence of tokens, and decode an image sequentially following the raster scan ordering (i.e. line-by-line). We find this strategy neither optimal nor efficient. This paper proposes a novel image synthesis paradigm using a bidirectional transformer decoder, which we term MaskGIT. During training, MaskGIT learns to predict randomly masked tokens by attending to tokens in all directions. At inference time, the model begins with generating all tokens of an image simultaneously, and then refines the image iteratively conditioned on the previous generation. Our experiments demonstrate that MaskGIT significantly outperforms the state-of-the-art transformer model on the ImageNet dataset, and accelerates autoregressive decoding by up to 48x. Besides, we illustrate that MaskGIT can be easily extended to various image editing tasks, such as inpainting, extrapolation, and image manipulation. Project page: masked-generative-image-transformer.github.io.",
    "citationCount": 917,
    "pdf_filename": "2022_MaskGIT__Masked_Generative_Image_Transfo_7c597874.pdf"
  },
  "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da": {
    "paperId": "5288b9f3a9f575543f44c39e1d3b78b3ca4c99da",
    "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
    "year": 2022,
    "authors": "Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida I. Wang, Eric Wallace",
    "abstract": "Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined. We introduce InCoder, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via infilling). InCoder is trained to generate code files from a large corpus of permissively licensed code, where regions of code have been randomly masked and moved to the end of each file, allowing code infilling with bidirectional context. Our model is the first generative model that is able to directly perform zero-shot code infilling, which we evaluate on challenging tasks such as type inference, comment generation, and variable re-naming. We find that the ability to condition on bidirectional context substantially improves performance on these tasks, while still performing comparably on standard program synthesis benchmarks in comparison to left-to-right only models pretrained at similar scale. The InCoder models and code are publicly released. https://sites.google.com/view/incoder-code-models",
    "citationCount": 781,
    "pdf_filename": "2022_InCoder__A_Generative_Model_for_Code_Inf_5288b9f3.pdf"
  },
  "60ee030773ba1b68eb222a265b052ca028353362": {
    "paperId": "60ee030773ba1b68eb222a265b052ca028353362",
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "year": 2022,
    "authors": "Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin",
    "abstract": "In this paper, we design and train a Generative Image-to-text Transformer, GIT, to unify vision-language tasks such as image/video captioning and question answering. While generative models provide a consistent network architecture between pre-training and fine-tuning, existing work typically contains complex structures (uni/multi-modal encoder/decoder) and depends on external modules such as object detectors/taggers and optical character recognition (OCR). In GIT, we simplify the architecture as one image encoder and one text decoder under a single language modeling task. We also scale up the pre-training data and the model size to boost the model performance. Without bells and whistles, our GIT establishes new state of the arts on 12 challenging benchmarks with a large margin. For instance, our model surpasses the human performance for the first time on TextCaps (138.2 vs. 125.5 in CIDEr). Furthermore, we present a new scheme of generation-based image classification and scene text recognition, achieving decent performance on standard benchmarks. Codes are released at \\url{https://github.com/microsoft/GenerativeImage2Text}.",
    "citationCount": 688,
    "pdf_filename": "2022_GIT__A_Generative_Image_to_text_Transfor_60ee0307.pdf"
  },
  "f19dfc360088922cf1d423c538662aae8d542c28": {
    "paperId": "f19dfc360088922cf1d423c538662aae8d542c28",
    "title": "Is Conditional Generative Modeling all you need for Decision-Making?",
    "year": 2022,
    "authors": "Anurag Ajay, Yilun Du, Abhi Gupta, J. Tenenbaum, T. Jaakkola",
    "abstract": "Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of reinforcement learning (RL), but rather through conditional generative modeling. To our surprise, we find that our formulation leads to policies that can outperform existing offline RL approaches across standard benchmarks. By modeling a policy as a return-conditional diffusion model, we illustrate how we may circumvent the need for dynamic programming and subsequently eliminate many of the complexities that come with traditional offline RL. We further demonstrate the advantages of modeling policies as conditional diffusion models by considering two other conditioning variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrate a composition of skills. Our results illustrate that conditional generative modeling is a powerful tool for decision-making.",
    "citationCount": 513,
    "pdf_filename": "2022_Is_Conditional_Generative_Modeling_all_y_f19dfc36.pdf"
  },
  "8f9e864fab09bbae4a46a2a62bb954db1a88eb3e": {
    "paperId": "8f9e864fab09bbae4a46a2a62bb954db1a88eb3e",
    "title": "Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts",
    "year": 2023,
    "authors": "J.D. Zamfirescu-Pereira, Richmond Y. Wong, Bjoern Hartmann, Qian Yang",
    "abstract": "Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.",
    "citationCount": 881,
    "pdf_filename": "2023_Why_Johnny_Can_t_Prompt__How_Non_AI_Expe_8f9e864f.pdf"
  },
  "8b28792f8405b737229afb92c99c579b86d8aa98": {
    "paperId": "8b28792f8405b737229afb92c99c579b86d8aa98",
    "title": "Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations",
    "year": 2023,
    "authors": "Hakan Inan, K. Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer",
    "abstract": "We introduce Llama Guard, an LLM-based input-output safeguard model geared towards Human-AI conversation use cases. Our model incorporates a safety risk taxonomy, a valuable tool for categorizing a specific set of safety risks found in LLM prompts (i.e., prompt classification). This taxonomy is also instrumental in classifying the responses generated by LLMs to these prompts, a process we refer to as response classification. For the purpose of both prompt and response classification, we have meticulously gathered a dataset of high quality. Llama Guard, a Llama2-7b model that is instruction-tuned on our collected dataset, albeit low in volume, demonstrates strong performance on existing benchmarks such as the OpenAI Moderation Evaluation dataset and ToxicChat, where its performance matches or exceeds that of currently available content moderation tools. Llama Guard functions as a language model, carrying out multi-class classification and generating binary decision scores. Furthermore, the instruction fine-tuning of Llama Guard allows for the customization of tasks and the adaptation of output formats. This feature enhances the model's capabilities, such as enabling the adjustment of taxonomy categories to align with specific use cases, and facilitating zero-shot or few-shot prompting with diverse taxonomies at the input. We are making Llama Guard model weights available and we encourage researchers to further develop and adapt them to meet the evolving needs of the community for AI safety.",
    "citationCount": 699,
    "pdf_filename": "2023_Llama_Guard__LLM_based_Input_Output_Safe_8b28792f.pdf"
  },
  "58fdf550600fc3873729d466601c5d08a51ba8a0": {
    "paperId": "58fdf550600fc3873729d466601c5d08a51ba8a0",
    "title": "Representation Engineering: A Top-Down Approach to AI Transparency",
    "year": 2023,
    "authors": "Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo",
    "abstract": "In this paper, we identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places population-level representations, rather than neurons or circuits, at the center of analysis, equipping us with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). We provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving our understanding and control of large language models. We showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power-seeking, and more, demonstrating the promise of top-down transparency research. We hope that this work catalyzes further exploration of RepE and fosters advancements in the transparency and safety of AI systems.",
    "citationCount": 665,
    "pdf_filename": "2023_Representation_Engineering__A_Top_Down_A_58fdf550.pdf"
  },
  "ad14e11bc97cc2fed0fd344e7cb7d7ce4205bfc6": {
    "paperId": "ad14e11bc97cc2fed0fd344e7cb7d7ce4205bfc6",
    "title": "Score-based Generative Modeling in Latent Space",
    "year": 2021,
    "authors": "Arash Vahdat, Karsten Kreis, Jan Kautz",
    "abstract": "Score-based generative models (SGMs) have recently demonstrated impressive results in terms of both sample quality and distribution coverage. However, they are usually applied directly in data space and often require thousands of network evaluations for sampling. Here, we propose the Latent Score-based Generative Model (LSGM), a novel approach that trains SGMs in a latent space, relying on the variational autoencoder framework. Moving from data to latent space allows us to train more expressive generative models, apply SGMs to non-continuous data, and learn smoother SGMs in a smaller space, resulting in fewer network evaluations and faster sampling. To enable training LSGMs end-to-end in a scalable and stable manner, we (i) introduce a new score-matching objective suitable to the LSGM setting, (ii) propose a novel parameterization of the score function that allows SGM to focus on the mismatch of the target distribution with respect to a simple Normal one, and (iii) analytically derive multiple techniques for variance reduction of the training objective. LSGM obtains a state-of-the-art FID score of 2.10 on CIFAR-10, outperforming all existing generative results on this dataset. On CelebA-HQ-256, LSGM is on a par with previous SGMs in sample quality while outperforming them in sampling time by two orders of magnitude. In modeling binary images, LSGM achieves state-of-the-art likelihood on the binarized OMNIGLOT dataset. Our project page and code can be found at https://nvlabs.github.io/LSGM .",
    "citationCount": 793,
    "pdf_filename": "2021_Score_based_Generative_Modeling_in_Laten_ad14e11b.pdf"
  },
  "4f73a26f7c2c942d7f1b8267e1307d6f5207613b": {
    "paperId": "4f73a26f7c2c942d7f1b8267e1307d6f5207613b",
    "title": "Tackling the Generative Learning Trilemma with Denoising Diffusion GANs",
    "year": 2021,
    "authors": "Zhisheng Xiao, Karsten Kreis, Arash Vahdat",
    "abstract": "A wide variety of deep generative models has been developed in the past decade. Yet, these models often struggle with simultaneously addressing three key requirements including: high sample quality, mode coverage, and fast sampling. We call the challenge imposed by these requirements the generative learning trilemma, as the existing models often trade some of them for others. Particularly, denoising diffusion models have shown impressive sample quality and diversity, but their expensive sampling does not yet allow them to be applied in many real-world applications. In this paper, we argue that slow sampling in these models is fundamentally attributed to the Gaussian assumption in the denoising step which is justified only for small step sizes. To enable denoising with large steps, and hence, to reduce the total number of denoising steps, we propose to model the denoising distribution using a complex multimodal distribution. We introduce denoising diffusion generative adversarial networks (denoising diffusion GANs) that model each denoising step using a multimodal conditional GAN. Through extensive evaluations, we show that denoising diffusion GANs obtain sample quality and diversity competitive with original diffusion models while being 2000$\\times$ faster on the CIFAR-10 dataset. Compared to traditional GANs, our model exhibits better mode coverage and sample diversity. To the best of our knowledge, denoising diffusion GAN is the first model that reduces sampling cost in diffusion models to an extent that allows them to be applied to real-world applications inexpensively. Project page and code can be found at https://nvlabs.github.io/denoising-diffusion-gan",
    "citationCount": 655,
    "pdf_filename": "2021_Tackling_the_Generative_Learning_Trilemm_4f73a26f.pdf"
  },
  "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd": {
    "paperId": "4a7f6c4e71e20311ade4e76e8d0945d499c31fcd",
    "title": "ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge",
    "year": 2023,
    "authors": "Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steven Jiang",
    "abstract": "Objective The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice. Methods We achieved this by adapting and refining the large language model meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases. Results The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses. Conclusion Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.",
    "citationCount": 563,
    "pdf_filename": "2023_ChatDoctor__A_Medical_Chat_Model_Fine_Tu_4a7f6c4e.pdf"
  },
  "49f6dbf4ead6a8a3d26f9cf218a654f2f3d1d896": {
    "paperId": "49f6dbf4ead6a8a3d26f9cf218a654f2f3d1d896",
    "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
    "year": 2021,
    "authors": "Yang Song, Liyue Shen, Lei Xing, Stefano Ermon",
    "abstract": "Reconstructing medical images from partial measurements is an important inverse problem in Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). Existing solutions based on machine learning typically train a model to directly map measurements to medical images, leveraging a training dataset of paired images and measurements. These measurements are typically synthesized from images using a fixed physical model of the measurement process, which hinders the generalization capability of models to unknown measurement processes. To address this issue, we propose a fully unsupervised technique for inverse problem solving, leveraging the recently introduced score-based generative models. Specifically, we first train a score-based generative model on medical images to capture their prior distribution. Given measurements and a physical model of the measurement process at test time, we introduce a sampling method to reconstruct an image consistent with both the prior and the observed measurements. Our method does not assume a fixed measurement process during training, and can thus be flexibly adapted to different measurement processes at test time. Empirically, we observe comparable or better performance to supervised learning techniques in several medical imaging tasks in CT and MRI, while demonstrating significantly better generalization to unknown measurement processes.",
    "citationCount": 627,
    "pdf_filename": "2021_Solving_Inverse_Problems_in_Medical_Imag_49f6dbf4.pdf"
  },
  "fad8bd00bca79005f89a0b0e2aa13fddc864fe22": {
    "paperId": "fad8bd00bca79005f89a0b0e2aa13fddc864fe22",
    "title": "Diffusion Schrödinger Bridge with Applications to Score-Based Generative Modeling",
    "year": 2021,
    "authors": "Valentin De Bortoli, James Thornton, J. Heng, A. Doucet",
    "abstract": "Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\\\"odinger Bridge problem (SB), i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the methodology proposed by Song et al. (2021), with the flexibility of using shorter time intervals, as subsequent DSB iterations reduce the discrepancy between the final-time marginal of the forward (resp. backward) SDE with respect to the prior (resp. data) distribution. Beyond generative modeling, DSB offers a widely applicable computational optimal transport tool as the continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi, 2013).",
    "citationCount": 582,
    "pdf_filename": "2021_Diffusion_Schrödinger_Bridge_with_Applic_fad8bd00.pdf"
  },
  "54483c5672bbee68cb77969d9cf6681209230b95": {
    "paperId": "54483c5672bbee68cb77969d9cf6681209230b95",
    "title": "Towards Real-World Blind Face Restoration with Generative Facial Prior",
    "year": 2021,
    "authors": "Xintao Wang, Yu Li, Honglun Zhang, Ying Shan",
    "abstract": "Blind face restoration usually relies on facial priors, such as facial geometry prior or reference prior, to restore realistic and faithful details. However, very low-quality inputs cannot offer accurate geometric prior while high-quality references are inaccessible, limiting the applicability in real-world scenarios. In this work, we propose GFP-GAN that leverages rich and diverse priors encapsulated in a pretrained face GAN for blind face restoration. This Generative Facial Prior (GFP) is incorporated into the face restoration process via spatial feature transform layers, which allow our method to achieve a good balance of realness and fidelity. Thanks to the powerful generative facial prior and delicate designs, our GFP-GAN could jointly restore facial details and enhance colors with just a single forward pass, while GAN inversion methods require image-specific optimization at inference. Extensive experiments show that our method achieves superior performance to prior art on both synthetic and real-world datasets.",
    "citationCount": 550,
    "pdf_filename": "2021_Towards_Real_World_Blind_Face_Restoratio_54483c56.pdf"
  },
  "ed0959d722f06e2fb2862601aceae3ec1a511db9": {
    "paperId": "ed0959d722f06e2fb2862601aceae3ec1a511db9",
    "title": "GANMcC: A Generative Adversarial Network With Multiclassification Constraints for Infrared and Visible Image Fusion",
    "year": 2021,
    "authors": "Jiayi Ma, Hao Zhang, Z. Shao, Pengwei Liang, Han Xu",
    "abstract": "Visible images contain rich texture information, whereas infrared images have significant contrast. It is advantageous to combine these two kinds of information into a single image so that it not only has good contrast but also contains rich texture details. In general, previous fusion methods cannot achieve this goal well, where the fused results are inclined to either a visible or an infrared image. To address this challenge, a new fusion framework called generative adversarial network with multiclassification constraints (GANMcC) is proposed, which transforms image fusion into a multidistribution simultaneous estimation problem to fuse infrared and visible images in a more reasonable way. We adopt a generative adversarial network with multiclassification to estimate the distributions of visible light and infrared domains at the same time, in which the game of multiclassification discrimination will make the fused result to have these two distributions in a more balanced manner, so as to have significant contrast and rich texture details. In addition, we design a specific content loss to constrain the generator, which introduces the idea of main and auxiliary into the extraction of gradient and intensity information, which will enable the generator to extract more sufficient information from source images in a complementary manner. Extensive experiments demonstrate the advantages of our GANMcC over the state-of-the-art methods in terms of both qualitative effect and quantitative metric. Moreover, our method can achieve good fused results even the visible image is overexposed. Our code is publicly available at https://github.com/jiayi-ma/GANMcC.",
    "citationCount": 579,
    "pdf_filename": "2021_GANMcC__A_Generative_Adversarial_Network_ed0959d7.pdf"
  },
  "4858fa952d9e313ba58febafcf9c82b1bcf2ddb3": {
    "paperId": "4858fa952d9e313ba58febafcf9c82b1bcf2ddb3",
    "title": "Revolutionizing education with AI: Exploring the transformative potential of ChatGPT",
    "year": 2023,
    "authors": "Tufan Adiguzel, M. H. Kaya, Fatih Kursat Cansu",
    "abstract": "Artificial intelligence (AI) introduces new tools to the educational environment with the potential to transform conventional teaching and learning processes. This study offers a comprehensive overview of AI technologies, their potential applications in education, and the difficulties involved. Chatbots and related algorithms that can simulate human interactions and generate human-like text based on input from natural language are discussed. In addition to the advantages of cutting-edge chatbots like ChatGPT, their use in education raises important ethical and practical challenges. The authors aim to provide insightful information on how AI may be successfully incorporated into the educational setting to benefit teachers and students, while promoting responsible and ethical use.",
    "citationCount": 593,
    "pdf_filename": "2023_Revolutionizing_education_with_AI__Explo_4858fa95.pdf"
  },
  "bc519f58ae61afbf6318d6e4239d2d565c7ba467": {
    "paperId": "bc519f58ae61afbf6318d6e4239d2d565c7ba467",
    "title": "Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models",
    "year": 2021,
    "authors": "Sam Bond-Taylor, Adam Leach, Yang Long, Chris G. Willcocks",
    "abstract": "Deep generative models are a class of techniques that train deep neural networks to model the distribution of training samples. Research has fragmented into various interconnected approaches, each of which make trade-offs including run-time, diversity, and architectural restrictions. In particular, this compendium covers energy-based models, variational autoencoders, generative adversarial networks, autoregressive models, normalizing flows, in addition to numerous hybrid approaches. These techniques are compared and contrasted, explaining the premises behind each and how they are interrelated, while reviewing current state-of-the-art advances and implementations.",
    "citationCount": 612,
    "pdf_filename": "2021_Deep_Generative_Modelling__A_Comparative_bc519f58.pdf"
  },
  "0968f1592f9401d72bf0d97e740496818c1a3135": {
    "paperId": "0968f1592f9401d72bf0d97e740496818c1a3135",
    "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
    "year": 2021,
    "authors": "Vivian Liu, Lydia B. Chilton",
    "abstract": "Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.",
    "citationCount": 598,
    "pdf_filename": "2021_Design_Guidelines_for_Prompt_Engineering_0968f159.pdf"
  },
  "d00735241af700d21762d2f3ca00d920241a15a4": {
    "paperId": "d00735241af700d21762d2f3ca00d920241a15a4",
    "title": "Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models",
    "year": 2023,
    "authors": "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu",
    "abstract": "\n While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.",
    "citationCount": 775,
    "pdf_filename": "2023_Siren_s_Song_in_the_AI_Ocean__A_Survey_o_d0073524.pdf"
  },
  "18faafb15d7e7a8ad923b293f8c945c35680a2ef": {
    "paperId": "18faafb15d7e7a8ad923b293f8c945c35680a2ef",
    "title": "ChatGPT and Open-AI Models: A Preliminary Review",
    "year": 2023,
    "authors": "Konstantinos I. Roumeliotis, Nikolaos D. Tselikas",
    "abstract": "According to numerous reports, ChatGPT represents a significant breakthrough in the field of artificial intelligence. ChatGPT is a pre-trained AI model designed to engage in natural language conversations, utilizing sophisticated techniques from Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to comprehend and generate text comparable to human-generated text. This article provides an overview of the training process and fundamental functionality of ChatGPT, accompanied by a preliminary review of the relevant literature. Notably, this article presents the first comprehensive literature review of this technology at the time of publication, aiming to aggregate all the available pertinent articles to facilitate further developments in the field. Ultimately, the authors aim to offer an appraisal of the technology’s potential implications on existing knowledge and technology, along with potential challenges that must be addressed.",
    "citationCount": 567,
    "pdf_filename": "2023_ChatGPT_and_Open_AI_Models__A_Preliminar_18faafb1.pdf"
  },
  "12594b6afe01461384d2856d2bf44f1cf8533e3e": {
    "paperId": "12594b6afe01461384d2856d2bf44f1cf8533e3e",
    "title": "ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health",
    "year": 2023,
    "authors": "L. De Angelis, F. Baglivo, G. Arzilli, G. P. Privitera, P. Ferragina",
    "abstract": "Large Language Models (LLMs) have recently gathered attention with the release of ChatGPT, a user-centered chatbot released by OpenAI. In this perspective article, we retrace the evolution of LLMs to understand the revolution brought by ChatGPT in the artificial intelligence (AI) field. The opportunities offered by LLMs in supporting scientific research are multiple and various models have already been tested in Natural Language Processing (NLP) tasks in this domain. The impact of ChatGPT has been huge for the general public and the research community, with many authors using the chatbot to write part of their articles and some papers even listing ChatGPT as an author. Alarming ethical and practical challenges emerge from the use of LLMs, particularly in the medical field for the potential impact on public health. Infodemic is a trending topic in public health and the ability of LLMs to rapidly produce vast amounts of text could leverage misinformation spread at an unprecedented scale, this could create an “AI-driven infodemic,” a novel public health threat. Policies to contrast this phenomenon need to be rapidly elaborated, the inability to accurately detect artificial-intelligence-produced text is an unresolved issue.",
    "citationCount": 510,
    "pdf_filename": "2023_ChatGPT_and_the_rise_of_large_language_m_12594b6a.pdf"
  },
  "8d17d62952f141fe5c4948eeafb8be5a8db9d054": {
    "paperId": "8d17d62952f141fe5c4948eeafb8be5a8db9d054",
    "title": "pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis",
    "year": 2020,
    "authors": "Eric Chan, M. Monteiro, Petr Kellnhofer, Jiajun Wu, Gordon Wetzstein",
    "abstract": "We have witnessed rapid progress on 3D-aware image synthesis, leveraging recent advances in generative visual models and neural rendering. Existing approaches how-ever fall short in two ways: first, they may lack an under-lying 3D representation or rely on view-inconsistent rendering, hence synthesizing images that are not multi-view consistent; second, they often depend upon representation network architectures that are not expressive enough, and their results thus lack in image quality. We propose a novel generative model, named Periodic Implicit Generative Adversarial Networks (π-GAN or pi-GAN), for high-quality 3D-aware image synthesis. π-GAN leverages neural representations with periodic activation functions and volumetric rendering to represent scenes as view-consistent radiance fields. The proposed approach obtains state-of-the-art results for 3D-aware image synthesis with multiple real and synthetic datasets.",
    "citationCount": 924,
    "pdf_filename": "2020_pi_GAN__Periodic_Implicit_Generative_Adv_8d17d629.pdf"
  },
  "62d337dbaead376ca042f23d62c0d4b65ec98546": {
    "paperId": "62d337dbaead376ca042f23d62c0d4b65ec98546",
    "title": "GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis",
    "year": 2020,
    "authors": "Katja Schwarz, Yiyi Liao, Michael Niemeyer, Andreas Geiger",
    "abstract": "While 2D generative adversarial networks have enabled high-resolution image synthesis, they largely lack an understanding of the 3D world and the image formation process. Thus, they do not provide precise control over camera viewpoint or object pose. To address this problem, several recent approaches leverage intermediate voxel-based representations in combination with differentiable rendering. However, existing methods either produce low image resolution or fall short in disentangling camera and scene properties, e.g., the object identity may vary with the viewpoint. In this paper, we propose a generative model for radiance fields which have recently proven successful for novel view synthesis of a single scene. In contrast to voxel-based representations, radiance fields are not confined to a coarse discretization of the 3D space, yet allow for disentangling camera and scene properties while degrading gracefully in the presence of reconstruction ambiguity. By introducing a multi-scale patch-based discriminator, we demonstrate synthesis of high-resolution images while training our model from unposed 2D images alone. We systematically analyze our approach on several challenging synthetic and real-world datasets. Our experiments reveal that radiance fields are a powerful representation for generative image synthesis, leading to 3D consistent models that render with high fidelity.",
    "citationCount": 931,
    "pdf_filename": "2020_GRAF__Generative_Radiance_Fields_for_3D__62d337db.pdf"
  },
  "fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea": {
    "paperId": "fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea",
    "title": "A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications",
    "year": 2020,
    "authors": "Jie Gui, Zhenan Sun, Yonggang Wen, D. Tao, Jieping Ye",
    "abstract": "Generative adversarial networks (GANs) have recently become a hot research topic; however, they have been studied since 2014, and a large number of algorithms have been proposed. Nevertheless, few comprehensive studies explain the connections among different GAN variants and how they have evolved. In this paper, we attempt to provide a review of the various GAN methods from the perspectives of algorithms, theory, and applications. First, the motivations, mathematical representations, and structures of most GAN algorithms are introduced in detail, and we compare their commonalities and differences. Second, theoretical issues related to GANs are investigated. Finally, typical applications of GANs in image processing and computer vision, natural language processing, music, speech and audio, the medical field, and data science are discussed.",
    "citationCount": 991,
    "pdf_filename": "2020_A_Review_on_Generative_Adversarial_Netwo_fbc5486a.pdf"
  },
  "2ed0d4931d89528bd53482a0b6587ebcbba6d096": {
    "paperId": "2ed0d4931d89528bd53482a0b6587ebcbba6d096",
    "title": "Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search",
    "year": 2020,
    "authors": "Jaehyeon Kim, Sungwon Kim, Jungil Kong, Sungroh Yoon",
    "abstract": "Recently, text-to-speech (TTS) models such as FastSpeech and ParaNet have been proposed to generate mel-spectrograms from text in parallel. Despite the advantage, the parallel TTS models cannot be trained without guidance from autoregressive TTS models as their external aligners. In this work, we propose Glow-TTS, a flow-based generative model for parallel TTS that does not require any external aligner. By combining the properties of flows and dynamic programming, the proposed model searches for the most probable monotonic alignment between text and the latent representation of speech on its own. We demonstrate that enforcing hard monotonic alignments enables robust TTS, which generalizes to long utterances, and employing generative flows enables fast, diverse, and controllable speech synthesis. Glow-TTS obtains an order-of-magnitude speed-up over the autoregressive model, Tacotron 2, at synthesis with comparable speech quality. We further show that our model can be easily extended to a multi-speaker setting.",
    "citationCount": 565,
    "pdf_filename": "2020_Glow_TTS__A_Generative_Flow_for_Text_to__2ed0d493.pdf"
  },
  "3efbcfeeb0ea1051a71101d3318da4411081f0b8": {
    "paperId": "3efbcfeeb0ea1051a71101d3318da4411081f0b8",
    "title": "Scaling Laws for Autoregressive Generative Modeling",
    "year": 2020,
    "authors": "T. Henighan, J. Kaplan, Mor Katz, Mark Chen, Christopher Hesse",
    "abstract": "We identify empirical scaling laws for the cross-entropy loss in four domains: generative image modeling, video modeling, multimodal image$\\leftrightarrow$text models, and mathematical problem solving. In all cases autoregressive Transformers smoothly improve in performance as model size and compute budgets increase, following a power-law plus constant scaling law. The optimal model size also depends on the compute budget through a power-law, with exponents that are nearly universal across all data domains. \nThe cross-entropy loss has an information theoretic interpretation as $S($True$) + D_{\\mathrm{KL}}($True$||$Model$)$, and the empirical scaling laws suggest a prediction for both the true data distribution's entropy and the KL divergence between the true and model distributions. With this interpretation, billion-parameter Transformers are nearly perfect models of the YFCC100M image distribution downsampled to an $8\\times 8$ resolution, and we can forecast the model size needed to achieve any given reducible loss (ie $D_{\\mathrm{KL}}$) in nats/image for other resolutions. \nWe find a number of additional scaling laws in specific domains: (a) we identify a scaling relation for the mutual information between captions and images in multimodal models, and show how to answer the question \"Is a picture worth a thousand words?\"; (b) in the case of mathematical problem solving, we identify scaling laws for model performance when extrapolating beyond the training distribution; (c) we finetune generative image models for ImageNet classification and find smooth scaling of the classification loss and error rate, even as the generative loss levels off. Taken together, these results strengthen the case that scaling laws have important implications for neural network performance, including on downstream tasks.",
    "citationCount": 537,
    "pdf_filename": "2020_Scaling_Laws_for_Autoregressive_Generati_3efbcfee.pdf"
  },
  "9b6a7df58664000c9a9bc4e3141e2630e02ac177": {
    "paperId": "9b6a7df58664000c9a9bc4e3141e2630e02ac177",
    "title": "High-Fidelity Generative Image Compression",
    "year": 2020,
    "authors": "Fabian Mentzer, G. Toderici, Michael Tschannen, E. Agustsson",
    "abstract": "We extensively study how to combine Generative Adversarial Networks and learned compression to obtain a state-of-the-art generative lossy compression system. In particular, we investigate normalization layers, generator and discriminator architectures, training strategies, as well as perceptual losses. In contrast to previous work, i) we obtain visually pleasing reconstructions that are perceptually similar to the input, ii) we operate in a broad range of bitrates, and iii) our approach can be applied to high-resolution images. We bridge the gap between rate-distortion-perception theory and practice by evaluating our approach both quantitatively with various perceptual metrics and a user study. The study shows that our method is preferred to previous approaches even if they use more than 2x the bitrate.",
    "citationCount": 543,
    "pdf_filename": "2020_High_Fidelity_Generative_Image_Compressi_9b6a7df5.pdf"
  },
  "67dea28495cab71703993d0d52ca4733b9a66077": {
    "paperId": "67dea28495cab71703993d0d52ca4733b9a66077",
    "title": "Jukebox: A Generative Model for Music",
    "year": 2020,
    "authors": "Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford",
    "abstract": "We introduce Jukebox, a model that generates music with singing in the raw audio domain. We tackle the long context of raw audio using a multi-scale VQ-VAE to compress it to discrete codes, and modeling those using autoregressive Transformers. We show that the combined model at scale can generate high-fidelity and diverse songs with coherence up to multiple minutes. We can condition on artist and genre to steer the musical and vocal style, and on unaligned lyrics to make the singing more controllable. We are releasing thousands of non cherry-picked samples at this https URL, along with model weights and code at this https URL",
    "citationCount": 888,
    "pdf_filename": "2020_Jukebox__A_Generative_Model_for_Music_67dea284.pdf"
  },
  "5be878987dfccd543c73f31db973a81cc738aefa": {
    "paperId": "5be878987dfccd543c73f31db973a81cc738aefa",
    "title": "PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models",
    "year": 2020,
    "authors": "Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, C. Rudin",
    "abstract": "The primary aim of single-image super-resolution is to construct a high-resolution (HR) image from a corresponding low-resolution (LR) input. In previous approaches, which have generally been supervised, the training objective typically measures a pixel-wise average distance between the super-resolved (SR) and HR images. Optimizing such metrics often leads to blurring, especially in high variance (detailed) regions. We propose an alternative formulation of the super-resolution problem based on creating realistic SR images that downscale correctly. We present a novel super-resolution algorithm addressing this problem, PULSE (Photo Upsampling via Latent Space Exploration), which generates high-resolution, realistic images at resolutions previously unseen in the literature. It accomplishes this in an entirely self-supervised fashion and is not confined to a specific degradation operator used during training, unlike previous methods (which require training on databases of LR-HR image pairs for supervised learning). Instead of starting with the LR image and slowly adding detail, PULSE traverses the high-resolution natural image manifold, searching for images that downscale to the original LR image. This is formalized through the “downscaling loss,” which guides exploration through the latent space of a generative model. By leveraging properties of high-dimensional Gaussians, we restrict the search space to guarantee that our outputs are realistic. PULSE thereby generates super-resolved images that both are realistic and downscale correctly. We show extensive experimental results demonstrating the efficacy of our approach in the domain of face super-resolution (also known as face hallucination). Our method outperforms state-of-the-art methods in perceptual quality at higher resolutions and scale factors than previously possible.",
    "citationCount": 600,
    "pdf_filename": "2020_PULSE__Self_Supervised_Photo_Upsampling__5be87898.pdf"
  },
  "c689d1f3ae2447fd5b2f108b5b4436276e4d3761": {
    "paperId": "c689d1f3ae2447fd5b2f108b5b4436276e4d3761",
    "title": "LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking",
    "year": 2022,
    "authors": "Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, Furu Wei",
    "abstract": "Self-supervised pre-training techniques have achieved remarkable progress in Document AI. Most multimodal pre-trained models use a masked language modeling objective to learn bidirectional representations on the text modality, but they differ in pre-training objectives for the image modality. This discrepancy adds difficulty to multimodal representation learning. In this paper, we propose LayoutLMv3 to pre-train multimodal Transformers for Document AI with unified text and image masking. Additionally, LayoutLMv3 is pre-trained with a word-patch alignment objective to learn cross-modal alignment by predicting whether the corresponding image patch of a text word is masked. The simple unified architecture and training objectives make LayoutLMv3 a general-purpose pre-trained model for both text-centric and image-centric Document AI tasks. Experimental results show that LayoutLMv3 achieves state-of-the-art performance not only in text-centric tasks, including form understanding, receipt understanding, and document visual question answering, but also in image-centric tasks such as document image classification and document layout analysis. The code and models are publicly available at https://aka.ms/layoutlmv3.",
    "citationCount": 589,
    "pdf_filename": "2022_LayoutLMv3__Pre_training_for_Document_AI_c689d1f3.pdf"
  },
  "7caaafd5a3ee033c98e792c7ea5b699d005753d5": {
    "paperId": "7caaafd5a3ee033c98e792c7ea5b699d005753d5",
    "title": "From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI",
    "year": 2022,
    "authors": "Meike Nauta, Jan Trienes, Shreyasi Pathak, Elisa Nguyen, Michelle Peters",
    "abstract": "The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the past 7 years at major AI and ML conferences that introduce an XAI method. We find that one in three papers evaluate exclusively with anecdotal evidence, and one in five papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark, and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training to optimize for accuracy and interpretability simultaneously.",
    "citationCount": 536,
    "pdf_filename": "2022_From_Anecdotal_Evidence_to_Quantitative__7caaafd5.pdf"
  },
  "22548cb1c72e4966a3c465c8363c1e421ab66748": {
    "paperId": "22548cb1c72e4966a3c465c8363c1e421ab66748",
    "title": "AI-Based Modeling: Techniques, Applications and Research Issues Towards Automation, Intelligent and Smart Systems",
    "year": 2022,
    "authors": "Iqbal H. Sarker",
    "abstract": "Artificial intelligence (AI) is a leading technology of the current age of the Fourth Industrial Revolution (Industry 4.0 or 4IR), with the capability of incorporating human behavior and intelligence into machines or systems. Thus, AI-based modeling is the key to build automated, intelligent, and smart systems according to today’s needs. To solve real-world issues, various types of AI such as analytical, functional, interactive, textual, and visual AI can be applied to enhance the intelligence and capabilities of an application. However, developing an effective AI model is a challenging task due to the dynamic nature and variation in real-world problems and data. In this paper, we present a comprehensive view on “AI-based Modeling” with the principles and capabilities of potential AI techniques that can play an important role in developing intelligent and smart systems in various real-world application areas including business, finance, healthcare, agriculture, smart cities, cybersecurity and many more. We also emphasize and highlight the research issues within the scope of our study. Overall, the goal of this paper is to provide a broad overview of AI-based modeling that can be used as a reference guide by academics and industry people as well as decision-makers in various real-world scenarios and application domains.",
    "citationCount": 736,
    "pdf_filename": "2022_AI_Based_Modeling__Techniques__Applicati_22548cb1.pdf"
  },
  "3b8abd466697998c6e17df2cd30f48a7594d795b": {
    "paperId": "3b8abd466697998c6e17df2cd30f48a7594d795b",
    "title": "Explainable AI (XAI): Core Ideas, Techniques, and Solutions",
    "year": 2022,
    "authors": "Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, O. Rana",
    "abstract": "As our dependence on intelligent machines continues to grow, so does the demand for more transparent and interpretable models. In addition, the ability to explain the model generally is now the gold standard for building trust and deployment of artificial intelligence systems in critical domains. Explainable artificial intelligence (XAI) aims to provide a suite of machine learning techniques that enable human users to understand, appropriately trust, and produce more explainable models. Selecting an appropriate approach for building an XAI-enabled application requires a clear understanding of the core ideas within XAI and the associated programming frameworks. We survey state-of-the-art programming techniques for XAI and present the different phases of XAI in a typical machine learning development process. We classify the various XAI approaches and, using this taxonomy, discuss the key differences among the existing XAI techniques. Furthermore, concrete examples are used to describe these techniques that are mapped to programming frameworks and software toolkits. It is the intention that this survey will help stakeholders in selecting the appropriate approaches, programming frameworks, and software toolkits by comparing them through the lens of the presented taxonomy.",
    "citationCount": 820,
    "pdf_filename": "2022_Explainable_AI__XAI___Core_Ideas__Techni_3b8abd46.pdf"
  },
  "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea": {
    "paperId": "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea",
    "title": "“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI",
    "year": 2021,
    "authors": "Nithya Sambasivan, Shivani Kapania, H. Highfill, Diana Akrong, Praveen K. Paritosh",
    "abstract": "AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades—compounding events causing negative, downstream effects from data issues—triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.",
    "citationCount": 830,
    "pdf_filename": "2021__Everyone_wants_to_do_the_model_work__no_63d7e40d.pdf"
  },
  "c18ff70a0a0ac21b22e9736ecebc627707924fa7": {
    "paperId": "c18ff70a0a0ac21b22e9736ecebc627707924fa7",
    "title": "Atlas of AI: Power, Politics and the Planetary Costs of Artificial Intelligence",
    "year": 2021,
    "authors": "Kate Crawford",
    "abstract": "ATLAS OF AI: Power, Politics, and the Planetary Costs of Artificial Intelligence by Kate Crawford. New Haven, CT: Yale University Press, 2021. 336 pages. Hardcover; $28.00. ISBN: 9780300209570. *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence is Kate Crawford's analysis of the state of the AI industry. A central idea of her book is the importance of redefining Artificial Intelligence (AI). She states, \"I've argued that there is much at stake in how we define AI, what its boundaries are, and who determines them: it shapes what can be seen and contested\" (p. 217). *My own definition of AI goes something like this: I¬†imagine a future where I'm sitting in a cafe drinking coffee with my friends, but in this future, one of my friends is a robot, who like me is trying to make a living in this world. A future where humans and robots live in harmony. Crawford views this definition as mythological: \"These mythologies are particularly strong in the field of artificial intelligence, where the belief that human intelligence can be formalized and reproduced by machines has been axiomatic since the mid-twentieth century\" (p.¬†5). I do not know if my definition of artificial intelligence can come true, but I am enjoying the process of building, experimenting, and dreaming. *In her book, she asks me to consider that I may be unknowingly participating, as she states, in \"a material product of colonialism, with its patterns of extraction, conflict, and environmental destruction\" (p. 38). The book's subtitle illuminates the purpose of the book: specifically, the power, politics, and planetary costs of usurping artificial intelligence. Of course, this is not exactly Crawford's subtitle, and this is where I both agree and disagree with her. The book's subtitle is actually Power, Politics, and the Planetary Costs of Artificial Intelligence. In my opinion, AI is more the canary in the coal mine. We can use the canary to detect the poisonous gases, but we cannot blame the canary for the poisonous gas. It risks missing the point. Is AI itself to be feared? Should we no longer teach or learn AI? Or is this more about how we discern responsible use and direction for AI technology? *There is another author who speaks to similar issues. In Weapons of Math Destruction, Cathy O'Neil states it this way, \"If we had been clear-headed, we all would have taken a step back at this point to figure out how math had been misused ... But instead ... new mathematical techniques were hotter than ever ... A computer program could speed through thousands of resumes or loan applications in a second or two and sort them into neat lists, with the most promising candidates on top\" (p. 13). *Both Crawford and O'Neil point to human flaws that often lead to well-intentioned software developers creating code that results in unfair and discriminatory decisions. AI models encode unintended human biases that may not evaluate candidates as fairly as we would expect, yet there is a widespread notion that we can trust the algorithm. For example, the last time you registered an account on a website, did you click the checkbox confirming that \"yes, I read the disclaimer\" even though you did not? When we click \"yes\" we are accepting this disclaimer and placing trust in the software. Business owners place trust in software when they use it to make predictions. Engineers place trust in their algorithms when they write software without rigorous testing protocols. I¬†am just as guilty. *Crawford suggests that AI is often used in ways that are harmful. In the Atlas of AI we are given a tour of how technology is damaging our world: strip mining, labor injustice, the misuse of personal data, issues of state and power, to name a few of the concerns Crawford raises. The reality is that AI is built upon existing infrastructure. For example, Facebook, Instagram, YouTube, Amazon, TikTok have been collecting our information for profit even before AI became important to them. The data centers, CPU houses, and worldwide network infrastructure were already in place to meet consumer demand and geopolitics. But it is true that AI brings new technologies to the table, such as automated face recognition and decision tools to compare prospective employment applicants with diverse databases and employee monitoring tools that can make automatic recommendations. Governments, militaries, and intelligence agencies have taken notice. As invasion of privacy and social justice concerns emerge, Crawford calls us to consider these issues carefully. *Reading Crawford's words pricked my conscience, convicting me to reconsider my erroneous ways. For big tech to exist, to supply what we demand, it needs resources. She walks us through the many resources the technology industry needs to provide what we want, and AI is the \"new kid on the block.\" This book is not about AI, per se; it is instead about the side effects of poor business/research practices, opportunist behavior, power politics, and how these behaviors not only exploit our planet but also unjustly affect marginalized people. The AI industry is simply a new example of this reality: data mining, low wages to lower costs, foreign workers with fewer rights, strip mining, relying on coal and oil for electricity (although some tech companies have made strides to improve sustainability). This sounds more like a parable about the sins of the tech industry than a critique about the dangers of AI. *Could the machine learning community, like the inventors of dynamite who wanted to simply help railroads excavate tunnels, be unintentionally causing harm? Should we, as a community, be on the lookout for these potential harms? Do we have a moral responsibility? Maybe the technology sector needs to look more inwardly to ensure that process efficiency and cost savings are not elevated as most important. *I did not agree with everything that Crawford classified as AI, but I do agree that as a community we are responsible for our actions. If there are injustices, then this should be important to us. In particular, as people of faith, we should heed the call of Micah 6:8 to act justly in this world, and this includes how we use AI. *Reviewed by Joseph Vybihal, Professor of Computer Science, McGill University, Montreal, PQ H3A 0G4.",
    "citationCount": 653,
    "pdf_filename": "2021_Atlas_of_AI__Power__Politics_and_the_Pla_c18ff70a.pdf"
  },
  "f46bce5b7dd78736133c1af1824ddb83c0ec2e55": {
    "paperId": "f46bce5b7dd78736133c1af1824ddb83c0ec2e55",
    "title": "Habitat-Matterport 3D Dataset (HM3D): 1000 Large-scale 3D Environments for Embodied AI",
    "year": 2021,
    "authors": "Santhosh K. Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets, Alexander Clegg",
    "abstract": "We present the Habitat-Matterport 3D (HM3D) dataset. HM3D is a large-scale dataset of 1,000 building-scale 3D reconstructions from a diverse set of real-world locations. Each scene in the dataset consists of a textured 3D mesh reconstruction of interiors such as multi-floor residences, stores, and other private indoor spaces. HM3D surpasses existing datasets available for academic research in terms of physical scale, completeness of the reconstruction, and visual fidelity. HM3D contains 112.5k m^2 of navigable space, which is 1.4 - 3.7x larger than other building-scale datasets such as MP3D and Gibson. When compared to existing photorealistic 3D datasets such as Replica, MP3D, Gibson, and ScanNet, images rendered from HM3D have 20 - 85% higher visual fidelity w.r.t. counterpart images captured with real cameras, and HM3D meshes have 34 - 91% fewer artifacts due to incomplete surface reconstruction. The increased scale, fidelity, and diversity of HM3D directly impacts the performance of embodied AI agents trained using it. In fact, we find that HM3D is `pareto optimal' in the following sense -- agents trained to perform PointGoal navigation on HM3D achieve the highest performance regardless of whether they are evaluated on HM3D, Gibson, or MP3D. No similar claim can be made about training on other datasets. HM3D-trained PointNav agents achieve 100% performance on Gibson-test dataset, suggesting that it might be time to retire that episode dataset.",
    "citationCount": 525,
    "pdf_filename": "2021_Habitat_Matterport_3D_Dataset__HM3D___10_f46bce5b.pdf"
  },
  "021bd56b6c95d0196f3b8e818c948ea0702b0836": {
    "paperId": "021bd56b6c95d0196f3b8e818c948ea0702b0836",
    "title": "AI Choreographer: Music Conditioned 3D Dance Generation with AIST++",
    "year": 2021,
    "authors": "Ruilong Li, Sha Yang, David A. Ross, Angjoo Kanazawa",
    "abstract": "We present AIST++, a new multi-modal dataset of 3D dance motion and music, along with FACT, a Full-Attention Cross-modal Transformer network for generating 3D dance motion conditioned on music. The proposed AIST++ dataset contains 5.2 hours of 3D dance motion in 1408 sequences, covering 10 dance genres with multi-view videos with known camera poses—the largest dataset of this kind to our knowledge. We show that naively applying sequence models such as transformers to this dataset for the task of music conditioned 3D motion generation does not produce satisfactory 3D motion that is well correlated with the input music. We overcome these shortcomings by introducing key changes in its architecture design and supervision: FACT model involves a deep cross-modal transformer block with full-attention that is trained to predict N future motions. We empirically show that these changes are key factors in generating long sequences of realistic dance motion that are well-attuned to the input music. We conduct extensive experiments on AIST++ with user studies, where our method outperforms recent state-of-the-art methods both qualitatively and quantitatively. The code and the dataset can be found at: https://google.github.io/aichoreographer.",
    "citationCount": 613,
    "pdf_filename": "2021_AI_Choreographer__Music_Conditioned_3D_D_021bd56b.pdf"
  },
  "83311744b174550032cfe09cb2940703dc9c9245": {
    "paperId": "83311744b174550032cfe09cb2940703dc9c9245",
    "title": "A Review of Artificial Intelligence (AI) in Education from 2010 to 2020",
    "year": 2021,
    "authors": "Xuesong Zhai, Xiaoyan Chu, C. Chai, M. Jong, Andreja Istenič",
    "abstract": "This study provided a content analysis of studies aiming to disclose how artificial intelligence (AI) has been applied to the education sector and explore the potential research trends and challenges of AI in education. A total of 100 papers including 63 empirical papers (74 studies) and 37 analytic papers were selected from the education and educational research category of Social Sciences Citation Index database from 2010 to 2020. The content analysis showed that the research questions could be classified into development layer (classification, matching, recommendation, and deep learning), application layer (feedback, reasoning, and adaptive learning), and integration layer (affection computing, role-playing, immersive learning, and gamification). Moreover, four research trends, including Internet of Things, swarm intelligence, deep learning, and neuroscience, as well as an assessment of AI in education, were suggested for further investigation. However, we also proposed the challenges in education may be caused by AI with regard to inappropriate use of AI techniques, changing roles of teachers and students, as well as social and ethical issues. The results provide insights into an overview of the AI used for education domain, which helps to strengthen the theoretical foundation of AI in education and provides a promising channel for educators and AI engineers to carry out further collaborative research.",
    "citationCount": 762,
    "pdf_filename": "2021_A_Review_of_Artificial_Intelligence__AI__83311744.pdf"
  },
  "cfaea43aec271372091aadbc65f089ca67cac8d5": {
    "paperId": "cfaea43aec271372091aadbc65f089ca67cac8d5",
    "title": "Ethics of AI in Education: Towards a Community-Wide Framework",
    "year": 2021,
    "authors": "Wayne Holmes, K. Porayska-Pomsta, Kenneth Holstein, Emma Sutherland, Toby Baker",
    "abstract": "While Artificial Intelligence in Education (AIED) research has at its core the desire to support student learning, experience from other AI domains suggest that such ethical intentions are not by themselves sufficient. There is also the need to consider explicitly issues such as fairness, accountability, transparency, bias, autonomy, agency, and inclusion. At a more general level, there is also a need to differentiate between doing ethical things and doing things ethically, to understand and to make pedagogical choices that are ethical, and to account for the ever-present possibility of unintended consequences. However, addressing these and related questions is far from trivial. As a first step towards addressing this critical gap, we invited 60 of the AIED community’s leading researchers to respond to a survey of questions about ethics and the application of AI in educational contexts. In this paper, we first introduce issues around the ethics of AI in education. Next, we summarise the contributions of the 17 respondents, and discuss the complex issues that they raised. Specific outcomes include the recognition that most AIED researchers are not trained to tackle the emerging ethical questions. A well-designed framework for engaging with ethics of AIED that combined a multidisciplinary approach and a set of robust guidelines seems vital in this context.",
    "citationCount": 599,
    "pdf_filename": "2021_Ethics_of_AI_in_Education__Towards_a_Com_cfaea43a.pdf"
  },
  "0bb29f3e0b7151920795b6d3588084d13c33c672": {
    "paperId": "0bb29f3e0b7151920795b6d3588084d13c33c672",
    "title": "Understanding anthropomorphism in service provision: a meta-analysis of physical robots, chatbots, and other AI",
    "year": 2021,
    "authors": "Markus Blut, Cheng Wang, N. Wünderlich, Christian Brock",
    "abstract": "An increasing number of firms introduce service robots, such as physical robots and virtual chatbots, to provide services to customers. While some firms use robots that resemble human beings by looking and acting humanlike to increase customers’ use intention of this technology, others employ machinelike robots to avoid uncanny valley effects, assuming that very humanlike robots may induce feelings of eeriness. There is no consensus in the service literature regarding whether customers’ anthropomorphism of robots facilitates or constrains their use intention. The present meta-analysis synthesizes data from 11,053 individuals interacting with service robots reported in 108 independent samples. The study synthesizes previous research to clarify this issue and enhance understanding of the construct. We develop a comprehensive model to investigate relationships between anthropomorphism and its antecedents and consequences. Customer traits and predispositions (e.g., computer anxiety), sociodemographics (e.g., gender), and robot design features (e.g., physical, nonphysical) are identified as triggers of anthropomorphism. Robot characteristics (e.g., intelligence) and functional characteristics (e.g., usefulness) are identified as important mediators, although relational characteristics (e.g., rapport) receive less support as mediators. The findings clarify contextual circumstances in which anthropomorphism impacts customer intention to use a robot. The moderator analysis indicates that the impact depends on robot type (i.e., robot gender) and service type (i.e., possession-processing service, mental stimulus-processing service). Based on these findings, we develop a comprehensive agenda for future research on service robots in marketing.",
    "citationCount": 733,
    "pdf_filename": "2021_Understanding_anthropomorphism_in_servic_0bb29f3e.pdf"
  },
  "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0": {
    "paperId": "2c6df83795cd5baf3b8c6e2639b85e2df0cee1d0",
    "title": "Sustainable AI: Environmental Implications, Challenges and Opportunities",
    "year": 2021,
    "authors": "Carole-Jean Wu, R. Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani",
    "abstract": "This paper explores the environmental impact of the super-linear growth trends for AI from a holistic perspective, spanning Data, Algorithms, and System Hardware. We characterize the carbon footprint of AI computing by examining the model development cycle across industry-scale machine learning use cases and, at the same time, considering the life cycle of system hardware. Taking a step further, we capture the operational and manufacturing carbon footprint of AI computing and present an end-to-end analysis for what and how hardware-software design and at-scale optimization can help reduce the overall carbon footprint of AI. Based on the industry experience and lessons learned, we share the key challenges and chart out important development directions across the many dimensions of AI. We hope the key messages and insights presented in this paper can inspire the community to advance the field of AI in an environmentally-responsible manner.",
    "citationCount": 512,
    "pdf_filename": "2021_Sustainable_AI__Environmental_Implicatio_2c6df837.pdf"
  },
  "eb90f7a7f281ccbf64084e11adf822fae2d9bc3f": {
    "paperId": "eb90f7a7f281ccbf64084e11adf822fae2d9bc3f",
    "title": "Sustainable AI: AI for sustainability and the sustainability of AI",
    "year": 2021,
    "authors": "Aimee van Wynsberghe",
    "abstract": "While there is a growing effort towards AI for Sustainability (e.g. towards the sustainable development goals) it is time to move beyond that and to address the sustainability of developing and using AI systems. In this paper I propose a definition of Sustainable AI; Sustainable AI is a movement to foster change in the entire lifecycle of AI products (i.e. idea generation, training, re-tuning, implementation, governance) towards greater ecological integrity and social justice. As such, Sustainable AI is focused on more than AI applications; rather, it addresses the whole sociotechnical system of AI. I have suggested here that Sustainable AI is not about how to sustain the development of AI per say but it is about how to develop AI that is compatible with sustaining environmental resources for current and future generations; economic models for societies; and societal values that are fundamental to a given society. I have articulated that the phrase Sustainable AI be understood as having two branches; AI for sustainability and sustainability of AI (e.g. reduction of carbon emissions and computing power). I propose that Sustainable AI take sustainable development at the core of its definition with three accompanying tensions between AI innovation and equitable resource distribution; inter and intra-generational justice; and, between environment, society, and economy. This paper is not meant to engage with each of the three pillars of sustainability (i.e. social, economic, environment), and as such the pillars of sustainable AI. Rather, this paper is meant to inspire the reader, the policy maker, the AI ethicist, the AI developer to connect with the environment—to remember that there are environmental costs to AI. Further, to direct funding towards sustainable methods of AI.",
    "citationCount": 542,
    "pdf_filename": "2021_Sustainable_AI__AI_for_sustainability_an_eb90f7a7.pdf"
  },
  "dbde9692749150152354690e0706c3032b9c6be0": {
    "paperId": "dbde9692749150152354690e0706c3032b9c6be0",
    "title": "Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence",
    "year": 2021,
    "authors": "G. Collins, P. Dhiman, C. A. Andaur Navarro, Jie Ma, L. Hooft",
    "abstract": "Introduction The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. Methods and analysis TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethics and dissemination Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. PROSPERO registration number CRD42019140361 and CRD42019161764.",
    "citationCount": 554,
    "pdf_filename": "2021_Protocol_for_development_of_a_reporting__dbde9692.pdf"
  },
  "d3640eb3b542eaf36fee2261f037a6bf0d8eac9c": {
    "paperId": "d3640eb3b542eaf36fee2261f037a6bf0d8eac9c",
    "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts",
    "year": 2021,
    "authors": "Tongshuang Sherry Wu, Michael Terry, Carrie J. Cai",
    "abstract": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by “unit-testing” sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.",
    "citationCount": 556,
    "pdf_filename": "2021_AI_Chains__Transparent_and_Controllable__d3640eb3.pdf"
  },
  "87d5b61f5b6fdb0a57fc66b5c5bb428c398eaa86": {
    "paperId": "87d5b61f5b6fdb0a57fc66b5c5bb428c398eaa86",
    "title": "Deep learning for AI",
    "year": 2021,
    "authors": "Yoshua Bengio, Yann LeCun, Geoffrey E. Hinton",
    "abstract": "How can neural networks learn the rich internal representations required for difficult tasks such as recognizing objects or understanding language?",
    "citationCount": 567,
    "pdf_filename": "2021_Deep_learning_for_AI_87d5b61f.pdf"
  },
  "107169ebaa4f979572bebfe56452120440bacb7a": {
    "paperId": "107169ebaa4f979572bebfe56452120440bacb7a",
    "title": "Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI extension",
    "year": 2020,
    "authors": "S. Cruz Rivera, Xiaoxuan Liu, A. Chan, A. Denniston, M. Calvert",
    "abstract": "The SPIRIT 2013 statement aims to improve the completeness of clinical trial protocol reporting by providing evidence-based recommendations for the minimum set of items to be addressed. This guidance has been instrumental in promoting transparent evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate their impact on health outcomes. The SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence) extension is a new reporting guideline for clinical trial protocols evaluating interventions with an AI component. It was developed in parallel with its companion statement for trial reports: CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 26 candidate items, which were consulted upon by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The SPIRIT-AI extension includes 15 new items that were considered sufficiently important for clinical trial protocols of AI interventions. These new items should be routinely reported in addition to the core SPIRIT 2013 items. SPIRIT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention will be integrated, considerations for the handling of input and output data, the human–AI interaction and analysis of error cases. SPIRIT-AI will help promote transparency and completeness for clinical trial protocols for AI interventions. Its use will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the design and risk of bias for a planned clinical trial. The CONSORT-AI and SPIRIT-AI extensions improve the transparency of clinical trial design and trial protocol reporting for artificial intelligence interventions.",
    "citationCount": 905,
    "pdf_filename": "2020_Guidelines_for_clinical_trial_protocols__107169eb.pdf"
  },
  "7d089d4cc4aff5c10c1704f02119e2487fc898c9": {
    "paperId": "7d089d4cc4aff5c10c1704f02119e2487fc898c9",
    "title": "Questioning the AI: Informing Design Practices for Explainable AI User Experiences",
    "year": 2020,
    "authors": "Q. Liao, D. Gruen, Sarah Miller",
    "abstract": "A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.",
    "citationCount": 798,
    "pdf_filename": "2020_Questioning_the_AI__Informing_Design_Pra_7d089d4c.pdf"
  },
  "5cc4100a67fd6f2ce3c760655ba7a12f358c7950": {
    "paperId": "5cc4100a67fd6f2ce3c760655ba7a12f358c7950",
    "title": "Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making",
    "year": 2020,
    "authors": "Yunfeng Zhang, Q. V. Liao, Rachel K. E. Bellamy",
    "abstract": "Today, AI is being increasingly used to help human experts make decisions in high-stakes scenarios. In these scenarios, full automation is often undesirable, not only due to the significance of the outcome, but also because human experts can draw on their domain knowledge complementary to the model's to ensure task success. We refer to these scenarios as AI-assisted decision making, where the individual strengths of the human and the AI come together to optimize the joint decision outcome. A key to their success is to appropriately calibrate human trust in the AI on a case-by-case basis; knowing when to trust or distrust the AI allows the human expert to appropriately apply their knowledge, improving decision outcomes in cases where the model is likely to perform poorly. This research conducts a case study of AI-assisted decision making in which humans and AI have comparable performance alone, and explores whether features that reveal case-specific model information can calibrate trust and improve the joint performance of the human and AI. Specifically, we study the effect of showing confidence score and local explanation for a particular prediction. Through two human experiments, we show that confidence score can help calibrate people's trust in an AI model, but trust calibration alone is not sufficient to improve AI-assisted decision making, which may also depend on whether the human can bring in enough unique knowledge to complement the AI's errors. We also highlight the problems in using local explanation for AI-assisted decision making scenarios and invite the research community to explore new approaches to explainability for calibrating human trust in AI.",
    "citationCount": 770,
    "pdf_filename": "2020_Effect_of_confidence_and_explanation_on__5cc4100a.pdf"
  },
  "ebcbbb8fe297940d79b17aeb6d46bedff9db7fec": {
    "paperId": "ebcbbb8fe297940d79b17aeb6d46bedff9db7fec",
    "title": "Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance",
    "year": 2020,
    "authors": "Gagan Bansal, Tongshuang Sherry Wu, Joyce Zhou, Raymond Fok, Besmira Nushi",
    "abstract": "Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI’s recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?",
    "citationCount": 713,
    "pdf_filename": "2020_Does_the_Whole_Exceed_its_Parts__The_Eff_ebcbbb8f.pdf"
  },
  "65906e6027246ae9e4ecd18d6e019a24505c842e": {
    "paperId": "65906e6027246ae9e4ecd18d6e019a24505c842e",
    "title": "Aligning AI With Shared Human Values",
    "year": 2020,
    "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, J. Li",
    "abstract": "We show how to assess a language model's knowledge of basic concepts of morality. We introduce the ETHICS dataset, a new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality. Models predict widespread moral judgments about diverse text scenarios. This requires connecting physical and social world knowledge to value judgements, a capability that may enable us to steer chatbot outputs or eventually regularize open-ended reinforcement learning agents. With the ETHICS dataset, we find that current language models have a promising but incomplete understanding of basic ethical knowledge. Our work shows that progress can be made on machine ethics today, and it provides a steppingstone toward AI that is aligned with human values.",
    "citationCount": 723,
    "pdf_filename": "2020_Aligning_AI_With_Shared_Human_Values_65906e60.pdf"
  },
  "0412076e1004d030ac02de77bc44cc7d92b13ab9": {
    "paperId": "0412076e1004d030ac02de77bc44cc7d92b13ab9",
    "title": "Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing",
    "year": 2020,
    "authors": "Inioluwa Deborah Raji, A. Smart, Rebecca N. White, Margaret Mitchell, Timnit Gebru",
    "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source. In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.",
    "citationCount": 916,
    "pdf_filename": "2020_Closing_the_AI_accountability_gap__defin_0412076e.pdf"
  },
  "58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9": {
    "paperId": "58bb24b72fea6d0ce172bdaf9c2f16c2bd7649e9",
    "title": "Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI",
    "year": 2020,
    "authors": "Jessica Fjeld, Nele Achten, Hannah Hilligoss, Ádám Nagy, M. Srikumar",
    "abstract": "The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and human rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these \"AI principles,\" there has been little scholarly focus on understanding these efforts either individually or as contextualized within an expanding universe of principles with discernible trends.\r\n\r\nTo that end, this white paper and its associated data visualization compare the contents of thirty-six prominent AI principles documents side-by-side. This effort uncovered a growing consensus around eight key thematic trends: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. Underlying this “normative core,” our analysis examined the forty-seven individual principles that make up the themes, detailing notable similarities and differences in interpretation found across the documents. In sharing these observations, it is our hope that policymakers, advocates, scholars, and others working to maximize the benefits and minimize the harms of AI will be better positioned to build on existing efforts and to push the fractured, global conversation on the future of AI toward consensus.",
    "citationCount": 690,
    "pdf_filename": "2020_Principled_Artificial_Intelligence__Mapp_58bb24b7.pdf"
  },
  "0a309c2c47c34f51ef94e8075f11586ad2b1dd2b": {
    "paperId": "0a309c2c47c34f51ef94e8075f11586ad2b1dd2b",
    "title": "Adoption of AI-based chatbots for hospitality and tourism",
    "year": 2020,
    "authors": "Rajasshrie Pillai, Brijesh Sivathanu",
    "abstract": "This study aims to investigate the customers’ behavioral intention and actual usage (AUE) of artificial intelligence (AI)-powered chatbots for hospitality and tourism in India by extending the technology adoption model (TAM) with context-specific variables.,To understand the customers’ behavioral intention and AUE of AI-powered chatbots for tourism, the mixed-method design was used whereby qualitative and quantitative techniques were combined. A total of 36 senior managers and executives from the travel agencies were interviewed and the analysis of interview data was done using NVivo 8.0 software. A total of 1,480 customers were surveyed and the partial least squares structural equation modeling technique was used for data analysis.,As per the results, the predictors of chatbot adoption intention (AIN) are perceived ease of use, perceived usefulness, perceived trust (PTR), perceived intelligence (PNT) and anthropomorphism (ANM). Technological anxiety (TXN) does not influence the chatbot AIN. Stickiness to traditional human travel agents negatively moderates the relation of AIN and AUE of chatbots in tourism and provides deeper insights into manager’s commitment to providing travel planning services using AI-based chatbots.,This research presents unique practical insights to the practitioners, managers and executives in the tourism industry, system designers and developers of AI-based chatbot technologies to understand the antecedents of chatbot adoption by travelers. TXN is a vital concern for the customers; so, designers and developers should ensure that chatbots are easily accessible, have a user-friendly interface, be more human-like and communicate in various native languages with the customers.,This study contributes theoretically by extending the TAM to provide better explanatory power with human–robot interaction context-specific constructs – PTR, PNT, ANM and TXN – to examine the customers’ chatbot AIN. This is the first step in the direction to empirically test and validate a theoretical model for chatbots’ adoption and usage, which is a disruptive technology in the hospitality and tourism sector in an emerging economy such as India.",
    "citationCount": 540,
    "pdf_filename": "2020_Adoption_of_AI_based_chatbots_for_hospit_0a309c2c.pdf"
  },
  "529025645c70a935221bd434484faee695ad0f25": {
    "paperId": "529025645c70a935221bd434484faee695ad0f25",
    "title": "Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design",
    "year": 2020,
    "authors": "Qian Yang, Aaron Steinfeld, C. Rosé, J. Zimmerman",
    "abstract": "Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.",
    "citationCount": 533,
    "pdf_filename": "2020_Re_examining_Whether__Why__and_How_Human_52902564.pdf"
  },
  "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9": {
    "paperId": "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9",
    "title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI",
    "year": 2020,
    "authors": "Alon Jacovi, Ana Marasović, Tim Miller, Yoav Goldberg",
    "abstract": "Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.",
    "citationCount": 531,
    "pdf_filename": "2020_Formalizing_Trust_in_Artificial_Intellig_14dddd1d.pdf"
  },
  "5936b8dcaa3f57c1202e2e75870d4eeb83eb2d21": {
    "paperId": "5936b8dcaa3f57c1202e2e75870d4eeb83eb2d21",
    "title": "Rise of Machine Agency: A Framework for Studying the Psychology of Human-AI Interaction (HAII)",
    "year": 2020,
    "authors": "S. Sundar",
    "abstract": "\n Advances in personalization algorithms and other applications of machine learning have vastly enhanced the ease and convenience of our media and communication experiences, but they have also raised significant concerns about privacy, transparency of technologies and human control over their operations. Going forth, reconciling such tensions between machine agency and human agency will be important in the era of artificial intelligence (AI), as machines get more agentic and media experiences become increasingly determined by algorithms. Theory and research should be geared toward a deeper understanding of the human experience of algorithms in general and the psychology of Human–AI interaction (HAII) in particular. This article proposes some directions by applying the dual-process framework of the Theory of Interactive Media Effects (TIME) for studying the symbolic and enabling effects of the affordances of AI-driven media on user perceptions and experiences.",
    "citationCount": 508,
    "pdf_filename": "2020_Rise_of_Machine_Agency__A_Framework_for__5936b8dc.pdf"
  },
  "00a407540a8bdd6d7425bd8a561eb21d69682511": {
    "paperId": "00a407540a8bdd6d7425bd8a561eb21d69682511",
    "title": "Rapid AI Development Cycle for the Coronavirus (COVID-19) Pandemic: Initial Results for Automated Detection & Patient Monitoring using Deep Learning CT Image Analysis",
    "year": 2020,
    "authors": "Ophir Gozes, Maayan Frid-Adar, H. Greenspan, P. Browning, Huangqi Zhang",
    "abstract": "Purpose: Develop AI-based automated CT image analysis tools for detection, quantification, and tracking of Coronavirus; demonstrate they can differentiate coronavirus patients from non-patients. Materials and Methods: Multiple international datasets, including from Chinese disease-infected areas were included. We present a system that utilizes robust 2D and 3D deep learning models, modifying and adapting existing AI models and combining them with clinical understanding. We conducted multiple retrospective experiments to analyze the performance of the system in the detection of suspected COVID-19 thoracic CT features and to evaluate evolution of the disease in each patient over time using a 3D volume review, generating a Corona score. The study includes a testing set of 157 international patients (China and U.S). Results: Classification results for Coronavirus vs Non-coronavirus cases per thoracic CT studies were 0.996 AUC (95%CI: 0.989-1.00) ; on datasets of Chinese control and infected patients. Possible working point: 98.2% sensitivity, 92.2% specificity. For time analysis of Coronavirus patients, the system output enables quantitative measurements for smaller opacities (volume, diameter) and visualization of the larger opacities in a slice-based heat map or a 3D volume display. Our suggested Corona score measures the progression of disease over time. Conclusion: This initial study, which is currently being expanded to a larger population, demonstrated that rapidly developed AI-based image analysis can achieve high accuracy in detection of Coronavirus as well as quantification and tracking of disease burden.",
    "citationCount": 815,
    "pdf_filename": "2020_Rapid_AI_Development_Cycle_for_the_Coron_00a40754.pdf"
  },
  "4c33b3312875ce39d4475747e6e02f1672ff4886": {
    "paperId": "4c33b3312875ce39d4475747e6e02f1672ff4886",
    "title": "AI-based chatbots in customer service and their effects on user compliance",
    "year": 2020,
    "authors": "Martin Adam, Michael Wessel, Alexander Benlian",
    "abstract": "Communicating with customers through live chat interfaces has become an increasingly popular means to provide real-time customer service in many e-commerce settings. Today, human chat service agents are frequently replaced by conversational software agents or chatbots, which are systems designed to communicate with human users by means of natural language often based on artificial intelligence (AI). Though cost- and time-saving opportunities triggered a widespread implementation of AI-based chatbots, they still frequently fail to meet customer expectations, potentially resulting in users being less inclined to comply with requests made by the chatbot. Drawing on social response and commitment-consistency theory, we empirically examine through a randomized online experiment how verbal anthropomorphic design cues and the foot-in-the-door technique affect user request compliance. Our results demonstrate that both anthropomorphism as well as the need to stay consistent significantly increase the likelihood that users comply with a chatbot’s request for service feedback. Moreover, the results show that social presence mediates the effect of anthropomorphic design cues on user compliance.",
    "citationCount": 772,
    "pdf_filename": "2020_AI_based_chatbots_in_customer_service_an_4c33b331.pdf"
  },
  "75994ebb52094581dcb7d145795f6bafe6e276bb": {
    "paperId": "75994ebb52094581dcb7d145795f6bafe6e276bb",
    "title": "Influence of artificial intelligence (AI) on firm performance: the business value of AI-based transformation projects",
    "year": 2020,
    "authors": "Serge-Lopez Wamba-Taguimdje, S. Wamba, Jean Robert Kala Kamdjoug, C. Wanko",
    "abstract": "PurposeThe main purpose of our study is to analyze the influence of Artificial Intelligence (AI) on firm performance, notably by building on the business value of AI-based transformation projects. This study was conducted using a four-step sequential approach: (1) analysis of AI and AI concepts/technologies; (2) in-depth exploration of case studies from a great number of industrial sectors; (3) data collection from the databases (websites) of AI-based solution providers; and (4) a review of AI literature to identify their impact on the performance of organizations while highlighting the business value of AI-enabled projects transformation within organizations.Design/methodology/approachThis study has called on the theory of IT capabilities to seize the influence of AI business value on firm performance (at the organizational and process levels). The research process (responding to the research question, making discussions, interpretations and comparisons, and formulating recommendations) was based on a review of 500 case studies from IBM, AWS, Cloudera, Nvidia, Conversica, Universal Robots websites, etc. Studying the influence of AI on the performance of organizations, and more specifically, of the business value of such organizations’ AI-enabled transformation projects, required us to make an archival data analysis following the three steps, namely the conceptual phase, the refinement and development phase, and the assessment phase.FindingsAI covers a wide range of technologies, including machine translation, chatbots and self-learning algorithms, all of which can allow individuals to better understand their environment and act accordingly. Organizations have been adopting AI technological innovations with a view to adapting to or disrupting their ecosystem while developing and optimizing their strategic and competitive advantages. AI fully expresses its potential through its ability to optimize existing processes and improve automation, information and transformation effects, but also to detect, predict and interact with humans. Thus, the results of our study have highlighted such AI benefits in organizations, and more specifically, its ability to improve on performance at both the organizational (financial, marketing and administrative) and process levels. By building on these AI attributes, organizations can, therefore, enhance the business value of their transformed projects. The same results also showed that organizations achieve performance through AI capabilities only when they use their features/technologies to reconfigure their processes.Research limitations/implicationsAI obviously influences the way businesses are done today. Therefore, practitioners and researchers need to consider AI as a valuable support or even a pilot for a new business model. For the purpose of our study, we adopted a research framework geared toward a more inclusive and comprehensive approach so as to better account for the intangible benefits of AI within organizations. In terms of interest, this study nurtures a scientific interest, which aims at proposing a model for analyzing the influence of AI on the performance of organizations, and at the same time, filling the associated gap in the literature. As for the managerial interest, our study aims to provide managers with elements to be reconfigured or added in order to take advantage of the full benefits of AI, and therefore improve organizations’ performance, the profitability of their investments in AI transformation projects, and some competitive advantage. This study also allows managers to consider AI not as a single technology but as a set/combination of several different configurations of IT in the various company’s business areas because multiple key elements must be brought together to ensure the success of AI: data, talent mix, domain knowledge, key decisions, external partnerships and scalable infrastructure.Originality/valueThis article analyses case studies on the reuse of secondary data from AI deployment reports in organizations. The transformation of projects based on the use of AI focuses mainly on business process innovations and indirectly on those occurring at the organizational level. Thus, 500 case studies are being examined to provide significant and tangible evidence about the business value of AI-based projects and the impact of AI on firm performance. More specifically, this article, through these case studies, exposes the influence of AI at both the organizational and process performance levels, while considering it not as a single technology but as a set/combination of the several different configurations of IT in various industries.",
    "citationCount": 638,
    "pdf_filename": "2020_Influence_of_artificial_intelligence__AI_75994ebb.pdf"
  },
  "420e771cfbd7d31aa33f29a5ba1c5540c0f5f7fd": {
    "paperId": "420e771cfbd7d31aa33f29a5ba1c5540c0f5f7fd",
    "title": "Engaged to a Robot? The Role of AI in Service",
    "year": 2020,
    "authors": "Ming-Hui Huang, R. Rust",
    "abstract": "This article develops a strategic framework for using artificial intelligence (AI) to engage customers for different service benefits. This framework lays out guidelines of how to use different AIs to engage customers based on considerations of nature of service task, service offering, service strategy, and service process. AI develops from mechanical, to thinking, and to feeling. As AI advances to a higher intelligence level, more human service employees and human intelligence (HI) at the intelligence levels lower than that level should be used less. Thus, at the current level of AI development, mechanical service should be performed mostly by mechanical AI, thinking service by both thinking AI and HI, and feeling service mostly by HI. Mechanical AI should be used for standardization when service is routine and transactional, for cost leadership, and mostly at the service delivery stage. Thinking AI should be used for personalization when service is data-rich and utilitarian, for quality leadership, and mostly at the service creation stage. Feeling AI should be used for relationalization when service is relational and high touch, for relationship leadership, and mostly at the service interaction stage. We illustrate various AI applications for the three major AI benefits, providing managerial guidelines for service providers to leverage the advantages of AI as well as future research implications for service researchers to investigate AI in service from modeling, consumer, and policy perspectives.",
    "citationCount": 678,
    "pdf_filename": "2020_Engaged_to_a_Robot__The_Role_of_AI_in_Se_420e771c.pdf"
  },
  "fb98ceb0e4efca62ea57d8dc7eb2787b3feee7b9": {
    "paperId": "fb98ceb0e4efca62ea57d8dc7eb2787b3feee7b9",
    "title": "Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension",
    "year": 2020,
    "authors": "An-Wen Chan, A. Darzi, Christopher Holmes, Christopher Yau, D. Moher",
    "abstract": "The CONSORT 2010 statement provides minimum guidelines for reporting randomized trials. Its widespread use has been instrumental in ensuring transparency in the evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence) extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials–Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 29 candidate items, which were assessed by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a two-day consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The CONSORT-AI extension includes 14 new items that were considered sufficiently important for AI interventions that they should be routinely reported in addition to the core CONSORT 2010 items. CONSORT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention is integrated, the handling of inputs and outputs of the AI intervention, the human–AI interaction and provision of an analysis of error cases. CONSORT-AI will help promote transparency and completeness in reporting clinical trials for AI interventions. It will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the quality of clinical trial design and risk of bias in the reported outcomes. The CONSORT-AI and SPIRIT-AI extensions improve the transparency of clinical trial design and trial protocol reporting for artificial intelligence interventions.",
    "citationCount": 662,
    "pdf_filename": "2020_Reporting_guidelines_for_clinical_trial__fb98ceb0.pdf"
  },
  "6e62a903dac8e643160bd1337d6cb8b09bf2f062": {
    "paperId": "6e62a903dac8e643160bd1337d6cb8b09bf2f062",
    "title": "AI for radiographic COVID-19 detection selects shortcuts over signal",
    "year": 2020,
    "authors": "A. DeGrave, Joseph D. Janizek, Su-In Lee",
    "abstract": "Artificial intelligence (AI) researchers and radiologists have recently reported AI systems that accurately detect COVID-19 in chest radiographs. However, the robustness of these systems remains unclear. Using state-of-the-art techniques in explainable AI, we demonstrate that recent deep learning systems to detect COVID-19 from chest radiographs rely on confounding factors rather than medical pathology, creating an alarming situation in which the systems appear accurate, but fail when tested in new hospitals. We observe that the approach to obtain training data for these AI systems introduces a nearly ideal scenario for AI to learn these spurious ‘shortcuts’. Because this approach to data collection has also been used to obtain training data for the detection of COVID-19 in computed tomography scans and for medical imaging tasks related to other diseases, our study reveals a far-reaching problem in medical-imaging AI. In addition, we show that evaluation of a model on external data is insufficient to ensure AI systems rely on medically relevant pathology, because the undesired ‘shortcuts’ learned by AI systems may not impair performance in new hospitals. These findings demonstrate that explainable AI should be seen as a prerequisite to clinical deployment of machine-learning healthcare models. The urgency of the developing COVID-19 epidemic has led to a large number of novel diagnostic approaches, many of which use machine learning. DeGrave and colleagues use explainable AI techniques to analyse a selection of these approaches and find that the methods frequently learn to identify features unrelated to the actual disease.",
    "citationCount": 594,
    "pdf_filename": "2020_AI_for_radiographic_COVID_19_detection_s_6e62a903.pdf"
  },
  "9fbbd520f24a810a4278e1054f04f481d417c8bd": {
    "paperId": "9fbbd520f24a810a4278e1054f04f481d417c8bd",
    "title": "A Comprehensive Review of the COVID-19 Pandemic and the Role of IoT, Drones, AI, Blockchain, and 5G in Managing its Impact",
    "year": 2020,
    "authors": "V. Chamola, Vikas Hassija, Vatsal Gupta, M. Guizani",
    "abstract": "The unprecedented outbreak of the 2019 novel coronavirus, termed as COVID-19 by the World Health Organization (WHO), has placed numerous governments around the world in a precarious position. The impact of the COVID-19 outbreak, earlier witnessed by the citizens of China alone, has now become a matter of grave concern for virtually every country in the world. The scarcity of resources to endure the COVID-19 outbreak combined with the fear of overburdened healthcare systems has forced a majority of these countries into a state of partial or complete lockdown. The number of laboratory-confirmed coronavirus cases has been increasing at an alarming rate throughout the world, with reportedly more than 3 million confirmed cases as of 30 April 2020. Adding to these woes, numerous false reports, misinformation, and unsolicited fears in regards to coronavirus, are being circulated regularly since the outbreak of the COVID-19. In response to such acts, we draw on various reliable sources to present a detailed review of all the major aspects associated with the COVID-19 pandemic. In addition to the direct health implications associated with the outbreak of COVID-19, this study highlights its impact on the global economy. In drawing things to a close, we explore the use of technologies such as the Internet of Things (IoT), Unmanned Aerial Vehicles (UAVs), blockchain, Artificial Intelligence (AI), and 5G, among others, to help mitigate the impact of COVID-19 outbreak.",
    "citationCount": 809,
    "pdf_filename": "2020_A_Comprehensive_Review_of_the_COVID_19_P_9fbbd520.pdf"
  },
  "6edc9d0937b450d6facdbf7bbf1131bbb708fa2a": {
    "paperId": "6edc9d0937b450d6facdbf7bbf1131bbb708fa2a",
    "title": "AI-based pathology predicts origins for cancers of unknown primary",
    "year": 2020,
    "authors": "Ming Y. Lu, Tiffany Y. Chen, Drew F. K. Williamson, Melissa Zhao, Maha Shady",
    "abstract": "Cancer of unknown primary (CUP) origin is an enigmatic group of diagnoses in which the primary anatomical site of tumour origin cannot be determined1,2. This poses a considerable challenge, as modern therapeutics are predominantly specific to the primary tumour3. Recent research has focused on using genomics and transcriptomics to identify the origin of a tumour4–9. However, genomic testing is not always performed and lacks clinical penetration in low-resource settings. Here, to overcome these challenges, we present a deep-learning-based algorithm—Tumour Origin Assessment via Deep Learning (TOAD)—that can provide a differential diagnosis for the origin of the primary tumour using routinely acquired histology slides. We used whole-slide images of tumours with known primary origins to train a model that simultaneously identifies the tumour as primary or metastatic and predicts its site of origin. On our held-out test set of tumours with known primary origins, the model achieved a top-1 accuracy of 0.83 and a top-3 accuracy of 0.96, whereas on our external test set it achieved top-1 and top-3 accuracies of 0.80 and 0.93, respectively. We further curated a dataset of 317 cases of CUP for which a differential diagnosis was assigned. Our model predictions resulted in concordance for 61% of cases and a top-3 agreement of 82%. TOAD can be used as an assistive tool to assign a differential diagnosis to complicated cases of metastatic tumours and CUPs and could be used in conjunction with or in lieu of ancillary tests and extensive diagnostic work-ups to reduce the occurrence of CUP. A deep-learning-based algorithm uses routinely acquired histology slides to provide a differential diagnosis for the origin of the primary tumour for complicated cases of metastatic tumours and cancers of unknown primary origin.",
    "citationCount": 550,
    "pdf_filename": "2020_AI_based_pathology_predicts_origins_for__6edc9d09.pdf"
  },
  "19f6ed24abf591c4c592cf52106e7b8248df7155": {
    "paperId": "19f6ed24abf591c4c592cf52106e7b8248df7155",
    "title": "Building Face Ageing Model Using Face Synthesis",
    "year": 2024,
    "authors": "Shraddha Mishra, Manvi Chahar, Shivani Jaswal",
    "abstract": "Advancements in face synthesis technology have enabled innovative methods for modeling facial aging. This research paper focuses primarily on creating a robust face aging model using deep learning and Generative Adversarial Networks (GANs), trained on a diverse dataset of facial images. The proposed approach captures both global features and local textures to produce realistic age-progressed images while preserving the subject's identity. This paper also examines face synthesis techniques, with specific emphasis for the various practical usage of GANs. The key objective of our project is to upgrade both the discriminator and the generator parts of GANs to generate more realistic, age- progressed face images. We evaluated the model using quantitative metrics and qualitative assessments, demonstrating its effectiveness. Additionally, we address ethical considerations, proposing guidelines for responsible use. Our study offers a novel framework with significant applications in security, forensics, and entertainment, and suggests future research directions to improve accuracy and ethical standards.",
    "citationCount": 702,
    "pdf_filename": "2024_Building_Face_Ageing_Model_Using_Face_Sy_19f6ed24.pdf"
  },
  "7260442ef9c0448f07ce3803efd49cebaffcebe9": {
    "paperId": "7260442ef9c0448f07ce3803efd49cebaffcebe9",
    "title": "DeepSeek LLM: Scaling Open-Source Language Models with Longtermism",
    "year": 2024,
    "authors": "DeepSeek-AI Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai",
    "abstract": "The rapid development of open-source large language models (LLMs) has been truly remarkable. However, the scaling law described in previous literature presents varying conclusions, which casts a dark cloud over scaling LLMs. We delve into the study of scaling laws and present our distinctive findings that facilitate scaling of large scale models in two commonly used open-source configurations, 7B and 67B. Guided by the scaling laws, we introduce DeepSeek LLM, a project dedicated to advancing open-source language models with a long-term perspective. To support the pre-training phase, we have developed a dataset that currently consists of 2 trillion tokens and is continuously expanding. We further conduct supervised fine-tuning (SFT) and Direct Preference Optimization (DPO) on DeepSeek LLM Base models, resulting in the creation of DeepSeek Chat models. Our evaluation results demonstrate that DeepSeek LLM 67B surpasses LLaMA-2 70B on various benchmarks, particularly in the domains of code, mathematics, and reasoning. Furthermore, open-ended evaluations reveal that DeepSeek LLM 67B Chat exhibits superior performance compared to GPT-3.5.",
    "citationCount": 578,
    "pdf_filename": "2024_DeepSeek_LLM__Scaling_Open_Source_Langua_7260442e.pdf"
  },
  "a9a654ea503386cbfd8bb119fc650cc3d08dc206": {
    "paperId": "a9a654ea503386cbfd8bb119fc650cc3d08dc206",
    "title": "Revised Surgical CAse REport (SCARE) guideline: An update for the age of Artificial Intelligence",
    "year": 2025,
    "authors": "Ahmed Kerwan, A. Al-Jabir, Ginimol Mathew, C. Sohrabi, Rasha Rashid",
    "abstract": "Introduction: Artificial intelligence (AI) is rapidly transforming healthcare and scientific publishing. Reporting guidelines need to be updated to take into account this advance. The SCARE Guideline 2025 update adds a new AI-focused domain to promote transparency, reproducibility, and ethical integrity in surgical case reports involving AI.\n\nMethods: A Delphi consensus exercise was conducted to update the SCARE guidelines. A panel of 49 surgical and scientific experts were invited to rate proposed new items. In round 1, participants scored each item on a 9-point Likert scale and provided feedback. Items not meeting consensus were revised or discarded.\n\nResults: A 94% response rate occurred amongst participants (46/49) in the first round. Ratings were analysed for agreement levels, and consensus was reached on all six proposed AI-related items. A revised SCARE checklist is presented which incorporates these new AI related items. Authors are now expected to disclose AI involvement not only in patient care but also in manuscript preparation, as exemplified by this paper.\n\nConclusion: The SCARE 2025 guideline provides an up-to-date framework for surgical case reports in the era of AI. Through a robust consensus process, we have added specific reporting criteria for AI to ensure that any use of artificial intelligence in a case report is clearly documented, explained and discussed including with respect to bias and ethics. This update will help maintain the quality, transparency, and clinical relevance of case reports, ultimately improving their educational value and trustworthiness for the surgical community.",
    "citationCount": 697,
    "pdf_filename": "2025_Revised_Surgical_CAse_REport__SCARE__gui_a9a654ea.pdf"
  },
  "909ad57ce8caa6b390a65ae09db352d27d8f3996": {
    "paperId": "909ad57ce8caa6b390a65ae09db352d27d8f3996",
    "title": "SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
    "year": 2023,
    "authors": "Elias Frantar, Dan Alistarh",
    "abstract": "We show for the first time that large-scale generative pretrained transformer (GPT) family models can be pruned to at least 50% sparsity in one-shot, without any retraining, at minimal loss of accuracy. This is achieved via a new pruning method called SparseGPT, specifically designed to work efficiently and accurately on massive GPT-family models. We can execute SparseGPT on the largest available open-source models, OPT-175B and BLOOM-176B, in under 4.5 hours, and can reach 60% unstructured sparsity with negligible increase in perplexity: remarkably, more than 100 billion weights from these models can be ignored at inference time. SparseGPT generalizes to semi-structured (2:4 and 4:8) patterns, and is compatible with weight quantization approaches. The code is available at: https://github.com/IST-DASLab/sparsegpt.",
    "citationCount": 984,
    "pdf_filename": "2023_SparseGPT__Massive_Language_Models_Can_B_909ad57c.pdf"
  },
  "312e66bcee5bad5376a97f4d771ecdcca2c78078": {
    "paperId": "312e66bcee5bad5376a97f4d771ecdcca2c78078",
    "title": "Transparency In The reporting of Artificial INtelligence – the TITAN guideline",
    "year": 2025,
    "authors": "R. Agha, Ginimol Mathew, Rasha Rashid, Ahmed Kerwan, A. Al-Jabir",
    "abstract": "The use of AI in research and the literature is increasing. The need for transparency is clear. Here we present a guideline to transparently reporting the use of AI in any manuscript in general. The guideline items cover; declaration, purpose and scope, AI tools and configuration, data inputs and safeguards, human oversight and verification, bias, ethics and regulatory compliance and reproducibility and transparency. This guide will evolve over time as technology, systems and behaviour evolve.",
    "citationCount": 614,
    "pdf_filename": "2025_Transparency_In_The_reporting_of_Artific_312e66bc.pdf"
  },
  "c8dc4af5c61f95cc79b7f83e8339efa62af8f811": {
    "paperId": "c8dc4af5c61f95cc79b7f83e8339efa62af8f811",
    "title": "Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation",
    "year": 2023,
    "authors": "Liucheng Hu, Xin Gao, Peng Zhang, Ke Sun, Bang Zhang",
    "abstract": "Character Animation aims to generating character videos from still images through driving signals. Currently, diffusion models have become the mainstream in visual generation research, owing to their robust generative capabilities. However, challenges persist in the realm of image-to-video, especially in character animation, where temporally maintaining consistency with detailed information from character remains a formidable problem. In this paper, we leverage the power of diffusion models and propose a novel framework tailored for character animation. To preserve consistency of intricate appearance features from reference image, we design ReferenceNet to merge detail features via spatial attention. To ensure controllability and continuity, we introduce an efficient pose guider to direct character's movements and employ an effective temporal modeling approach to ensure smooth inter-frame transitions between video frames. By expanding the training data, our approach can animate arbitrary characters, yielding superior results in character animation compared to other image-to-video methods. Furthermore, we evaluate our method on image animation benchmarks, achieving state-of-the-art results.",
    "citationCount": 605,
    "pdf_filename": "2023_Animate_Anyone__Consistent_and_Controlla_c8dc4af5.pdf"
  },
  "2e965b5d97c2d6fb4af284307735be39283792ba": {
    "paperId": "2e965b5d97c2d6fb4af284307735be39283792ba",
    "title": "Extracting Training Data from Diffusion Models",
    "year": 2023,
    "authors": "Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag",
    "abstract": "Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
    "citationCount": 769,
    "pdf_filename": "2023_Extracting_Training_Data_from_Diffusion__2e965b5d.pdf"
  },
  "cf8fced1f446c554ca0c5608ae0a1131184212f6": {
    "paperId": "cf8fced1f446c554ca0c5608ae0a1131184212f6",
    "title": "High-Fidelity Audio Compression with Improved RVQGAN",
    "year": 2023,
    "authors": "Rithesh Kumar, Prem Seetharaman, Alejandro Luebs, I. Kumar, Kundan Kumar",
    "abstract": "Language models have been successfully used to model natural signals, such as images, speech, and music. A key component of these models is a high quality neural compression model that can compress high-dimensional natural signals into lower dimensional discrete tokens. To that end, we introduce a high-fidelity universal neural audio compression algorithm that achieves ~90x compression of 44.1 KHz audio into tokens at just 8kbps bandwidth. We achieve this by combining advances in high-fidelity audio generation with better vector quantization techniques from the image domain, along with improved adversarial and reconstruction losses. We compress all domains (speech, environment, music, etc.) with a single universal model, making it widely applicable to generative modeling of all audio. We compare with competing audio compression algorithms, and find our method outperforms them significantly. We provide thorough ablations for every design choice, as well as open-source code and trained model weights. We hope our work can lay the foundation for the next generation of high-fidelity audio modeling.",
    "citationCount": 541,
    "pdf_filename": "2023_High_Fidelity_Audio_Compression_with_Imp_cf8fced1.pdf"
  },
  "c3c7464acb90049c5f520b0732dc7435ba3690bd": {
    "paperId": "c3c7464acb90049c5f520b0732dc7435ba3690bd",
    "title": "Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models",
    "year": 2023,
    "authors": "Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, D. Cohen-Or",
    "abstract": "Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g., colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention-based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention units to attend to all subject tokens in the text prompt and strengthen --- or excite --- their activations, encouraging the model to generate all subjects described in the text prompt. We compare our approach to alternative approaches and demonstrate that it conveys the desired concepts more faithfully across a range of text prompts. Code is available at our project page: https://attendandexcite.github.io/Attend-and-Excite/.",
    "citationCount": 642,
    "pdf_filename": "2023_Attend_and_Excite__Attention_Based_Seman_c3c7464a.pdf"
  },
  "d8c78221e4366d6a72a6b3e41e35b706cc45c01d": {
    "paperId": "d8c78221e4366d6a72a6b3e41e35b706cc45c01d",
    "title": "Training Diffusion Models with Reinforcement Learning",
    "year": 2023,
    "authors": "Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, S. Levine",
    "abstract": "Diffusion models are a class of flexible generative models trained with an approximation to the log-likelihood objective. However, most use cases of diffusion models are not concerned with likelihoods, but instead with downstream objectives such as human-perceived image quality or drug effectiveness. In this paper, we investigate reinforcement learning methods for directly optimizing diffusion models for such objectives. We describe how posing denoising as a multi-step decision-making problem enables a class of policy gradient algorithms, which we refer to as denoising diffusion policy optimization (DDPO), that are more effective than alternative reward-weighted likelihood approaches. Empirically, DDPO is able to adapt text-to-image diffusion models to objectives that are difficult to express via prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. Finally, we show that DDPO can improve prompt-image alignment using feedback from a vision-language model without the need for additional data collection or human annotation. The project's website can be found at http://rl-diffusion.github.io .",
    "citationCount": 589,
    "pdf_filename": "2023_Training_Diffusion_Models_with_Reinforce_d8c78221.pdf"
  },
  "9fc93a7ae7fabaabe1923a5914a29761dead1551": {
    "paperId": "9fc93a7ae7fabaabe1923a5914a29761dead1551",
    "title": "Future Progress in Artificial Intelligence: A Survey of Expert Opinion",
    "year": 2025,
    "authors": "V. C. Müller, N. Bostrom",
    "abstract": "There is, in some quarters, concern about high–level machine intelligence and superintelligent AI coming up in a few decades, bringing with it significant risks for humanity. In other quarters, these issues are ignored or considered science fiction. We wanted to clarify what the distribution of opinions actually is, what probability the best experts currently assign to high–level machine intelligence coming up within a particular time–frame, which risks they see with that development, and how fast they see these developing. We thus designed a brief questionnaire and distributed it to four groups of experts in 2012/2013. The median estimate of respondents was for a one in two chance that high-level machine intelligence will be developed around 2040–2050, rising to a nine in ten chance by 2075. Experts expect that systems will move on to superintelligence in less than 30 years thereafter. They estimate the chance is about one in three that this development turns out to be ‘bad’ or ‘extremely bad’ for humanity.",
    "citationCount": 501,
    "pdf_filename": "2025_Future_Progress_in_Artificial_Intelligen_9fc93a7a.pdf"
  },
  "07be0ec1f45e21a1032616535d0290ee6bfe0f6b": {
    "paperId": "07be0ec1f45e21a1032616535d0290ee6bfe0f6b",
    "title": "Structure and Content-Guided Video Synthesis with Diffusion Models",
    "year": 2023,
    "authors": "Patrick Esser, Johnathan Chiu, Parmida Atighehchian, Jonathan Granskog, Anastasis Germanidis",
    "abstract": "Text-guided generative diffusion models unlock powerful image creation and editing tools. Recent approaches that edit the content of footage while retaining structure require expensive re-training for every input or rely on error-prone propagation of image edits across frames.In this work, we present a structure and content-guided video diffusion model that edits videos based on descriptions of the desired output. Conflicts between user-provided content edits and structure representations occur due to insufficient disentanglement between the two aspects. As a solution, we show that training on monocular depth estimates with varying levels of detail provides control over structure and content fidelity. A novel guidance method, enabled by joint video and image training, exposes explicit control over temporal consistency. Our experiments demonstrate a wide variety of successes; fine-grained control over output characteristics, customization based on a few reference images, and a strong user preference towards results by our model.",
    "citationCount": 654,
    "pdf_filename": "2023_Structure_and_Content_Guided_Video_Synth_07be0ec1.pdf"
  },
  "da9683e826c37a6383c124b5c6cddefcb35ee8fd": {
    "paperId": "da9683e826c37a6383c124b5c6cddefcb35ee8fd",
    "title": "ChatGPT and a new academic reality: Artificial Intelligence‐written research papers and the ethics of the large language models in scholarly publishing",
    "year": 2023,
    "authors": "Brady D. Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, S. Shimray",
    "abstract": "This article discusses OpenAI's ChatGPT, a generative pre‐trained transformer, which uses natural language processing to fulfill text‐based user requests (i.e., a “chatbot”). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT‐3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.",
    "citationCount": 651,
    "pdf_filename": "2023_ChatGPT_and_a_new_academic_reality__Arti_da9683e8.pdf"
  },
  "a4960c5758a76faee04bf8c2962d30c789d7a3f1": {
    "paperId": "a4960c5758a76faee04bf8c2962d30c789d7a3f1",
    "title": "SpectralGPT: Spectral Remote Sensing Foundation Model",
    "year": 2023,
    "authors": "D. Hong, Bing Zhang, Xuyang Li, Yuxuan Li, Chenyu Li",
    "abstract": "The foundation model has recently garnered significant attention due to its potential to revolutionize the field of visual representation learning in a self-supervised manner. While most foundation models are tailored to effectively process RGB images for various visual tasks, there is a noticeable gap in research focused on spectral data, which offers valuable information for scene understanding, especially in remote sensing (RS) applications. To fill this gap, we created for the first time a universal RS foundation model, named SpectralGPT, which is purpose-built to handle spectral RS images using a novel 3D generative pretrained transformer (GPT). Compared to existing foundation models, SpectralGPT 1) accommodates input images with varying sizes, resolutions, time series, and regions in a progressive training fashion, enabling full utilization of extensive RS Big Data; 2) leverages 3D token generation for spatial-spectral coupling; 3) captures spectrally sequential patterns via multi-target reconstruction; and 4) trains on one million spectral RS images, yielding models with over 600 million parameters. Our evaluation highlights significant performance improvements with pretrained SpectralGPT models, signifying substantial potential in advancing spectral RS Big Data applications within the field of geoscience across four downstream tasks: single/multi-label scene classification, semantic segmentation, and change detection.",
    "citationCount": 606,
    "pdf_filename": "2023_SpectralGPT__Spectral_Remote_Sensing_Fou_a4960c57.pdf"
  },
  "ee57e4d7a125f4ca8916284a857c3760d7d378d3": {
    "paperId": "ee57e4d7a125f4ca8916284a857c3760d7d378d3",
    "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture",
    "year": 2023,
    "authors": "Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent",
    "abstract": "This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.",
    "citationCount": 532,
    "pdf_filename": "2023_Self_Supervised_Learning_from_Images_wit_ee57e4d7.pdf"
  },
  "a6d3794c23626060781da0f1ff2bcdf7457b6c43": {
    "paperId": "a6d3794c23626060781da0f1ff2bcdf7457b6c43",
    "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models",
    "year": 2023,
    "authors": "Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang",
    "abstract": "Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in their capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications such as healthcare and finance -- where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives -- including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conversation history. We also find that although GPT-4 is usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more vulnerable given jailbreaking system or user prompts, potentially because GPT-4 follows (misleading) instructions more precisely. Our work illustrates a comprehensive trustworthiness evaluation of GPT models and sheds light on the trustworthiness gaps. Our benchmark is publicly available at https://decodingtrust.github.io/ ; our dataset can be previewed at https://huggingface.co/datasets/AI-Secure/DecodingTrust ; a concise version of this work is at https://openreview.net/pdf?id=kaHpo8OZw2 .",
    "citationCount": 534,
    "pdf_filename": "2023_DecodingTrust__A_Comprehensive_Assessmen_a6d3794c.pdf"
  },
  "daf61010eee0fbf6f9bab7db71c395ffca6f3ff3": {
    "paperId": "daf61010eee0fbf6f9bab7db71c395ffca6f3ff3",
    "title": "Zero-shot Image-to-Image Translation",
    "year": 2023,
    "authors": "Gaurav Parmar, Krishna Kumar Singh, Richard Zhang, Yijun Li, Jingwan Lu",
    "abstract": "Large-scale text-to-image generative models have shown their remarkable ability to synthesize diverse, high-quality images. However, directly applying these models for real image editing remains challenging for two reasons. First, it is hard for users to craft a perfect text prompt depicting every visual detail in the input image. Second, while existing models can introduce desirable changes in certain regions, they often dramatically alter the input content and introduce unexpected changes in unwanted regions. In this work, we introduce pix2pix-zero, an image-to-image translation method that can preserve the original image’s content without manual prompting. We first automatically discover editing directions that reflect desired edits in the text embedding space. To preserve the content structure, we propose cross-attention guidance, which aims to retain the cross-attention maps of the input image throughout the diffusion process. Finally, to enable interactive editing, we distill the diffusion model into a fast conditional GAN. We conduct extensive experiments and show that our method outperforms existing and concurrent works for both real and synthetic image editing. In addition, our method does not need additional training for these edits and can directly use the existing pre-trained text-to-image diffusion model.",
    "citationCount": 546,
    "pdf_filename": "2023_Zero_shot_Image_to_Image_Translation_daf61010.pdf"
  },
  "ae3d869719c15099889c02c03b922516b3b60aa0": {
    "paperId": "ae3d869719c15099889c02c03b922516b3b60aa0",
    "title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
    "year": 2023,
    "authors": "Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr",
    "abstract": "Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.",
    "citationCount": 531,
    "pdf_filename": "2023_How_Good_Are_GPT_Models_at_Machine_Trans_ae3d8697.pdf"
  },
  "d8008ace077d72ccd277be795c720e9381623c10": {
    "paperId": "d8008ace077d72ccd277be795c720e9381623c10",
    "title": "Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis",
    "year": 2023,
    "authors": "Xiaoshi Wu, Yiming Hao, Keqiang Sun, Yixiong Chen, Feng Zhu",
    "abstract": "Recent text-to-image generative models can generate high-fidelity images from text inputs, but the quality of these generated images cannot be accurately evaluated by existing evaluation metrics. To address this issue, we introduce Human Preference Dataset v2 (HPD v2), a large-scale dataset that captures human preferences on images from a wide range of sources. HPD v2 comprises 798,090 human preference choices on 433,760 pairs of images, making it the largest dataset of its kind. The text prompts and images are deliberately collected to eliminate potential bias, which is a common issue in previous datasets. By fine-tuning CLIP on HPD v2, we obtain Human Preference Score v2 (HPS v2), a scoring model that can more accurately predict human preferences on generated images. Our experiments demonstrate that HPS v2 generalizes better than previous metrics across various image distributions and is responsive to algorithmic improvements of text-to-image generative models, making it a preferable evaluation metric for these models. We also investigate the design of the evaluation prompts for text-to-image generative models, to make the evaluation stable, fair and easy-to-use. Finally, we establish a benchmark for text-to-image generative models using HPS v2, which includes a set of recent text-to-image models from the academic, community and industry. The code and dataset is available at https://github.com/tgxs002/HPSv2 .",
    "citationCount": 526,
    "pdf_filename": "2023_Human_Preference_Score_v2__A_Solid_Bench_d8008ace.pdf"
  },
  "cd7427ba511c126ed0cf32ba9404b6aa53da0153": {
    "paperId": "cd7427ba511c126ed0cf32ba9404b6aa53da0153",
    "title": "Stochastic Interpolants: A Unifying Framework for Flows and Diffusions",
    "year": 2023,
    "authors": "M. S. Albergo, N. Boffi, E. Vanden-Eijnden",
    "abstract": "A class of generative models that unifies flow-based and diffusion-based methods is introduced. These models extend the framework proposed in Albergo&Vanden-Eijnden (2023), enabling the use of a broad class of continuous-time stochastic processes called `stochastic interpolants' to bridge any two arbitrary probability density functions exactly in finite time. These interpolants are built by combining data from the two prescribed densities with an additional latent variable that shapes the bridge in a flexible way. The time-dependent probability density function of the stochastic interpolant is shown to satisfy a first-order transport equation as well as a family of forward and backward Fokker-Planck equations with tunable diffusion. Upon consideration of the time evolution of an individual sample, this viewpoint immediately leads to both deterministic and stochastic generative models based on probability flow equations or stochastic differential equations with an adjustable level of noise. The drift coefficients entering these models are time-dependent velocity fields characterized as the unique minimizers of simple quadratic objective functions, one of which is a new objective for the score of the interpolant density. Remarkably, we show that minimization of these quadratic objectives leads to control of the likelihood for any of our generative models built upon stochastic dynamics. By contrast, we establish that generative models based upon a deterministic dynamics must, in addition, control the Fisher divergence between the target and the model. We also construct estimators for the likelihood and the cross-entropy of interpolant-based generative models, discuss connections with other stochastic bridges, and demonstrate that such models recover the Schr\\\"odinger bridge between the two target densities when explicitly optimizing over the interpolant.",
    "citationCount": 522,
    "pdf_filename": "2023_Stochastic_Interpolants__A_Unifying_Fram_cd7427ba.pdf"
  },
  "bd0fae435b93819d407f36d9d52565d5dfb5f87c": {
    "paperId": "bd0fae435b93819d407f36d9d52565d5dfb5f87c",
    "title": "MiniCPM-V: A GPT-4V Level MLLM on Your Phone",
    "year": 2024,
    "authors": "Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui",
    "abstract": "The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claude 3 on OpenCompass, a comprehensive evaluation over 11 popular benchmarks, (2) strong OCR capability and 1.8M pixel high-resolution image perception at any aspect ratio, (3) trustworthy behavior with low hallucination rates, (4) multilingual support for 30+ languages, and (5) efficient deployment on mobile phones. More importantly, MiniCPM-V can be viewed as a representative example of a promising trend: The model sizes for achieving usable (e.g., GPT-4V) level performance are rapidly decreasing, along with the fast growth of end-side computation capacity. This jointly shows that GPT-4V level MLLMs deployed on end devices are becoming increasingly possible, unlocking a wider spectrum of real-world AI applications in the near future.",
    "citationCount": 824,
    "pdf_filename": "2024_MiniCPM_V__A_GPT_4V_Level_MLLM_on_Your_P_bd0fae43.pdf"
  },
  "17a6116e5bbd8b87082cbb2e795885567300c483": {
    "paperId": "17a6116e5bbd8b87082cbb2e795885567300c483",
    "title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
    "year": 2023,
    "authors": "Melanie Sclar, Yejin Choi, Yulia Tsvetkov, Alane Suhr",
    "abstract": "As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FormatSpread, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.",
    "citationCount": 518,
    "pdf_filename": "2023_Quantifying_Language_Models__Sensitivity_17a6116e.pdf"
  },
  "1406bb4cb6801bc4767b661308118c888a9b09da": {
    "paperId": "1406bb4cb6801bc4767b661308118c888a9b09da",
    "title": "MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark",
    "year": 2024,
    "authors": "Yubo Wang, Xueguang Ma, Ge Zhang, Yuansheng Ni, Abhranil Chandra",
    "abstract": "In the age of large-scale language models, benchmarks like the Massive Multitask Language Understanding (MMLU) have been pivotal in pushing the boundaries of what AI can achieve in language comprehension and reasoning across diverse domains. However, as models continue to improve, their performance on these benchmarks has begun to plateau, making it increasingly difficult to discern differences in model capabilities. This paper introduces MMLU-Pro, an enhanced dataset designed to extend the mostly knowledge-driven MMLU benchmark by integrating more challenging, reasoning-focused questions and expanding the choice set from four to ten options. Additionally, MMLU-Pro eliminates the trivial and noisy questions in MMLU. Our experimental results show that MMLU-Pro not only raises the challenge, causing a significant drop in accuracy by 16% to 33% compared to MMLU but also demonstrates greater stability under varying prompts. With 24 different prompt styles tested, the sensitivity of model scores to prompt variations decreased from 4-5% in MMLU to just 2% in MMLU-Pro. Additionally, we found that models utilizing Chain of Thought (CoT) reasoning achieved better performance on MMLU-Pro compared to direct answering, which is in stark contrast to the findings on the original MMLU, indicating that MMLU-Pro includes more complex reasoning questions. Our assessments confirm that MMLU-Pro is a more discriminative benchmark to better track progress in the field.",
    "citationCount": 979,
    "pdf_filename": "2024_MMLU_Pro__A_More_Robust_and_Challenging__1406bb4c.pdf"
  },
  "20c02c51420a69ae39b74d8d73148417819dacc1": {
    "paperId": "20c02c51420a69ae39b74d8d73148417819dacc1",
    "title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence",
    "year": 2023,
    "authors": "Vikas Hassija, V. Chamola, Atmesh Mahapatra, Abhinandan Singal, Divyansh Goel",
    "abstract": "Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of domains. In this rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are inherently complex and lacks explanations of the decision making process causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as banking, e-commerce, healthcare, and public services and safety, is the difficulty in interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are getting harder which require transparency and easy predictability. Aiming to collate the current state-of-the-art in interpreting the black-box models, this study provides a comprehensive analysis of the explainable AI (XAI) models. To reduce false negative and false positive outcomes of these back-box models, finding flaws in them is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously through careful selection and analysis of the current state-of-the-art of XAI research. It also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it highlights emerging and critical issues pertaining to XAI research to showcase major, model-specific trends for better explanation, enhanced transparency, and improved prediction accuracy.",
    "citationCount": 948,
    "pdf_filename": "2023_Interpreting_Black_Box_Models__A_Review__20c02c51.pdf"
  },
  "c96297261467b5daa2d01227496a70d444602434": {
    "paperId": "c96297261467b5daa2d01227496a70d444602434",
    "title": "Baichuan 2: Open Large-scale Language Models",
    "year": 2023,
    "authors": "Ai Ming Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian",
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.",
    "citationCount": 902,
    "pdf_filename": "2023_Baichuan_2__Open_Large_scale_Language_Mo_c9629726.pdf"
  },
  "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9": {
    "paperId": "db9507cdd3e2d7d9c90ed185bd831e55c62dcec9",
    "title": "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration",
    "year": 2023,
    "authors": "Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang",
    "abstract": "Large language models (LLMs) have transformed numerous AI applications. On-device LLM is becoming increasingly important: running LLMs locally on edge devices can reduce cloud computing costs and protect users' privacy. However, the astronomical model size and the limited hardware resources pose significant deployment challenges. To solve these issues, we propose Activation-aware Weight Quantization (AWQ) and TinyChat, an algorithm-system full-stack solution for efficient on-device LLM deployment. AWQ is a novel quantization method that identifies and protects salient weights based on activation distribution, significantly reducing model size while preserving performance. TinyChat, an optimized inference framework, translates AWQ's theoretical memory savings into practical speedups through techniques such as on-the-fly dequantization, SIMD-aware weight packing, and kernel fusion. Together, they enable 4x model size reduction and 3-4x acceleration across various edge platforms, from high-end desktop GPUs to resource-constrained IoT devices. This solution democratizes on-device LLM deployment, offering privacy-preserving, low-latency AI capabilities across a wide range of applications.",
    "citationCount": 908,
    "pdf_filename": "2023_AWQ__Activation_aware_Weight_Quantizatio_db9507cd.pdf"
  },
  "15736f7c205d961c00378a938daffaacb5a0718d": {
    "paperId": "15736f7c205d961c00378a938daffaacb5a0718d",
    "title": "Human Motion Diffusion Model",
    "year": 2022,
    "authors": "Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or",
    "abstract": "Natural and expressive human motion generation is the holy grail of computer animation. It is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. Diffusion models, which have already shown remarkable generative capabilities in other domains, are promising candidates for human motion due to their many-to-many nature, but they tend to be resource hungry and hard to control. In this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain. MDM is transformer-based, combining insights from motion generation literature. A notable design-choice is the prediction of the sample, rather than the noise, in each diffusion step. This facilitates the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion and action-to-motion. https://guytevet.github.io/mdm-page/ .",
    "citationCount": 990,
    "pdf_filename": "2022_Human_Motion_Diffusion_Model_15736f7c.pdf"
  },
  "0f7308fbcae43d22813f70c334c2425df0b1cce1": {
    "paperId": "0f7308fbcae43d22813f70c334c2425df0b1cce1",
    "title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback",
    "year": 2023,
    "authors": "Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu",
    "abstract": "With the development of large language models (LLMs), striking a balance between the performance and safety of AI systems has never been more critical. However, the inherent tension between the objectives of helpfulness and harmlessness presents a significant challenge during LLM training. To address this issue, we propose Safe Reinforcement Learning from Human Feedback (Safe RLHF), a novel algorithm for human value alignment. Safe RLHF explicitly decouples human preferences regarding helpfulness and harmlessness, effectively avoiding the crowdworkers' confusion about the tension and allowing us to train separate reward and cost models. We formalize the safety concern of LLMs as an optimization task of maximizing the reward function while satisfying specified cost constraints. Leveraging the Lagrangian method to solve this constrained problem, Safe RLHF dynamically adjusts the balance between the two objectives during fine-tuning. Through a three-round fine-tuning using Safe RLHF, we demonstrate a superior ability to mitigate harmful responses while enhancing model performance compared to existing value-aligned algorithms. Experimentally, we fine-tuned the Alpaca-7B using Safe RLHF and aligned it with collected human preferences, significantly improving its helpfulness and harmlessness according to human evaluations.",
    "citationCount": 502,
    "pdf_filename": "2023_Safe_RLHF__Safe_Reinforcement_Learning_f_0f7308fb.pdf"
  },
  "e9685cf2c9aff2f7ff7bcfa5b65a11e90687a3ef": {
    "paperId": "e9685cf2c9aff2f7ff7bcfa5b65a11e90687a3ef",
    "title": "A SWOT analysis of ChatGPT: Implications for educational practice and research",
    "year": 2023,
    "authors": "Mohammadreza Farrokhnia, S. K. Banihashem, O. Noroozi, A. Wals",
    "abstract": "ABSTRACT ChatGPT is an AI tool that has sparked debates about its potential implications for education. We used the SWOT analysis framework to outline ChatGPT’s strengths and weaknesses and to discuss its opportunities for and threats to education. The strengths include using a sophisticated natural language model to generate plausible answers, self-improving capability, and providing personalised and real-time responses. As such, ChatGPT can increase access to information, facilitate personalised and complex learning, and decrease teaching workload, thereby making key processes and tasks more efficient. The weaknesses are a lack of deep understanding, difficulty in evaluating the quality of responses, a risk of bias and discrimination, and a lack of higher-order thinking skills. Threats to education include a lack of understanding of the context, threatening academic integrity, perpetuating discrimination in education, democratising plagiarism, and declining high-order cognitive skills. We provide agenda for educational practice and research in times of ChatGPT.",
    "citationCount": 868,
    "pdf_filename": "2023_A_SWOT_analysis_of_ChatGPT__Implications_e9685cf2.pdf"
  },
  "6c7ba2af4b3e472bd8a5717367b88dcdd4abbd31": {
    "paperId": "6c7ba2af4b3e472bd8a5717367b88dcdd4abbd31",
    "title": "Evaluating the Feasibility of ChatGPT in Healthcare: An Analysis of Multiple Clinical and Research Scenarios",
    "year": 2023,
    "authors": "M. Cascella, J. Montomoli, Valentina Bellini, E. Bignami",
    "abstract": "This paper aims to highlight the potential applications and limits of a large language model (LLM) in healthcare. ChatGPT is a recently developed LLM that was trained on a massive dataset of text for dialogue with users. Although AI-based language models like ChatGPT have demonstrated impressive capabilities, it is uncertain how well they will perform in real-world scenarios, particularly in fields such as medicine where high-level and complex thinking is necessary. Furthermore, while the use of ChatGPT in writing scientific articles and other scientific outputs may have potential benefits, important ethical concerns must also be addressed. Consequently, we investigated the feasibility of ChatGPT in clinical and research scenarios: (1) support of the clinical practice, (2) scientific production, (3) misuse in medicine and research, and (4) reasoning about public health topics. Results indicated that it is important to recognize and promote education on the appropriate use and potential pitfalls of AI-based LLMs in medicine.",
    "citationCount": 907,
    "pdf_filename": "2023_Evaluating_the_Feasibility_of_ChatGPT_in_6c7ba2af.pdf"
  },
  "7dbb386a617eacc954940c9540d9cb262529b8b1": {
    "paperId": "7dbb386a617eacc954940c9540d9cb262529b8b1",
    "title": "Equivariant Diffusion for Molecule Generation in 3D",
    "year": 2022,
    "authors": "Emiel Hoogeboom, Victor Garcia Satorras, Clément Vignac, M. Welling",
    "abstract": "This work introduces a diffusion model for molecule generation in 3D that is equivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model (EDM) learns to denoise a diffusion process with an equivariant network that jointly operates on both continuous (atom coordinates) and categorical features (atom types). In addition, we provide a probabilistic analysis which admits likelihood computation of molecules using our model. Experimentally, the proposed method significantly outperforms previous 3D molecular generative methods regarding the quality of generated samples and efficiency at training time.",
    "citationCount": 765,
    "pdf_filename": "2022_Equivariant_Diffusion_for_Molecule_Gener_7dbb386a.pdf"
  },
  "1b8a734dd28a9d766a5d3dbc0871e76b6a452b65": {
    "paperId": "1b8a734dd28a9d766a5d3dbc0871e76b6a452b65",
    "title": "Point-E: A System for Generating 3D Point Clouds from Complex Prompts",
    "year": 2022,
    "authors": "Alex Nichol, Heewoo Jun, Prafulla Dhariwal, Pamela Mishkin, Mark Chen",
    "abstract": "While recent work on text-conditional 3D object generation has shown promising results, the state-of-the-art methods typically require multiple GPU-hours to produce a single sample. This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes. In this paper, we explore an alternative method for 3D object generation which produces 3D models in only 1-2 minutes on a single GPU. Our method first generates a single synthetic view using a text-to-image diffusion model, and then produces a 3D point cloud using a second diffusion model which conditions on the generated image. While our method still falls short of the state-of-the-art in terms of sample quality, it is one to two orders of magnitude faster to sample from, offering a practical trade-off for some use cases. We release our pre-trained point cloud diffusion models, as well as evaluation code and models, at https://github.com/openai/point-e.",
    "citationCount": 753,
    "pdf_filename": "2022_Point_E__A_System_for_Generating_3D_Poin_1b8a734d.pdf"
  },
  "e1d2f2a717aa03280126f87c8e5fad695f52bf7c": {
    "paperId": "e1d2f2a717aa03280126f87c8e5fad695f52bf7c",
    "title": "Explainable Artificial Intelligence (XAI)",
    "year": 2023,
    "authors": "Ranu Sewada, Ashwani Jangid, Piyush Kumar, Neha Mishra",
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a critical facet in the realm of machine learning and artificial intelligence, responding to the increasing complexity of models, particularly deep neural networks, and the subsequent need for transparent decision making processes. This research paper delves into the essence of XAI, unraveling its significance across diverse domains such as healthcare, finance, and criminal justice. As a countermeasure to the opacity of intricate models, the paper explores various XAI methods and techniques, including LIME and SHAP, weighing their interpretability against computational efficiency and accuracy. Through an examination of real-world applications, the research elucidates how XAI not only enhances decision-making processes but also influences user trust and acceptance in AI systems. However, the paper also scrutinizes the delicate balance between interpretability and performance, shedding light on instances where the pursuit of accuracy may compromise explain-ability. Additionally, it navigates through the current challenges and limitations in XAI, the regulatory landscape surrounding AI explain-ability, and offers insights into future trends and directions, fostering a comprehensive understanding of XAI's present state and future potential.",
    "citationCount": 746,
    "pdf_filename": "2023_Explainable_Artificial_Intelligence__XAI_e1d2f2a7.pdf"
  },
  "e251ba9fe7992fc07a01365a5f8f2b4d9020b875": {
    "paperId": "e251ba9fe7992fc07a01365a5f8f2b4d9020b875",
    "title": "Artificial intelligence in higher education: the state of the field",
    "year": 2023,
    "authors": "H. Crompton, D. Burke",
    "abstract": "This systematic review provides unique findings with an up-to-date examination of artificial intelligence (AI) in higher education (HE) from 2016 to 2022. Using PRISMA principles and protocol, 138 articles were identified for a full examination. Using a priori, and grounded coding, the data from the 138 articles were extracted, analyzed, and coded. The findings of this study show that in 2021 and 2022, publications rose nearly two to three times the number of previous years. With this rapid rise in the number of AIEd HE publications, new trends have emerged. The findings show that research was conducted in six of the seven continents of the world. The trend has shifted from the US to China leading in the number of publications. Another new trend is in the researcher affiliation as prior studies showed a lack of researchers from departments of education. This has now changed to be the most dominant department. Undergraduate students were the most studied students at 72%. Similar to the findings of other studies, language learning was the most common subject domain. This included writing, reading, and vocabulary acquisition. In examination of who the AIEd was intended for 72% of the studies focused on students, 17% instructors, and 11% managers. In answering the overarching question of how AIEd was used in HE, grounded coding was used. Five usage codes emerged from the data: (1) Assessment/Evaluation, (2) Predicting, (3) AI Assistant, (4) Intelligent Tutoring System (ITS), and (5) Managing Student Learning. This systematic review revealed gaps in the literature to be used as a springboard for future researchers, including new tools, such as Chat GPT. A systematic review examining AIEd in higher education (HE) up to the end of 2022. Unique findings in the switch from US to China in the most studies published. A two to threefold increase in studies published in 2021 and 2022 to prior years. AIEd was used for: Assessment/Evaluation, Predicting, AI Assistant, Intelligent Tutoring System, and Managing Student Learning.",
    "citationCount": 790,
    "pdf_filename": "2023_Artificial_intelligence_in_higher_educat_e251ba9f.pdf"
  },
  "6eb46737bf0ef916a7f906ec6a8da82a45ffb623": {
    "paperId": "6eb46737bf0ef916a7f906ec6a8da82a45ffb623",
    "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
    "year": 2023,
    "authors": "Stephen Casper, Xander Davies, Claudia Shi, T. Gilbert, J'er'emy Scheurer",
    "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.",
    "citationCount": 686,
    "pdf_filename": "2023_Open_Problems_and_Fundamental_Limitation_6eb46737.pdf"
  },
  "fa75a55760e6ea49b39b83cb85c99a22e1088254": {
    "paperId": "fa75a55760e6ea49b39b83cb85c99a22e1088254",
    "title": "NExT-GPT: Any-to-Any Multimodal LLM",
    "year": 2023,
    "authors": "Shengqiong Wu, Hao Fei, Leigang Qu, Wei Ji, Tat-Seng Chua",
    "abstract": "While recently Multimodal Large Language Models (MM-LLMs) have made exciting strides, they mostly fall prey to the limitation of only input-side multimodal understanding, without the ability to produce content in multiple modalities. As we humans always perceive the world and communicate with people through various modalities, developing any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes essential to human-level AI. To fill the gap, we present an end-to-end general-purpose any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and different diffusion decoders, enabling NExT-GPT to perceive inputs and generate outputs in arbitrary combinations of text, images, videos, and audio. By leveraging the existing well-trained highly-performing encoders and decoders, NExT-GPT is tuned with only a small amount of parameter (1%) of certain projection layers, which not only benefits low-cost training and also facilitates convenient expansion to more potential modalities. Moreover, we introduce a modality-switching instruction tuning (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT is empowered with complex cross-modal semantic understanding and content generation. Overall, our research showcases the promising possibility of building an AI agent capable of modeling universal modalities, paving the way for more human-like AI research in the community. Project page: https://next-gpt.github.io/",
    "citationCount": 684,
    "pdf_filename": "2023_NExT_GPT__Any_to_Any_Multimodal_LLM_fa75a557.pdf"
  },
  "b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7": {
    "paperId": "b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7",
    "title": "GraphMAE: Self-Supervised Masked Graph Autoencoders",
    "year": 2022,
    "authors": "Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang",
    "abstract": "Self-supervised learning (SSL) has been extensively explored in recent years. Particularly, generative SSL has seen emerging success in natural language processing and other fields, such as the wide adoption of BERT and GPT. Despite this, contrastive learning---which heavily relies on structural data augmentation and complicated training strategies---has been the dominant approach in graph SSL, while the progress of generative SSL on graphs, especially graph autoencoders (GAEs), has thus far not reached the potential as promised in other fields. In this paper, we identify and examine the issues that negatively impact the development of GAEs, including their reconstruction objective, training robustness, and error metric. We present a masked graph autoencoder GraphMAE (code is publicly available at https://github.com/THUDM/GraphMAE) that mitigates these issues for generative self-supervised graph learning. Instead of reconstructing structures, we propose to focus on feature reconstruction with both a masking strategy and scaled cosine error that benefit the robust training of GraphMAE. We conduct extensive experiments on 21 public datasets for three different graph learning tasks. The results manifest that GraphMAE---a simple graph autoencoder with our careful designs---can consistently generate outperformance over both contrastive and generative state-of-the-art baselines. This study provides an understanding of graph autoencoders and demonstrates the potential of generative self-supervised learning on graphs.",
    "citationCount": 725,
    "pdf_filename": "2022_GraphMAE__Self_Supervised_Masked_Graph_A_b161c4aa.pdf"
  },
  "e99604e2da48483b633247c13dd4ad5f46196562": {
    "paperId": "e99604e2da48483b633247c13dd4ad5f46196562",
    "title": "DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking",
    "year": 2022,
    "authors": "Gabriele Corso, Hannes Stärk, Bowen Jing, R. Barzilay, T. Jaakkola",
    "abstract": "Predicting the binding structure of a small molecule ligand to a protein -- a task known as molecular docking -- is critical to drug design. Recent deep learning methods that treat docking as a regression problem have decreased runtime compared to traditional search-based methods but have yet to offer substantial improvements in accuracy. We instead frame molecular docking as a generative modeling problem and develop DiffDock, a diffusion generative model over the non-Euclidean manifold of ligand poses. To do so, we map this manifold to the product space of the degrees of freedom (translational, rotational, and torsional) involved in docking and develop an efficient diffusion process on this space. Empirically, DiffDock obtains a 38% top-1 success rate (RMSD<2A) on PDBBind, significantly outperforming the previous state-of-the-art of traditional docking (23%) and deep learning (20%) methods. Moreover, while previous methods are not able to dock on computationally folded structures (maximum accuracy 10.4%), DiffDock maintains significantly higher precision (21.7%). Finally, DiffDock has fast inference times and provides confidence estimates with high selective accuracy.",
    "citationCount": 597,
    "pdf_filename": "2022_DiffDock__Diffusion_Steps__Twists__and_T_e99604e2.pdf"
  },
  "9b41d745fe3a76443bd0420bc5f2df28be2bd65f": {
    "paperId": "9b41d745fe3a76443bd0420bc5f2df28be2bd65f",
    "title": "Diffusion Models for Adversarial Purification",
    "year": 2022,
    "authors": "Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat",
    "abstract": "Adversarial purification refers to a class of defense methods that remove adversarial perturbations using a generative model. These methods do not make assumptions on the form of attack and the classification model, and thus can defend pre-existing classifiers against unseen threats. However, their performance currently falls behind adversarial training methods. In this work, we propose DiffPure that uses diffusion models for adversarial purification: Given an adversarial example, we first diffuse it with a small amount of noise following a forward diffusion process, and then recover the clean image through a reverse generative process. To evaluate our method against strong adaptive attacks in an efficient and scalable way, we propose to use the adjoint method to compute full gradients of the reverse generative process. Extensive experiments on three image datasets including CIFAR-10, ImageNet and CelebA-HQ with three classifier architectures including ResNet, WideResNet and ViT demonstrate that our method achieves the state-of-the-art results, outperforming current adversarial training and adversarial purification methods, often by a large margin. Project page: https://diffpure.github.io.",
    "citationCount": 571,
    "pdf_filename": "2022_Diffusion_Models_for_Adversarial_Purific_9b41d745.pdf"
  },
  "eac11727ef9c7c29711cb1ba82ef6f011e8ad78d": {
    "paperId": "eac11727ef9c7c29711cb1ba82ef6f011e8ad78d",
    "title": "New Era of Artificial Intelligence in Education: Towards a Sustainable Multifaceted Revolution",
    "year": 2023,
    "authors": "Firuz Kamalov, David Santandreu Calonge, Ikhlaas Gurrib",
    "abstract": "The recent high performance of ChatGPT on several standardized academic tests has thrust the topic of artificial intelligence (AI) into the mainstream conversation about the future of education. As deep learning is poised to shift the teaching paradigm, it is essential to have a clear understanding of its effects on the current education system to ensure sustainable development and deployment of AI-driven technologies at schools and universities. This research aims to investigate the potential impact of AI on education through review and analysis of the existing literature across three major axes: applications, advantages, and challenges. Our review focuses on the use of artificial intelligence in collaborative teacher–student learning, intelligent tutoring systems, automated assessment, and personalized learning. We also report on the potential negative aspects, ethical issues, and possible future routes for AI implementation in education. Ultimately, we find that the only way forward is to embrace the new technology, while implementing guardrails to prevent its abuse.",
    "citationCount": 614,
    "pdf_filename": "2023_New_Era_of_Artificial_Intelligence_in_Ed_eac11727.pdf"
  },
  "fc011ed5ee986332523a62d2783adee1179dc1ed": {
    "paperId": "fc011ed5ee986332523a62d2783adee1179dc1ed",
    "title": "Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation",
    "year": 2022,
    "authors": "Haochen Wang, Xiaodan Du, Jiahao Li, Raymond A. Yeh, Gregory Shakhnarovich",
    "abstract": "A diffusion model learns to predict a vector field of gradients. We propose to apply chain rule on the learned gradients, and back-propagate the score of a diffusion model through the Jacobian of a differentiable renderer, which we instantiate to be a voxel radiance field. This setup aggregates 2D scores at multiple camera viewpoints into a 3D score, and re-purposes a pretrained 2D model for 3D data generation. We identify a technical challenge of distribution mismatch that arises in this application, and propose a novel estimation mechanism to resolve it. We run our algorithm on several off-the-shelf diffusion image generative models, including the recently released Stable Diffusion trained on the large-scale LAION 5B dataset.",
    "citationCount": 628,
    "pdf_filename": "2022_Score_Jacobian_Chaining__Lifting_Pretrai_fc011ed5.pdf"
  },
  "82ba96443173da0b8b3e870c5ab8f41109a67203": {
    "paperId": "82ba96443173da0b8b3e870c5ab8f41109a67203",
    "title": "StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets",
    "year": 2022,
    "authors": "Axel Sauer, Katja Schwarz, Andreas Geiger",
    "abstract": "Computer graphics has experienced a recent surge of data-centric approaches for photorealistic and controllable content creation. StyleGAN in particular sets new standards for generative modeling regarding image quality and controllability. However, StyleGAN’s performance severely degrades on large unstructured datasets such as ImageNet. StyleGAN was designed for controllability; hence, prior works suspect its restrictive design to be unsuitable for diverse datasets. In contrast, we find the main limiting factor to be the current training strategy. Following the recently introduced Projected GAN paradigm, we leverage powerful neural network priors and a progressive growing strategy to successfully train the latest StyleGAN3 generator on ImageNet. Our final model, StyleGAN-XL, sets a new state-of-the-art on large-scale image synthesis and is the first to generate images at a resolution of 10242 at such a dataset scale. We demonstrate that this model can invert and edit images beyond the narrow domain of portraits or specific object classes. Code, models, and supplementary videos can be found at https://sites.google.com/view/stylegan-xl/ .",
    "citationCount": 605,
    "pdf_filename": "2022_StyleGAN_XL__Scaling_StyleGAN_to_Large_D_82ba9644.pdf"
  },
  "282c568302701bc163d454702eae10e43ca784a3": {
    "paperId": "282c568302701bc163d454702eae10e43ca784a3",
    "title": "The future landscape of large language models in medicine",
    "year": 2023,
    "authors": "Jan Clusmann, F. Kolbinger, H. Muti, Zunamys I. Carrero, Jan-Niklas Eckardt",
    "abstract": "Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI’s ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.",
    "citationCount": 715,
    "pdf_filename": "2023_The_future_landscape_of_large_language_m_282c5683.pdf"
  },
  "b3f5cf32178bcbed91aa5303b70963c6463f48a2": {
    "paperId": "b3f5cf32178bcbed91aa5303b70963c6463f48a2",
    "title": "Improving Diffusion Models for Inverse Problems using Manifold Constraints",
    "year": 2022,
    "authors": "Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, J. C. Ye",
    "abstract": "Recently, diffusion models have been used to solve various inverse problems in an unsupervised manner with appropriate modifications to the sampling process. However, the current solvers, which recursively apply a reverse diffusion step followed by a projection-based measurement consistency step, often produce suboptimal results. By studying the generative sampling path, here we show that current solvers throw the sample path off the data manifold, and hence the error accumulates. To address this, we propose an additional correction term inspired by the manifold constraint, which can be used synergistically with the previous solvers to make the iterations close to the manifold. The proposed manifold constraint is straightforward to implement within a few lines of code, yet boosts the performance by a surprisingly large margin. With extensive experiments, we show that our method is superior to the previous methods both theoretically and empirically, producing promising results in many applications such as image inpainting, colorization, and sparse-view computed tomography. Code available https://github.com/HJ-harry/MCG_diffusion",
    "citationCount": 574,
    "pdf_filename": "2022_Improving_Diffusion_Models_for_Inverse_P_b3f5cf32.pdf"
  },
  "2e25c77f635cf887268c9d3df84d8ef61826042f": {
    "paperId": "2e25c77f635cf887268c9d3df84d8ef61826042f",
    "title": "Reimagining our futures together: a new social contract for education",
    "year": 2022,
    "authors": "S. Carney",
    "abstract": "fields of CIE and policy sociology. How do we move beyond the necessary documentation, description and critique of the constantly emerging developments in and around education policy and governance to also, at the same time, offer new ways of thinking outside those that the tools and techniques of quantification and comparison make possible? How can we collectively make discourses that actively challenge ‘number-intelligent activities’ appear less ‘unintelligent’ to the makers, practitioners and researchers of policy? And how can we then mobilise these new discursive terrains to imagine as-yet-unthought opportunities for thinking and doing education? There are no ready answers, but this volume offers some generative first steps.",
    "citationCount": 532,
    "pdf_filename": "2022_Reimagining_our_futures_together__a_new__2e25c77f.pdf"
  },
  "4e6244baf4236f4635e85f7dfb941a9a0a6c4a11": {
    "paperId": "4e6244baf4236f4635e85f7dfb941a9a0a6c4a11",
    "title": "Building Normalizing Flows with Stochastic Interpolants",
    "year": 2022,
    "authors": "M. S. Albergo, E. Vanden-Eijnden",
    "abstract": "A generative model based on a continuous-time normalizing flow between any pair of base and target probability densities is proposed. The velocity field of this flow is inferred from the probability current of a time-dependent density that interpolates between the base and the target in finite time. Unlike conventional normalizing flow inference methods based the maximum likelihood principle, which require costly backpropagation through ODE solvers, our interpolant approach leads to a simple quadratic loss for the velocity itself which is expressed in terms of expectations that are readily amenable to empirical estimation. The flow can be used to generate samples from either the base or target, and to estimate the likelihood at any time along the interpolant. In addition, the flow can be optimized to minimize the path length of the interpolant density, thereby paving the way for building optimal transport maps. In situations where the base is a Gaussian density, we also show that the velocity of our normalizing flow can also be used to construct a diffusion model to sample the target as well as estimate its score. However, our approach shows that we can bypass this diffusion completely and work at the level of the probability flow with greater simplicity, opening an avenue for methods based solely on ordinary differential equations as an alternative to those based on stochastic differential equations. Benchmarking on density estimation tasks illustrates that the learned flow can match and surpass conventional continuous flows at a fraction of the cost, and compares well with diffusions on image generation on CIFAR-10 and ImageNet $32\\times32$. The method scales ab-initio ODE flows to previously unreachable image resolutions, demonstrated up to $128\\times128$.",
    "citationCount": 598,
    "pdf_filename": "2022_Building_Normalizing_Flows_with_Stochast_4e6244ba.pdf"
  },
  "4a07ded5f56aa76c75e844f353e046414b427cc2": {
    "paperId": "4a07ded5f56aa76c75e844f353e046414b427cc2",
    "title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
    "year": 2023,
    "authors": "Laith Alzubaidi, Jinshuai Bai, Aiman Al-Sabaawi, José I. Santamaría, A. Albahri",
    "abstract": "Data scarcity is a major challenge when training deep learning (DL) models. DL demands a large amount of data to achieve exceptional performance. Unfortunately, many applications have small or inadequate data to train DL frameworks. Usually, manual labeling is needed to provide labeled data, which typically involves human annotators with a vast background of knowledge. This annotation process is costly, time-consuming, and error-prone. Usually, every DL framework is fed by a significant amount of labeled data to automatically learn representations. Ultimately, a larger amount of data would generate a better DL model and its performance is also application dependent. This issue is the main barrier for many applications dismissing the use of DL. Having sufficient data is the first step toward any successful and trustworthy DL application. This paper presents a holistic survey on state-of-the-art techniques to deal with training DL models to overcome three challenges including small, imbalanced datasets, and lack of generalization. This survey starts by listing the learning techniques. Next, the types of DL architectures are introduced. After that, state-of-the-art solutions to address the issue of lack of training data are listed, such as Transfer Learning (TL), Self-Supervised Learning (SSL), Generative Adversarial Networks (GANs), Model Architecture (MA), Physics-Informed Neural Network (PINN), and Deep Synthetic Minority Oversampling Technique (DeepSMOTE). Then, these solutions were followed by some related tips about data acquisition needed prior to training purposes, as well as recommendations for ensuring the trustworthiness of the training dataset. The survey ends with a list of applications that suffer from data scarcity, several alternatives are proposed in order to generate more data in each application including Electromagnetic Imaging (EMI), Civil Structural Health Monitoring, Medical imaging, Meteorology, Wireless Communications, Fluid Mechanics, Microelectromechanical system, and Cybersecurity. To the best of the authors’ knowledge, this is the first review that offers a comprehensive overview on strategies to tackle data scarcity in DL.",
    "citationCount": 593,
    "pdf_filename": "2023_A_survey_on_deep_learning_tools_dealing__4a07ded5.pdf"
  },
  "1a9b8c545ba9a6779f202e04639c2d67e6d34f63": {
    "paperId": "1a9b8c545ba9a6779f202e04639c2d67e6d34f63",
    "title": "Instruction-Following Evaluation for Large Language Models",
    "year": 2023,
    "authors": "Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu",
    "abstract": "One core capability of Large Language Models (LLMs) is to follow natural language instructions. However, the evaluation of such abilities is not standardized: Human evaluations are expensive, slow, and not objectively reproducible, while LLM-based auto-evaluation is potentially biased or limited by the ability of the evaluator LLM. To overcome these issues, we introduce Instruction-Following Eval (IFEval) for large language models. IFEval is a straightforward and easy-to-reproduce evaluation benchmark. It focuses on a set of\"verifiable instructions\"such as\"write in more than 400 words\"and\"mention the keyword of AI at least 3 times\". We identified 25 types of those verifiable instructions and constructed around 500 prompts, with each prompt containing one or more verifiable instructions. We show evaluation results of two widely available LLMs on the market. Our code and data can be found at https://github.com/google-research/google-research/tree/master/instruction_following_eval",
    "citationCount": 517,
    "pdf_filename": "2023_Instruction_Following_Evaluation_for_Lar_1a9b8c54.pdf"
  },
  "cdcf3f36866ef1e16eba26d57c2324362247ba84": {
    "paperId": "cdcf3f36866ef1e16eba26d57c2324362247ba84",
    "title": "Zephyr: Direct Distillation of LM Alignment",
    "year": 2023,
    "authors": "Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul",
    "abstract": "We aim to produce a smaller language model that is aligned to user intent. Previous research has shown that applying distilled supervised fine-tuning (dSFT) on larger models significantly improves task accuracy; however, these models are unaligned, i.e. they do not respond well to natural prompts. To distill this property, we experiment with the use of preference data from AI Feedback (AIF). Starting from a dataset of outputs ranked by a teacher model, we apply distilled direct preference optimization (dDPO) to learn a chat model with significantly improved intent alignment. The approach requires only a few hours of training without any additional sampling during fine-tuning. The final result, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B parameter models, and requires no human annotation. In particular, results on MT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access RLHF-based model. Code, models, data, and tutorials for the system are available at https://github.com/huggingface/alignment-handbook.",
    "citationCount": 507,
    "pdf_filename": "2023_Zephyr__Direct_Distillation_of_LM_Alignm_cdcf3f36.pdf"
  },
  "6c8a5d2d4e20103f666697092c81d2ae6939e963": {
    "paperId": "6c8a5d2d4e20103f666697092c81d2ae6939e963",
    "title": "The rise of ChatGPT: Exploring its potential in medical education",
    "year": 2023,
    "authors": "Hyunsu Lee",
    "abstract": "The integration of artificial intelligence (AI) into medical education has the potential to revolutionize the way students learn about biomedical sciences. Large language models, such as ChatGPT, can serve as virtual teaching assistants, providing students with detailed and relevant information and perhaps eventually interactive simulations. ChatGPT has the potential to increase student engagement and enhance student learning, though research is needed to confirm this. The challenges and limitations of ChatGPT must also be considered, including ethical issues and potentially harmful effects. It is crucial for medical educators to keep pace with technology's rapidly changing landscape and consider the implications for curriculum design, assessment strategies, and teaching methods. Continued research and evaluation are necessary to ensure the optimal integration of AI‐based learning tools into medical education.",
    "citationCount": 509,
    "pdf_filename": "2023_The_rise_of_ChatGPT__Exploring_its_poten_6c8a5d2d.pdf"
  },
  "438ea4f6becaadca82c9f9904208a423a0cfeba0": {
    "paperId": "438ea4f6becaadca82c9f9904208a423a0cfeba0",
    "title": "Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design",
    "year": 2023,
    "authors": "Lalitkumar K. Vora, A. Gholap, Keshava Jetha, R. Thakur, Hetvi K. Solanki",
    "abstract": "Artificial intelligence (AI) has emerged as a powerful tool that harnesses anthropomorphic knowledge and provides expedited solutions to complex challenges. Remarkable advancements in AI technology and machine learning present a transformative opportunity in the drug discovery, formulation, and testing of pharmaceutical dosage forms. By utilizing AI algorithms that analyze extensive biological data, including genomics and proteomics, researchers can identify disease-associated targets and predict their interactions with potential drug candidates. This enables a more efficient and targeted approach to drug discovery, thereby increasing the likelihood of successful drug approvals. Furthermore, AI can contribute to reducing development costs by optimizing research and development processes. Machine learning algorithms assist in experimental design and can predict the pharmacokinetics and toxicity of drug candidates. This capability enables the prioritization and optimization of lead compounds, reducing the need for extensive and costly animal testing. Personalized medicine approaches can be facilitated through AI algorithms that analyze real-world patient data, leading to more effective treatment outcomes and improved patient adherence. This comprehensive review explores the wide-ranging applications of AI in drug discovery, drug delivery dosage form designs, process optimization, testing, and pharmacokinetics/pharmacodynamics (PK/PD) studies. This review provides an overview of various AI-based approaches utilized in pharmaceutical technology, highlighting their benefits and drawbacks. Nevertheless, the continued investment in and exploration of AI in the pharmaceutical industry offer exciting prospects for enhancing drug development processes and patient care.",
    "citationCount": 520,
    "pdf_filename": "2023_Artificial_Intelligence_in_Pharmaceutica_438ea4f6.pdf"
  },
  "af997821231898a5f8d0fd78dad4eec526acabe5": {
    "paperId": "af997821231898a5f8d0fd78dad4eec526acabe5",
    "title": "Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models",
    "year": 2023,
    "authors": "Chenfei Wu, Sheng-Kai Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang",
    "abstract": "ChatGPT is attracting a cross-field interest as it provides a language interface with remarkable conversational competency and reasoning capabilities across many domains. However, since ChatGPT is trained with languages, it is currently not capable of processing or generating images from the visual world. At the same time, Visual Foundation Models, such as Visual Transformers or Stable Diffusion, although showing great visual understanding and generation capabilities, they are only experts on specific tasks with one-round fixed inputs and outputs. To this end, We build a system called \\textbf{Visual ChatGPT}, incorporating different Visual Foundation Models, to enable the user to interact with ChatGPT by 1) sending and receiving not only languages but also images 2) providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps. 3) providing feedback and asking for corrected results. We design a series of prompts to inject the visual model information into ChatGPT, considering models of multiple inputs/outputs and models that require visual feedback. Experiments show that Visual ChatGPT opens the door to investigating the visual roles of ChatGPT with the help of Visual Foundation Models. Our system is publicly available at \\url{https://github.com/microsoft/visual-chatgpt}.",
    "citationCount": 747,
    "pdf_filename": "2023_Visual_ChatGPT__Talking__Drawing_and_Edi_af997821.pdf"
  },
  "3f5cedf340ae910cd7548472ae100895c1f49c2b": {
    "paperId": "3f5cedf340ae910cd7548472ae100895c1f49c2b",
    "title": "Discovering biomarkers associated and predicting cardiovascular disease with high accuracy using a novel nexus of machine learning techniques for precision medicine",
    "year": 2023,
    "authors": "William DeGroat, Habiba Abdelhalim, K. Patel, Dinesh Mendhe, Saman Zeeshan",
    "abstract": "Personalized interventions are deemed vital given the intricate characteristics, advancement, inherent genetic composition, and diversity of cardiovascular diseases (CVDs). The appropriate utilization of artificial intelligence (AI) and machine learning (ML) methodologies can yield novel understandings of CVDs, enabling improved personalized treatments through predictive analysis and deep phenotyping. In this study, we proposed and employed a novel approach combining traditional statistics and a nexus of cutting-edge AI/ML techniques to identify significant biomarkers for our predictive engine by analyzing the complete transcriptome of CVD patients. After robust gene expression data pre-processing, we utilized three statistical tests (Pearson correlation, Chi-square test, and ANOVA) to assess the differences in transcriptomic expression and clinical characteristics between healthy individuals and CVD patients. Next, the recursive feature elimination classifier assigned rankings to transcriptomic features based on their relation to the case–control variable. The top ten percent of commonly observed significant biomarkers were evaluated using four unique ML classifiers (Random Forest, Support Vector Machine, Xtreme Gradient Boosting Decision Trees, and k-Nearest Neighbors). After optimizing hyperparameters, the ensembled models, which were implemented using a soft voting classifier, accurately differentiated between patients and healthy individuals. We have uncovered 18 transcriptomic biomarkers that are highly significant in the CVD population that were used to predict disease with up to 96% accuracy. Additionally, we cross-validated our results with clinical records collected from patients in our cohort. The identified biomarkers served as potential indicators for early detection of CVDs. With its successful implementation, our newly developed predictive engine provides a valuable framework for identifying patients with CVDs based on their biomarker profiles.",
    "citationCount": 514,
    "pdf_filename": "2023_Discovering_biomarkers_associated_and_pr_3f5cedf3.pdf"
  },
  "6651ff3d8c89a3cddfeef0c5d03ac4cb121758e3": {
    "paperId": "6651ff3d8c89a3cddfeef0c5d03ac4cb121758e3",
    "title": "Fast Sampling of Diffusion Models with Exponential Integrator",
    "year": 2022,
    "authors": "Qinsheng Zhang, Yongxin Chen",
    "abstract": "The past few years have witnessed the great success of Diffusion models~(DMs) in generating high-fidelity samples in generative modeling tasks. A major limitation of the DM is its notoriously slow sampling procedure which normally requires hundreds to thousands of time discretization steps of the learned diffusion process to reach the desired accuracy. Our goal is to develop a fast sampling method for DMs with a much less number of steps while retaining high sample quality. To this end, we systematically analyze the sampling procedure in DMs and identify key factors that affect the sample quality, among which the method of discretization is most crucial. By carefully examining the learned diffusion process, we propose Diffusion Exponential Integrator Sampler~(DEIS). It is based on the Exponential Integrator designed for discretizing ordinary differential equations (ODEs) and leverages a semilinear structure of the learned diffusion process to reduce the discretization error. The proposed method can be applied to any DMs and can generate high-fidelity samples in as few as 10 steps. In our experiments, it takes about 3 minutes on one A6000 GPU to generate $50k$ images from CIFAR10. Moreover, by directly using pre-trained DMs, we achieve the state-of-art sampling performance when the number of score function evaluation~(NFE) is limited, e.g., 4.17 FID with 10 NFEs, 3.37 FID, and 9.74 IS with only 15 NFEs on CIFAR10. Code is available at https://github.com/qsh-zh/deis",
    "citationCount": 516,
    "pdf_filename": "2022_Fast_Sampling_of_Diffusion_Models_with_E_6651ff3d.pdf"
  },
  "c879b25308026d6538e52b27bcf4fd3cb60855f3": {
    "paperId": "c879b25308026d6538e52b27bcf4fd3cb60855f3",
    "title": "A Minimalist Approach to Offline Reinforcement Learning",
    "year": 2021,
    "authors": "Scott Fujimoto, S. Gu",
    "abstract": "Offline reinforcement learning (RL) defines the task of learning from a fixed batch of data. Due to errors in value estimation from out-of-distribution actions, most offline RL algorithms take the approach of constraining or regularizing the policy with the actions contained in the dataset. Built on pre-existing RL algorithms, modifications to make an RL algorithm work offline comes at the cost of additional complexity. Offline RL algorithms introduce new hyperparameters and often leverage secondary components such as generative models, while adjusting the underlying RL algorithm. In this paper we aim to make a deep RL algorithm work while making minimal changes. We find that we can match the performance of state-of-the-art offline RL algorithms by simply adding a behavior cloning term to the policy update of an online RL algorithm and normalizing the data. The resulting algorithm is a simple to implement and tune baseline, while more than halving the overall run time by removing the additional computational overhead of previous methods.",
    "citationCount": 963,
    "pdf_filename": "2021_A_Minimalist_Approach_to_Offline_Reinfor_c879b253.pdf"
  },
  "78d80c343d36baaf89f18e12d325cf6309fb6c8f": {
    "paperId": "78d80c343d36baaf89f18e12d325cf6309fb6c8f",
    "title": "CutPaste: Self-Supervised Learning for Anomaly Detection and Localization",
    "year": 2021,
    "authors": "Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, Tomas Pfister",
    "abstract": "We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
    "citationCount": 987,
    "pdf_filename": "2021_CutPaste__Self_Supervised_Learning_for_A_78d80c34.pdf"
  },
  "e8441a9d8c22f333b4092d3a95d3fbb64a36d428": {
    "paperId": "e8441a9d8c22f333b4092d3a95d3fbb64a36d428",
    "title": "Legal and Ethical Consideration in Artificial Intelligence in Healthcare: Who Takes Responsibility?",
    "year": 2022,
    "authors": "Nithesh Naik, B. Hameed, Dasharathraj K. Shetty, Dishant Swain, M. Shah",
    "abstract": "The legal and ethical issues that confront society due to Artificial Intelligence (AI) include privacy and surveillance, bias or discrimination, and potentially the philosophical challenge is the role of human judgment. Concerns about newer digital technologies becoming a new source of inaccuracy and data breaches have arisen as a result of its use. Mistakes in the procedure or protocol in the field of healthcare can have devastating consequences for the patient who is the victim of the error. Because patients come into contact with physicians at moments in their lives when they are most vulnerable, it is crucial to remember this. Currently, there are no well-defined regulations in place to address the legal and ethical issues that may arise due to the use of artificial intelligence in healthcare settings. This review attempts to address these pertinent issues highlighting the need for algorithmic transparency, privacy, and protection of all the beneficiaries involved and cybersecurity of associated vulnerabilities.",
    "citationCount": 581,
    "pdf_filename": "2022_Legal_and_Ethical_Consideration_in_Artif_e8441a9d.pdf"
  },
  "28ab6b4b1c80bc16fe1afd654f938349dca601f8": {
    "paperId": "28ab6b4b1c80bc16fe1afd654f938349dca601f8",
    "title": "Digital Twins: A Survey on Enabling Technologies, Challenges, Trends and Future Prospects",
    "year": 2022,
    "authors": "Stefan Mihai, Mahnoor Yaqoob, D. V. Hung, W. Davis, Praveer Towakel",
    "abstract": "Digital Twin (DT) is an emerging technology surrounded by many promises, and potentials to reshape the future of industries and society overall. A DT is a system-of-systems which goes far beyond the traditional computer-based simulations and analysis. It is a replication of all the elements, processes, dynamics, and firmware of a physical system into a digital counterpart. The two systems (physical and digital) exist side by side, sharing all the inputs and operations using real-time data communications and information transfer. With the incorporation of Internet of Things (IoT), Artificial Intelligence (AI), 3D models, next generation mobile communications (5G/6G), Augmented Reality (AR), Virtual Reality (VR), distributed computing, Transfer Learning (TL), and electronic sensors, the digital/virtual counterpart of the real-world system is able to provide seamless monitoring, analysis, evaluation and predictions. The DT offers a platform for the testing and analysing of complex systems, which would be impossible in traditional simulations and modular evaluations. However, the development of this technology faces many challenges including the complexities in effective communication and data accumulation, data unavailability to train Machine Learning (ML) models, lack of processing power to support high fidelity twins, the high need for interdisciplinary collaboration, and the absence of standardized development methodologies and validation measures. Being in the early stages of development, DTs lack sufficient documentation. In this context, this survey paper aims to cover the important aspects in realization of the technology. The key enabling technologies, challenges and prospects of DTs are highlighted. The paper provides a deep insight into the technology, lists design goals and objectives, highlights design challenges and limitations across industries, discusses research and commercial developments, provides its applications and use cases, offers case studies in industry, infrastructure and healthcare, lists main service providers and stakeholders, and covers developments to date, as well as viable research dimensions for future developments in DTs.",
    "citationCount": 568,
    "pdf_filename": "2022_Digital_Twins__A_Survey_on_Enabling_Tech_28ab6b4b.pdf"
  },
  "47a67e76ed84260ff19f7a948d764005d1edf1c9": {
    "paperId": "47a67e76ed84260ff19f7a948d764005d1edf1c9",
    "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge",
    "year": 2022,
    "authors": "Dustin Schwenk, Apoorv Khandelwal, Christopher Clark, Kenneth Marino, Roozbeh Mottaghi",
    "abstract": "The Visual Question Answering (VQA) task aspires to provide a meaningful testbed for the development of AI models that can jointly reason over visual and natural language inputs. Despite a proliferation of VQA datasets, this goal is hindered by a set of common limitations. These include a reliance on relatively simplistic questions that are repetitive in both concepts and linguistic structure, little world knowledge needed outside of the paired image, and limited reasoning required to arrive at the correct answer. We introduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about 25K questions requiring a broad base of commonsense and world knowledge to answer. In contrast to the existing knowledge-based VQA datasets, the questions generally cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning about the scene depicted in the image. We demonstrate the potential of this new dataset through a detailed analysis of its contents and baseline performance measurements over a variety of state-of-the-art vision-language models. Project page: http://a-okvqa.allenai.org/",
    "citationCount": 729,
    "pdf_filename": "2022_A_OKVQA__A_Benchmark_for_Visual_Question_47a67e76.pdf"
  },
  "a122863d239643453195424c04067e89406246e1": {
    "paperId": "a122863d239643453195424c04067e89406246e1",
    "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations",
    "year": 2023,
    "authors": "Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng",
    "abstract": "Fine-tuning on instruction data has been widely validated as an effective practice for implementing chat language models like ChatGPT. Scaling the diversity and quality of such data, although straightforward, stands a great chance of leading to improved performance. This paper aims to improve the upper bound of open-source models further. We first provide a systematically designed, diverse, informative, large-scale dataset of instructional conversations, UltraChat, which does not involve human queries. Our objective is to capture the breadth of interactions that a human might have with an AI assistant and employs a comprehensive framework to generate multi-turn conversation iteratively. UltraChat contains 1.5 million high-quality multi-turn dialogues and covers a wide range of topics and instructions. Our statistical analysis of UltraChat reveals its superiority in various key metrics, including scale, average length, diversity, coherence, etc., solidifying its position as a leading open-source dataset. Building upon UltraChat, we fine-tune a LLaMA model to create a powerful conversational model, UltraLLaMA. Our evaluations indicate that UltraLLaMA consistently outperforms other open-source models, including Vicuna, the previously recognized state-of-the-art open-source model. The dataset and the model will be publicly released\\footnote{\\url{https://github.com/thunlp/UltraChat}}.",
    "citationCount": 721,
    "pdf_filename": "2023_Enhancing_Chat_Language_Models_by_Scalin_a122863d.pdf"
  },
  "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa": {
    "paperId": "1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa",
    "title": "CogView: Mastering Text-to-Image Generation via Transformers",
    "year": 2021,
    "authors": "Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou",
    "abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E.",
    "citationCount": 905,
    "pdf_filename": "2021_CogView__Mastering_Text_to_Image_Generat_1197ae4a.pdf"
  },
  "f4dc1886a9ba1def1e9fa230572d21cc85934f7d": {
    "paperId": "f4dc1886a9ba1def1e9fa230572d21cc85934f7d",
    "title": "A foundation model for generalizable disease detection from retinal images",
    "year": 2023,
    "authors": "Yukun Zhou, Mark A. Chia, S. K. Wagner, M. S. Ayhan, Dominic J. Williamson",
    "abstract": "RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled images, is trained on 1.6 million unlabelled images by self-supervised learning and then adapted to disease detection tasks with explicit labels. Medical artificial intelligence (AI) offers great potential for recognizing signs of health conditions in retinal images and expediting the diagnosis of eye diseases and systemic disorders^ 1 . However, the development of AI models requires substantial annotation and models are usually task-specific with limited generalizability to different clinical applications^ 2 . Here, we present RETFound, a foundation model for retinal images that learns generalizable representations from unlabelled retinal images and provides a basis for label-efficient model adaptation in several applications. Specifically, RETFound is trained on 1.6 million unlabelled retinal images by means of self-supervised learning and then adapted to disease detection tasks with explicit labels. We show that adapted RETFound consistently outperforms several comparison models in the diagnosis and prognosis of sight-threatening eye diseases, as well as incident prediction of complex systemic disorders such as heart failure and myocardial infarction with fewer labelled data. RETFound provides a generalizable solution to improve model performance and alleviate the annotation workload of experts to enable broad clinical AI applications from retinal imaging.",
    "citationCount": 594,
    "pdf_filename": "2023_A_foundation_model_for_generalizable_dis_f4dc1886.pdf"
  },
  "af1c871282ec122869d03f5420ef5d9143358a91": {
    "paperId": "af1c871282ec122869d03f5420ef5d9143358a91",
    "title": "Visual Programming: Compositional visual reasoning without training",
    "year": 2022,
    "authors": "Tanmay Gupta, Aniruddha Kembhavi",
    "abstract": "We present Visprog, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions. Visprog avoids the need for any task-specific training. Instead, it uses the incontext learning ability of large language models to generate python-like modular programs, which are then executed to get both the solution and a comprehensive and interpretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models, image processing subroutines, or python functions to produce intermediate outputs that may be consumed by subsequent parts of the program. We demonstrate the flexibility of VIsPROG on 4 diverse tasks - compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image editing. We believe neuro-symbolic approaches like Visprog are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform.",
    "citationCount": 544,
    "pdf_filename": "2022_Visual_Programming__Compositional_visual_af1c8712.pdf"
  },
  "3b378f4bf5de699906f5dcf8161e2e24e60aef5b": {
    "paperId": "3b378f4bf5de699906f5dcf8161e2e24e60aef5b",
    "title": "Version 3 of the Global Aridity Index and Potential Evapotranspiration Database",
    "year": 2022,
    "authors": "R. Zomer, Jian-chu Xu, A. Trabucco",
    "abstract": "The “Global Aridity Index and Potential Evapotranspiration Database - Version 3” (Global-AI_PET_v3) provides high-resolution (30 arc-seconds) global hydro-climatic data averaged (1970–2000) monthly and yearly, based upon the FAO Penman-Monteith Reference Evapotranspiration (ET0) equation. An overview of the methods used to implement the Penman-Monteith equation geospatially and a technical evaluation of the results is provided. Results were compared for technical validation with weather station data from the FAO “CLIMWAT 2.0 for CROPWAT” (ET0: r2 = 0.85; AI: r2 = 0.90) and the U.K. “Climate Research Unit: Time Series v 4.04” (ET0: r2 = 0.89; AI: r2 = 0.83), while showing significant differences to an earlier version of the database. The current version of the Global-AI_PET_v3 supersedes previous versions, showing a higher correlation to real world weather station data. Developed using the generally agreed upon standard methodology for estimation of reference ET0, this database and notably, the accompanying source code, provide a robust tool for a variety of scientific applications in an era of rapidly changing climatic conditions. Measurement(s) evapotranspiration Technology Type(s) Geographic Information System Sample Characteristic - Environment climate system Measurement(s) evapotranspiration Technology Type(s) Geographic Information System Sample Characteristic - Environment climate system",
    "citationCount": 646,
    "pdf_filename": "2022_Version_3_of_the_Global_Aridity_Index_an_3b378f4b.pdf"
  },
  "622428f5122ad12a40229e1768ecb929fd747ee7": {
    "paperId": "622428f5122ad12a40229e1768ecb929fd747ee7",
    "title": "Multimodal Learning With Transformers: A Survey",
    "year": 2022,
    "authors": "P. Xu, Xiatian Zhu, D. Clifton",
    "abstract": "Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal Big Data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.",
    "citationCount": 798,
    "pdf_filename": "2022_Multimodal_Learning_With_Transformers__A_622428f5.pdf"
  },
  "95a26eafabf06b1fc5dec6c460a927cf5964e97e": {
    "paperId": "95a26eafabf06b1fc5dec6c460a927cf5964e97e",
    "title": "DRÆM – A discriminatively trained reconstruction embedding for surface anomaly detection",
    "year": 2021,
    "authors": "Vitjan Zavrtanik, M. Kristan, D. Skočaj",
    "abstract": "Visual surface anomaly detection aims to detect local image regions that significantly deviate from normal appearance. Recent surface anomaly detection methods rely on generative models to accurately reconstruct the normal areas and to fail on anomalies. These methods are trained only on anomaly-free images, and often require hand-crafted post-processing steps to localize the anomalies, which prohibits optimizing the feature extraction for maximal detection capability. In addition to reconstructive approach, we cast surface anomaly detection primarily as a discriminative problem and propose a discriminatively trained reconstruction anomaly embedding model (DRÆM). The proposed method learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and anomalous examples. The method enables direct anomaly localization without the need for additional complicated post-processing of the network output and can be trained using simple and general anomaly simulations. On the challenging MVTec anomaly detection dataset, DRÆM outperforms the current state-of-the-art unsupervised methods by a large margin and even de-livers detection performance close to the fully-supervised methods on the widely used DAGM surface-defect detection dataset, while substantially outperforming them in localization accuracy. Code at github.com/VitjanZ/DRAEM.",
    "citationCount": 848,
    "pdf_filename": "2021_DRÆM___A_discriminatively_trained_recons_95a26eaf.pdf"
  },
  "332dc8b2ca9d49fad607c7282f3360bb2a9aacf3": {
    "paperId": "332dc8b2ca9d49fad607c7282f3360bb2a9aacf3",
    "title": "A large language model for electronic health records",
    "year": 2022,
    "authors": "Xi Yang, Aokun Chen, Nima M. Pournejatian, Hoo-Chang Shin, Kaleb E. Smith",
    "abstract": "There is an increasing interest in developing artificial intelligence (AI) systems to process and interpret electronic health records (EHRs). Natural language processing (NLP) powered by pretrained language models is the key technology for medical AI systems utilizing clinical narratives. However, there are few clinical language models, the largest of which trained in the clinical domain is comparatively small at 110 million parameters (compared with billions of parameters in the general domain). It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured EHRs. In this study, we develop from scratch a large clinical language model—GatorTron—using >90 billion words of text (including >82 billion words of de-identified clinical text) and systematically evaluate it on five clinical NLP tasks including clinical concept extraction, medical relation extraction, semantic textual similarity, natural language inference (NLI), and medical question answering (MQA). We examine how (1) scaling up the number of parameters and (2) scaling up the size of the training data could benefit these NLP tasks. GatorTron models scale up the clinical language model from 110 million to 8.9 billion parameters and improve five clinical NLP tasks (e.g., 9.6% and 9.5% improvement in accuracy for NLI and MQA), which can be applied to medical AI systems to improve healthcare delivery. The GatorTron models are publicly available at: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og .",
    "citationCount": 675,
    "pdf_filename": "2022_A_large_language_model_for_electronic_he_332dc8b2.pdf"
  },
  "1b7e528ace42b4dc407789550a6a3e78aa9c5586": {
    "paperId": "1b7e528ace42b4dc407789550a6a3e78aa9c5586",
    "title": "Introduction to Stochastic Processes",
    "year": 2022,
    "authors": "Hoel., Stone",
    "abstract": "We use the notation A ∈ F to indicate that the set A is in F . Remark that since A∩B = (A ∪B) and more generally ⋂ Ai = ( ⋃ Ai) c (Exercise: Prove this equality) axiom ii) holds with union replaced by intersection. Also we have A−B = A ∩B so if A, B ∈ F then A−B ∈ F . Basically you should think of a σ-algebra as a system of subsets in which you can perform any of the usual set-theoretic operations (union, intersection, difference) on countably many sets. We get an obvious example by taking F to be the system of all subsets of Ω, P(Ω). At the other extreme the system consisting only of Ω itself and ∅ is a σ-algebra. Given any system of subsets S of Ω we can consider the smallest σ-algebra containing S. This is the intersection of all the σ-algebras containing S. Since the set of all subsets of Ω is a σ-algebra containing S, there is at least one σ-algebra containing S. The smallest σ-algebra containing S is called the σ-algebra generated by S.",
    "citationCount": 538,
    "pdf_filename": "2022_Introduction_to_Stochastic_Processes_1b7e528a.pdf"
  },
  "cda3fbbac6734b603bee363b0938e9baa924aa78": {
    "paperId": "cda3fbbac6734b603bee363b0938e9baa924aa78",
    "title": "ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models",
    "year": 2021,
    "authors": "Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, Sungroh Yoon",
    "abstract": "Denoising diffusion probabilistic models (DDPM) have shown remarkable performance in unconditional image generation. However, due to the stochasticity of the generative process in DDPM, it is challenging to generate images with the desired semantics. In this work, we propose Iterative Latent Variable Refinement (ILVR), a method to guide the generative process in DDPM to generate high-quality images based on a given reference image. Here, the refinement of the generative process in DDPM enables a single DDPM to sample images from various sets directed by the reference image. The proposed ILVR method generates high-quality images while controlling the generation. The controllability of our method allows adaptation of a single DDPM without any additional learning in various image generation tasks, such as generation from various downsampling factors, multi-domain image translation, paint-to-image, and editing with scribbles.",
    "citationCount": 840,
    "pdf_filename": "2021_ILVR__Conditioning_Method_for_Denoising__cda3fbba.pdf"
  },
  "80743a9fbea0767761d59fae1d209b7fc7ef3f28": {
    "paperId": "80743a9fbea0767761d59fae1d209b7fc7ef3f28",
    "title": "The Promises and Challenges of Artificial Intelligence for Teachers: a Systematic Review of Research",
    "year": 2022,
    "authors": "I. Celik, M. Dindar, H. Muukkonen, Sanna Järvelä",
    "abstract": "This study provides an overview of research on teachers’ use of artificial intelligence (AI) applications and machine learning methods to analyze teachers’ data. Our analysis showed that AI offers teachers several opportunities for improved planning (e.g., by defining students’ needs and familiarizing teachers with such needs), implementation (e.g., through immediate feedback and teacher intervention), and assessment (e.g., through automated essay scoring) of their teaching. We also found that teachers have various roles in the development of AI technology. These roles include acting as models for training AI algorithms and participating in AI development by checking the accuracy of AI automated assessment systems. Our findings further underlined several challenges in AI implementation in teaching practice, which provide guidelines for developing the field.",
    "citationCount": 539,
    "pdf_filename": "2022_The_Promises_and_Challenges_of_Artificia_80743a9f.pdf"
  },
  "4d44de6653f6192efba8aef36f814d4c0420f21d": {
    "paperId": "4d44de6653f6192efba8aef36f814d4c0420f21d",
    "title": "Action-Conditioned 3D Human Motion Synthesis with Transformer VAE",
    "year": 2021,
    "authors": "Mathis Petrovich, Michael J. Black, Gul Varol",
    "abstract": "We tackle the problem of action-conditioned generation of realistic and diverse human motion sequences. In contrast to methods that complete, or extend, motion sequences, this task does not require an initial pose or sequence. Here we learn an action-aware latent representation for human motions by training a generative variational autoencoder (VAE). By sampling from this latent space and querying a certain duration through a series of positional encodings, we synthesize variable-length motion sequences conditioned on a categorical action. Specifically, we design a Transformer-based architecture, ACTOR, for encoding and decoding a sequence of parametric SMPL human body models estimated from action recognition datasets. We evaluate our approach on the NTU RGB+D, HumanAct12 and UESTC datasets and show improvements over the state of the art. Furthermore, we present two use cases: improving action recognition through adding our synthesized data to training, and motion denoising. Code and models are available on our project page [53].",
    "citationCount": 604,
    "pdf_filename": "2021_Action_Conditioned_3D_Human_Motion_Synth_4d44de66.pdf"
  },
  "cb596bffc5c5042c254058b62317a57fa156fea4": {
    "paperId": "cb596bffc5c5042c254058b62317a57fa156fea4",
    "title": "Unifying Vision-and-Language Tasks via Text Generation",
    "year": 2021,
    "authors": "Jaemin Cho, Jie Lei, Hao Tan, Mohit Bansal",
    "abstract": "Existing methods for vision-and-language learning typically require designing task-specific architectures and objectives for each task. For example, a multi-label answer classifier for visual question answering, a region scorer for referring expression comprehension, and a language decoder for image captioning, etc. To alleviate these hassles, in this work, we propose a unified framework that learns different tasks in a single architecture with the same language modeling objective, i.e., multimodal conditional text generation, where our models learn to generate labels in text based on the visual and textual inputs. On 7 popular vision-and-language benchmarks, including visual question answering, referring expression comprehension, visual commonsense reasoning, most of which have been previously modeled as discriminative tasks, our generative approach (with a single unified architecture) reaches comparable performance to recent task-specific state-of-the-art vision-and-language models. Moreover, our generative approach shows better generalization ability on questions that have rare answers. Also, we show that our framework allows multi-task learning in a single architecture with a single set of parameters, achieving similar performance to separately optimized single-task models. Our code is publicly available at: https://github.com/j-min/VL-T5",
    "citationCount": 602,
    "pdf_filename": "2021_Unifying_Vision_and_Language_Tasks_via_T_cb596bff.pdf"
  },
  "3fdda879abf2462b09139fb1fd1c2c147c9a0ef0": {
    "paperId": "3fdda879abf2462b09139fb1fd1c2c147c9a0ef0",
    "title": "StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis",
    "year": 2021,
    "authors": "Jiatao Gu, Lingjie Liu, Peng Wang, C. Theobalt",
    "abstract": "We propose StyleNeRF, a 3D-aware generative model for photo-realistic high-resolution image synthesis with high multi-view consistency, which can be trained on unstructured 2D images. Existing approaches either cannot synthesize high-resolution images with fine details or yield noticeable 3D-inconsistent artifacts. In addition, many of them lack control over style attributes and explicit 3D camera poses. StyleNeRF integrates the neural radiance field (NeRF) into a style-based generator to tackle the aforementioned challenges, i.e., improving rendering efficiency and 3D consistency for high-resolution image generation. We perform volume rendering only to produce a low-resolution feature map and progressively apply upsampling in 2D to address the first issue. To mitigate the inconsistencies caused by 2D upsampling, we propose multiple designs, including a better upsampler and a new regularization loss. With these designs, StyleNeRF can synthesize high-resolution images at interactive rates while preserving 3D consistency at high quality. StyleNeRF also enables control of camera poses and different levels of styles, which can generalize to unseen views. It also supports challenging tasks, including zoom-in and-out, style mixing, inversion, and semantic editing.",
    "citationCount": 599,
    "pdf_filename": "2021_StyleNeRF__A_Style_based_3D_Aware_Genera_3fdda879.pdf"
  },
  "8762a085024dbc3de27999b5a75b8b9f82cafca0": {
    "paperId": "8762a085024dbc3de27999b5a75b8b9f82cafca0",
    "title": "3D Shape Generation and Completion through Point-Voxel Diffusion",
    "year": 2021,
    "authors": "Linqi Zhou, Yilun Du, Jiajun Wu",
    "abstract": "We propose a novel approach for probabilistic generative modeling of 3D shapes. Unlike most existing models that learn to deterministically translate a latent vector to a shape, our model, Point-Voxel Diffusion (PVD), is a unified, probabilistic formulation for unconditional shape generation and conditional, multi-modal shape completion. PVD marries denoising diffusion models with the hybrid, point-voxel representation of 3D shapes. It can be viewed as a series of denoising steps, reversing the diffusion process from observed point cloud data to Gaussian noise, and is trained by optimizing a variational lower bound to the (conditional) likelihood function. Experiments demonstrate that PVD is capable of synthesizing high-fidelity shapes, completing partial point clouds, and generating multiple completion results from single-view depth scans of real objects.",
    "citationCount": 623,
    "pdf_filename": "2021_3D_Shape_Generation_and_Completion_throu_8762a085.pdf"
  },
  "ec13995de8797a4e977024942d79fc0d27e20b7b": {
    "paperId": "ec13995de8797a4e977024942d79fc0d27e20b7b",
    "title": "Ethical principles for artificial intelligence in education",
    "year": 2022,
    "authors": "Andy Nguyen, H. Ngo, Yvonne Hong, Belle Dang, Bich-Phuong Thi Nguyen",
    "abstract": "The advancement of artificial intelligence in education (AIED) has the potential to transform the educational landscape and influence the role of all involved stakeholders. In recent years, the applications of AIED have been gradually adopted to progress our understanding of students’ learning and enhance learning performance and experience. However, the adoption of AIED has led to increasing ethical risks and concerns regarding several aspects such as personal data and learner autonomy. Despite the recent announcement of guidelines for ethical and trustworthy AIED, the debate revolves around the key principles underpinning ethical AIED. This paper aims to explore whether there is a global consensus on ethical AIED by mapping and analyzing international organizations’ current policies and guidelines. In this paper, we first introduce the opportunities offered by AI in education and potential ethical issues. Then, thematic analysis was conducted to conceptualize and establish a set of ethical principles by examining and synthesizing relevant ethical policies and guidelines for AIED. We discuss each principle and associated implications for relevant educational stakeholders, including students, teachers, technology developers, policymakers, and institutional decision-makers. The proposed set of ethical principles is expected to serve as a framework to inform and guide educational stakeholders in the development and deployment of ethical and trustworthy AIED as well as catalyze future development of related impact studies in the field.",
    "citationCount": 595,
    "pdf_filename": "2022_Ethical_principles_for_artificial_intell_ec13995d.pdf"
  },
  "e27b881192cd14a04018c372352b12e531870fc1": {
    "paperId": "e27b881192cd14a04018c372352b12e531870fc1",
    "title": "Pivotal Tuning for Latent-based Editing of Real Images",
    "year": 2021,
    "authors": "Daniel Roich, Ron Mokady, Amit H. Bermano, D. Cohen-Or",
    "abstract": "Recently, numerous facial editing techniques have been proposed that leverage the generative power of a pretrained StyleGAN. To successfully edit an image this way, one must first project (or invert) the image into the pretrained generator’s domain. As it turns out, StyleGAN’s latent space induces an inherent tradeoff between distortion and editability, i.e., between maintaining the original appearance and convincingly altering its attributes. Hence, it remains challenging to apply ID-preserving edits to real facial images. In this article, we present an approach to bridge this gap. The idea is Pivotal Tuning—a brief training process that preserves editing quality, while surgically changing the portrayed identity and appearance. In Pivotal Tuning Inversion, an initial inverted latent code serves as a pivot, around which the generator is fine-tuned. At the same time, a regularization term keeps nearby identities intact, to locally contain the effect. We further show that Pivotal Tuning also applies to accommodating for a multitude of faces, while introducing negligible distortion on the rest of the domain. We validate our technique through inversion and editing metrics and show preferable scores to state-of-the-art methods. Last, we present successful editing for harder cases, including elaborate make-up or headwear.",
    "citationCount": 586,
    "pdf_filename": "2021_Pivotal_Tuning_for_Latent_based_Editing__e27b8811.pdf"
  },
  "2d9ae4c167510ed78803735fc57ea67c3cc55a35": {
    "paperId": "2d9ae4c167510ed78803735fc57ea67c3cc55a35",
    "title": "VideoGPT: Video Generation using VQ-VAE and Transformers",
    "year": 2021,
    "authors": "Wilson Yan, Yunzhi Zhang, P. Abbeel, A. Srinivas",
    "abstract": "We present VideoGPT: a conceptually simple architecture for scaling likelihood based generative modeling to natural videos. VideoGPT uses VQ-VAE that learns downsampled discrete latent representations of a raw video by employing 3D convolutions and axial self-attention. A simple GPT-like architecture is then used to autoregressively model the discrete latents using spatio-temporal position encodings. Despite the simplicity in formulation and ease of training, our architecture is able to generate samples competitive with state-of-the-art GAN models for video generation on the BAIR Robot dataset, and generate high fidelity natural videos from UCF-101 and Tumbler GIF Dataset (TGIF). We hope our proposed architecture serves as a reproducible reference for a minimalistic implementation of transformer based video generation models. Samples and code are available at https://wilson1yan.github.io/videogpt/index.html",
    "citationCount": 622,
    "pdf_filename": "2021_VideoGPT__Video_Generation_using_VQ_VAE__2d9ae4c1.pdf"
  },
  "42f2271cebb7f272b0066c1f22d33381f139ee68": {
    "paperId": "42f2271cebb7f272b0066c1f22d33381f139ee68",
    "title": "Label-Efficient Semantic Segmentation with Diffusion Models",
    "year": 2021,
    "authors": "Dmitry Baranchuk, Ivan Rubachev, A. Voynov, Valentin Khrulkov, Artem Babenko",
    "abstract": "Denoising diffusion probabilistic models have recently received much research attention since they outperform alternative approaches, such as GANs, and currently provide state-of-the-art generative performance. The superior performance of diffusion models has made them an appealing tool in several applications, including inpainting, super-resolution, and semantic editing. In this paper, we demonstrate that diffusion models can also serve as an instrument for semantic segmentation, especially in the setup when labeled data is scarce. In particular, for several pretrained diffusion models, we investigate the intermediate activations from the networks that perform the Markov step of the reverse diffusion process. We show that these activations effectively capture the semantic information from an input image and appear to be excellent pixel-level representations for the segmentation problem. Based on these observations, we describe a simple segmentation method, which can work even if only a few training images are provided. Our approach significantly outperforms the existing alternatives on several datasets for the same amount of human supervision.",
    "citationCount": 645,
    "pdf_filename": "2021_Label_Efficient_Semantic_Segmentation_wi_42f2271c.pdf"
  },
  "9c7a2cd13b783bb73ad2d1ec2880bdd9b995cbdc": {
    "paperId": "9c7a2cd13b783bb73ad2d1ec2880bdd9b995cbdc",
    "title": "Vector-quantized Image Modeling with Improved VQGAN",
    "year": 2021,
    "authors": "Jiahui Yu, Xin Li, Jing Yu Koh, Han Zhang, Ruoming Pang",
    "abstract": "Pretraining language models with next-token prediction on massive text corpora has delivered phenomenal zero-shot, few-shot, transfer learning and multi-tasking capabilities on both generative and discriminative language tasks. Motivated by this success, we explore a Vector-quantized Image Modeling (VIM) approach that involves pretraining a Transformer to predict rasterized image tokens autoregressively. The discrete image tokens are encoded from a learned Vision-Transformer-based VQGAN (ViT-VQGAN). We first propose multiple improvements over vanilla VQGAN from architecture to codebook learning, yielding better efficiency and reconstruction fidelity. The improved ViT-VQGAN further improves vector-quantized image modeling tasks, including unconditional, class-conditioned image generation and unsupervised representation learning. When trained on ImageNet at \\(256\\times256\\) resolution, we achieve Inception Score (IS) of 175.1 and Fr'echet Inception Distance (FID) of 4.17, a dramatic improvement over the vanilla VQGAN, which obtains 70.6 and 17.04 for IS and FID, respectively. Based on ViT-VQGAN and unsupervised pretraining, we further evaluate the pretrained Transformer by averaging intermediate features, similar to Image GPT (iGPT). This ImageNet-pretrained VIM-L significantly beats iGPT-L on linear-probe accuracy from 60.3% to 73.2% for a similar model size. VIM-L also outperforms iGPT-XL which is trained with extra web image data and larger model size.",
    "citationCount": 660,
    "pdf_filename": "2021_Vector_quantized_Image_Modeling_with_Imp_9c7a2cd1.pdf"
  },
  "62cadbc4fcc73204a72847300cb2214f4401efad": {
    "paperId": "62cadbc4fcc73204a72847300cb2214f4401efad",
    "title": "Human-in-the-loop machine learning: a state of the art",
    "year": 2022,
    "authors": "E. Mosqueira-Rey, Elena Hernández-Pereira, David Alonso-Ríos, José Bobes-Bascarán, Á. Fernández-Leal",
    "abstract": "Researchers are defining new types of interactions between humans and machine learning algorithms generically called human-in-the-loop machine learning. Depending on who is in control of the learning process, we can identify: active learning, in which the system remains in control; interactive machine learning, in which there is a closer interaction between users and learning systems; and machine teaching, where human domain experts have control over the learning process. Aside from control, humans can also be involved in the learning process in other ways. In curriculum learning human domain experts try to impose some structure on the examples presented to improve the learning; in explainable AI the focus is on the ability of the model to explain to humans why a given solution was chosen. This collaboration between AI models and humans should not be limited only to the learning process; if we go further, we can see other terms that arise such as Usable and Useful AI. In this paper we review the state of the art of the techniques involved in the new forms of relationship between humans and ML algorithms. Our contribution is not merely listing the different approaches, but to provide definitions clarifying confusing, varied and sometimes contradictory terms; to elucidate and determine the boundaries between the different methods; and to correlate all the techniques searching for the connections and influences between them.",
    "citationCount": 571,
    "pdf_filename": "2022_Human_in_the_loop_machine_learning__a_st_62cadbc4.pdf"
  },
  "30b99ae0682d42a2010be401dd1d8f7baca9bb5f": {
    "paperId": "30b99ae0682d42a2010be401dd1d8f7baca9bb5f",
    "title": "A Unifying Review of Deep and Shallow Anomaly Detection",
    "year": 2020,
    "authors": "Lukas Ruff, Jacob R. Kauffmann, Robert A. Vandermeulen, G. Montavon, W. Samek",
    "abstract": "Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic “shallow” and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.",
    "citationCount": 919,
    "pdf_filename": "2020_A_Unifying_Review_of_Deep_and_Shallow_An_30b99ae0.pdf"
  },
  "9b90291103892b9f9665c11461d7bc9ea40ea9ec": {
    "paperId": "9b90291103892b9f9665c11461d7bc9ea40ea9ec",
    "title": "MONAI: An open-source framework for deep learning in healthcare",
    "year": 2022,
    "authors": "M. Cardoso, Wenqi Li, Richard Brown, Nic Ma, E. Kerfoot",
    "abstract": "Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.",
    "citationCount": 705,
    "pdf_filename": "2022_MONAI__An_open_source_framework_for_deep_9b902911.pdf"
  },
  "8e970913466a81207230a09f6516bab944563cc0": {
    "paperId": "8e970913466a81207230a09f6516bab944563cc0",
    "title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
    "year": 2021,
    "authors": "Tianchang Shen, Jun Gao, K. Yin, Ming-Yu Liu, S. Fidler",
    "abstract": "We introduce DMTet, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, DMTet directly optimizes for the reconstructed surface, which enables us to synthesize finer geometric details with fewer artifacts. Unlike deep 3D generative models that directly generate explicit representations such as meshes, our model can synthesize shapes with arbitrary topology. The core of DMTet includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh. Our approach significantly outperforms existing work on conditional shape synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal shapes. Project page: https://nv-tlabs.github.io/DMTet/.",
    "citationCount": 558,
    "pdf_filename": "2021_Deep_Marching_Tetrahedra__a_Hybrid_Repre_8e970913.pdf"
  },
  "ac40415570e7d51efb237c5e4b4dbe4e93919409": {
    "paperId": "ac40415570e7d51efb237c5e4b4dbe4e93919409",
    "title": "Membership Inference Attacks on Machine Learning: A Survey",
    "year": 2021,
    "authors": "Hongsheng Hu, Z. Salcic, Lichao Sun, G. Dobbie, P. Yu",
    "abstract": "Machine learning (ML) models have been widely applied to various applications, including image classification, text generation, audio recognition, and graph data analysis. However, recent studies have shown that ML models are vulnerable to membership inference attacks (MIAs), which aim to infer whether a data record was used to train a target model or not. MIAs on ML models can directly lead to a privacy breach. For example, via identifying the fact that a clinical record that has been used to train a model associated with a certain disease, an attacker can infer that the owner of the clinical record has the disease with a high chance. In recent years, MIAs have been shown to be effective on various ML models, e.g., classification models and generative models. Meanwhile, many defense methods have been proposed to mitigate MIAs. Although MIAs on ML models form a newly emerging and rapidly growing research area, there has been no systematic survey on this topic yet. In this article, we conduct the first comprehensive survey on membership inference attacks and defenses. We provide the taxonomies for both attacks and defenses, based on their characterizations, and discuss their pros and cons. Based on the limitations and gaps identified in this survey, we point out several promising future research directions to inspire the researchers who wish to follow this area. This survey not only serves as a reference for the research community but also provides a clear description for researchers outside this research domain. To further help the researchers, we have created an online resource repository, which we will keep updated with future relevant work. Interested readers can find the repository at https://github.com/HongshengHu/membership-inference-machine-learning-literature.",
    "citationCount": 561,
    "pdf_filename": "2021_Membership_Inference_Attacks_on_Machine__ac404155.pdf"
  },
  "5877e373c41e64701a20ecf308965d9ec0978bb1": {
    "paperId": "5877e373c41e64701a20ecf308965d9ec0978bb1",
    "title": "A Survey on Deep Semi-Supervised Learning",
    "year": 2021,
    "authors": "Xiangli Yang, Zixing Song, Irwin King, Zenglin Xu",
    "abstract": "Deep semi-supervised learning is a fast-growing field with a range of practical applications. This paper provides a comprehensive survey on both fundamentals and recent advances in deep semi-supervised learning methods from perspectives of model design and unsupervised loss functions. We first present a taxonomy for deep semi-supervised learning that categorizes existing methods, including deep generative methods, consistency regularization methods, graph-based methods, pseudo-labeling methods, and hybrid methods. Then we provide a comprehensive review of 60 representative methods and offer a detailed comparison of these methods in terms of the type of losses, architecture differences, and test performance results. In addition to the progress in the past few years, we further discuss some shortcomings of existing methods and provide some tentative heuristic solutions for solving these open problems.",
    "citationCount": 729,
    "pdf_filename": "2021_A_Survey_on_Deep_Semi_Supervised_Learnin_5877e373.pdf"
  },
  "ea72fb2a0d340f9d14fbcf300cd5f5fbbe1050bb": {
    "paperId": "ea72fb2a0d340f9d14fbcf300cd5f5fbbe1050bb",
    "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
    "year": 2023,
    "authors": "K. Singhal, Tao Tu, Juraj Gottweis, R. Sayres, Ellery Wulczyn",
    "abstract": "Recent artificial intelligence (AI) systems have reached milestones in\"grand challenges\"ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a\"passing\"score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM by over 19% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p<0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p<0.001) on newly introduced datasets of 240 long-form\"adversarial\"questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.",
    "citationCount": 663,
    "pdf_filename": "2023_Towards_Expert_Level_Medical_Question_An_ea72fb2a.pdf"
  },
  "7c1933359a6860fe49d15c6353a241763879e81f": {
    "paperId": "7c1933359a6860fe49d15c6353a241763879e81f",
    "title": "From Artificial Intelligence to Explainable Artificial Intelligence in Industry 4.0: A Survey on What, How, and Where",
    "year": 2022,
    "authors": "Imran Ahmed, Gwanggil Jeon, F. Piccialli",
    "abstract": "Nowadays, Industry 4.0 can be considered a reality, a paradigm integrating modern technologies and innovations. Artificial intelligence (AI) can be considered the leading component of the industrial transformation enabling intelligent machines to execute tasks autonomously such as self-monitoring, interpretation, diagnosis, and analysis. AI-based methodologies (especially machine learning and deep learning support manufacturers and industries in predicting their maintenance needs and reducing downtime. Explainable artificial intelligence (XAI) studies and designs approaches, algorithms and tools producing human-understandable explanations of AI-based systems information and decisions. This article presents a comprehensive survey of AI and XAI-based methods adopted in the Industry 4.0 scenario. First, we briefly discuss different technologies enabling Industry 4.0. Then, we present an in-depth investigation of the main methods used in the literature: we also provide the details of what, how, why, and where these methods have been applied for Industry 4.0. Furthermore, we illustrate the opportunities and challenges that elicit future research directions toward responsible or human-centric AI and XAI systems, essential for adopting high-stakes industry applications.",
    "citationCount": 521,
    "pdf_filename": "2022_From_Artificial_Intelligence_to_Explaina_7c193335.pdf"
  },
  "0eada4b19bd4b415a27bd3ec891c3fc3e0cd2404": {
    "paperId": "0eada4b19bd4b415a27bd3ec891c3fc3e0cd2404",
    "title": "Leveraging Frequency Analysis for Deep Fake Image Recognition",
    "year": 2020,
    "authors": "J. Frank, Thorsten Eisenhofer, Lea Schönherr, Asja Fischer, D. Kolossa",
    "abstract": "Deep neural networks can generate images that are astonishingly realistic, so much so that it is often hard for humans to distinguish them from actual photos. These achievements have been largely made possible by Generative Adversarial Networks (GANs). While deep fake images have been thoroughly investigated in the image domain - a classical approach from the area of image forensics - an analysis in the frequency domain has been missing so far. In this paper, we address this shortcoming and our results reveal that in frequency space, GAN-generated images exhibit severe artifacts that can be easily identified. We perform a comprehensive analysis, showing that these artifacts are consistent across different neural network architectures, data sets, and resolutions. In a further investigation, we demonstrate that these artifacts are caused by upsampling operations found in all current GAN architectures, indicating a structural and fundamental problem in the way images are generated via GANs. Based on this analysis, we demonstrate how the frequency representation can be used to identify deep fake images in an automated way, surpassing state-of-the-art methods.",
    "citationCount": 706,
    "pdf_filename": "2020_Leveraging_Frequency_Analysis_for_Deep_F_0eada4b1.pdf"
  },
  "ec325571af034d8c4588428333ca922afc769ed8": {
    "paperId": "ec325571af034d8c4588428333ca922afc769ed8",
    "title": "In-Domain GAN Inversion for Real Image Editing",
    "year": 2020,
    "authors": "Jiapeng Zhu, Yujun Shen, Deli Zhao, Bolei Zhou",
    "abstract": "Recent work has shown that a variety of semantics emerge in the latent space of Generative Adversarial Networks (GANs) when being trained to synthesize images. However, it is difficult to use these learned semantics for real image editing. A common practice of feeding a real image to a trained GAN generator is to invert it back to a latent code. However, existing inversion methods typically focus on reconstructing the target image by pixel values yet fail to land the inverted code in the semantic domain of the original latent space. As a result, the reconstructed image cannot well support semantic editing through varying the inverted code. To solve this problem, we propose an in-domain GAN inversion approach, which not only faithfully reconstructs the input image but also ensures the inverted code to be semantically meaningful for editing. We first learn a novel domain-guided encoder to project a given image to the native latent space of GANs. We then propose domain-regularized optimization by involving the encoder as a regularizer to fine-tune the code produced by the encoder and better recover the target image. Extensive experiments suggest that our inversion method achieves satisfying real image reconstruction and more importantly facilitates various image editing tasks, significantly outperforming start-of-the-arts.",
    "citationCount": 675,
    "pdf_filename": "2020_In_Domain_GAN_Inversion_for_Real_Image_E_ec325571.pdf"
  },
  "670f9d0d8cafaeaeea564c88645b9816b1146cef": {
    "paperId": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
    "title": "Differentiable Augmentation for Data-Efficient GAN Training",
    "year": 2020,
    "authors": "Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, Song Han",
    "abstract": "The performance of generative adversarial networks (GANs) heavily deteriorates given a limited amount of training data. This is mainly because the discriminator is memorizing the exact training set. To combat it, we propose Differentiable Augmentation (DiffAugment), a simple method that improves the data efficiency of GANs by imposing various types of differentiable augmentations on both real and fake samples. Previous attempts to directly augment the training data manipulate the distribution of real images, yielding little benefit; DiffAugment enables us to adopt the differentiable augmentation for the generated samples, effectively stabilizes training, and leads to better convergence. Experiments demonstrate consistent gains of our method over a variety of GAN architectures and loss functions for both unconditional and class-conditional generation. With DiffAugment, we achieve a state-of-the-art FID of 6.80 with an IS of 100.8 on ImageNet 128x128. Furthermore, with only 20% training data, we can match the top performance on CIFAR-10 and CIFAR-100. Finally, our method can generate high-fidelity images using only 100 images without pre-training, while being on par with existing transfer learning algorithms. Code is available at this https URL.",
    "citationCount": 646,
    "pdf_filename": "2020_Differentiable_Augmentation_for_Data_Eff_670f9d0d.pdf"
  },
  "dc0668754e95da573cd64dbe5e2fed07ac9ddf97": {
    "paperId": "dc0668754e95da573cd64dbe5e2fed07ac9ddf97",
    "title": "InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs",
    "year": 2020,
    "authors": "Yujun Shen, Ceyuan Yang, Xiaoou Tang, Bolei Zhou",
    "abstract": "Although generative adversarial networks (GANs) have made significant progress in face synthesis, there lacks enough understanding of what GANs have learned in the latent representation to map a random code to a photo-realistic image. In this work, we propose a framework called InterFaceGAN to interpret the disentangled face representation learned by the state-of-the-art GAN models and study the properties of the facial semantics encoded in the latent space. We first find that GANs learn various semantics in some linear subspaces of the latent space. After identifying these subspaces, we can realistically manipulate the corresponding facial attributes without retraining the model. We then conduct a detailed study on the correlation between different semantics and manage to better disentangle them via subspace projection, resulting in more precise control of the attribute manipulation. Besides manipulating the gender, age, expression, and presence of eyeglasses, we can even alter the face pose and fix the artifacts accidentally made by GANs. Furthermore, we perform an in-depth face identity analysis and a layer-wise analysis to evaluate the editing results quantitatively. Finally, we apply our approach to real face editing by employing GAN inversion approaches and explicitly training feed-forward models based on the synthetic data established by InterFaceGAN. Extensive experimental results suggest that learning to synthesize faces spontaneously brings a disentangled and controllable face representation.",
    "citationCount": 663,
    "pdf_filename": "2020_InterFaceGAN__Interpreting_the_Disentang_dc066875.pdf"
  },
  "dc0092d06ab76465431edfd51b08d823b7d1ff3f": {
    "paperId": "dc0092d06ab76465431edfd51b08d823b7d1ff3f",
    "title": "Closed-Form Factorization of Latent Semantics in GANs",
    "year": 2020,
    "authors": "Yujun Shen, Bolei Zhou",
    "abstract": "A rich set of interpretable dimensions has been shown to emerge in the latent space of the Generative Adversarial Networks (GANs) trained for synthesizing images. In order to identify such latent dimensions for image editing, previous methods typically annotate a collection of synthesized samples and train linear classifiers in the latent space. However, they require a clear definition of the target attribute as well as the corresponding manual annotations, limiting their applications in practice. In this work, we examine the internal representation learned by GANs to reveal the underlying variation factors in an unsupervised manner. In particular, we take a closer look into the generation mechanism of GANs and further propose a closedform factorization algorithm for latent semantic discovery by directly decomposing the pre-trained weights. With a lightning-fast implementation, our approach is capable of not only finding semantically meaningful dimensions comparably to the state-of-the-art supervised methods, but also resulting in far more versatile concepts across multiple GAN models trained on a wide range of datasets.1",
    "citationCount": 626,
    "pdf_filename": "2020_Closed_Form_Factorization_of_Latent_Sema_dc0092d0.pdf"
  },
  "1e04ca1998c04040c9c10685fc0daa4ecc13855b": {
    "paperId": "1e04ca1998c04040c9c10685fc0daa4ecc13855b",
    "title": "AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients",
    "year": 2020,
    "authors": "Juntang Zhuang, Tommy M. Tang, Yifan Ding, S. Tatikonda, N. Dvornek",
    "abstract": "Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g. Adam) and accelerated schemes (e.g. stochastic gradient descent (SGD) with momentum). For many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability.We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the \"belief\" in the current gradient direction. Viewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step. We validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer. Code is available at this https URL",
    "citationCount": 593,
    "pdf_filename": "2020_AdaBelief_Optimizer__Adapting_Stepsizes__1e04ca19.pdf"
  },
  "c8d222efa51edc4fdeb6ab4e6369f7cfa596da14": {
    "paperId": "c8d222efa51edc4fdeb6ab4e6369f7cfa596da14",
    "title": "Semantic Communications: Overview, Open Issues, and Future Research Directions",
    "year": 2022,
    "authors": "Xuewen Luo, Hsiao-Hwa Chen, Qing Guo",
    "abstract": "With the deployment of the fifth generation (5G) in many countries, people start to think about what the next-generation of wireless communications will be. The current communication technologies are already approaching the Shannon physical capacity limit with advanced encoding (decoding) and modulation techniques. On the other hand, artificial intelligence (AI) plays an increasingly important role in the evolution from traditional communication technologies to the future. Semantic communication is one of the emerging communication paradigms, which works based on its innovative “semantic-meaning passing” concept. The core of semantic communication is to extract the “meanings” of sent information at a transmitter, and with the help of a matched knowledge base (KB) between a transmitter and a receiver, the semantic information can be “interpreted” successfully at a receiver. Therefore, semantic communication essentially is a communication scheme based largely on AI. In this article, an overview of the latest deep learning (DL) and end-to-end (E2E) communication based semantic communications will be given and open issues that need to be tackled will be discussed explicitly.",
    "citationCount": 506,
    "pdf_filename": "2022_Semantic_Communications__Overview__Open__c8d222ef.pdf"
  },
  "fc086bf5f6d1627153b68abdd5a4450e141b4ca3": {
    "paperId": "fc086bf5f6d1627153b68abdd5a4450e141b4ca3",
    "title": "CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows",
    "year": 2021,
    "authors": "Denis A. Gudovskiy, Shun Ishizaka, K. Kozuka",
    "abstract": "Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. In this paper, we propose a real-time model and analytically derive its relationship to prior methods. Our CFLOW-AD model is based on a conditional normalizing flow frame- work adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative de- coders where the latter explicitly estimate likelihood of the encoded features. Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10× than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by 1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments1.",
    "citationCount": 517,
    "pdf_filename": "2021_CFLOW_AD__Real_Time_Unsupervised_Anomaly_fc086bf5.pdf"
  },
  "97ac037b7589d9d0f2cb5109aa2b095ad06067fd": {
    "paperId": "97ac037b7589d9d0f2cb5109aa2b095ad06067fd",
    "title": "The Creation and Detection of Deepfakes",
    "year": 2020,
    "authors": "Yisroel Mirsky, Wenke Lee",
    "abstract": "Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly. In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.",
    "citationCount": 681,
    "pdf_filename": "2020_The_Creation_and_Detection_of_Deepfakes_97ac037b.pdf"
  },
  "2b6d375d8abea91d46894ebfa7051077253834d5": {
    "paperId": "2b6d375d8abea91d46894ebfa7051077253834d5",
    "title": "Artificial intelligence in healthcare: transforming the practice of medicine",
    "year": 2021,
    "authors": "Junaid Bajwa, Usman Munir, A. Nori, Bryan Williams",
    "abstract": "ABSTRACT Artificial intelligence (AI) is a powerful and disruptive area of computer science, with the potential to fundamentally transform the practice of medicine and the delivery of healthcare. In this review article, we outline recent breakthroughs in the application of AI in healthcare, describe a roadmap to building effective, reliable and safe AI systems, and discuss the possible future direction of AI augmented healthcare systems.",
    "citationCount": 952,
    "pdf_filename": "2021_Artificial_intelligence_in_healthcare__t_2b6d375d.pdf"
  },
  "4ef0de54bec014b8e2ab9dd48d8b5d961c335a28": {
    "paperId": "4ef0de54bec014b8e2ab9dd48d8b5d961c335a28",
    "title": "CovidGAN: Data Augmentation Using Auxiliary Classifier GAN for Improved Covid-19 Detection",
    "year": 2020,
    "authors": "Abdul Waheed, Muskan Goyal, Deepak Gupta, Ashish Khanna, F. Al-turjman",
    "abstract": "Coronavirus (COVID-19) is a viral disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spread of COVID-19 seems to have a detrimental effect on the global economy and health. A positive chest X-ray of infected patients is a crucial step in the battle against COVID-19. Early results suggest that abnormalities exist in chest X-rays of patients suggestive of COVID-19. This has led to the introduction of a variety of deep learning systems and studies have shown that the accuracy of COVID-19 patient detection through the use of chest X-rays is strongly optimistic. Deep learning networks like convolutional neural networks (CNNs) need a substantial amount of training data. Because the outbreak is recent, it is difficult to gather a significant number of radiographic images in such a short time. Therefore, in this research, we present a method to generate synthetic chest X-ray (CXR) images by developing an Auxiliary Classifier Generative Adversarial Network (ACGAN) based model called CovidGAN. In addition, we demonstrate that the synthetic images produced from CovidGAN can be utilized to enhance the performance of CNN for COVID-19 detection. Classification using CNN alone yielded 85% accuracy. By adding synthetic images produced by CovidGAN,the accuracy increased to 95%. We hope this method will speed up COVID-19 detection and lead to more robust systems of radiology.",
    "citationCount": 619,
    "pdf_filename": "2020_CovidGAN__Data_Augmentation_Using_Auxili_4ef0de54.pdf"
  },
  "68b2725071b7d37cefd9cacd4e65eccc34ec5066": {
    "paperId": "68b2725071b7d37cefd9cacd4e65eccc34ec5066",
    "title": "Model Adaptation: Unsupervised Domain Adaptation Without Source Data",
    "year": 2020,
    "authors": "Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, Si Wu",
    "abstract": "In this paper, we investigate a challenging unsupervised domain adaptation setting --- unsupervised model adaptation. We aim to explore how to rely only on unlabeled target data to improve performance of an existing source prediction model on the target domain, since labeled source data may not be available in some real-world scenarios due to data privacy issues. For this purpose, we propose a new framework, which is referred to as collaborative class conditional generative adversarial net to bypass the dependence on the source data. Specifically, the prediction model is to be improved through generated target-style data, which provides more accurate guidance for the generator. As a result, the generator and the prediction model can collaborate with each other without source data. Furthermore, due to the lack of supervision from source data, we propose a weight constraint that encourages similarity to the source model. A clustering-based regularization is also introduced to produce more discriminative features in the target domain. Compared to conventional domain adaptation methods, our model achieves superior performance on multiple adaptation tasks with only unlabeled target data, which verifies its effectiveness in this challenging setting.",
    "citationCount": 553,
    "pdf_filename": "2020_Model_Adaptation__Unsupervised_Domain_Ad_68b27250.pdf"
  },
  "7bfb4ef17eabec1acd266958bdb08622eebfbb05": {
    "paperId": "7bfb4ef17eabec1acd266958bdb08622eebfbb05",
    "title": "Brain-inspired replay for continual learning with artificial neural networks",
    "year": 2020,
    "authors": "Gido M. van de Ven, H. Siegelmann, A. Tolias",
    "abstract": "Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as ‘generative replay’, which can successfully – and surprisingly efficiently – prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network’s own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on CIFAR-100) without storing data, and it provides a novel model for replay in the brain. One challenge that faces artificial intelligence is the inability of deep neural networks to continuously learn new information without catastrophically forgetting what has been learnt before. To solve this problem, here the authors propose a replay-based algorithm for deep learning without the need to store data.",
    "citationCount": 540,
    "pdf_filename": "2020_Brain_inspired_replay_for_continual_lear_7bfb4ef1.pdf"
  },
  "f2a97118793a12734f38f6c5d01bb9b13d7fb1e4": {
    "paperId": "f2a97118793a12734f38f6c5d01bb9b13d7fb1e4",
    "title": "An empirical survey of data augmentation for time series classification with neural networks",
    "year": 2020,
    "authors": "Brian Kenji Iwana, S. Uchida",
    "abstract": "In recent times, deep artificial neural networks have achieved many successes in pattern recognition. Part of this success can be attributed to the reliance on big data to increase generalization. However, in the field of time series recognition, many datasets are often very small. One method of addressing this problem is through the use of data augmentation. In this paper, we survey data augmentation techniques for time series and their application to time series classification with neural networks. We propose a taxonomy and outline the four families in time series data augmentation, including transformation-based methods, pattern mixing, generative models, and decomposition methods. Furthermore, we empirically evaluate 12 time series data augmentation methods on 128 time series classification datasets with six different types of neural networks. Through the results, we are able to analyze the characteristics, advantages and disadvantages, and recommendations of each data augmentation method. This survey aims to help in the selection of time series data augmentation for neural network applications.",
    "citationCount": 565,
    "pdf_filename": "2020_An_empirical_survey_of_data_augmentation_f2a97118.pdf"
  },
  "a4c6cb385a90441061218f50abe2871d5e384a2e": {
    "paperId": "a4c6cb385a90441061218f50abe2871d5e384a2e",
    "title": "IntelliCode compose: code generation using transformer",
    "year": 2020,
    "authors": "Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, Neel Sundaresan",
    "abstract": "In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments. In this paper, we introduce IntelliCode Compose – a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook. Our best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for Python programming language.",
    "citationCount": 551,
    "pdf_filename": "2020_IntelliCode_compose__code_generation_usi_a4c6cb38.pdf"
  },
  "4aa88c1406414cda3ce9cf76c8af0abaa8391760": {
    "paperId": "4aa88c1406414cda3ce9cf76c8af0abaa8391760",
    "title": "Habitat 2.0: Training Home Assistants to Rearrange their Habitat",
    "year": 2021,
    "authors": "Andrew Szot, Alexander Clegg, Eric Undersander, Erik Wijmans, Yili Zhao",
    "abstract": "We introduce Habitat 2.0 (H2.0), a simulation platform for training virtual robots in interactive 3D environments and complex physics-enabled scenarios. We make comprehensive contributions to all levels of the embodied AI stack - data, simulation, and benchmark tasks. Specifically, we present: (i) ReplicaCAD: an artist-authored, annotated, reconfigurable 3D dataset of apartments (matching real spaces) with articulated objects (e.g. cabinets and drawers that can open/close); (ii) H2.0: a high-performance physics-enabled 3D simulator with speeds exceeding 25,000 simulation steps per second (850x real-time) on an 8-GPU node, representing 100x speed-ups over prior work; and, (iii) Home Assistant Benchmark (HAB): a suite of common tasks for assistive robots (tidy the house, prepare groceries, set the table) that test a range of mobile manipulation capabilities. These large-scale engineering contributions allow us to systematically compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with an emphasis on generalization to new objects, receptacles, and layouts. We find that (1) flat RL policies struggle on HAB compared to hierarchical ones; (2) a hierarchy with independent skills suffers from 'hand-off problems', and (3) SPA pipelines are more brittle than RL policies.",
    "citationCount": 618,
    "pdf_filename": "2021_Habitat_2_0__Training_Home_Assistants_to_4aa88c14.pdf"
  },
  "c0a8fe3ac767c0911f10296bce29cb97a7382266": {
    "paperId": "c0a8fe3ac767c0911f10296bce29cb97a7382266",
    "title": "Artificial intelligence in education: Addressing ethical challenges in K-12 settings",
    "year": 2021,
    "authors": "Selin Akgun, Christine Greenhow",
    "abstract": "Artificial intelligence (AI) is a field of study that combines the applications of machine learning, algorithm productions, and natural language processing. Applications of AI transform the tools of education. AI has a variety of educational applications, such as personalized learning platforms to promote students’ learning, automated assessment systems to aid teachers, and facial recognition systems to generate insights about learners’ behaviors. Despite the potential benefits of AI to support students’ learning experiences and teachers’ practices, the ethical and societal drawbacks of these systems are rarely fully considered in K-12 educational contexts. The ethical challenges of AI in education must be identified and introduced to teachers and students. To address these issues, this paper (1) briefly defines AI through the concepts of machine learning and algorithms; (2) introduces applications of AI in educational settings and benefits of AI systems to support students’ learning processes; (3) describes ethical challenges and dilemmas of using AI in education; and (4) addresses the teaching and understanding of AI by providing recommended instructional resources from two providers—i.e., the Massachusetts Institute of Technology’s (MIT) Media Lab and Code.org. The article aims to help practitioners reap the benefits and navigate ethical challenges of integrating AI in K-12 classrooms, while also introducing instructional resources that teachers can use to advance K-12 students’ understanding of AI and ethics.",
    "citationCount": 755,
    "pdf_filename": "2021_Artificial_intelligence_in_education__Ad_c0a8fe3a.pdf"
  },
  "e3d5ee10d0489c768e943546038e3f53e7697349": {
    "paperId": "e3d5ee10d0489c768e943546038e3f53e7697349",
    "title": "State of the Art on Neural Rendering",
    "year": 2020,
    "authors": "A. Tewari, Ohad Fried, Justus Thies, V. Sitzmann, Stephen Lombardi",
    "abstract": "Efficient rendering of photo‐realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo‐realistic images from hand‐crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo‐realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists. This state‐of‐the‐art report summarizes the recent trends and applications of neural rendering. We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photorealistic outputs. Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches. Specifically, our emphasis is on the type of control, i.e., how the control is provided, which parts of the pipeline are learned, explicit vs. implicit control, generalization, and stochastic vs. deterministic synthesis. The second half of this state‐of‐the‐art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free‐viewpoint video, and the creation of photo‐realistic avatars for virtual and augmented reality telepresence. Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems.",
    "citationCount": 501,
    "pdf_filename": "2020_State_of_the_Art_on_Neural_Rendering_e3d5ee10.pdf"
  },
  "101bd9c3515c77982fb9249790dd6aa60e403339": {
    "paperId": "101bd9c3515c77982fb9249790dd6aa60e403339",
    "title": "Tortured phrases: A dubious writing style emerging in science. Evidence of critical issues affecting established journals",
    "year": 2021,
    "authors": "G. Cabanac, C. Labb'e, A. Magazinov",
    "abstract": "Probabilistic text generators have been used to produce fake scientific papers for more than a decade. Such nonsensical papers are easily detected by both human and machine. Now more complex AI-powered generation techniques produce texts indistinguishable from that of humans and the generation of scientific texts from a few keywords has been documented. Our study introduces the concept of tortured phrases: unexpected weird phrases in lieu of established ones, such as 'counterfeit consciousness' instead of 'artificial intelligence.' We combed the literature for tortured phrases and study one reputable journal where these concentrated en masse. Hypothesising the use of advanced language models we ran a detector on the abstracts of recent articles of this journal and on several control sets. The pairwise comparisons reveal a concentration of abstracts flagged as 'synthetic' in the journal. We also highlight irregularities in its operation, such as abrupt changes in editorial timelines. We substantiate our call for investigation by analysing several individual dubious articles, stressing questionable features: tortured writing style, citation of non-existent literature, and unacknowledged image reuse. Surprisingly, some websites offer to rewrite texts for free, generating gobbledegook full of tortured phrases. We believe some authors used rewritten texts to pad their manuscripts. We wish to raise the awareness on publications containing such questionable AI-generated or rewritten texts that passed (poor) peer review. Deception with synthetic texts threatens the integrity of the scientific literature.",
    "citationCount": 613,
    "pdf_filename": "2021_Tortured_phrases__A_dubious_writing_styl_101bd9c3.pdf"
  },
  "2429ff978b9067efdc328d400b2241e5973cf44f": {
    "paperId": "2429ff978b9067efdc328d400b2241e5973cf44f",
    "title": "Applications of Remote Sensing in Precision Agriculture: A Review",
    "year": 2020,
    "authors": "R. Sishodia, Ram Lakhan Ray, Sudhir Kumar Singh",
    "abstract": "Agriculture provides for the most basic needs of humankind: food and fiber. The introduction of new farming techniques in the past century (e.g., during the Green Revolution) has helped agriculture keep pace with growing demands for food and other agricultural products. However, further increases in food demand, a growing population, and rising income levels are likely to put additional strain on natural resources. With growing recognition of the negative impacts of agriculture on the environment, new techniques and approaches should be able to meet future food demands while maintaining or reducing the environmental footprint of agriculture. Emerging technologies, such as geospatial technologies, Internet of Things (IoT), Big Data analysis, and artificial intelligence (AI), could be utilized to make informed management decisions aimed to increase crop production. Precision agriculture (PA) entails the application of a suite of such technologies to optimize agricultural inputs to increase agricultural production and reduce input losses. Use of remote sensing technologies for PA has increased rapidly during the past few decades. The unprecedented availability of high resolution (spatial, spectral and temporal) satellite images has promoted the use of remote sensing in many PA applications, including crop monitoring, irrigation management, nutrient application, disease and pest management, and yield prediction. In this paper, we provide an overview of remote sensing systems, techniques, and vegetation indices along with their recent (2015–2020) applications in PA. Remote-sensing-based PA technologies such as variable fertilizer rate application technology in Green Seeker and Crop Circle have already been incorporated in commercial agriculture. Use of unmanned aerial vehicles (UAVs) has increased tremendously during the last decade due to their cost-effectiveness and flexibility in obtaining the high-resolution (cm-scale) images needed for PA applications. At the same time, the availability of a large amount of satellite data has prompted researchers to explore advanced data storage and processing techniques such as cloud computing and machine learning. Given the complexity of image processing and the amount of technical knowledge and expertise needed, it is critical to explore and develop a simple yet reliable workflow for the real-time application of remote sensing in PA. Development of accurate yet easy to use, user-friendly systems is likely to result in broader adoption of remote sensing technologies in commercial and non-commercial PA applications.",
    "citationCount": 923,
    "pdf_filename": "2020_Applications_of_Remote_Sensing_in_Precis_2429ff97.pdf"
  },
  "d020b66a033ab1adc121010e116c594415cb2cea": {
    "paperId": "d020b66a033ab1adc121010e116c594415cb2cea",
    "title": "A strategic framework for artificial intelligence in marketing",
    "year": 2020,
    "authors": "Ming-Hui Huang, R. Rust",
    "abstract": "The authors develop a three-stage framework for strategic marketing planning, incorporating multiple artificial intelligence (AI) benefits: mechanical AI for automating repetitive marketing functions and activities, thinking AI for processing data to arrive at decisions, and feeling AI for analyzing interactions and human emotions. This framework lays out the ways that AI can be used for marketing research, strategy (segmentation, targeting, and positioning, STP), and actions. At the marketing research stage, mechanical AI can be used for data collection, thinking AI for market analysis, and feeling AI for customer understanding. At the marketing strategy (STP) stage, mechanical AI can be used for segmentation (segment recognition), thinking AI for targeting (segment recommendation), and feeling AI for positioning (segment resonance). At the marketing action stage, mechanical AI can be used for standardization, thinking AI for personalization, and feeling AI for relationalization. We apply this framework to various areas of marketing, organized by marketing 4Ps/4Cs, to illustrate the strategic use of AI.",
    "citationCount": 899,
    "pdf_filename": "2020_A_strategic_framework_for_artificial_int_d020b66a.pdf"
  },
  "209f9bde2dee7cf1677801586562ffe56d435d38": {
    "paperId": "209f9bde2dee7cf1677801586562ffe56d435d38",
    "title": "Learning How to Ask: Querying LMs with Mixtures of Soft Prompts",
    "year": 2021,
    "authors": "Guanghui Qin, J. Eisner",
    "abstract": "Natural-language prompts have recently been used to coax pretrained language models into performing other AI tasks, using a fill-in-the-blank paradigm (Petroni et al., 2019) or a few-shot extrapolation paradigm (Brown et al., 2020). For example, language models retain factual knowledge from their training corpora that can be extracted by asking them to “fill in the blank” in a sentential prompt. However, where does this prompt come from? We explore the idea of learning prompts by gradient descent—either fine-tuning prompts taken from previous work, or starting from random initialization. Our prompts consist of “soft words,” i.e., continuous vectors that are not necessarily word type embeddings from the language model. Furthermore, for each task, we optimize a mixture of prompts, learning which prompts are most effective and how to ensemble them. Across multiple English LMs and tasks, our approach hugely outperforms previous methods, showing that the implicit factual knowledge in language models was previously underestimated. Moreover, this knowledge is cheap to elicit: random initialization is nearly as good as informed initialization.",
    "citationCount": 577,
    "pdf_filename": "2021_Learning_How_to_Ask__Querying_LMs_with_M_209f9bde.pdf"
  },
  "4a6e74d4bf4fd0106891e5518692a77c7aa8811d": {
    "paperId": "4a6e74d4bf4fd0106891e5518692a77c7aa8811d",
    "title": "Outlier Detection in High Dimensional Data",
    "year": 2021,
    "authors": "C. Aggarwal, Philip S. Yu",
    "abstract": "Artificial intelligence (AI) is the science that allows\ncomputers to replicate human intelligence in areas such as\ndecision-making, text processing, visual perception. Artificial\nIntelligence is the broader field that contains several subfields\nsuch as machine learning, robotics, and computer vision.\nMachine Learning is a branch of Artificial Intelligence that\nallows a machine to learn and improve at a task over time. Deep\nLearning is a subset of machine learning that makes use of deep\nartificial neural networks for training. The paper proposed on\noutlier detection for multivariate high dimensional data for\nAutoencoder unsupervised model.",
    "citationCount": 589,
    "pdf_filename": "2021_Outlier_Detection_in_High_Dimensional_Da_4a6e74d4.pdf"
  },
  "6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d": {
    "paperId": "6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d",
    "title": "Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions",
    "year": 2021,
    "authors": "H. Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, R. Karri",
    "abstract": "There is burgeoning interest in designing AI-based systems to assist humans in designing computing systems, including tools that automatically generate computer code. The most notable of these comes in the form of the first self-described ‘AI pair programmer’, GitHub Copilot, which is a language model trained over open-source GitHub code. However, code often contains bugs—and so, given the vast quantity of unvetted code that Copilot has processed, it is certain that the language model will have learned from exploitable, buggy code. This raises concerns on the security of Copilot’s code contributions. In this work, we systematically investigate the prevalence and conditions that can cause GitHub Copilot to recommend insecure code. To perform this analysis we prompt Copilot to generate code in scenarios relevant to high-risk cybersecurity weaknesses, e.g. those from MITRE’s “Top 25” Common Weakness Enumeration (CWE) list. We explore Copilot’s performance on three distinct code generation axes—examining how it performs given diversity of weaknesses, diversity of prompts, and diversity of domains. In total, we produce 89 different scenarios for Copilot to complete, producing 1,689 programs. Of these, we found approximately 40% to be vulnerable.",
    "citationCount": 558,
    "pdf_filename": "2021_Asleep_at_the_Keyboard__Assessing_the_Se_6e5eb616.pdf"
  },
  "7cc44884667e9771d11491c142df90e091d3d4a7": {
    "paperId": "7cc44884667e9771d11491c142df90e091d3d4a7",
    "title": "COVID-CT-Dataset: A CT Scan Dataset about COVID-19",
    "year": 2020,
    "authors": "Xingyi Yang, Jinyu Zhao, Yichen Zhang, Xuehai He, Pengtao Xie",
    "abstract": "During the outbreak time of COVID-19, computed tomography (CT) is a useful manner for diagnosing COVID-19 patients. Due to privacy issues, publicly available COVID-19 CT datasets are highly difficult to obtain, which hinders the research and development of AI-powered diagnosis methods of COVID-19 based on CTs. To address this issue, we build an open-sourced dataset -- COVID-CT, which contains 349 COVID-19 CT images from 216 patients and 463 non-COVID-19 CTs. The utility of this dataset is confirmed by a senior radiologist who has been diagnosing and treating COVID-19 patients since the outbreak of this pandemic. We also perform experimental studies which further demonstrate that this dataset is useful for developing AI-based diagnosis models of COVID-19. Using this dataset, we develop diagnosis methods based on multi-task learning and self-supervised learning, that achieve an F1 of 0.90, an AUC of 0.98, and an accuracy of 0.89. According to the senior radiologist, models with such performance are good enough for clinical usage. The data and code are available at this https URL",
    "citationCount": 886,
    "pdf_filename": "2020_COVID_CT_Dataset__A_CT_Scan_Dataset_abou_7cc44884.pdf"
  },
  "f6c8dc069dd107ff46c1973017f63e099c922398": {
    "paperId": "f6c8dc069dd107ff46c1973017f63e099c922398",
    "title": "Mapping the human genetic architecture of COVID-19",
    "year": 2021,
    "authors": "Mari E. K. Juha Rachel G. Benjamin M. Mark Andrea Gita  Niemi Karjalainen Liao Neale Daly Ganna Pathak And, Mari E. K. Juha Rachel G. Benjamin M. Mark Andrea Niemi Karjalainen Liao Neale Daly Ganna, Mari E. K. Niemi, J. Karjalainen, Rachel G Liao",
    "abstract": "The genetic make-up of an individual contributes to the susceptibility and response to viral infection. Although environmental, clinical and social factors have a role in the chance of exposure to SARS-CoV-2 and the severity of COVID-191,2, host genetics may also be important. Identifying host-specific genetic factors may reveal biological mechanisms of therapeutic relevance and clarify causal relationships of modifiable environmental risk factors for SARS-CoV-2 infection and outcomes. We formed a global network of researchers to investigate the role of human genetics in SARS-CoV-2 infection and COVID-19 severity. Here we describe the results of three genome-wide association meta-analyses that consist of up to 49,562 patients with COVID-19 from 46 studies across 19 countries. We report 13 genome-wide significant loci that are associated with SARS-CoV-2 infection or severe manifestations of COVID-19. Several of these loci correspond to previously documented associations to lung or autoimmune and inflammatory diseases3–7. They also represent potentially actionable mechanisms in response to infection. Mendelian randomization analyses support a causal role for smoking and body-mass index for severe COVID-19 although not for type II diabetes. The identification of novel host genetic factors associated with COVID-19 was made possible by the community of human genetics researchers coming together to prioritize the sharing of data, results, resources and analytical frameworks. This working model of international collaboration underscores what is possible for future genetic discoveries in emerging pandemics, or indeed for any complex human disease. A global network of researchers was formed to investigate the role of human genetics in SARS-CoV-2 infection and COVID-19 severity; this paper reports 13 genome-wide significant loci and potentially actionable mechanisms in response to infection.",
    "citationCount": 782,
    "pdf_filename": "2021_Mapping_the_human_genetic_architecture_o_f6c8dc06.pdf"
  },
  "f2f2026f76ebada185531ab95808515923ea5952": {
    "paperId": "f2f2026f76ebada185531ab95808515923ea5952",
    "title": "An Overview of Artificial Intelligence Applications for Power Electronics",
    "year": 2020,
    "authors": "Shuai Zhao, F. Blaabjerg, Huai Wang",
    "abstract": "This article gives an overview of the artificial intelligence (AI) applications for power electronic systems. The three distinctive life-cycle phases, design, control, and maintenance are correlated with one or more tasks to be addressed by AI, including optimization, classification, regression, and data structure exploration. The applications of four categories of AI are discussed, which are expert system, fuzzy logic, metaheuristic method, and machine learning. More than 500 publications have been reviewed to identify the common understandings, practical implementation challenges, and research opportunities in the application of AI for power electronics. This article is accompanied by an Excel file listing the relevant publications for statistical analytics.",
    "citationCount": 586,
    "pdf_filename": "2020_An_Overview_of_Artificial_Intelligence_A_f2f2026f.pdf"
  },
  "a81434e08ea760cc364c5a9d8aa8cdc09fcbc9f1": {
    "paperId": "a81434e08ea760cc364c5a9d8aa8cdc09fcbc9f1",
    "title": "The role of artificial intelligence in healthcare: a structured literature review",
    "year": 2021,
    "authors": "Silvana Secinaro, D. Calandra, A. Secinaro, V. Muthurangu, P. Biancone",
    "abstract": "Background/Introduction Artificial intelligence (AI) in the healthcare sector is receiving attention from researchers and health professionals. Few previous studies have investigated this topic from a multi-disciplinary perspective, including accounting, business and management, decision sciences and health professions. Methods The structured literature review with its reliable and replicable research protocol allowed the researchers to extract 288 peer-reviewed papers from Scopus. The authors used qualitative and quantitative variables to analyse authors, journals, keywords, and collaboration networks among researchers. Additionally, the paper benefited from the Bibliometrix R software package. Results The investigation showed that the literature in this field is emerging. It focuses on health services management, predictive medicine, patient data and diagnostics, and clinical decision-making. The United States, China, and the United Kingdom contributed the highest number of studies. Keyword analysis revealed that AI can support physicians in making a diagnosis, predicting the spread of diseases and customising treatment paths. Conclusions The literature reveals several AI applications for health services and a stream of research that has not fully been covered. For instance, AI projects require skills and data quality awareness for data-intensive analysis and knowledge-based management. Insights can help researchers and health professionals understand and address future research on AI in the healthcare field.",
    "citationCount": 651,
    "pdf_filename": "2021_The_role_of_artificial_intelligence_in_h_a81434e0.pdf"
  },
  "a7a65aec0792126674544fdbdca1aff418de3add": {
    "paperId": "a7a65aec0792126674544fdbdca1aff418de3add",
    "title": "Artificial intelligence-enhanced electrocardiography in cardiovascular disease management",
    "year": 2021,
    "authors": "K. Siontis, P. Noseworthy, Z. Attia, P. Friedman",
    "abstract": "The application of artificial intelligence (AI) to the electrocardiogram (ECG), a ubiquitous and standardized test, is an example of the ongoing transformative effect of AI on cardiovascular medicine. Although the ECG has long offered valuable insights into cardiac and non-cardiac health and disease, its interpretation requires considerable human expertise. Advanced AI methods, such as deep-learning convolutional neural networks, have enabled rapid, human-like interpretation of the ECG, while signals and patterns largely unrecognizable to human interpreters can be detected by multilayer AI networks with precision, making the ECG a powerful, non-invasive biomarker. Large sets of digital ECGs linked to rich clinical data have been used to develop AI models for the detection of left ventricular dysfunction, silent (previously undocumented and asymptomatic) atrial fibrillation and hypertrophic cardiomyopathy, as well as the determination of a person’s age, sex and race, among other phenotypes. The clinical and population-level implications of AI-based ECG phenotyping continue to emerge, particularly with the rapid rise in the availability of mobile and wearable ECG technologies. In this Review, we summarize the current and future state of the AI-enhanced ECG in the detection of cardiovascular disease in at-risk populations, discuss its implications for clinical decision-making in patients with cardiovascular disease and critically appraise potential limitations and unknowns. In this Review, Friedman and colleagues summarize the use of artificial intelligence-enhanced electrocardiography in the detection of cardiovascular disease in at-risk populations, discuss its implications for clinical decision-making in patients with cardiovascular disease and critically appraise potential limitations and unknowns. The feasibility and potential value of the application of advanced artificial intelligence methods, particularly deep-learning convolutional neural networks (CNNs), to the electrocardiogram (ECG) have been demonstrated. CNNs developed with the use of large numbers of digital ECGs linked to rich clinical datasets might be able to perform accurate and nuanced, human-like interpretation of ECGs. CNNs have also been developed to detect asymptomatic left ventricular dysfunction, silent atrial fibrillation, hypertrophic cardiomyopathy and an individual’s age, sex and race on the basis of the ECG alone. CNNs to detect other cardiac conditions, such as aortic valve stenosis and amyloid heart disease, are in active development. These approaches might be applicable to the standard 12-lead ECG or to data obtained from single-lead or multilead mobile or wearable ECG technologies. Evidence on patient outcomes, as well as the challenges and potential limitations from the real-world implementation of the artificial intelligence-enhanced ECG, continues to emerge. The feasibility and potential value of the application of advanced artificial intelligence methods, particularly deep-learning convolutional neural networks (CNNs), to the electrocardiogram (ECG) have been demonstrated. CNNs developed with the use of large numbers of digital ECGs linked to rich clinical datasets might be able to perform accurate and nuanced, human-like interpretation of ECGs. CNNs have also been developed to detect asymptomatic left ventricular dysfunction, silent atrial fibrillation, hypertrophic cardiomyopathy and an individual’s age, sex and race on the basis of the ECG alone. CNNs to detect other cardiac conditions, such as aortic valve stenosis and amyloid heart disease, are in active development. These approaches might be applicable to the standard 12-lead ECG or to data obtained from single-lead or multilead mobile or wearable ECG technologies. Evidence on patient outcomes, as well as the challenges and potential limitations from the real-world implementation of the artificial intelligence-enhanced ECG, continues to emerge.",
    "citationCount": 638,
    "pdf_filename": "2021_Artificial_intelligence_enhanced_electro_a7a65aec.pdf"
  },
  "ab5923948a3d8c15f964c1577eec2b3c379ba09e": {
    "paperId": "ab5923948a3d8c15f964c1577eec2b3c379ba09e",
    "title": "Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations",
    "year": 2021,
    "authors": "Laleh Seyyed-Kalantari, Haoran Zhang, Matthew B. A. McDermott, I. Chen, M. Ghassemi",
    "abstract": "Artificial intelligence (AI) systems have increasingly achieved expert-level performance in medical imaging applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations such as female patients, Black patients, or patients of low socioeconomic status. Such biases are especially troubling in the context of underdiagnosis, whereby the AI algorithm would inaccurately label an individual with a disease as healthy, potentially delaying access to care. Here, we examine algorithmic underdiagnosis in chest X-ray pathology classification across three large chest X-ray datasets, as well as one multi-source dataset. We find that classifiers produced using state-of-the-art computer vision techniques consistently and selectively underdiagnosed under-served patient populations and that the underdiagnosis rate was higher for intersectional under-served subpopulations, for example, Hispanic female patients. Deployment of AI systems using medical imaging for disease diagnosis with such biases risks exacerbation of existing care biases and can potentially lead to unequal access to medical treatment, thereby raising ethical concerns for the use of these models in the clinic. Artificial intelligence algorithms trained using chest X-rays consistently underdiagnose pulmonary abnormalities or diseases in historically under-served patient populations, raising ethical concerns about the clinical use of such algorithms.",
    "citationCount": 610,
    "pdf_filename": "2021_Underdiagnosis_bias_of_artificial_intell_ab592394.pdf"
  },
  "be0bbf06977c4dadbf702287733187884a531b8a": {
    "paperId": "be0bbf06977c4dadbf702287733187884a531b8a",
    "title": "Edge Artificial Intelligence for 6G: Vision, Enabling Technologies, and Applications",
    "year": 2021,
    "authors": "K. Letaief, Yuanming Shi, Jianmin Lu, Jianhua Lu",
    "abstract": "The thriving of artificial intelligence (AI) applications is driving the further evolution of wireless networks. It has been envisioned that 6G will be transformative and will revolutionize the evolution of wireless from “connected things” to “connected intelligence”. However, state-of-the-art deep learning and big data analytics based AI systems require tremendous computation and communication resources, causing significant latency, energy consumption, network congestion, and privacy leakage in both of the training and inference processes. By embedding model training and inference capabilities into the network edge, edge AI stands out as a disruptive technology for 6G to seamlessly integrate sensing, communication, computation, and intelligence, thereby improving the efficiency, effectiveness, privacy, and security of 6G networks. In this paper, we shall provide our vision for scalable and trustworthy edge AI systems with integrated design of wireless communication strategies and decentralized machine learning models. New design principles of wireless networks, service-driven resource allocation optimization methods, as well as a holistic end-to-end system architecture to support edge AI will be described. Standardization, software and hardware platforms, and application scenarios are also discussed to facilitate the industrialization and commercialization of edge AI systems.",
    "citationCount": 511,
    "pdf_filename": "2021_Edge_Artificial_Intelligence_for_6G__Vis_be0bbf06.pdf"
  },
  "2ee9bf45d2185f9297508b9e29af2f960c42edf8": {
    "paperId": "2ee9bf45d2185f9297508b9e29af2f960c42edf8",
    "title": "Near Infrared Light Triggered Nitric Oxide-Enhanced Photodynamic Therapy and Low-Temperature Photothermal Therapy for Biofilm Elimination.",
    "year": 2020,
    "authors": "Zhang Yuan, Chuanchuan Lin, Ye He, Bailong Tao, Maowen Chen",
    "abstract": "Photothermal treatment (PTT) involving combination therapeutic modalities were recently emerged as an efficient alternative for combating biofilm. However, PTT-related local high temperature may destroy the surrounding healthy tissues. Herein, we present an all-in-one photo-therapeutic nanoplatform consisting of L-arginine (L-Arg), indocyanine green (ICG) and mesoporous polydopamine (MPDA), namely AI-MPDA, to eliminate the already-formed biofilm. The fabrication process included surface modification of MPDA with L-Arg and further adsorption of ICG via π-π stacking. Under near infrared (NIR) exposure, AI-MPDA not only generated heat, but also produced reactive oxygen species (ROS), causing cascade catalysis of L-Arg to release nitric oxide (NO). Under near infrared (NIR) irradiation, biofilm elimination was attributed to the NO-enhanced photodynamic therapy (PDT) and low-temperature PTT (≤ 45 °C). Notably, NIR-triggered all-in-one strategy resulted in severe destruction of bacterial membranes. The photo-therapeutic AI-MPDA also displayed good cytocompatibility. NIR-irradiated AI-MPDA nanoparticles not only prevented bacterial colonization, but also realized a rapid recovery of infected wound. More importantly, the all-in-one photo-therapeutic platform displayed effective biofilm elimination with an efficiency of around 100% in a abscess formation model. Overall, this low-temperature photo-therapeutic platform provides a reliable tool for combating already-formed biofilm in clinical applications.",
    "citationCount": 533,
    "pdf_filename": "2020_Near_Infrared_Light_Triggered_Nitric_Oxi_2ee9bf45.pdf"
  },
  "7aa70e2c12c8ba2dcc828893adb8bb56e3766726": {
    "paperId": "7aa70e2c12c8ba2dcc828893adb8bb56e3766726",
    "title": "Artificial Intelligence, Values, and Alignment",
    "year": 2020,
    "authors": "Iason Gabriel",
    "abstract": "This paper looks at philosophical questions that arise in the context of AI alignment. It defends three propositions. First, normative and technical aspects of the AI alignment problem are interrelated, creating space for productive engagement between people working in both domains. Second, it is important to be clear about the goal of alignment. There are significant differences between AI that aligns with instructions, intentions, revealed preferences, ideal preferences, interests and values. A principle-based approach to AI alignment, which combines these elements in a systematic way, has considerable advantages in this context. Third, the central challenge for theorists is not to identify ‘true’ moral principles for AI; rather, it is to identify fair principles for alignment that receive reflective endorsement despite widespread variation in people’s moral beliefs. The final part of the paper explores three ways in which fair principles for AI alignment could potentially be identified.",
    "citationCount": 809,
    "pdf_filename": "2020_Artificial_Intelligence__Values__and_Ali_7aa70e2c.pdf"
  },
  "8278c6964ed7485f69523711faf7dd12dd0e3825": {
    "paperId": "8278c6964ed7485f69523711faf7dd12dd0e3825",
    "title": "Privacy and artificial intelligence: challenges for protecting health information in a new era",
    "year": 2021,
    "authors": "Blake Murdoch",
    "abstract": "Advances in healthcare artificial intelligence (AI) are occurring rapidly and there is a growing discussion about managing its development. Many AI technologies end up owned and controlled by private entities. The nature of the implementation of AI could mean such corporations, clinics and public bodies will have a greater than typical role in obtaining, utilizing and protecting patient health information. This raises privacy issues relating to implementation and data security. The first set of concerns includes access, use and control of patient data in private hands. Some recent public–private partnerships for implementing AI have resulted in poor protection of privacy. As such, there have been calls for greater systemic oversight of big data health research. Appropriate safeguards must be in place to maintain privacy and patient agency. Private custodians of data can be impacted by competing goals and should be structurally encouraged to ensure data protection and to deter alternative use thereof. Another set of concerns relates to the external risk of privacy breaches through AI-driven methods. The ability to deidentify or anonymize patient health data may be compromised or even nullified in light of new algorithms that have successfully reidentified such data. This could increase the risk to patient data under private custodianship. We are currently in a familiar situation in which regulation and oversight risk falling behind the technologies they govern. Regulation should emphasize patient agency and consent, and should encourage increasingly sophisticated methods of data anonymization and protection.",
    "citationCount": 544,
    "pdf_filename": "2021_Privacy_and_artificial_intelligence__cha_8278c696.pdf"
  },
  "e70d609ce18cd61799b087bf3a5e14c1ce70a41a": {
    "paperId": "e70d609ce18cd61799b087bf3a5e14c1ce70a41a",
    "title": "Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey",
    "year": 2020,
    "authors": "By Lei Deng, Guoqi Li, Song Han, Luping Shi, Yuan Xie",
    "abstract": "Domain-specific hardware is becoming a promising topic in the backdrop of improvement slow down for general-purpose processors due to the foreseeable end of Moore’s Law. Machine learning, especially deep neural networks (DNNs), has become the most dazzling domain witnessing successful applications in a wide spectrum of artificial intelligence (AI) tasks. The incomparable accuracy of DNNs is achieved by paying the cost of hungry memory consumption and high computational complexity, which greatly impedes their deployment in embedded systems. Therefore, the DNN compression concept was naturally proposed and widely used for memory saving and compute acceleration. In the past few years, a tremendous number of compression techniques have sprung up to pursue a satisfactory tradeoff between processing efficiency and application accuracy. Recently, this wave has spread to the design of neural network accelerators for gaining extremely high performance. However, the amount of related works is incredibly huge and the reported approaches are quite divergent. This research chaos motivates us to provide a comprehensive survey on the recent advances toward the goal of efficient compression and execution of DNNs without significantly compromising accuracy, involving both the high-level algorithms and their applications in hardware design. In this article, we review the mainstream compression approaches such as compact model, tensor decomposition, data quantization, and network sparsification. We explain their compression principles, evaluation metrics, sensitivity analysis, and joint-way use. Then, we answer the question of how to leverage these methods in the design of neural network accelerators and present the state-of-the-art hardware architectures. In the end, we discuss several existing issues such as fair comparison, testing workloads, automatic compression, influence on security, and framework/hardware-level support, and give promising topics in this field and the possible challenges as well. This article attempts to enable readers to quickly build up a big picture of neural network compression and acceleration, clearly evaluate various methods, and confidently get started in the right way.",
    "citationCount": 830,
    "pdf_filename": "2020_Model_Compression_and_Hardware_Accelerat_e70d609c.pdf"
  },
  "c483beec0afae8d08f011182460095049025b8d1": {
    "paperId": "c483beec0afae8d08f011182460095049025b8d1",
    "title": "Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",
    "year": 2020,
    "authors": "Arun Das, P. Rad",
    "abstract": "Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.",
    "citationCount": 683,
    "pdf_filename": "2020_Opportunities_and_Challenges_in_Explaina_c483beec.pdf"
  },
  "ea9a516d5cb0b298f0df50e82b3e0400b72fcdff": {
    "paperId": "ea9a516d5cb0b298f0df50e82b3e0400b72fcdff",
    "title": "Microsoft Academic Graph: When experts are not enough",
    "year": 2020,
    "authors": "Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong",
    "abstract": "Abstract An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed.",
    "citationCount": 627,
    "pdf_filename": "2020_Microsoft_Academic_Graph__When_experts_a_ea9a516d.pdf"
  },
  "5f2c083f80073c56c41c4ea66ae48312513c55aa": {
    "paperId": "5f2c083f80073c56c41c4ea66ae48312513c55aa",
    "title": "Energy and Policy Considerations for Modern Deep Learning Research",
    "year": 2020,
    "authors": "Emma Strubell, Ananya Ganesh, A. McCallum",
    "abstract": "The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community.",
    "citationCount": 698,
    "pdf_filename": "2020_Energy_and_Policy_Considerations_for_Mod_5f2c083f.pdf"
  },
  "feeaefe8b4d6cc1a0f30c1fbd66c041399161558": {
    "paperId": "feeaefe8b4d6cc1a0f30c1fbd66c041399161558",
    "title": "Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News",
    "year": 2020,
    "authors": "Cristian Vaccari, A. Chadwick",
    "abstract": "Artificial Intelligence (AI) now enables the mass creation of what have become known as “deepfakes”: synthetic videos that closely resemble real videos. Integrating theories about the power of visual communication and the role played by uncertainty in undermining trust in public discourse, we explain the likely contribution of deepfakes to online disinformation. Administering novel experimental treatments to a large representative sample of the United Kingdom population allowed us to compare people’s evaluations of deepfakes. We find that people are more likely to feel uncertain than to be misled by deepfakes, but this resulting uncertainty, in turn, reduces trust in news on social media. We conclude that deepfakes may contribute toward generalized indeterminacy and cynicism, further intensifying recent challenges to online civic culture in democratic societies.",
    "citationCount": 613,
    "pdf_filename": "2020_Deepfakes_and_Disinformation__Exploring__feeaefe8.pdf"
  },
  "d3e63950eec7de183779702151a7d7f8279953fa": {
    "paperId": "d3e63950eec7de183779702151a7d7f8279953fa",
    "title": "Tobacco Product Use Among Adults — United States, 2019",
    "year": 2020,
    "authors": "M. Cornelius, Teresa W. Wang, Ahmed Jamal, Caitlin G. Loretan, L. Neff",
    "abstract": "Cigarette smoking remains the leading cause of preventable disease and death in the United States (1). The prevalence of current cigarette smoking among U.S. adults has declined over the past several decades, with a prevalence of 13.7% in 2018 (2). However, a variety of combustible, noncombustible, and electronic tobacco products are available in the United States (1,3). To assess recent national estimates of tobacco product use among U.S. adults aged ≥18 years, CDC analyzed data from the 2019 National Health Interview Survey (NHIS). In 2019, an estimated 50.6 million U.S. adults (20.8%) reported currently using any tobacco product, including cigarettes (14.0%), e-cigarettes (4.5%), cigars (3.6%), smokeless tobacco (2.4%), and pipes* (1.0%).† Most current tobacco product users (80.5%) reported using combustible products (cigarettes, cigars, or pipes), and 18.6% reported using two or more tobacco products.§ The prevalence of any current tobacco product use was higher among males; adults aged ≤65 years; non-Hispanic American Indian/Alaska Native (AI/AN) adults; those whose highest level of educational attainment was a General Educational Development (GED) certificate; those with an annual household income <$35,000; lesbian, gay, or bisexual (LGB) adults; uninsured adults and those with Medicaid; those with a disability; or those with mild, moderate, or severe generalized anxiety disorder. E-cigarette use was highest among adults aged 18-24 years (9.3%), with over half (56.0%) of these young adults reporting that they had never smoked cigarettes. Implementing comprehensive, evidence-based, population level interventions (e.g., tobacco price increases, comprehensive smoke-free policies, high-impact antitobacco media campaigns, and barrier-free cessation coverage), in coordination with regulation of the manufacturing, marketing, and sale of all tobacco products, can reduce tobacco-related disease and death in the United States (1,4). As part of a comprehensive approach, targeted interventions are also warranted to reach subpopulations with the highest prevalence of use, which might vary by tobacco product type.",
    "citationCount": 965,
    "pdf_filename": "2020_Tobacco_Product_Use_Among_Adults___Unite_d3e63950.pdf"
  },
  "7c7caf195c3d6cfe1939a958836e68c1dacd864b": {
    "paperId": "7c7caf195c3d6cfe1939a958836e68c1dacd864b",
    "title": "Effects of COVID-19 on hotel marketing and management: a perspective article",
    "year": 2020,
    "authors": "Yangyang Jiang, Jun Wen",
    "abstract": "This paper aims to discuss the effects of COVID-19 on hotel marketing and management practices and outlines a three-pronged research agenda to stimulate knowledge development in the hotel sector.,This paper is based on an overview of the relevant literature on hotel marketing and management and the hotel guest behavior. The authors also investigated hospitality service trends to propose a research agenda.,This paper presents a research agenda from three dimensions – artificial intelligence (AI) and robotics, hygiene and cleanliness and health and health care. First, different types of AI (mechanical, thinking and feeling) might open up distinct research streams at the intersection of health crises and hotel management, in light of the COVID-19 pandemic. Additionally, this paper recommends that researchers move beyond typical perspectives on the antecedents and outcomes of hotel hygiene and cleanliness to delve into guests’ perceptions of the cleanliness of specific hotel surfaces. Furthermore, a more in-depth analysis is warranted about the evolving relationship between hotels and the health-care sector.,The recommended research areas are intended to advance the knowledge base to help hotels recover from the COVID-19 pandemic. The suggested research streams are expected to provide actionable insights to promote the development and sustainability of the hotel sector.,This paper appears to be a frontier study, critically examining possible effects of the COVID-19 pandemic on hotel marketing and management practices and how hoteliers may respond to such challenges to recover after this pandemic.",
    "citationCount": 609,
    "pdf_filename": "2020_Effects_of_COVID_19_on_hotel_marketing_a_7c7caf19.pdf"
  },
  "5ab9776bf67a6470951a932d5f9a1beaf1cec184": {
    "paperId": "5ab9776bf67a6470951a932d5f9a1beaf1cec184",
    "title": "Consumers and Artificial Intelligence: An Experiential Perspective",
    "year": 2020,
    "authors": "S. Puntoni, R. W. Reczek, M. Giesler, Simona Botti",
    "abstract": "Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations’ investments into AI and to lay out an agenda for future research.",
    "citationCount": 638,
    "pdf_filename": "2020_Consumers_and_Artificial_Intelligence__A_5ab9776b.pdf"
  },
  "d851b4ca421100d9fe6dc0ae9cdbed816461eab9": {
    "paperId": "d851b4ca421100d9fe6dc0ae9cdbed816461eab9",
    "title": "Tobacco Product Use Among Adults — United States, 2020",
    "year": 2022,
    "authors": "M. Cornelius, Caitlin G. Loretan, Teresa W. Wang, Ahmed Jamal, D. Homa",
    "abstract": "Although cigarette smoking has declined over the past several decades, a diverse landscape of combustible and noncombustible tobacco products has emerged in the United States (1-4). To assess recent national estimates of commercial tobacco product use among U.S. adults aged ≥18 years, CDC analyzed data from the 2020 National Health Interview Survey (NHIS). In 2020, an estimated 47.1 million U.S. adults (19.0%) reported currently using any commercial tobacco product, including cigarettes (12.5%), e-cigarettes (3.7%), cigars (3.5%), smokeless tobacco (2.3%), and pipes* (1.1%).† From 2019 to 2020, the prevalence of overall tobacco product use, combustible tobacco product use, cigarettes, e-cigarettes, and use of two or more tobacco products decreased. Among those who reported current tobacco product use, 79.6% reported using combustible products (e.g., cigarettes, cigars, or pipes), and 17.3% reported using two or more tobacco products.§ The prevalence of any current commercial tobacco product use was higher among the following groups: 1) men; 2) adults aged <65 years; 3) non-Hispanic American Indian or Alaska Native (AI/AN) adults and non-Hispanic adults categorized as of \"Other\" race¶; 4) adults in rural (nonmetropolitan) areas; 5) those whose highest level of educational attainment was a general educational development certificate (GED); 6) those with an annual household income <$35,000; 7) lesbian, gay, or bisexual adults; 8) uninsured adults or those with Medicaid; 9) adults living with a disability; and 10) those who regularly had feelings of anxiety or depression. Continued monitoring of tobacco product use and tailored strategies and policies that reduce the effects of inequitable conditions could aid in reducing disparities in tobacco use (1,4).",
    "citationCount": 503,
    "pdf_filename": "2022_Tobacco_Product_Use_Among_Adults___Unite_d851b4ca.pdf"
  },
  "152ef7762980f60ad23aa6fad59aaf7df9b82df0": {
    "paperId": "152ef7762980f60ad23aa6fad59aaf7df9b82df0",
    "title": "Ethical and legal challenges of artificial intelligence-driven healthcare",
    "year": 2020,
    "authors": "S. Gerke, T. Minssen, Glenn Cohen",
    "abstract": "\n Abstract\n \n This chapter will map the ethical and legal challenges posed by artificial intelligence (AI) in healthcare and suggest directions for resolving them. Section 1 will briefly clarify what AI is and Section 2 will give an idea of the trends and strategies in the United States (US) and Europe, thereby tailoring the discussion to the ethical and legal debate of AI-driven healthcare. This will be followed in Section 3 by a discussion of four primary ethical challenges, namely, (1) informed consent to use, (2) safety and transparency, (3) algorithmic fairness and biases, and (4) data privacy. Section 4 will then analyze five legal challenges in the US and Europe: (1) safety and effectiveness, (2) liability, (3) data protection and privacy, (4) cybersecurity, and (5) intellectual property law. Finally, Section 5 will summarize the major conclusions and especially emphasize the importance of building an AI-driven healthcare system that is successful and promotes trust and the motto Health AIs for All of Us.\n \n",
    "citationCount": 647,
    "pdf_filename": "2020_Ethical_and_legal_challenges_of_artifici_152ef776.pdf"
  },
  "76b1768c4185b4b6e525e797be137964ffd46cd5": {
    "paperId": "76b1768c4185b4b6e525e797be137964ffd46cd5",
    "title": "Artificial Intelligence in Dentistry: Chances and Challenges",
    "year": 2020,
    "authors": "F. Schwendicke, W. Samek, J. Krois",
    "abstract": "The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce.",
    "citationCount": 765,
    "pdf_filename": "2020_Artificial_Intelligence_in_Dentistry__Ch_76b1768c.pdf"
  },
  "0623ccb3694aae29857890809afe5868931a98ec": {
    "paperId": "0623ccb3694aae29857890809afe5868931a98ec",
    "title": "The state of artificial intelligence-based FDA-approved medical devices and algorithms: an online database",
    "year": 2020,
    "authors": "S. Benjamens, Pranavsingh Dhunnoo, B. Meskó",
    "abstract": "At the beginning of the artificial intelligence (AI)/machine learning (ML) era, the expectations are high, and experts foresee that AI/ML shows potential for diagnosing, managing and treating a wide variety of medical conditions. However, the obstacles for implementation of AI/ML in daily clinical practice are numerous, especially regarding the regulation of these technologies. Therefore, we provide an insight into the currently available AI/ML-based medical devices and algorithms that have been approved by the US Food & Drugs Administration (FDA). We aimed to raise awareness of the importance of regulatory bodies, clearly stating whether a medical device is AI/ML based or not. Cross-checking and validating all approvals, we identified 64 AI/ML based, FDA approved medical devices and algorithms. Out of those, only 29 (45%) mentioned any AI/ML-related expressions in the official FDA announcement. The majority (85.9%) was approved by the FDA with a 510(k) clearance, while 8 (12.5%) received de novo pathway clearance and one (1.6%) premarket approval (PMA) clearance. Most of these technologies, notably 30 (46.9%), 16 (25.0%), and 10 (15.6%) were developed for the fields of Radiology, Cardiology and Internal Medicine/General Practice respectively. We have launched the first comprehensive and open access database of strictly AI/ML-based medical technologies that have been approved by the FDA. The database will be constantly updated.",
    "citationCount": 781,
    "pdf_filename": "2020_The_state_of_artificial_intelligence_bas_0623ccb3.pdf"
  },
  "17f423a5e542a4bd4de0243548e127038dea6ab5": {
    "paperId": "17f423a5e542a4bd4de0243548e127038dea6ab5",
    "title": "Bias in data‐driven artificial intelligence systems—An introductory survey",
    "year": 2020,
    "authors": "Eirini Ntoutsi, P. Fafalios, U. Gadiraju, Vasileios Iosifidis, W. Nejdl",
    "abstract": "Artificial Intelligence (AI)‐based systems are widely employed nowadays to make decisions that have far‐reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well‐grounded in a legal frame. In this survey, we focus on data‐driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth.",
    "citationCount": 798,
    "pdf_filename": "2020_Bias_in_data_driven_artificial_intellige_17f423a5.pdf"
  },
  "0b2703b3aef8987c682a5635fb9c6f250252d10e": {
    "paperId": "0b2703b3aef8987c682a5635fb9c6f250252d10e",
    "title": "Carbon Nitride Supported High-Loading Fe Single-Atom Catalyst for Activating of Peroxymonosulfate to Generate 1O2 with 100% Selectivity.",
    "year": 2021,
    "authors": "Long-Shuai Zhang, Xunheng Jiang, Zi‐Ai Zhong, Lei Tian, Qing Sun",
    "abstract": "Singlet oxygen (1O2) is an excellent active species for the selective degradation of organic pollutions. However, it is difficult to achieve high efficiency and selectivity for the generation of 1O2. In this work, we develop a graphitic carbon nitride supported Fe single-atoms catalyst (Fe1/CN) containing highly uniform Fe-N4 active sites with a high Fe loading of 11.2 wt%. The Fe1/CN achieves generation of 100% 1O2 by activating peroxymonosulfate (PMS), which shows an ultrahigh p-chlorophenol degradation efficiency. Density functional theory calculations results demonstrate that in contrast to Co and Ni single-atom sites, the Fe-N4 sites in Fe1/CN adsorb the terminal O of PMS, which can facilitate the oxidization of PMS to form SO5•-, and thereafter efficiently generate 1O2 with 100% selectivity. In addition, the Fe1/CN exhibits strong resistance to inorganic ions, natural organic matter, and pH value during the degradation of organic pollutants in the presence of PMS. This work develops a novel catalyst for the 100% selective production of 1O2 for highly selective and efficient degradation of pollutants.",
    "citationCount": 833,
    "pdf_filename": "2021_Carbon_Nitride_Supported_High_Loading_Fe_0b2703b3.pdf"
  },
  "286a3bf8579deadd9b892bb800614b7c35d5d9a6": {
    "paperId": "286a3bf8579deadd9b892bb800614b7c35d5d9a6",
    "title": "Artificial Intelligence and Business Value: a Literature Review",
    "year": 2021,
    "authors": "Ida Merete Enholm, Emmanouil Papagiannidis, Patrick Mikalef, J. Krogstie",
    "abstract": "Artificial Intelligence (AI) are a wide-ranging set of technologies that promise several advantages for organizations in terms off added business value. Over the past few years, organizations are increasingly turning to AI in order to gain business value following a deluge of data and a strong increase in computational capacity. Nevertheless, organizations are still struggling to adopt and leverage AI in their operations. The lack of a coherent understanding of how AI technologies create business value, and what type of business value is expected, therefore necessitates a holistic understanding. This study provides a systematic literature review that attempts to explain how organizations can leverage AI technologies in their operations and elucidate the value-generating mechanisms. Our analysis synthesizes the current literature and highlights: (1) the key enablers and inhibitors of AI adoption and use; (2) the typologies of AI use in the organizational setting; and (3) the first- and second-order effects of AI. The paper concludes with an identification of the gaps in the literature and develops a research agenda that identifies areas that need to be addressed by future studies.",
    "citationCount": 526,
    "pdf_filename": "2021_Artificial_Intelligence_and_Business_Val_286a3bf8.pdf"
  },
  "4043785dacd1c04ed93ec1c08ecf779f4e1717fc": {
    "paperId": "4043785dacd1c04ed93ec1c08ecf779f4e1717fc",
    "title": "A Review of Deep Learning in Medical Imaging: Imaging Traits, Technology Trends, Case Studies With Progress Highlights, and Future Promises",
    "year": 2020,
    "authors": "S. K. Zhou, H. Greenspan, C. Davatzikos, J. Duncan, B. Ginneken",
    "abstract": "Since its renaissance, deep learning (DL) has been widely used in various medical imaging tasks and has achieved remarkable success in many medical imaging applications, thereby propelling us into the so-called artificial intelligence (AI) era. It is known that the success of AI is mostly attributed to the availability of big data with annotations for a single task and the advances in high-performance computing. However, medical imaging presents unique challenges that confront DL approaches. In this survey article, we first present traits of medical imaging, highlight both clinical needs and technical challenges in medical imaging, and describe how emerging trends in DL are addressing these issues. We cover the topics of network architecture, sparse and noisy labels, federating learning, interpretability, uncertainty quantification, and so on. Then, we present several case studies that are commonly found in clinical practice, including digital pathology and chest, brain, cardiovascular, and abdominal imaging. Rather than presenting an exhaustive literature survey, we instead describe some prominent research highlights related to these case study applications. We conclude with a discussion and presentation of promising future directions.",
    "citationCount": 791,
    "pdf_filename": "2020_A_Review_of_Deep_Learning_in_Medical_Ima_4043785d.pdf"
  },
  "5fb1ddd3c37597138795e7b0f0c3641239cf21f7": {
    "paperId": "5fb1ddd3c37597138795e7b0f0c3641239cf21f7",
    "title": "Machine Learning in Predictive Maintenance towards Sustainable Smart Manufacturing in Industry 4.0",
    "year": 2020,
    "authors": "Z. Çınar, Abubakar Abdussalam Nuhu, Q. Zeeshan, Orhan Korhan, M.B.A Asmael",
    "abstract": "Recently, with the emergence of Industry 4.0 (I4.0), smart systems, machine learning (ML) within artificial intelligence (AI), predictive maintenance (PdM) approaches have been extensively applied in industries for handling the health status of industrial equipment. Due to digital transformation towards I4.0, information techniques, computerized control, and communication networks, it is possible to collect massive amounts of operational and processes conditions data generated form several pieces of equipment and harvest data for making an automated fault detection and diagnosis with the aim to minimize downtime and increase utilization rate of the components and increase their remaining useful lives. PdM is inevitable for sustainable smart manufacturing in I4.0. Machine learning (ML) techniques have emerged as a promising tool in PdM applications for smart manufacturing in I4.0, thus it has increased attraction of authors during recent years. This paper aims to provide a comprehensive review of the recent advancements of ML techniques widely applied to PdM for smart manufacturing in I4.0 by classifying the research according to the ML algorithms, ML category, machinery, and equipment used, device used in data acquisition, classification of data, size and type, and highlight the key contributions of the researchers, and thus offers guidelines and foundation for further research.",
    "citationCount": 573,
    "pdf_filename": "2020_Machine_Learning_in_Predictive_Maintenan_5fb1ddd3.pdf"
  },
  "a025ad05916ddf3281a2bca0cdffbaed99a2c9dd": {
    "paperId": "a025ad05916ddf3281a2bca0cdffbaed99a2c9dd",
    "title": "Federated Learning Meets Blockchain in Edge Computing: Opportunities and Challenges",
    "year": 2021,
    "authors": "Dinh C. Nguyen, Ming Ding, Viet Quoc Pham, P. Pathirana, Long Bao",
    "abstract": "Mobile-edge computing (MEC) has been envisioned as a promising paradigm to handle the massive volume of data generated from ubiquitous mobile devices for enabling intelligent services with the help of artificial intelligence (AI). Traditionally, AI techniques often require centralized data collection and training in a single entity, e.g., an MEC server, which is now becoming a weak point due to data privacy concerns and high overhead of raw data communications. In this context, federated learning (FL) has been proposed to provide collaborative data training solutions, by coordinating multiple mobile devices to train a shared AI model without directly exposing their underlying data, which enjoys considerable privacy enhancement. To improve the security and scalability of FL implementation, blockchain as a ledger technology is attractive for realizing decentralized FL training without the need for any central server. Particularly, the integration of FL and blockchain leads to a new paradigm, called FLchain, which potentially transforms intelligent MEC networks into decentralized, secure, and privacy-enhancing systems. This article presents an overview of the fundamental concepts and explores the opportunities of FLchain in MEC networks. We identify several main issues in FLchain design, including communication cost, resource allocation, incentive mechanism, security and privacy protection. The key solutions and the lessons learned along with the outlooks are also discussed. Then, we investigate the applications of FLchain in popular MEC domains, such as edge data sharing, edge content caching and edge crowdsensing. Finally, important research challenges and future directions are also highlighted.",
    "citationCount": 520,
    "pdf_filename": "2021_Federated_Learning_Meets_Blockchain_in_E_a025ad05.pdf"
  },
  "b5b98051b65da6b1b3b579862b0407d48c5bef48": {
    "paperId": "b5b98051b65da6b1b3b579862b0407d48c5bef48",
    "title": "Principles and Practice of Explainable Machine Learning",
    "year": 2020,
    "authors": "Vaishak Belle, I. Papantonis",
    "abstract": "Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.",
    "citationCount": 516,
    "pdf_filename": "2020_Principles_and_Practice_of_Explainable_M_b5b98051.pdf"
  },
  "6178542e6905055c5ac7a3e9f2a3d0a3641e4124": {
    "paperId": "6178542e6905055c5ac7a3e9f2a3d0a3641e4124",
    "title": "XGBoost Model for Chronic Kidney Disease Diagnosis",
    "year": 2020,
    "authors": "Adeola Ogunleye, Qing-Guo Wang",
    "abstract": "Chronic Kidney Disease (CKD) is a menace that is affecting 10 percent of the world population and 15 percent of the South African population. The early and cheap diagnosis of this disease with accuracy and reliability will save 20,000 lives in South Africa per year. Scientists are developing smart solutions with Artificial Intelligence (AI). In this paper, several typical and recent AI algorithms are studied in the context of CKD and the extreme gradient boosting (XGBoost) is chosen as our base model for its high performance. Then, the model is optimized and the optimal full model trained on all the features achieves a testing accuracy, sensitivity, and specificity of 1.000, 1.000, and 1.000, respectively. Note that, to cover the widest range of people, the time and monetary costs of CKD diagnosis have to be minimized with fewest patient tests. Thus, the reduced model using fewer features is desirable while it should still maintain high performance. To this end, the set-theory based rule is presented which combines a few feature selection methods with their collective strengths. The reduced model using about a half of the original full features performs better than the models based on individual feature selection methods and achieves accuracy, sensitivity and specificity, of 1.000, 1.000, and 1.000, respectively.",
    "citationCount": 553,
    "pdf_filename": "2020_XGBoost_Model_for_Chronic_Kidney_Disease_6178542e.pdf"
  },
  "efcc84bc5542453001483bc9c81c7d4c6c409b80": {
    "paperId": "efcc84bc5542453001483bc9c81c7d4c6c409b80",
    "title": "The Future of Healthcare Internet of Things: A Survey of Emerging Technologies",
    "year": 2020,
    "authors": "Yazdan Ahmad Qadri, Alissa Nauman, Y. B. Zikria, A. Vasilakos, S. Kim",
    "abstract": "The impact of the Internet of Things (IoT) on the advancement of the healthcare industry is immense. The ushering of the Medicine 4.0 has resulted in an increased effort to develop platforms, both at the hardware level as well as the underlying software level. This vision has led to the development of Healthcare IoT (H-IoT) systems. The basic enabling technologies include the communication systems between the sensing nodes and the processors; and the processing algorithms for generating an output from the data collected by the sensors. However, at present, these enabling technologies are also supported by several new technologies. The use of Artificial Intelligence (AI) has transformed the H-IoT systems at almost every level. The fog/edge paradigm is bringing the computing power close to the deployed network and hence mitigating many challenges in the process. While the big data allows handling an enormous amount of data. Additionally, the Software Defined Networks (SDNs) bring flexibility to the system while the blockchains are finding the most novel use cases in H-IoT systems. The Internet of Nano Things (IoNT) and Tactile Internet (TI) are driving the innovation in the H-IoT applications. This paper delves into the ways these technologies are transforming the H-IoT systems and also identifies the future course for improving the Quality of Service (QoS) using these new technologies.",
    "citationCount": 562,
    "pdf_filename": "2020_The_Future_of_Healthcare_Internet_of_Thi_efcc84bc.pdf"
  },
  "85efad9b06541cf19f095efd177bf849856755b3": {
    "paperId": "85efad9b06541cf19f095efd177bf849856755b3",
    "title": "Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis",
    "year": 2020,
    "authors": "Agostina J. Larrazabal, Nicolás Nieto, Victoria Peterson, Diego H. Milone, Enzo Ferrante",
    "abstract": "Artificial intelligence (AI) systems for computer-aided diagnosis and image-based screening are being adopted worldwide by medical institutions. In such a context, generating fair and unbiased classifiers becomes of paramount importance. The research community of medical image computing is making great efforts in developing more accurate algorithms to assist medical doctors in the difficult task of disease diagnosis. However, little attention is paid to the way databases are collected and how this may influence the performance of AI systems. Our study sheds light on the importance of gender balance in medical imaging datasets used to train AI systems for computer-assisted diagnosis. We provide empirical evidence supported by a large-scale study, based on three deep neural network architectures and two well-known publicly available X-ray image datasets used to diagnose various thoracic diseases under different gender imbalance conditions. We found a consistent decrease in performance for underrepresented genders when a minimum balance is not fulfilled. This raises the alarm for national agencies in charge of regulating and approving computer-assisted diagnosis systems, which should include explicit gender balance and diversity recommendations. We also establish an open problem for the academic medical image computing community which needs to be addressed by novel algorithms endowed with robustness to gender imbalance.",
    "citationCount": 540,
    "pdf_filename": "2020_Gender_imbalance_in_medical_imaging_data_85efad9b.pdf"
  },
  "a25e4e4f1534e9d7ec2c15edbec3c18bfc4d92fe": {
    "paperId": "a25e4e4f1534e9d7ec2c15edbec3c18bfc4d92fe",
    "title": "The impact of artificial intelligence on learner–instructor interaction in online learning",
    "year": 2021,
    "authors": "Kyoungwon Seo, Joice Tang, Ido Roll, Sidney S. Fels, Dongwook Yoon",
    "abstract": "Artificial intelligence (AI) systems offer effective support for online learning and teaching, including personalizing learning for students, automating instructors’ routine tasks, and powering adaptive assessments. However, while the opportunities for AI are promising, the impact of AI systems on the culture of, norms in, and expectations about interactions between students and instructors are still elusive. In online learning, learner–instructor interaction (inter alia, communication, support, and presence) has a profound impact on students’ satisfaction and learning outcomes. Thus, identifying how students and instructors perceive the impact of AI systems on their interaction is important to identify any gaps, challenges, or barriers preventing AI systems from achieving their intended potential and risking the safety of these interactions. To address this need for forward-looking decisions, we used Speed Dating with storyboards to analyze the authentic voices of 12 students and 11 instructors on diverse use cases of possible AI systems in online learning. Findings show that participants envision adopting AI systems in online learning can enable personalized learner–instructor interaction at scale but at the risk of violating social boundaries. Although AI systems have been positively recognized for improving the quantity and quality of communication, for providing just-in-time, personalized support for large-scale settings, and for improving the feeling of connection, there were concerns about responsibility, agency, and surveillance issues. These findings have implications for the design of AI systems to ensure explainability, human-in-the-loop, and careful data collection and presentation. Overall, contributions of this study include the design of AI system storyboards which are technically feasible and positively support learner–instructor interaction, capturing students’ and instructors’ concerns of AI systems through Speed Dating, and suggesting practical implications for maximizing the positive impact of AI systems while minimizing the negative ones.",
    "citationCount": 501,
    "pdf_filename": "2021_The_impact_of_artificial_intelligence_on_a25e4e4f.pdf"
  },
  "719eabcd265a3280e3ec36f38b45fb5668d77403": {
    "paperId": "719eabcd265a3280e3ec36f38b45fb5668d77403",
    "title": "Haptic-feedback smart glove as a creative human-machine interface (HMI) for virtual/augmented reality applications",
    "year": 2020,
    "authors": "Minglu Zhu, Zhongda Sun, Zixuan Zhang, Qiongfeng Shi, Tianyiyi He",
    "abstract": "A haptic-feedback glove with triboelectric sensors and piezoelectric stimulators is developed for interaction in virtual space. Human-machine interfaces (HMIs) experience increasing requirements for intuitive and effective manipulation. Current commercialized solutions of glove-based HMI are limited by either detectable motions or the huge cost on fabrication, energy, and computing power. We propose the haptic-feedback smart glove with triboelectric-based finger bending sensors, palm sliding sensor, and piezoelectric mechanical stimulators. The detection of multidirectional bending and sliding events is demonstrated in virtual space using the self-generated triboelectric signals for various degrees of freedom on human hand. We also perform haptic mechanical stimulation via piezoelectric chips to realize the augmented HMI. The smart glove achieves object recognition using machine learning technique, with an accuracy of 96%. Through the integrated demonstration of multidimensional manipulation, haptic feedback, and AI-based object recognition, our glove reveals its potential as a promising solution for low-cost and advanced human-machine interaction, which can benefit diversified areas, including entertainment, home healthcare, sports training, and medical industry.",
    "citationCount": 609,
    "pdf_filename": "2020_Haptic_feedback_smart_glove_as_a_creativ_719eabcd.pdf"
  },
  "3e3df220673388402b6b114eab68a9c5396210b1": {
    "paperId": "3e3df220673388402b6b114eab68a9c5396210b1",
    "title": "Empowering Things With Intelligence: A Survey of the Progress, Challenges, and Opportunities in Artificial Intelligence of Things",
    "year": 2020,
    "authors": "Jing Zhang, D. Tao",
    "abstract": "In the Internet-of-Things (IoT) era, billions of sensors and devices collect and process data from the environment, transmit them to cloud centers, and receive feedback via the Internet for connectivity and perception. However, transmitting massive amounts of heterogeneous data, perceiving complex environments from these data, and then making smart decisions in a timely manner are difficult. Artificial intelligence (AI), especially deep learning, is now a proven success in various areas, including computer vision, speech recognition, and natural language processing. AI introduced into the IoT heralds the era of AI of things (AIoT). This article presents a comprehensive survey on AIoT to show how AI can empower the IoT to make it faster, smarter, greener, and safer. Specifically, we briefly present the AIoT architecture in the context of cloud computing, fog computing, and edge computing. Then, we present progress in AI research for IoT from four perspectives: 1) perceiving; 2) learning; 3) reasoning; and 4) behaving. Next, we summarize some promising applications of AIoT that are likely to profoundly reshape our world. Finally, we highlight the challenges facing AIoT and some potential research opportunities.",
    "citationCount": 545,
    "pdf_filename": "2020_Empowering_Things_With_Intelligence__A_S_3e3df220.pdf"
  },
  "b6b7fea1846e85ac1e3c7e3adda6e65b127d0368": {
    "paperId": "b6b7fea1846e85ac1e3c7e3adda6e65b127d0368",
    "title": "IoT, Big Data, and Artificial Intelligence in Agriculture and Food Industry",
    "year": 2020,
    "authors": "N. Misra, Ahmad Al-Mallahi, A. Martynenko, Manreet Bhullar, R. Upadhyay",
    "abstract": "Internet of Things (IoT) results in a massive amount of streaming data, often referred to as “big data,” which brings new opportunities to monitor agricultural and food processes. Besides sensors, big data from social media is also becoming important for the food industry. In this review, we present an overview of IoT, big data, and artificial intelligence (AI), and their disruptive role in shaping the future of agri-food systems. Following an introduction to the fields of IoT, big data, and AI, we discuss the role of IoT and big data analysis in agriculture (including greenhouse monitoring, intelligent farm machines, and drone-based crop imaging), supply chain modernization, social media (for open innovation and sentiment analysis) in food industry, food quality assessment (using spectral methods and sensor fusion), and finally, food safety (using gene sequencing and blockchain-based digital traceability). A special emphasis is laid on the commercial status of applications and translational research outcomes.",
    "citationCount": 537,
    "pdf_filename": "2020_IoT__Big_Data__and_Artificial_Intelligen_b6b7fea1.pdf"
  },
  "fccecba3e77aaf4889ae9dab1f3b31d89f7aebf2": {
    "paperId": "fccecba3e77aaf4889ae9dab1f3b31d89f7aebf2",
    "title": "A compute-in-memory chip based on resistive random-access memory",
    "year": 2022,
    "authors": "W. Wan, R. Kubendran, Clemens J. S. Schaefer, S. Eryilmaz, Wenqiang Zhang",
    "abstract": "Realizing increasingly complex artificial intelligence (AI) functionalities directly on edge devices calls for unprecedented energy efficiency of edge hardware. Compute-in-memory (CIM) based on resistive random-access memory (RRAM)1 promises to meet such demand by storing AI model weights in dense, analogue and non-volatile RRAM devices, and by performing AI computation directly within RRAM, thus eliminating power-hungry data movement between separate compute and memory2–5. Although recent studies have demonstrated in-memory matrix-vector multiplication on fully integrated RRAM-CIM hardware6–17, it remains a goal for a RRAM-CIM chip to simultaneously deliver high energy efficiency, versatility to support diverse models and software-comparable accuracy. Although efficiency, versatility and accuracy are all indispensable for broad adoption of the technology, the inter-related trade-offs among them cannot be addressed by isolated improvements on any single abstraction level of the design. Here, by co-optimizing across all hierarchies of the design from algorithms and architecture to circuits and devices, we present NeuRRAM—a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures, energy efficiency that is two-times better than previous state-of-the-art RRAM-CIM chips across various computational bit-precisions, and inference accuracy comparable to software models quantized to four-bit weights across various AI tasks, including accuracy of 99.0 percent on MNIST18 and 85.7 percent on CIFAR-1019 image classification, 84.7-percent accuracy on Google speech command recognition20, and a 70-percent reduction in image-reconstruction error on a Bayesian image-recovery task. A compute-in-memory neural-network inference accelerator based on resistive random-access memory simultaneously improves energy efficiency, flexibility and accuracy compared with existing hardware by co-optimizing across all hierarchies of the design.",
    "citationCount": 636,
    "pdf_filename": "2022_A_compute_in_memory_chip_based_on_resist_fccecba3.pdf"
  },
  "7345f9493fc0eba1e8ccd1d7352394848952baa6": {
    "paperId": "7345f9493fc0eba1e8ccd1d7352394848952baa6",
    "title": "Artificial Neural Networks Based Optimization Techniques: A Review",
    "year": 2021,
    "authors": "Maher G. M. Abdolrasol, S. Hussain, T. Ustun, M. R. Sarker, M. Hannan",
    "abstract": "In the last few years, intensive research has been done to enhance artificial intelligence (AI) using optimization techniques. In this paper, we present an extensive review of artificial neural networks (ANNs) based optimization algorithm techniques with some of the famous optimization techniques, e.g., genetic algorithm (GA), particle swarm optimization (PSO), artificial bee colony (ABC), and backtracking search algorithm (BSA) and some modern developed techniques, e.g., the lightning search algorithm (LSA) and whale optimization algorithm (WOA), and many more. The entire set of such techniques is classified as algorithms based on a population where the initial population is randomly created. Input parameters are initialized within the specified range, and they can provide optimal solutions. This paper emphasizes enhancing the neural network via optimization algorithms by manipulating its tuned parameters or training parameters to obtain the best structure network pattern to dissolve the problems in the best way. This paper includes some results for improving the ANN performance by PSO, GA, ABC, and BSA optimization techniques, respectively, to search for optimal parameters, e.g., the number of neurons in the hidden layers and learning rate. The obtained neural net is used for solving energy management problems in the virtual power plant system.",
    "citationCount": 548,
    "pdf_filename": "2021_Artificial_Neural_Networks_Based_Optimiz_7345f949.pdf"
  },
  "f3b684f3d2ddd29134c842f6d31664157703a089": {
    "paperId": "f3b684f3d2ddd29134c842f6d31664157703a089",
    "title": "Threats to Federated Learning: A Survey",
    "year": 2020,
    "authors": "Lingjuan Lyu, Han Yu, Qiang Yang",
    "abstract": "With the emergence of data silos and popular privacy awareness, the traditional centralized approach of training artificial intelligence (AI) models is facing strong challenges. Federated learning (FL) has recently emerged as a promising solution under this new reality. Existing FL protocol design has been shown to exhibit vulnerabilities which can be exploited by adversaries both within and without the system to compromise data privacy. It is thus of paramount importance to make FL system designers to be aware of the implications of future FL algorithm design on privacy-preservation. Currently, there is no survey on this topic. In this paper, we bridge this important gap in FL literature. By providing a concise introduction to the concept of FL, and a unique taxonomy covering threat models and two major attacks on FL: 1) poisoning attacks and 2) inference attacks, this paper provides an accessible review of this important topic. We highlight the intuitions, key techniques as well as fundamental assumptions adopted by various attacks, and discuss promising future research directions towards more robust privacy preservation in FL.",
    "citationCount": 500,
    "pdf_filename": "2020_Threats_to_Federated_Learning__A_Survey_f3b684f3.pdf"
  },
  "de8ac25e552dbbb57f28e39a98f6eb27c93cf3bd": {
    "paperId": "de8ac25e552dbbb57f28e39a98f6eb27c93cf3bd",
    "title": "False negative of RT‐PCR and prolonged nucleic acid conversion in COVID‐19: Rather than recurrence",
    "year": 2020,
    "authors": "Ai Tang Xiao, Y. Tong, S. Zhang",
    "abstract": "A novel coronavirus (COVID-19) pandemic cause by Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) threatens the world. We read with interest the recent report by Li et al. that included 610 patients with Coronavirus Disease 2019 (COVID-19). They reported a high false-negative rate of real-time reverse transcription polymerase chain reaction (RT-PCR) results for SARS-CoV-2 detection. In addition, recent report regarding SARS-CoV-2 \"turn positive\" in recovered cases with COVID-19 were published. Here, we studied the characteristics of nucleic acid conversion for SARS-CoV-2 from 70 COVID-19 patients. We found that 15 (21.4%) patients experienced a \"turn positive\" of nucleic acid detection by RT-PCR test for SARS-CoV-2 after two consecutive negative results, which may be related to the false negative of RT-PCR test and prolonged nucleic acid conversion This article is protected by copyright. All rights reserved.",
    "citationCount": 529,
    "pdf_filename": "2020_False_negative_of_RT_PCR_and_prolonged_n_de8ac25e.pdf"
  },
  "082353d332c39840be2d4af46c8fb23194a34c23": {
    "paperId": "082353d332c39840be2d4af46c8fb23194a34c23",
    "title": "A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy",
    "year": 2020,
    "authors": "Emma Beede, E. Baylor, Fred Hersch, A. Iurchenko, Lauren Wilcox",
    "abstract": "Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.",
    "citationCount": 540,
    "pdf_filename": "2020_A_Human_Centered_Evaluation_of_a_Deep_Le_082353d3.pdf"
  },
  "22ab01ce4d468a129cb4eda61937b534ea073923": {
    "paperId": "22ab01ce4d468a129cb4eda61937b534ea073923",
    "title": "Emerging Electrochromic Materials and Devices for Future Displays",
    "year": 2022,
    "authors": "Chang Gu, Ai-Bo Jia, Yu‐Mo Zhang, Sean Xiao‐An Zhang",
    "abstract": "With the rapid development of optoelectronic fields, electrochromic (EC) materials and devices have received remarkable attention and have shown attractive potential for use in emerging wearable and portable electronics, electronic papers/billboards, see-through displays, and other new-generation displays, due to the advantages of low power consumption, easy viewing, flexibility, stretchability, etc. Despite continuous progress in related fields, determining how to make electrochromics truly meet the requirements of mature displays (e.g., ideal overall performance) has been a long-term problem. Therefore, the commercialization of relevant high-quality products is still in its infancy. In this review, we will focus on the progress in emerging EC materials and devices for potential displays, including two mainstream EC display prototypes (segmented displays and pixel displays) and their commercial applications. Among these topics, the related materials/devices, EC performance, construction approaches, and processing techniques are comprehensively disscussed and reviewed. We also outline the current barriers with possible solutions and discuss the future of this field.",
    "citationCount": 500,
    "pdf_filename": "2022_Emerging_Electrochromic_Materials_and_De_22ab01ce.pdf"
  },
  "6303e323126e3605429fc3803a4b578d6695e841": {
    "paperId": "6303e323126e3605429fc3803a4b578d6695e841",
    "title": "Artificial Intelligence in Utilitarian vs. Hedonic Contexts: The “Word-of-Machine” Effect",
    "year": 2020,
    "authors": "Chiara Longoni, Luca Cian",
    "abstract": "Rapid development and adoption of AI, machine learning, and natural language processing applications challenge managers and policy makers to harness these transformative technologies. In this context, the authors provide evidence of a novel “word-of-machine” effect, the phenomenon by which utilitarian/hedonic attribute trade-offs determine preference for, or resistance to, AI-based recommendations compared with traditional word of mouth, or human-based recommendations. The word-of-machine effect stems from a lay belief that AI recommenders are more competent than human recommenders in the utilitarian realm and less competent than human recommenders in the hedonic realm. As a consequence, importance or salience of utilitarian attributes determine preference for AI recommenders over human ones, and importance or salience of hedonic attributes determine resistance to AI recommenders over human ones (Studies 1–4). The word-of machine effect is robust to attribute complexity, number of options considered, and transaction costs. The word-of-machine effect reverses for utilitarian goals if a recommendation needs matching to a person’s unique preferences (Study 5) and is eliminated in the case of human–AI hybrid decision making (i.e., augmented rather than artificial intelligence; Study 6). An intervention based on the consider-the-opposite protocol attenuates the word-of-machine effect (Studies 7a–b).",
    "citationCount": 515,
    "pdf_filename": "2020_Artificial_Intelligence_in_Utilitarian_v_6303e323.pdf"
  },
  "77a2f5515b8957163bc64d408af5683f650c3573": {
    "paperId": "77a2f5515b8957163bc64d408af5683f650c3573",
    "title": "Innovation and Design in the Age of Artificial Intelligence",
    "year": 2020,
    "authors": "R. Verganti, Luca Vendraminelli, M. Iansiti",
    "abstract": "At the heart of any innovation process lies a fundamental practice: the way people create ideas and solve problems. This “decision making” side of innovation is what scholars and practitioners refer to as “design.” Decisions in innovation processes have so far been taken by humans. What happens when they can be substituted by machines? Artificial Intelligence (AI) brings data and algorithms to the core of the innovation processes. What are the implications of this diffusion of AI for our understanding of design and innovation? Is AI just another digital technology that, akin to many others, will not significantly question what we know about design? Or will it create transformations in design that current theoretical frameworks cannot capture? This paper proposes a framework for understanding the design and innovation in the age of AI. We discuss the implications for design and innovation theory. Specifically, we observe that, as creative problem-solving is significantly conducted by algorithms, human design increasingly becomes an activity of sensemaking, that is, understanding which problems should or could be addressed. This shift in focus calls for the new theories and brings design closer to leadership, which is, inherently, an activity of sensemaking. Our insights are derived from and illustrated with two cases at the frontier of AI—Netflix and Airbnb (com-plemented with analyses of Microsoft and Tesla)—which point to two directions for the evolution of design and innovation in firms. First, AI enables an organization to overcome many past limitations of human-intensive design processes, by improving the scalability of the process, broadening its scope across traditional boundaries, and en-hancing its ability to learn and adapt on the fly. Second, and maybe more surprising, while removing these limitations, AI also appears to deeply enact several popular design principles. AI thus reinforces the principles of Design Thinking, namely: being people-centered, abductive, and iterative. In fact, AI enables the creation of solutions that are more highly user centered than human-based approaches (i.e., to an extreme level of granularity, designed for every single person); that are potentially more creative; and that are continuously updated through learning iterations across the entire product life cycle. In sum, while AI does not undermine the basic principles of design, it profoundly changes the practice of design. Problem-solving tasks, traditionally carried out by designers, are now automated into learning loops that operate without limitations of volume and speed. The algorithms embedded in these loops think in a radically different way than a designer who handles the complex problems holistically with a systemic perspective. Algorithms instead han-dle complexity through very simple tasks, which are iterated continuously. This paper discusses the implications of these insights for design and innovation management scholars and practitioners.",
    "citationCount": 501,
    "pdf_filename": "2020_Innovation_and_Design_in_the_Age_of_Arti_77a2f551.pdf"
  },
  "96cdfbd9440b87a85994ba8c074bd5184ab54dd2": {
    "paperId": "96cdfbd9440b87a85994ba8c074bd5184ab54dd2",
    "title": "Change Detection Based on Artificial Intelligence: State-of-the-Art and Challenges",
    "year": 2020,
    "authors": "W. Shi, Min Zhang, Rui Zhang, S. Chen, Zhao Zhan",
    "abstract": "Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth’s surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field.",
    "citationCount": 519,
    "pdf_filename": "2020_Change_Detection_Based_on_Artificial_Int_96cdfbd9.pdf"
  },
  "d9a34cd562e936a9722c75c34cb2f13078c91cd4": {
    "paperId": "d9a34cd562e936a9722c75c34cb2f13078c91cd4",
    "title": "Deep learning in cancer pathology: a new generation of clinical biomarkers",
    "year": 2020,
    "authors": "A. Echle, Niklas Rindtorff, T. Brinker, Tom Luedde, A. Pearson",
    "abstract": "Clinical workflows in oncology rely on predictive and prognostic molecular biomarkers. However, the growing number of these complex biomarkers tends to increase the cost and time for decision-making in routine daily oncology practice; furthermore, biomarkers often require tumour tissue on top of routine diagnostic material. Nevertheless, routinely available tumour tissue contains an abundance of clinically relevant information that is currently not fully exploited. Advances in deep learning (DL), an artificial intelligence (AI) technology, have enabled the extraction of previously hidden information directly from routine histology images of cancer, providing potentially clinically useful information. Here, we outline emerging concepts of how DL can extract biomarkers directly from histology images and summarise studies of basic and advanced image analysis for cancer histology. Basic image analysis tasks include detection, grading and subtyping of tumour tissue in histology images; they are aimed at automating pathology workflows and consequently do not immediately translate into clinical decisions. Exceeding such basic approaches, DL has also been used for advanced image analysis tasks, which have the potential of directly affecting clinical decision-making processes. These advanced approaches include inference of molecular features, prediction of survival and end-to-end prediction of therapy response. Predictions made by such DL systems could simplify and enrich clinical decision-making, but require rigorous external validation in clinical settings.",
    "citationCount": 518,
    "pdf_filename": "2020_Deep_learning_in_cancer_pathology__a_new_d9a34cd5.pdf"
  },
  "c3df199cbca74763c4ae9889409bbd4aa29b6255": {
    "paperId": "c3df199cbca74763c4ae9889409bbd4aa29b6255",
    "title": "Deep learning-enabled medical computer vision",
    "year": 2021,
    "authors": "A. Esteva, Katherine Chou, Serena Yeung, N. Naik, Ali Madani",
    "abstract": "A decade of unprecedented progress in artificial intelligence (AI) has demonstrated the potential for many fields—including medicine—to benefit from the insights that AI techniques can extract from data. Here we survey recent progress in the development of modern computer vision techniques—powered by deep learning—for medical applications, focusing on medical imaging, medical video, and clinical deployment. We start by briefly summarizing a decade of progress in convolutional neural networks, including the vision tasks they enable, in the context of healthcare. Next, we discuss several example medical imaging applications that stand to benefit—including cardiology, pathology, dermatology, ophthalmology–and propose new avenues for continued work. We then expand into general medical video, highlighting ways in which clinical workflows can integrate computer vision to enhance care. Finally, we discuss the challenges and hurdles required for real-world clinical deployment of these technologies.",
    "citationCount": 968,
    "pdf_filename": "2021_Deep_learning_enabled_medical_computer_v_c3df199c.pdf"
  },
  "3893783a815a5d46a26f154683115d4195b1b004": {
    "paperId": "3893783a815a5d46a26f154683115d4195b1b004",
    "title": "Preparing Medical Imaging Data for Machine Learning.",
    "year": 2020,
    "authors": "M. Willemink, W. A. Koszek, Cailin Hardell, Jie Wu, D. Fleischmann",
    "abstract": "Artificial intelligence (AI) continues to garner substantial interest in medical imaging. The potential applications are vast and include the entirety of the medical imaging life cycle from image creation to diagnosis to outcome prediction. The chief obstacles to development and clinical implementation of AI algorithms include availability of sufficiently large, curated, and representative training data that includes expert labeling (eg, annotations). Current supervised AI methods require a curation process for data to optimally train, validate, and test algorithms. Currently, most research groups and industry have limited data access based on small sample sizes from small geographic areas. In addition, the preparation of data is a costly and time-intensive process, the results of which are algorithms with limited utility and poor generalization. In this article, the authors describe fundamental steps for preparing medical imaging data in AI algorithm development, explain current limitations to data curation, and explore new approaches to address the problem of data availability.",
    "citationCount": 781,
    "pdf_filename": "2020_Preparing_Medical_Imaging_Data_for_Machi_3893783a.pdf"
  },
  "d457f7760237df1f147ad0075b34f38711bc74d3": {
    "paperId": "d457f7760237df1f147ad0075b34f38711bc74d3",
    "title": "Federated Learning for Smart Healthcare: A Survey",
    "year": 2021,
    "authors": "Dinh C. Nguyen, Viet Quoc Pham, P. Pathirana, Ming Ding, A. Seneviratne",
    "abstract": "Recent advances in communication technologies and the Internet-of-Medical-Things (IOMT) have transformed smart healthcare enabled by artificial intelligence (AI). Traditionally, AI techniques require centralized data collection and processing that may be infeasible in realistic healthcare scenarios due to the high scalability of modern healthcare networks and growing data privacy concerns. Federated Learning (FL), as an emerging distributed collaborative AI paradigm, is particularly attractive for smart healthcare, by coordinating multiple clients (e.g., hospitals) to perform AI training without sharing raw data. Accordingly, we provide a comprehensive survey on the use of FL in smart healthcare. First, we present the recent advances in FL, the motivations, and the requirements of using FL in smart healthcare. The recent FL designs for smart healthcare are then discussed, ranging from resource-aware FL, secure and privacy-aware FL to incentive FL and personalized FL. Subsequently, we provide a state-of-the-art review on the emerging applications of FL in key healthcare domains, including health data management, remote health monitoring, medical imaging, and COVID-19 detection. Several recent FL-based smart healthcare projects are analyzed, and the key lessons learned from the survey are also highlighted. Finally, we discuss interesting research challenges and possible directions for future FL research in smart healthcare.",
    "citationCount": 707,
    "pdf_filename": "2021_Federated_Learning_for_Smart_Healthcare__d457f776.pdf"
  },
  "256db9dba1978f004a67c86ffc321563b1aee79a": {
    "paperId": "256db9dba1978f004a67c86ffc321563b1aee79a",
    "title": "Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges",
    "year": 2021,
    "authors": "C. Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova",
    "abstract": "Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the\"Rashomon set\"of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.",
    "citationCount": 829,
    "pdf_filename": "2021_Interpretable_Machine_Learning__Fundamen_256db9db.pdf"
  },
  "69d49a06f09cf934310ccbf3bb2a360fa719272d": {
    "paperId": "69d49a06f09cf934310ccbf3bb2a360fa719272d",
    "title": "Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans",
    "year": 2020,
    "authors": "M. Roberts, D. Driggs, Matthew Thorpe, J. Gilbey, Michael Yeung",
    "abstract": "Machine learning methods offer great promise for fast and accurate detection and prognostication of coronavirus disease 2019 (COVID-19) from standard-of-care chest radiographs (CXR) and chest computed tomography (CT) images. Many articles have been published in 2020 describing new machine learning-based models for both of these tasks, but it is unclear which are of potential clinical utility. In this systematic review, we consider all published papers and preprints, for the period from 1 January 2020 to 3 October 2020, which describe new machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images. All manuscripts uploaded to bioRxiv, medRxiv and arXiv along with all entries in EMBASE and MEDLINE in this timeframe are considered. Our search identified 2,212 studies, of which 415 were included after initial screening and, after quality screening, 62 studies were included in this systematic review. Our review finds that none of the models identified are of potential clinical use due to methodological flaws and/or underlying biases. This is a major weakness, given the urgency with which validated COVID-19 models are needed. To address this, we give many recommendations which, if followed, will solve these issues and lead to higher-quality model development and well-documented manuscripts. Many machine learning-based approaches have been developed for the prognosis and diagnosis of COVID-19 from medical images and this Analysis identifies over 2,200 relevant published papers and preprints in this area. After initial screening, 62 studies are analysed and the authors find they all have methodological flaws standing in the way of clinical utility. The authors have several recommendations to address these issues.",
    "citationCount": 821,
    "pdf_filename": "2020_Common_pitfalls_and_recommendations_for__69d49a06.pdf"
  },
  "2262e6f2c53efa9ce8ac04e6c3229523c3a08462": {
    "paperId": "2262e6f2c53efa9ce8ac04e6c3229523c3a08462",
    "title": "Hartree-Fock on a superconducting qubit quantum computer",
    "year": 2020,
    "authors": "F. Arute, K. Arya, R. Babbush, D. Bacon, J. Bardin",
    "abstract": "Twelve-qubit quantum computing for chemistry Accurate electronic structure calculations are considered one of the most anticipated applications of quantum computing that will revolutionize theoretical chemistry and other related fields. Using the Google Sycamore quantum processor, Google AI Quantum and collaborators performed a variational quantum eigensolver (VQE) simulation of two intermediate-scale chemistry problems: the binding energy of hydrogen chains (as large as H12) and the isomerization mechanism of diazene (see the Perspective by Yuan). The simulations were performed on up to 12 qubits, involving up to 72 two-qubit gates, and show that it is possible to achieve chemical accuracy when VQE is combined with error mitigation strategies. The key building blocks of the proposed VQE algorithm are potentially scalable to larger systems that cannot be simulated classically. Science, this issue p. 1084; see also p. 1054 Accurate quantum simulations of chemistry are performed using up to 12 superconducting qubits and 72 two-qubit gates. The simulation of fermionic systems is among the most anticipated applications of quantum computing. We performed several quantum simulations of chemistry with up to one dozen qubits, including modeling the isomerization mechanism of diazene. We also demonstrated error-mitigation strategies based on N-representability that dramatically improve the effective fidelity of our experiments. Our parameterized ansatz circuits realized the Givens rotation approach to noninteracting fermion evolution, which we variationally optimized to prepare the Hartree-Fock wave function. This ubiquitous algorithmic primitive is classically tractable to simulate yet still generates highly entangled states over the computational basis, which allowed us to assess the performance of our hardware and establish a foundation for scaling up correlated quantum chemistry simulations.",
    "citationCount": 795,
    "pdf_filename": "2020_Hartree_Fock_on_a_superconducting_qubit__2262e6f2.pdf"
  },
  "2e8bf9d2ea46012af3806a0418f4d0db9787f76a": {
    "paperId": "2e8bf9d2ea46012af3806a0418f4d0db9787f76a",
    "title": "Detection of air and surface contamination by SARS-CoV-2 in hospital rooms of infected patients",
    "year": 2020,
    "authors": "P. Chia, K. K. Coleman, Yian Kim Tan, S. Ong, Marcus Gum",
    "abstract": "Understanding the particle size distribution in the air and patterns of environmental contamination of SARS-CoV-2 is essential for infection prevention policies. Here we screen surface and air samples from hospital rooms of COVID-19 patients for SARS-CoV-2 RNA. Environmental sampling is conducted in three airborne infection isolation rooms (AIIRs) in the ICU and 27 AIIRs in the general ward. 245 surface samples are collected. 56.7% of rooms have at least one environmental surface contaminated. High touch surface contamination is shown in ten (66.7%) out of 15 patients in the first week of illness, and three (20%) beyond the first week of illness (p = 0.01, χ2 test). Air sampling is performed in three of the 27 AIIRs in the general ward, and detects SARS-CoV-2 PCR-positive particles of sizes >4 µm and 1–4 µm in two rooms, despite these rooms having 12 air changes per hour. This warrants further study of the airborne transmission potential of SARS-CoV-2. Here, the authors sample air and surfaces in hospital rooms of COVID-19 patients, detect SARS-CoV-2 RNA in air samples of two of three tested airborne infection isolation rooms, and find surface contamination in 66.7% of tested rooms during the first week of illness and 20% beyond the first week of illness.",
    "citationCount": 771,
    "pdf_filename": "2020_Detection_of_air_and_surface_contaminati_2e8bf9d2.pdf"
  },
  "d0cd7180b55eb75fcca5bbd8ad27f7f37bcee09d": {
    "paperId": "d0cd7180b55eb75fcca5bbd8ad27f7f37bcee09d",
    "title": "Intubation and Ventilation amid the COVID-19 Outbreak",
    "year": 2020,
    "authors": "L. Meng, H. Qiu, L. Wan, Y. Ai, Zhanggang Xue",
    "abstract": "The COVID-19 outbreak has led to 80,409 diagnosed cases and 3,012 deaths in mainland China based on the data released on March 4, 2020. Approximately 3.2% of patients with COVID-19 required intubation and invasive ventilation at some point in the disease course. Providing best practices regarding intubation and ventilation for an overwhelming number of patients with COVID-19 amid an enhanced risk of cross-infection is a daunting undertaking. The authors presented the experience of caring for the critically ill patients with COVID-19 in Wuhan. It is extremely important to follow strict self-protection precautions. Timely, but not premature, intubation is crucial to counter a progressively enlarging oxygen debt despite high-flow oxygen therapy and bilevel positive airway pressure ventilation. Thorough preparation, satisfactory preoxygenation, modified rapid sequence induction, and rapid intubation using a video laryngoscope are widely used intubation strategies in Wuhan. Lung-protective ventilation, prone position ventilation, and adequate sedation and analgesia are essential components of ventilation management.",
    "citationCount": 549,
    "pdf_filename": "2020_Intubation_and_Ventilation_amid_the_COVI_d0cd7180.pdf"
  },
  "b72bc37f41ea84e585b2ec82288355128844dc1b": {
    "paperId": "b72bc37f41ea84e585b2ec82288355128844dc1b",
    "title": "Lithium ion battery degradation: what you need to know.",
    "year": 2021,
    "authors": "J. Edge, S. O’Kane, R. Prosser, Niall Kirkaldy, Anisha N. Patel",
    "abstract": "The expansion of lithium-ion batteries from consumer electronics to larger-scale transport and energy storage applications has made understanding the many mechanisms responsible for battery degradation increasingly important. The literature in this complex topic has grown considerably; this perspective aims to distil current knowledge into a succinct form, as a reference and a guide to understanding battery degradation. Unlike other reviews, this work emphasises the coupling between the different mechanisms and the different physical and chemical approaches used to trigger, identify and monitor various mechanisms, as well as the various computational models that attempt to simulate these interactions. Degradation is separated into three levels: the actual mechanisms themselves, the observable consequences at cell level called modes and the operational effects such as capacity or power fade. Five principal and thirteen secondary mechanisms were found that are generally considered to be the cause of degradation during normal operation, which all give rise to five observable modes. A flowchart illustrates the different feedback loops that couple the various forms of degradation, whilst a table is presented to highlight the experimental conditions that are most likely to trigger specific degradation mechanisms. Together, they provide a powerful guide to designing experiments or models for investigating battery degradation.",
    "citationCount": 588,
    "pdf_filename": "2021_Lithium_ion_battery_degradation__what_yo_b72bc37f.pdf"
  },
  "bd3e894559bbcbd114ab08108767b6efefbeb25e": {
    "paperId": "bd3e894559bbcbd114ab08108767b6efefbeb25e",
    "title": "Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets",
    "year": 2020,
    "authors": "S. Harmon, Thomas Sanford, Sheng Xu, E. Turkbey, H. Roth",
    "abstract": "Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Artificial intelligence (AI) has the potential to aid in rapid evaluation of CT scans for differentiation of COVID-19 findings from other clinical entities. Here we show that a series of deep learning algorithms, trained in a diverse multinational cohort of 1280 patients to localize parietal pleura/lung parenchyma followed by classification of COVID-19 pneumonia, can achieve up to 90.8% accuracy, with 84% sensitivity and 93% specificity, as evaluated in an independent test set (not included in training and validation) of 1337 patients. Normal controls included chest CTs from oncology, emergency, and pneumonia-related indications. The false positive rate in 140 patients with laboratory confirmed other (non COVID-19) pneumonias was 10%. AI-based algorithms can readily identify CT scans with COVID-19 associated pneumonia, as well as distinguish non-COVID related pneumonias with high specificity in diverse patient populations. Chest CT is emerging as a valuable diagnostic tool for clinical management of COVID-19 associated lung disease. Here, the authors present a multinational study on the application of deep learning algorithms for COVID-19 diagnosis against multiple lung conditions as controls.",
    "citationCount": 506,
    "pdf_filename": "2020_Artificial_intelligence_for_the_detectio_bd3e8945.pdf"
  },
  "3a1654821eba10268ea0ecf25922ed7f57d9668a": {
    "paperId": "3a1654821eba10268ea0ecf25922ed7f57d9668a",
    "title": "Epidemiological and clinical features of the 2019 novel coronavirus outbreak in China",
    "year": 2020,
    "authors": "Yang Yang, Q. Lu, Mingjin Liu, Yixing Wang, Anran Zhang",
    "abstract": "Our manuscript was based on surveillance cases of COVID-19 identified before January 26, 2020. As of February 20, 2020, the total number of confirmed cases in mainland China has reached 18 times of the number in our manuscript. While the methods and the main conclusions in our original analyses remain solid, we decided to withdraw this preprint for the time being, and will replace it with a more up-to-date version shortly. Should you have any comments or suggestions, please feel free to contact the corresponding author.",
    "citationCount": 515,
    "pdf_filename": "2020_Epidemiological_and_clinical_features_of_3a165482.pdf"
  },
  "3b6179c293df29e31d31cea46476f104ab6950f2": {
    "paperId": "3b6179c293df29e31d31cea46476f104ab6950f2",
    "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
    "year": 2023,
    "authors": "Zhiliang Peng, Wenhui Wang, Li Dong, Y. Hao, Shaohan Huang",
    "abstract": "We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world. Specifically, we represent refer expressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where object descriptions are sequences of location tokens. Together with multimodal corpora, we construct large-scale data of grounded image-text pairs (called GrIT) to train the model. In addition to the existing capabilities of MLLMs (e.g., perceiving general modalities, following instructions, and performing in-context learning), Kosmos-2 integrates the grounding capability into downstream applications. We evaluate Kosmos-2 on a wide range of tasks, including (i) multimodal grounding, such as referring expression comprehension, and phrase grounding, (ii) multimodal referring, such as referring expression generation, (iii) perception-language tasks, and (iv) language understanding and generation. This work lays out the foundation for the development of Embodiment AI and sheds light on the big convergence of language, multimodal perception, action, and world modeling, which is a key step toward artificial general intelligence. Code and pretrained models are available at https://aka.ms/kosmos-2.",
    "citationCount": 992,
    "pdf_filename": "2023_Kosmos_2__Grounding_Multimodal_Large_Lan_3b6179c2.pdf"
  },
  "7bf72a3b5fbac8bc0f461780810fbc781c28ef53": {
    "paperId": "7bf72a3b5fbac8bc0f461780810fbc781c28ef53",
    "title": "CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society",
    "year": 2023,
    "authors": "G. Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem",
    "abstract": "The rapid advancement of chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents, and provides insight into their\"cognitive\"processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of a society of agents, providing a valuable resource for investigating conversational language models. In particular, we conduct comprehensive studies on instruction-following cooperation in multi-agent settings. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond: https://github.com/camel-ai/camel.",
    "citationCount": 874,
    "pdf_filename": "2023_CAMEL__Communicative_Agents_for__Mind__E_7bf72a3b.pdf"
  },
  "8fafd95a6ffbecf9c1b5f4542ac4b78a00602551": {
    "paperId": "8fafd95a6ffbecf9c1b5f4542ac4b78a00602551",
    "title": "PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis",
    "year": 2023,
    "authors": "Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie",
    "abstract": "The most advanced text-to-image (T2I) models require significant training costs (e.g., millions of GPU hours), seriously hindering the fundamental innovation for the AIGC community while increasing CO2 emissions. This paper introduces PIXART-$\\alpha$, a Transformer-based T2I diffusion model whose image generation quality is competitive with state-of-the-art image generators (e.g., Imagen, SDXL, and even Midjourney), reaching near-commercial application standards. Additionally, it supports high-resolution image synthesis up to 1024px resolution with low training cost, as shown in Figure 1 and 2. To achieve this goal, three core designs are proposed: (1) Training strategy decomposition: We devise three distinct training steps that separately optimize pixel dependency, text-image alignment, and image aesthetic quality; (2) Efficient T2I Transformer: We incorporate cross-attention modules into Diffusion Transformer (DiT) to inject text conditions and streamline the computation-intensive class-condition branch; (3) High-informative data: We emphasize the significance of concept density in text-image pairs and leverage a large Vision-Language model to auto-label dense pseudo-captions to assist text-image alignment learning. As a result, PIXART-$\\alpha$'s training speed markedly surpasses existing large-scale T2I models, e.g., PIXART-$\\alpha$ only takes 10.8% of Stable Diffusion v1.5's training time (675 vs. 6,250 A100 GPU days), saving nearly \\$300,000 (\\$26,000 vs. \\$320,000) and reducing 90% CO2 emissions. Moreover, compared with a larger SOTA model, RAPHAEL, our training cost is merely 1%. Extensive experiments demonstrate that PIXART-$\\alpha$ excels in image quality, artistry, and semantic control. We hope PIXART-$\\alpha$ will provide new insights to the AIGC community and startups to accelerate building their own high-quality yet low-cost generative models from scratch.",
    "citationCount": 632,
    "pdf_filename": "2023_PixArt_α__Fast_Training_of_Diffusion_Tra_8fafd95a.pdf"
  },
  "923a03032014a12c4e8b26511c0394e1b915fe74": {
    "paperId": "923a03032014a12c4e8b26511c0394e1b915fe74",
    "title": "Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators",
    "year": 2023,
    "authors": "Levon Khachatryan, A. Movsisyan, Vahram Tadevosyan, Roberto Henschel, Zhangyang Wang",
    "abstract": "Recent text-to-video generation approaches rely on computationally heavy training and require large-scale video datasets. In this paper, we introduce a new task, zero-shot text-to-video generation, and propose a low-cost approach (without any training or optimization) by leveraging the power of existing text-to-image synthesis methods (e.g. Stable Diffusion), making them suitable for the video domain. Our key modifications include (i) enriching the latent codes of the generated frames with motion dynamics to keep the global scene and the background time consistent; and (ii) reprogramming frame-level self-attention using a new cross-frame attention of each frame on the first frame, to preserve the context, appearance, and identity of the foreground object. Experiments show that this leads to low overhead, yet high-quality and remarkably consistent video generation. Moreover, our approach is not limited to text-to-video synthesis but is also applicable to other tasks such as conditional and content-specialized video generation, and Video Instruct-Pix2Pix, i.e., instruction-guided video editing. As experiments show, our method performs comparably or sometimes better than recent approaches, despite not being trained on additional video data. Our code is publicly available at: https://github.com/Picsart-AI-Research/Text2Video-Zero.",
    "citationCount": 711,
    "pdf_filename": "2023_Text2Video_Zero__Text_to_Image_Diffusion_923a0303.pdf"
  },
  "b486982fa7c68a8a08df1111ba9607119419c488": {
    "paperId": "b486982fa7c68a8a08df1111ba9607119419c488",
    "title": "A survey on large language models for recommendation",
    "year": 2023,
    "authors": "Likang Wu, Zhilan Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu",
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning, prompt tuning, etc. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discriminative LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation (GLLM4Rec), with the latter being systematically sorted out for the first time. Furthermore, we systematically review and analyze existing LLM-based recommendation systems within each paradigm, providing insights into their methodologies, techniques, and performance. Additionally, we identify key challenges and several valuable findings to provide researchers and practitioners with inspiration. We have also created a GitHub repository to index relevant papers and resources on LLMs for recommendation (https://github.com/WLiK/LLM4Rec-Awesome-Papers).",
    "citationCount": 607,
    "pdf_filename": "2023_A_survey_on_large_language_models_for_re_b486982f.pdf"
  },
  "29c7f009df21d0112c48dec254ff80cc45fac3af": {
    "paperId": "29c7f009df21d0112c48dec254ff80cc45fac3af",
    "title": "Are Emergent Abilities of Large Language Models a Mirage?",
    "year": 2023,
    "authors": "Rylan Schaeffer, B. Miranda, Oluwasanmi Koyejo",
    "abstract": "Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due to the researcher's choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities; (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on BIG-Bench; and (3) show to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.",
    "citationCount": 552,
    "pdf_filename": "2023_Are_Emergent_Abilities_of_Large_Language_29c7f009.pdf"
  },
  "3f3b35fa0b8b942bcae7c755603ce56de616da93": {
    "paperId": "3f3b35fa0b8b942bcae7c755603ce56de616da93",
    "title": "Deep learning modelling techniques: current progress, applications, advantages, and challenges",
    "year": 2023,
    "authors": "S. Ahmed, Md. Sakib Bin Alam, Maruf Hassan, M. R. Rozbu, Taoseef Ishtiak",
    "abstract": "Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.",
    "citationCount": 560,
    "pdf_filename": "2023_Deep_learning_modelling_techniques__curr_3f3b35fa.pdf"
  },
  "2ad12a7be5eaf339a98c4defd8669e11fe726acc": {
    "paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc",
    "title": "MaxViT: Multi-Axis Vision Transformer",
    "year": 2022,
    "authors": "Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, P. Milanfar",
    "abstract": "Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to ''see'' globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.",
    "citationCount": 855,
    "pdf_filename": "2022_MaxViT__Multi_Axis_Vision_Transformer_2ad12a7b.pdf"
  },
  "fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b": {
    "paperId": "fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b",
    "title": "Scaling Laws for Reward Model Overoptimization",
    "year": 2022,
    "authors": "Leo Gao, John Schulman, Jacob Hilton",
    "abstract": "In reinforcement learning from human feedback, it is common to optimize against a reward model trained to predict human preferences. Because the reward model is an imperfect proxy, optimizing its value too much can hinder ground truth performance, in accordance with Goodhart's law. This effect has been frequently observed, but not carefully measured due to the expense of collecting human preference data. In this work, we use a synthetic setup in which a fixed\"gold-standard\"reward model plays the role of humans, providing labels used to train a proxy reward model. We study how the gold reward model score changes as we optimize against the proxy reward model using either reinforcement learning or best-of-$n$ sampling. We find that this relationship follows a different functional form depending on the method of optimization, and that in both cases its coefficients scale smoothly with the number of reward model parameters. We also study the effect on this relationship of the size of the reward model dataset, the number of reward model and policy parameters, and the coefficient of the KL penalty added to the reward in the reinforcement learning setup. We explore the implications of these empirical results for theoretical considerations in AI alignment.",
    "citationCount": 744,
    "pdf_filename": "2022_Scaling_Laws_for_Reward_Model_Overoptimi_fb3dc5e2.pdf"
  },
  "dcb31b98ec58f3fff9f94f148e2952595f017fd9": {
    "paperId": "dcb31b98ec58f3fff9f94f148e2952595f017fd9",
    "title": "ProtGPT2 is a deep unsupervised language model for protein design",
    "year": 2022,
    "authors": "Noelia Ferruz, Steffen Schmidt, B. Höcker",
    "abstract": "Protein design aims to build novel proteins customized for specific purposes, thereby holding the potential to tackle many environmental and biomedical problems. Recent progress in Transformer-based architectures has enabled the implementation of language models capable of generating text with human-like capabilities. Here, motivated by this success, we describe ProtGPT2, a language model trained on the protein space that generates de novo protein sequences following the principles of natural ones. The generated proteins display natural amino acid propensities, while disorder predictions indicate that 88% of ProtGPT2-generated proteins are globular, in line with natural sequences. Sensitive sequence searches in protein databases show that ProtGPT2 sequences are distantly related to natural ones, and similarity networks further demonstrate that ProtGPT2 is sampling unexplored regions of protein space. AlphaFold prediction of ProtGPT2-sequences yields well-folded non-idealized structures with embodiments and large loops and reveals topologies not captured in current structure databases. ProtGPT2 generates sequences in a matter of seconds and is freely available. Protein design aims to build novel proteins customized for specific purposes, thereby holding the potential to tackle many environmental and biomedical problems. Here the authors apply some of the latest advances in natural language processing, generative Transformers, to train ProtGPT2, a language model that explores unseen regions of the protein space while designing proteins with nature-like properties.",
    "citationCount": 669,
    "pdf_filename": "2022_ProtGPT2_is_a_deep_unsupervised_language_dcb31b98.pdf"
  },
  "40f4d7fe800810288a80f84cdb357a8f4c28e880": {
    "paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880",
    "title": "Rethinking Spatial Dimensions of Vision Transformers",
    "year": 2021,
    "authors": "Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe",
    "abstract": "Vision Transformer (ViT) extends the application range of transformers from language processing to computer vision tasks as being an alternative architecture against the existing convolutional neural networks (CNN). Since the transformer-based architecture has been innovative for computer vision modeling, the design convention towards an effective architecture has been less studied yet. From the successful design principles of CNN, we investigate the role of spatial dimension conversion and its effectiveness on transformer-based architecture. We particularly attend to the dimension reduction principle of CNNs; as the depth increases, a conventional CNN increases channel dimension and decreases spatial dimensions. We empirically show that such a spatial dimension reduction is beneficial to a transformer architecture as well, and propose a novel Pooling-based Vision Transformer (PiT) upon the original ViT model. We show that PiT achieves the improved model capability and generalization performance against ViT. Throughout the extensive experiments, we further show PiT outperforms the baseline on several tasks such as image classification, object detection, and robustness evaluation. Source codes and ImageNet models are available at https://github.com/naver-ai/pit.",
    "citationCount": 678,
    "pdf_filename": "2021_Rethinking_Spatial_Dimensions_of_Vision__40f4d7fe.pdf"
  },
  "bd3d0238549555bd07fd25ff61b3d7e01eb02296": {
    "paperId": "bd3d0238549555bd07fd25ff61b3d7e01eb02296",
    "title": "Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review",
    "year": 2021,
    "authors": "D. Vrontis, M. Christofi, V. Pereira, S. Tarba, Anna Makrides",
    "abstract": "Abstract Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management (HRM) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for HRM. In a systematic search of 13,136 potentially relevant studies published in the top HRM, international business (IB), general management (GM) and information management (IM) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within HRM settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for HRM but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified to concentrate on HRM strategies, namely, job replacement, human-robot/AI collaboration, decision-making and learning opportunities, and HRM activities, namely, recruiting, training and job performance. This study discusses these shifts in detail, along with the main contributions to theory and practice and directions for future research.",
    "citationCount": 704,
    "pdf_filename": "2021_Artificial_intelligence__robotics__advan_bd3d0238.pdf"
  },
  "29409efa04ac99ccf01d2a011d21d5d14e870000": {
    "paperId": "29409efa04ac99ccf01d2a011d21d5d14e870000",
    "title": "Artificial intelligence to deep learning: machine intelligence approach for drug discovery",
    "year": 2021,
    "authors": "Rohan Gupta, Devesh Srivastava, Mehar Sahu, Swati Tiwari, R. K. Ambasta",
    "abstract": "Drug designing and development is an important area of research for pharmaceutical companies and chemical scientists. However, low efficacy, off-target delivery, time consumption, and high cost impose a hurdle and challenges that impact drug design and discovery. Further, complex and big data from genomics, proteomics, microarray data, and clinical trials also impose an obstacle in the drug discovery pipeline. Artificial intelligence and machine learning technology play a crucial role in drug discovery and development. In other words, artificial neural networks and deep learning algorithms have modernized the area. Machine learning and deep learning algorithms have been implemented in several drug discovery processes such as peptide synthesis, structure-based virtual screening, ligand-based virtual screening, toxicity prediction, drug monitoring and release, pharmacophore modeling, quantitative structure–activity relationship, drug repositioning, polypharmacology, and physiochemical activity. Evidence from the past strengthens the implementation of artificial intelligence and deep learning in this field. Moreover, novel data mining, curation, and management techniques provided critical support to recently developed modeling algorithms. In summary, artificial intelligence and deep learning advancements provide an excellent opportunity for rational drug design and discovery process, which will eventually impact mankind. The primary concern associated with drug design and development is time consumption and production cost. Further, inefficiency, inaccurate target delivery, and inappropriate dosage are other hurdles that inhibit the process of drug delivery and development. With advancements in technology, computer-aided drug design integrating artificial intelligence algorithms can eliminate the challenges and hurdles of traditional drug design and development. Artificial intelligence is referred to as superset comprising machine learning, whereas machine learning comprises supervised learning, unsupervised learning, and reinforcement learning. Further, deep learning, a subset of machine learning, has been extensively implemented in drug design and development. The artificial neural network, deep neural network, support vector machines, classification and regression, generative adversarial networks, symbolic learning, and meta-learning are examples of the algorithms applied to the drug design and discovery process. Artificial intelligence has been applied to different areas of drug design and development process, such as from peptide synthesis to molecule design, virtual screening to molecular docking, quantitative structure–activity relationship to drug repositioning, protein misfolding to protein–protein interactions, and molecular pathway identification to polypharmacology. Artificial intelligence principles have been applied to the classification of active and inactive, monitoring drug release, pre-clinical and clinical development, primary and secondary drug screening, biomarker development, pharmaceutical manufacturing, bioactivity identification and physiochemical properties, prediction of toxicity, and identification of mode of action.",
    "citationCount": 878,
    "pdf_filename": "2021_Artificial_intelligence_to_deep_learning_29409efa.pdf"
  },
  "ee1e4158395060077c12174b85abdf18ee9aaa0b": {
    "paperId": "ee1e4158395060077c12174b85abdf18ee9aaa0b",
    "title": "LLVIP: A Visible-infrared Paired Dataset for Low-light Vision",
    "year": 2021,
    "authors": "Xinyu Jia, Chuang Zhu, Minzhen Li, Wenqi Tang, Wenli Zhou",
    "abstract": "It is very challenging for various visual tasks such as image fusion, pedestrian detection and image-to-image translation in low light conditions due to the loss of effective target areas. In this case, infrared and visible images can be used together to provide both rich detail information and effective target areas. In this paper, we present LLVIP, a visible-infrared paired dataset for low-light vision. This dataset contains 33672 images, or 16836 pairs, most of which were taken at very dark scenes, and all of the images are strictly aligned in time and space. Pedestrians in the dataset are labeled. We compare the dataset with other visible-infrared datasets and evaluate the performance of some popular visual algorithms including image fusion, pedestrian detection and image-to-image translation on the dataset. The experimental results demonstrate the complementary effect of fusion on image information, and find the deficiency of existing algorithms of the three visual tasks in very low-light conditions. We believe the LLVIP dataset will contribute to the community of computer vision by promoting image fusion, pedestrian detection and image-to-image translation in very low-light applications. The dataset is being released in https://bupt-ai-cz.github.io/LLVIP/.",
    "citationCount": 552,
    "pdf_filename": "2021_LLVIP__A_Visible_infrared_Paired_Dataset_ee1e4158.pdf"
  },
  "309c2c5ee60e725244da09180f913cd8d4b8d4e9": {
    "paperId": "309c2c5ee60e725244da09180f913cd8d4b8d4e9",
    "title": "MOReL : Model-Based Offline Reinforcement Learning",
    "year": 2020,
    "authors": "Rahul Kidambi, A. Rajeswaran, Praneeth Netrapalli, T. Joachims",
    "abstract": "In offline reinforcement learning (RL), the goal is to learn a highly rewarding policy based solely on a dataset of historical interactions with the environment. The ability to train RL policies offline can greatly expand the applicability of RL, its data efficiency, and its experimental velocity. Prior work in offline RL has been confined almost exclusively to model-free RL approaches. In this work, we present MOReL, an algorithmic framework for model-based offline RL. This framework consists of two steps: (a) learning a pessimistic MDP (P-MDP) using the offline dataset; and (b) learning a near-optimal policy in this P-MDP. The learned P-MDP has the property that for any policy, the performance in the real environment is approximately lower-bounded by the performance in the P-MDP. This enables it to serve as a good surrogate for purposes of policy evaluation and learning, and overcome common pitfalls of model-based RL like model exploitation. Theoretically, we show that MOReL is minimax optimal (up to log factors) for offline RL. Through experiments, we show that MOReL matches or exceeds state-of-the-art results in widely studied offline RL benchmarks. Moreover, the modular design of MOReL enables future advances in its components (e.g. generative modeling, uncertainty estimation, planning etc.) to directly translate into advances for offline RL.",
    "citationCount": 742,
    "pdf_filename": "2020_MOReL___Model_Based_Offline_Reinforcemen_309c2c5e.pdf"
  },
  "9834fb9ae25978c1fe1e37369162acc59741918e": {
    "paperId": "9834fb9ae25978c1fe1e37369162acc59741918e",
    "title": "Algorithmic content moderation: Technical and political challenges in the automation of platform governance",
    "year": 2020,
    "authors": "Robert Gorwa, Reuben Binns, Christian Katzenbach",
    "abstract": "As government pressure on major technology companies builds, both firms and legislators are searching for technical solutions to difficult platform governance puzzles such as hate speech and misinformation. Automated hash-matching and predictive machine learning tools – what we define here as algorithmic moderation systems – are increasingly being deployed to conduct content moderation at scale by major platforms for user-generated content such as Facebook, YouTube and Twitter. This article provides an accessible technical primer on how algorithmic moderation works; examines some of the existing automated tools used by major platforms to handle copyright infringement, terrorism and toxic speech; and identifies key political and ethical issues for these systems as the reliance on them grows. Recent events suggest that algorithmic moderation has become necessary to manage growing public expectations for increased platform responsibility, safety and security on the global stage; however, as we demonstrate, these systems remain opaque, unaccountable and poorly understood. Despite the potential promise of algorithms or ‘AI’, we show that even ‘well optimized’ moderation systems could exacerbate, rather than relieve, many existing problems with content policy as enacted by platforms for three main reasons: automated moderation threatens to (a) further increase opacity, making a famously non-transparent set of practices even more difficult to understand or audit, (b) further complicate outstanding issues of fairness and justice in large-scale sociotechnical systems and (c) re-obscure the fundamentally political nature of speech decisions being executed at scale.",
    "citationCount": 663,
    "pdf_filename": "2020_Algorithmic_content_moderation__Technica_9834fb9a.pdf"
  },
  "728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743": {
    "paperId": "728e0cdfdd5bb14b6eb74e7038ebcf5e975a4743",
    "title": "Remote Sensing Image Scene Classification Meets Deep Learning: Challenges, Methods, Benchmarks, and Opportunities",
    "year": 2020,
    "authors": "Gong Cheng, Xingxing Xie, Junwei Han, Lei Guo, Guisong Xia",
    "abstract": "Remote sensing image scene classification, which aims at labeling remote sensing images with a set of semantic categories based on their contents, has broad applications in a range of fields. Propelled by the powerful feature learning capabilities of deep neural networks, remote sensing image scene classification driven by deep learning has drawn remarkable attention and achieved significant breakthroughs. However, to the best of our knowledge, a comprehensive review of recent achievements regarding deep learning for scene classification of remote sensing images is still lacking. Considering the rapid evolution of this field, this article provides a systematic survey of deep learning methods for remote sensing image scene classification by covering more than 160 papers. To be specific, we discuss the main challenges of remote sensing image scene classification and survey: first, autoencoder-based remote sensing image scene classification methods; second, convolutional neural network-based remote sensing image scene classification methods; and third, generative adversarial network-based remote sensing image scene classification methods. In addition, we introduce the benchmarks used for remote sensing image scene classification and summarize the performance of more than two dozen of representative algorithms on three commonly used benchmark datasets. Finally, we discuss the promising opportunities for further research.",
    "citationCount": 724,
    "pdf_filename": "2020_Remote_Sensing_Image_Scene_Classificatio_728e0cdf.pdf"
  },
  "31852f9fc732c0868af12d631c72693702d80521": {
    "paperId": "31852f9fc732c0868af12d631c72693702d80521",
    "title": "Text Data Augmentation for Deep Learning",
    "year": 2021,
    "authors": "Connor Shorten, T. Khoshgoftaar, B. Furht",
    "abstract": "Natural Language Processing (NLP) is one of the most captivating applications of Deep Learning. In this survey, we consider how the Data Augmentation training strategy can aid in its development. We begin with the major motifs of Data Augmentation summarized into strengthening local decision boundaries, brute force training, causality and counterfactual examples, and the distinction between meaning and form. We follow these motifs with a concrete list of augmentation frameworks that have been developed for text data. Deep Learning generally struggles with the measurement of generalization and characterization of overfitting. We highlight studies that cover how augmentations can construct test sets for generalization. NLP is at an early stage in applying Data Augmentation compared to Computer Vision. We highlight the key differences and promising ideas that have yet to be tested in NLP. For the sake of practical implementation, we describe tools that facilitate Data Augmentation such as the use of consistency regularization, controllers, and offline and online augmentation pipelines, to preview a few. Finally, we discuss interesting topics around Data Augmentation in NLP such as task-specific augmentations, the use of prior knowledge in self-supervised learning versus Data Augmentation, intersections with transfer and multi-task learning, and ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires further research interest in Text Data Augmentation.",
    "citationCount": 533,
    "pdf_filename": "2021_Text_Data_Augmentation_for_Deep_Learning_31852f9f.pdf"
  },
  "0b5b6598e3e108147842f35ff66a95d989f9ec89": {
    "paperId": "0b5b6598e3e108147842f35ff66a95d989f9ec89",
    "title": "Advances in Neural Rendering",
    "year": 2021,
    "authors": "A. Tewari, O. Fried, Justus Thies, V. Sitzmann, S. Lombardi",
    "abstract": "Synthesizing photo‐realistic images and videos is at the heart of computer graphics and has been the focus of decades of research. Traditionally, synthetic images of a scene are generated using rendering algorithms such as rasterization or ray tracing, which take specifically defined representations of geometry and material properties as input. Collectively, these inputs define the actual scene and what is rendered, and are referred to as the scene representation (where a scene consists of one or more objects). Example scene representations are triangle meshes with accompanied textures (e.g., created by an artist), point clouds (e.g., from a depth sensor), volumetric grids (e.g., from a CT scan), or implicit surface functions (e.g., truncated signed distance fields). The reconstruction of such a scene representation from observations using differentiable rendering losses is known as inverse graphics or inverse rendering. Neural rendering is closely related, and combines ideas from classical computer graphics and machine learning to create algorithms for synthesizing images from real‐world observations. Neural rendering is a leap forward towards the goal of synthesizing photo‐realistic image and video content. In recent years, we have seen immense progress in this field through hundreds of publications that show different ways to inject learnable components into the rendering pipeline. This state‐of‐the‐art report on advances in neural rendering focuses on methods that combine classical rendering principles with learned 3D scene representations, often now referred to as neural scene representations. A key advantage of these methods is that they are 3D‐consistent by design, enabling applications such as novel viewpoint synthesis of a captured scene. In addition to methods that handle static scenes, we cover neural scene representations for modeling non‐rigidly deforming objects and scene editing and composition. While most of these approaches are scene‐specific, we also discuss techniques that generalize across object classes and can be used for generative tasks. In addition to reviewing these state‐of‐the‐art methods, we provide an overview of fundamental concepts and definitions used in the current literature. We conclude with a discussion on open challenges and social implications.",
    "citationCount": 506,
    "pdf_filename": "2021_Advances_in_Neural_Rendering_0b5b6598.pdf"
  },
  "1eac5d12f30697aa74d66f4026fb662c5d51bd43": {
    "paperId": "1eac5d12f30697aa74d66f4026fb662c5d51bd43",
    "title": "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers",
    "year": 2024,
    "authors": "Nanye Ma, Mark Goldstein, M. S. Albergo, N. Boffi, Eric Vanden-Eijnden",
    "abstract": "We present Scalable Interpolant Transformers (SiT), a family of generative models built on the backbone of Diffusion Transformers (DiT). The interpolant framework, which allows for connecting two distributions in a more flexible way than standard diffusion models, makes possible a modular study of various design choices impacting generative models built on dynamical transport: learning in discrete or continuous time, the objective function, the interpolant that connects the distributions, and deterministic or stochastic sampling. By carefully introducing the above ingredients, SiT surpasses DiT uniformly across model sizes on the conditional ImageNet 256x256 and 512x512 benchmark using the exact same model structure, number of parameters, and GFLOPs. By exploring various diffusion coefficients, which can be tuned separately from learning, SiT achieves an FID-50K score of 2.06 and 2.62, respectively.",
    "citationCount": 391,
    "pdf_filename": "2024_SiT__Exploring_Flow_and_Diffusion_based__1eac5d12.pdf"
  },
  "c064de2c71ebc5cf05493f49dc312b033c36b3b9": {
    "paperId": "c064de2c71ebc5cf05493f49dc312b033c36b3b9",
    "title": "Genie: Generative Interactive Environments",
    "year": 2024,
    "authors": "Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi",
    "abstract": "We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.",
    "citationCount": 328,
    "pdf_filename": "2024_Genie__Generative_Interactive_Environmen_c064de2c.pdf"
  },
  "6a703c99b5403556c124f6a0d878110cf14b4439": {
    "paperId": "6a703c99b5403556c124f6a0d878110cf14b4439",
    "title": "The Potential of Generative Artificial Intelligence Across Disciplines: Perspectives and Future Directions",
    "year": 2023,
    "authors": "K. Ooi, G. Tan, M. Al-Emran, Mohammed A. Al-Sharafi, A. Căpățînă",
    "abstract": "ABSTRACT In a short span of time since its introduction, generative artificial intelligence (AI) has garnered much interest at both personal and organizational levels. This is because of its potential to cause drastic and widespread shifts in many aspects of life that are comparable to those of the Internet and smartphones. More specifically, generative AI utilizes machine learning, neural networks, and other techniques to generate new content (e.g. text, images, music) by analyzing patterns and information from the training data. This has enabled generative AI to have a wide range of applications, from creating personalized content to improving business operations. Despite its many benefits, there are also significant concerns about the negative implications of generative AI. In view of this, the current article brings together experts in a variety of fields to expound and provide multi-disciplinary insights on the opportunities, challenges, and research agendas of generative AI in specific industries (i.e. marketing, healthcare, human resource, education, banking, retailing, the workplace, manufacturing, and sustainable IT management).",
    "citationCount": 408,
    "pdf_filename": "2023_The_Potential_of_Generative_Artificial_I_6a703c99.pdf"
  },
  "e586a4591ba0303b769f2c07cbddaf1899cb72e4": {
    "paperId": "e586a4591ba0303b769f2c07cbddaf1899cb72e4",
    "title": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
    "year": 2023,
    "authors": "Zhenyu (Allen) Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng",
    "abstract": "Large Language Models (LLMs), despite their recent impressive accomplishments, are notably cost-prohibitive to deploy, particularly for applications involving long-content generation, such as dialogue systems and story writing. Often, a large amount of transient state information, referred to as the KV cache, is stored in GPU memory in addition to model parameters, scaling linearly with the sequence length and batch size. In this paper, we introduce a novel approach for implementing the KV cache which significantly reduces its memory footprint. Our approach is based on the noteworthy observation that a small portion of tokens contributes most of the value when computing attention scores. We call these tokens Heavy Hitters (H$_2$). Through a comprehensive investigation, we find that (i) the emergence of H$_2$ is natural and strongly correlates with the frequent co-occurrence of tokens in the text, and (ii) removing them results in significant performance degradation. Based on these insights, we propose Heavy Hitter Oracle (H$_2$O), a KV cache eviction policy that dynamically retains a balance of recent and H$_2$ tokens. We formulate the KV cache eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work. We validate the accuracy of our algorithm with OPT, LLaMA, and GPT-NeoX across a wide range of tasks. Our implementation of H$_2$O with 20% heavy hitters improves the throughput over three leading inference systems DeepSpeed Zero-Inference, Hugging Face Accelerate, and FlexGen by up to 29$\\times$, 29$\\times$, and 3$\\times$ on OPT-6.7B and OPT-30B. With the same batch size, H2O can reduce the latency by up to 1.9$\\times$. The code is available at https://github.com/FMInference/H2O.",
    "citationCount": 449,
    "pdf_filename": "2023_H2O__Heavy_Hitter_Oracle_for_Efficient_G_e586a459.pdf"
  },
  "2a29e1bcbed17c588ffbae1fea2af3baaab924b8": {
    "paperId": "2a29e1bcbed17c588ffbae1fea2af3baaab924b8",
    "title": "Is synthetic data from generative models ready for image recognition?",
    "year": 2022,
    "authors": "Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang",
    "abstract": "Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in data-scarce settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData.",
    "citationCount": 370,
    "pdf_filename": "2022_Is_synthetic_data_from_generative_models_2a29e1bc.pdf"
  },
  "954f7412a37649eff89da3e84df0257aa63655e9": {
    "paperId": "954f7412a37649eff89da3e84df0257aa63655e9",
    "title": "The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT",
    "year": 2023,
    "authors": "K. Wach, Cong Doanh Duong, J. Ejdys, Rūta Kazlauskaitė, P. Korzyński",
    "abstract": "Objective: The objective of the article is to provide a comprehensive identification and understanding of the challenges and opportunities associated with the use of generative artificial intelligence (GAI) in business. This study sought to develop a conceptual framework that gathers the negative aspects of GAI development in management and economics, with a focus on ChatGPT. Research Design & Methods: The study employed a narrative and critical literature review and developed a conceptual framework based on prior literature. We used a line of deductive reasoning in formulating our theoretical framework to make the study’s overall structure rational and productive. Therefore, this article should be viewed as a conceptual article that highlights the controversies and threats of GAI in management and economics, with ChatGPT as a case study. Findings: Based on the conducted deep and extensive query of academic literature on the subject as well as professional press and Internet portals, we identified various controversies, threats, defects, and disadvantages of GAI, in particular ChatGPT. Next, we grouped the identified threats into clusters to summarize the seven main threats we see. In our opinion they are as follows: (i) no regulation of the AI market and urgent need for regulation, (ii) poor quality, lack of quality control, disinformation, deepfake content, algorithmic bias, (iii) automation-spurred job losses, (iv) personal data violation, social surveillance, and privacy violation, (v) social manipulation, weakening ethics and goodwill, (vi) widening socio-economic inequalities, and (vii) AI technostress. Implications & Recommendations: It is important to regulate the AI/GAI market. Advocating for the regulation of the AI market is crucial to ensure a level playing field, promote fair competition, protect intellectual property rights and privacy, and prevent potential geopolitical risks. The changing job market requires workers to continuously acquire new (digital) skills through education and retraining. As the training of AI systems becomes a prominent job category, it is important to adapt and take advantage of new opportunities. To mitigate the risks related to personal data violation, social surveillance, and privacy violation, GAI developers must prioritize ethical considerations and work to develop systems that prioritize user privacy and security. To avoid social manipulation and weaken ethics and goodwill, it is important to implement responsible AI practices and ethical guidelines: transparency in data usage, bias mitigation techniques, and monitoring of generated content for harmful or misleading information. Contribution & Value Added: This article may aid in bringing attention to the significance of resolving the ethical and legal considerations that arise from the use of GAI and ChatGPT by drawing attention to the contro-versies and hazards associated with these technologies.",
    "citationCount": 317,
    "pdf_filename": "2023_The_dark_side_of_generative_artificial_i_954f7412.pdf"
  },
  "968820dfae97f80b63674fd76cd7d82332498708": {
    "paperId": "968820dfae97f80b63674fd76cd7d82332498708",
    "title": "A Unified Generative Framework for Aspect-based Sentiment Analysis",
    "year": 2021,
    "authors": "Hang Yan, Junqi Dai, Tuo Ji, Xipeng Qiu, Zheng Zhang",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms, their corresponding sentiment polarities, and the opinion terms. There exist seven subtasks in ABSA. Most studies only focus on the subsets of these subtasks, which leads to various complicated ABSA models while hard to solve these subtasks in a unified framework. In this paper, we redefine every subtask target as a sequence mixed by pointer indexes and sentiment class indexes, which converts all ABSA subtasks into a unified generative formulation. Based on the unified formulation, we exploit the pre-training sequence-to-sequence model BART to solve all ABSA subtasks in an end-to-end framework. Extensive experiments on four ABSA datasets for seven subtasks demonstrate that our framework achieves substantial performance gain and provides a real unified end-to-end solution for the whole ABSA subtasks, which could benefit multiple tasks.",
    "citationCount": 319,
    "pdf_filename": "2021_A_Unified_Generative_Framework_for_Aspec_968820df.pdf"
  },
  "2cfc26b4af99f195b433fa7aa00f221b111c7cd4": {
    "paperId": "2cfc26b4af99f195b433fa7aa00f221b111c7cd4",
    "title": "Illuminating protein space with a programmable generative model",
    "year": 2022,
    "authors": "John Ingraham, Max Baranov, Zak Costello, Vincent Frappier, Ahmed Ismail",
    "abstract": "Three billion years of evolution has produced a tremendous diversity of protein molecules^ 1 , but the full potential of proteins is likely to be much greater. Accessing this potential has been challenging for both computation and experiments because the space of possible protein molecules is much larger than the space of those likely to have functions. Here we introduce Chroma, a generative model for proteins and protein complexes that can directly sample novel protein structures and sequences, and that can be conditioned to steer the generative process towards desired properties and functions. To enable this, we introduce a diffusion process that respects the conformational statistics of polymer ensembles, an efficient neural architecture for molecular systems that enables long-range reasoning with sub-quadratic scaling, layers for efficiently synthesizing three-dimensional structures of proteins from predicted inter-residue geometries and a general low-temperature sampling algorithm for diffusion models. Chroma achieves protein design as Bayesian inference under external constraints, which can involve symmetries, substructure, shape, semantics and even natural-language prompts. The experimental characterization of 310 proteins shows that sampling from Chroma results in proteins that are highly expressed, fold and have favourable biophysical properties. The crystal structures of two designed proteins exhibit atomistic agreement with Chroma samples (a backbone root-mean-square deviation of around 1.0 Å). With this unified approach to protein design, we hope to accelerate the programming of protein matter to benefit human health, materials science and synthetic biology. Evolution has produced a range of diverse proteins, and now a generative model called Chroma can expand that set by allowing the user to design new proteins and protein complexes with desired properties and functions.",
    "citationCount": 465,
    "pdf_filename": "2022_Illuminating_protein_space_with_a_progra_2cfc26b4.pdf"
  },
  "cb5323ef22a5a38cfba318abadcadee822ccf8a9": {
    "paperId": "cb5323ef22a5a38cfba318abadcadee822ccf8a9",
    "title": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation",
    "year": 2021,
    "authors": "Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, Y. Bengio",
    "abstract": "This paper is about the problem of learning a stochastic policy for generating an object (like a molecular graph) from a sequence of actions, such that the probability of generating an object is proportional to a given positive reward for that object. Whereas standard return maximization tends to converge to a single return-maximizing sequence, there are cases where we would like to sample a diverse set of high-return solutions. These arise, for example, in black-box function optimization when few rounds are possible, each with large batches of queries, where the batches should be diverse, e.g., in the design of new molecules. One can also see this as a problem of approximately converting an energy function to a generative distribution. While MCMC methods can achieve that, they are expensive and generally only perform local exploration. Instead, training a generative policy amortizes the cost of search during training and yields to fast generation. Using insights from Temporal Difference learning, we propose GFlowNet, based on a view of the generative process as a flow network, making it possible to handle the tricky case where different trajectories can yield the same final state, e.g., there are many ways to sequentially add atoms to generate some molecular graph. We cast the set of trajectories as a flow and convert the flow consistency equations into a learning objective, akin to the casting of the Bellman equations into Temporal Difference methods. We prove that any global minimum of the proposed objectives yields a policy which samples from the desired distribution, and demonstrate the improved performance and diversity of GFlowNet on a simple domain where there are many modes to the reward function, and on a molecule synthesis task.",
    "citationCount": 419,
    "pdf_filename": "2021_Flow_Network_based_Generative_Models_for_cb5323ef.pdf"
  },
  "a6f5b8f114b3eabbcd7f3f62091a481ca6f7f243": {
    "paperId": "a6f5b8f114b3eabbcd7f3f62091a481ca6f7f243",
    "title": "Predictability and Surprise in Large Generative Models",
    "year": 2022,
    "authors": "Deep Ganguli, Danny Hernandez, Liane Lovitt, Nova Dassarma, T. Henighan",
    "abstract": "Large-scale pre-training has recently emerged as a technique for creating capable, general-purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have a paradoxical combination of predictable loss on a broad training distribution (as embodied in their ”scaling laws”), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend for this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, funders who want to support work addressing these challenges, and academics who want to analyze, critique, and potentially develop large generative models.",
    "citationCount": 325,
    "pdf_filename": "2022_Predictability_and_Surprise_in_Large_Gen_a6f5b8f1.pdf"
  },
  "7101bc1c316740d99cd87185586829291a983a1d": {
    "paperId": "7101bc1c316740d99cd87185586829291a983a1d",
    "title": "Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation",
    "year": 2020,
    "authors": "Xingang Pan, Xiaohang Zhan, Bo Dai, Dahua Lin, Chen Change Loy",
    "abstract": "Learning a good image prior is a long-term goal for image restoration and manipulation. While existing methods like deep image prior (DIP) capture low-level image statistics, there are still gaps toward an image prior that captures rich image semantics including color, spatial coherence, textures, and high-level concepts. This work presents an effective way to exploit the image prior captured by a generative adversarial network (GAN) trained on large-scale natural images. As shown in Fig. 1, the deep generative prior (DGP) provides compelling results to restore missing semantics, e.g., color, patch, resolution, of various degraded images. It also enables diverse image manipulation including random jittering, image morphing, and category transfer. Such highly flexible restoration and manipulation are made possible through relaxing the assumption of existing GAN inversion methods, which tend to fix the generator. Notably, we allow the generator to be fine-tuned on-the-fly in a progressive manner regularized by feature distance obtained by the discriminator in GAN. We show that these easy-to-implement and practical changes help preserve the reconstruction to remain in the manifold of nature images, and thus lead to more precise and faithful reconstruction for real images. Code is available at https://github.com/XingangPan/deep-generative-prior.",
    "citationCount": 407,
    "pdf_filename": "2020_Exploiting_Deep_Generative_Prior_for_Ver_7101bc1c.pdf"
  },
  "3bf2147008e0bcb5d80298448fc4bf7f5d3c30ea": {
    "paperId": "3bf2147008e0bcb5d80298448fc4bf7f5d3c30ea",
    "title": "Underwater Image Enhancement Using a Multiscale Dense Generative Adversarial Network",
    "year": 2020,
    "authors": "Ye-cai Guo, Hanyu Li, Peixian Zhuang",
    "abstract": "Underwater image enhancement has received much attention in underwater vision research. However, raw underwater images easily suffer from color distortion, underexposure, and fuzz caused by the underwater scene. To address the above-mentioned problems, we propose a new multiscale dense generative adversarial network (GAN) for enhancing underwater images. The residual multiscale dense block is presented in the generator, where the multiscale, dense concatenation, and residual learning can boost the performance, render more details, and utilize previous features, respectively. And the discriminator employs computationally light spectral normalization to stabilize the training of the discriminator. Meanwhile, nonsaturating GAN loss function combining $L_1$ loss and gradient loss is presented to focus on image features of ground truth. Final enhanced results on synthetic and real underwater images demonstrate the superiority of the proposed method, which outperforms nondeep and deep learning methods in both qualitative and quantitative evaluations. Furthermore, we perform an ablation study to show the contributions of each component and carry out application tests to further demonstrate the effectiveness of the proposed method.",
    "citationCount": 405,
    "pdf_filename": "2020_Underwater_Image_Enhancement_Using_a_Mul_3bf21470.pdf"
  },
  "c09ff6965322ece56bce383266c75159234f59c4": {
    "paperId": "c09ff6965322ece56bce383266c75159234f59c4",
    "title": "A Unified Generative Framework for Various NER Subtasks",
    "year": 2021,
    "authors": "Hang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng Zhang",
    "abstract": "Named Entity Recognition (NER) is the task of identifying spans that represent entities in sentences. Whether the entity spans are nested or discontinuous, the NER task can be categorized into the flat NER, nested NER, and discontinuous NER subtasks. These subtasks have been mainly solved by the token-level sequence labelling or span-level classification. However, these solutions can hardly tackle the three kinds of NER subtasks concurrently. To that end, we propose to formulate the NER subtasks as an entity span sequence generation task, which can be solved by a unified sequence-to-sequence (Seq2Seq) framework. Based on our unified framework, we can leverage the pre-trained Seq2Seq model to solve all three kinds of NER subtasks without the special design of the tagging schema or ways to enumerate spans. We exploit three types of entity representations to linearize entities into a sequence. Our proposed framework is easy-to-implement and achieves state-of-the-art (SoTA) or near SoTA performance on eight English NER datasets, including two flat NER datasets, three nested NER datasets, and three discontinuous NER datasets.",
    "citationCount": 335,
    "pdf_filename": "2021_A_Unified_Generative_Framework_for_Vario_c09ff696.pdf"
  },
  "7e993a9ca01dcd4538362454aaac29a18a63c000": {
    "paperId": "7e993a9ca01dcd4538362454aaac29a18a63c000",
    "title": "RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion",
    "year": 2022,
    "authors": "Tengfei Wang, Bo Zhang, Ting Zhang, Shuyang Gu, Jianmin Bao",
    "abstract": "This paper presents a 3D diffusion model that automatically generates 3D digital avatars represented as neural radiance fields (NeRFs). A significant challenge for 3D diffusion is that the memory and processing costs are prohibitive for producing high-quality results with rich details. To tackle this problem, we propose the roll-out diffusion network (RODIN), which takes a 3D NeRF model represented as multiple 2D feature maps and rolls out them onto a single 2D feature plane within which we perform 3D-aware diffusion. The RODIN model brings much-needed computational efficiency while preserving the integrity of 3D diffusion by using 3D-aware convolution that attends to projected features in the 2D plane according to their original relationships in 3D. We also use latent conditioning to orchestrate the feature generation with global coherence, leading to high-fidelity avatars and enabling semantic editing based on text prompts. Finally, we use hierarchical synthesis to further enhance details. The 3D avatars generated by our model compare favorably with those produced by existing techniques. We can generate highly detailed avatars with realistic hairstyles and facial hair. We also demonstrate 3D avatar generation from image or text, as well as text-guided editability.",
    "citationCount": 348,
    "pdf_filename": "2022_RODIN__A_Generative_Model_for_Sculpting__7e993a9c.pdf"
  },
  "2d00798b8a7d979c925901e9faa5fe4360030ca2": {
    "paperId": "2d00798b8a7d979c925901e9faa5fe4360030ca2",
    "title": "Self-Supervised Learning on Graphs: Contrastive, Generative, or Predictive",
    "year": 2021,
    "authors": "Lirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan.Z.Li",
    "abstract": "Deep learning on graphs has recently achieved remarkable success on a variety of tasks, while such success relies heavily on the massive and carefully labeled data. However, precise annotations are generally very expensive and time-consuming. To address this problem, self-supervised learning (SSL) is emerging as a new paradigm for extracting informative knowledge through well-designed pretext tasks without relying on manual labels. In this survey, we extend the concept of SSL, which first emerged in the fields of computer vision and natural language processing, to present a timely and comprehensive review of existing SSL techniques for graph data. Specifically, we divide existing graph SSL methods into three categories: contrastive, generative, and predictive. More importantly, unlike other surveys that only provide a high-level description of published research, we present an additional mathematical summary of existing works in a unified framework. Furthermore, to facilitate methodological development and empirical comparisons, we also summarize the commonly used datasets, evaluation metrics, downstream tasks, open-source implementations, and experimental study of various algorithms. Finally, we discuss the technical challenges and potential future directions for improving graph self-supervised learning. Latest advances in graph SSL are summarized in a GitHub repository https://github.com/LirongWu/awesome-graph-self-supervised-learning.",
    "citationCount": 304,
    "pdf_filename": "2021_Self_Supervised_Learning_on_Graphs__Cont_2d00798b.pdf"
  },
  "6b68946e37ad95c812183d08607f9ad82019810a": {
    "paperId": "6b68946e37ad95c812183d08607f9ad82019810a",
    "title": "Inverse design of nanoporous crystalline reticular materials with deep generative models",
    "year": 2020,
    "authors": "Zhenpeng Yao, Benjamín Sánchez-Lengeling, N. Bobbitt, Benjamin J. Bucior, S. Kumar",
    "abstract": "Reticular frameworks are crystalline porous materials that form via the self-assembly of molecular building blocks in different topologies, with many having desirable properties for gas storage, separation, catalysis, biomedical applications and so on. The notable variety of building blocks makes reticular chemistry both promising and challenging for prospective materials design. Here we propose an automated nanoporous materials discovery platform powered by a supramolecular variational autoencoder for the generative design of reticular materials. We demonstrate the automated design process with a class of metal–organic framework (MOF) structures and the goal of separating carbon dioxide from natural gas or flue gas. Our model shows high fidelity in capturing MOF structural features. We show that the autoencoder has a promising optimization capability when jointly trained with multiple top adsorbent candidates identified for superior gas separation. MOFs discovered here are strongly competitive against some of the best-performing MOFs/zeolites ever reported. Reticular frameworks are crystalline porous materials with desirable properties such as gas separation, but their large design space presents a challenge. An automated nanoporous materials discovery platform powered by a supramolecular variational autoencoder can efficiently explore this space.",
    "citationCount": 305,
    "pdf_filename": "2020_Inverse_design_of_nanoporous_crystalline_6b68946e.pdf"
  },
  "155aec5cff650263a4c71136f97570611d1bba7a": {
    "paperId": "155aec5cff650263a4c71136f97570611d1bba7a",
    "title": "The Curse of Recursion: Training on Generated Data Makes Models Forget",
    "year": 2023,
    "authors": "Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Y. Gal, Nicolas Papernot",
    "abstract": "Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by LLMs in data crawled from the Internet.",
    "citationCount": 375,
    "pdf_filename": "2023_The_Curse_of_Recursion__Training_on_Gene_155aec5c.pdf"
  },
  "5be9a64df5f8d7e5a33fcc2c7bdfcde1fbbd085a": {
    "paperId": "5be9a64df5f8d7e5a33fcc2c7bdfcde1fbbd085a",
    "title": "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions",
    "year": 2023,
    "authors": "Alaa A. Abd-alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, P. Healy",
    "abstract": "The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.",
    "citationCount": 409,
    "pdf_filename": "2023_Large_Language_Models_in_Medical_Educati_5be9a64d.pdf"
  },
  "a6f7485dfdf45320e82d84bcfdc51bcd52dff18b": {
    "paperId": "a6f7485dfdf45320e82d84bcfdc51bcd52dff18b",
    "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models",
    "year": 2024,
    "authors": "Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao",
    "abstract": "Sora is a text-to-video generative AI model, released by OpenAI in February 2024. The model is trained to generate videos of realistic or imaginative scenes from text instructions and show potential in simulating the physical world. Based on public technical reports and reverse engineering, this paper presents a comprehensive review of the model's background, related technologies, applications, remaining challenges, and future directions of text-to-video AI models. We first trace Sora's development and investigate the underlying technologies used to build this\"world simulator\". Then, we describe in detail the applications and potential impact of Sora in multiple industries ranging from film-making and education to marketing. We discuss the main challenges and limitations that need to be addressed to widely deploy Sora, such as ensuring safe and unbiased video generation. Lastly, we discuss the future development of Sora and video generation models in general, and how advancements in the field could enable new ways of human-AI interaction, boosting productivity and creativity of video generation.",
    "citationCount": 455,
    "pdf_filename": "2024_Sora__A_Review_on_Background__Technology_a6f7485d.pdf"
  },
  "4761f173965195798cd3046ef4af608a83504e4d": {
    "paperId": "4761f173965195798cd3046ef4af608a83504e4d",
    "title": "TokenFlow: Consistent Diffusion Features for Consistent Video Editing",
    "year": 2023,
    "authors": "Michal Geyer, Omer Bar-Tal, Shai Bagon, Tali Dekel",
    "abstract": "The generative AI revolution has recently expanded to videos. Nevertheless, current state-of-the-art video models are still lagging behind image models in terms of visual quality and user control over the generated content. In this work, we present a framework that harnesses the power of a text-to-image diffusion model for the task of text-driven video editing. Specifically, given a source video and a target text-prompt, our method generates a high-quality video that adheres to the target text, while preserving the spatial layout and motion of the input video. Our method is based on a key observation that consistency in the edited video can be obtained by enforcing consistency in the diffusion feature space. We achieve this by explicitly propagating diffusion features based on inter-frame correspondences, readily available in the model. Thus, our framework does not require any training or fine-tuning, and can work in conjunction with any off-the-shelf text-to-image editing method. We demonstrate state-of-the-art editing results on a variety of real-world videos. Webpage: https://diffusion-tokenflow.github.io/",
    "citationCount": 358,
    "pdf_filename": "2023_TokenFlow__Consistent_Diffusion_Features_4761f173.pdf"
  },
  "0c26bfc15a7caecce0ed4567dc2f2909b80e5bdd": {
    "paperId": "0c26bfc15a7caecce0ed4567dc2f2909b80e5bdd",
    "title": "Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery",
    "year": 2023,
    "authors": "Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping",
    "abstract": "The strength of modern generative models lies in their ability to be controlled through text-based prompts. Typical\"hard\"prompts are made from interpretable words and tokens, and must be hand-crafted by humans. There are also\"soft\"prompts, which consist of continuous feature vectors. These can be discovered using powerful optimization methods, but they cannot be easily interpreted, re-used across models, or plugged into a text-based interface. We describe an approach to robustly optimize hard text prompts through efficient gradient-based optimization. Our approach automatically generates hard text-based prompts for both text-to-image and text-to-text applications. In the text-to-image setting, the method creates hard prompts for diffusion models, allowing API users to easily generate, discover, and mix and match image concepts without prior knowledge on how to prompt the model. In the text-to-text setting, we show that hard prompts can be automatically discovered that are effective in tuning LMs for classification.",
    "citationCount": 346,
    "pdf_filename": "2023_Hard_Prompts_Made_Easy__Gradient_Based_D_0c26bfc1.pdf"
  },
  "182c7b40ff7560a5545764814338f55a2098e441": {
    "paperId": "182c7b40ff7560a5545764814338f55a2098e441",
    "title": "Reinforced Self-Training (ReST) for Language Modeling",
    "year": 2023,
    "authors": "Caglar Gulcehre, T. Paine, S. Srinivasan, Ksenia Konyushkova, L. Weerts",
    "abstract": "Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.",
    "citationCount": 367,
    "pdf_filename": "2023_Reinforced_Self_Training__ReST__for_Lang_182c7b40.pdf"
  },
  "ec45c3f0f88c8ce1deb5baa71c2c0e14ad64d249": {
    "paperId": "ec45c3f0f88c8ce1deb5baa71c2c0e14ad64d249",
    "title": "Evaluating Text-to-Visual Generation with Image-to-Text Generation",
    "year": 2024,
    "authors": "Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia",
    "abstract": "Despite significant progress in generative AI, comprehensive evaluation remains challenging because of the lack of effective metrics and standardized benchmarks. For instance, the widely-used CLIPScore measures the alignment between a (generated) image and text prompt, but it fails to produce reliable scores for complex prompts involving compositions of objects, attributes, and relations. One reason is that text encoders of CLIP can notoriously act as a\"bag of words\", conflating prompts such as\"the horse is eating the grass\"with\"the grass is eating the horse\". To address this, we introduce the VQAScore, which uses a visual-question-answering (VQA) model to produce an alignment score by computing the probability of a\"Yes\"answer to a simple\"Does this figure show '{text}'?\"question. Though simpler than prior art, VQAScore computed with off-the-shelf models produces state-of-the-art results across many (8) image-text alignment benchmarks. We also compute VQAScore with an in-house model that follows best practices in the literature. For example, we use a bidirectional image-question encoder that allows image embeddings to depend on the question being asked (and vice versa). Our in-house model, CLIP-FlanT5, outperforms even the strongest baselines that make use of the proprietary GPT-4V. Interestingly, although we train with only images, VQAScore can also align text with video and 3D models. VQAScore allows researchers to benchmark text-to-visual generation using complex texts that capture the compositional structure of real-world prompts. We introduce GenAI-Bench, a more challenging benchmark with 1,600 compositional text prompts that require parsing scenes, objects, attributes, relationships, and high-order reasoning like comparison and logic. GenAI-Bench also offers over 15,000 human ratings for leading image and video generation models such as Stable Diffusion, DALL-E 3, and Gen2.",
    "citationCount": 321,
    "pdf_filename": "2024_Evaluating_Text_to_Visual_Generation_wit_ec45c3f0.pdf"
  },
  "eb8c0df75993c1c19c51cde9345e45fc260f661c": {
    "paperId": "eb8c0df75993c1c19c51cde9345e45fc260f661c",
    "title": "De novo design of protein structure and function with RFdiffusion",
    "year": 2023,
    "authors": "Joseph L. Watson, David Juergens, N. Bennett, Brian L. Trippe, Jason Yim",
    "abstract": "There has been considerable recent progress in designing new proteins using deep-learning methods^ 1 – 9 . Despite this progress, a general deep-learning framework for protein design that enables solution of a wide range of design challenges, including de novo binder design and design of higher-order symmetric architectures, has yet to be described. Diffusion models^ 10 , 11 have had considerable success in image and language generative modelling but limited success when applied to protein modelling, probably due to the complexity of protein backbone geometry and sequence–structure relationships. Here we show that by fine-tuning the RoseTTAFold structure prediction network on protein structure denoising tasks, we obtain a generative model of protein backbones that achieves outstanding performance on unconditional and topology-constrained protein monomer design, protein binder design, symmetric oligomer design, enzyme active site scaffolding and symmetric motif scaffolding for therapeutic and metal-binding protein design. We demonstrate the power and generality of the method, called RoseTTAFold diffusion (RFdiffusion), by experimentally characterizing the structures and functions of hundreds of designed symmetric assemblies, metal-binding proteins and protein binders. The accuracy of RFdiffusion is confirmed by the cryogenic electron microscopy structure of a designed binder in complex with influenza haemagglutinin that is nearly identical to the design model. In a manner analogous to networks that produce images from user-specified inputs, RFdiffusion enables the design of diverse functional proteins from simple molecular specifications. Fine-tuning the RoseTTAFold structure prediction network on protein structure denoising tasks yields a generative model for protein design that achieves outstanding performance on a wide range of protein structure and function design challenges.",
    "citationCount": 459,
    "pdf_filename": "2023_De_novo_design_of_protein_structure_and__eb8c0df7.pdf"
  },
  "69144d537f90f214d5b07a7c79121d16afd7da16": {
    "paperId": "69144d537f90f214d5b07a7c79121d16afd7da16",
    "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
    "year": 2022,
    "authors": "Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, Lingpeng Kong",
    "abstract": "Recently, diffusion models have emerged as a new paradigm for generative models. Despite the success in domains using continuous signals such as vision and audio, adapting diffusion models to natural language is under-explored due to the discrete nature of texts, especially for conditional generation. We tackle this challenge by proposing DiffuSeq: a diffusion model designed for sequence-to-sequence (Seq2Seq) text generation tasks. Upon extensive evaluation over a wide range of Seq2Seq tasks, we find DiffuSeq achieving comparable or even better performance than six established baselines, including a state-of-the-art model that is based on pre-trained language models. Apart from quality, an intriguing property of DiffuSeq is its high diversity during generation, which is desired in many Seq2Seq tasks. We further include a theoretical analysis revealing the connection between DiffuSeq and autoregressive/non-autoregressive models. Bringing together theoretical analysis and empirical evidence, we demonstrate the great potential of diffusion models in complex conditional language generation tasks. Code is available at \\url{https://github.com/Shark-NLP/DiffuSeq}",
    "citationCount": 436,
    "pdf_filename": "2022_DiffuSeq__Sequence_to_Sequence_Text_Gene_69144d53.pdf"
  },
  "036d743c7ca1e513adf0a91594fc8111e03dc30c": {
    "paperId": "036d743c7ca1e513adf0a91594fc8111e03dc30c",
    "title": "GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation",
    "year": 2020,
    "authors": "Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang",
    "abstract": "Molecular graph generation is a fundamental problem for drug discovery and has been attracting growing attention. The problem is challenging since it requires not only generating chemically valid molecular structures but also optimizing their chemical properties in the meantime. Inspired by the recent progress in deep generative models, in this paper we propose a flow-based autoregressive model for graph generation called GraphAF. GraphAF combines the advantages of both autoregressive and flow-based approaches and enjoys: (1) high model flexibility for data density estimation; (2) efficient parallel computation for training; (3) an iterative sampling process, which allows leveraging chemical domain knowledge for valency checking. Experimental results show that GraphAF is able to generate 68% chemically valid molecules even without chemical knowledge rules and 100% valid molecules with chemical rules. The training process of GraphAF is two times faster than the existing state-of-the-art approach GCPN. After fine-tuning the model for goal-directed property optimization with reinforcement learning, GraphAF achieves state-of-the-art performance on both chemical property optimization and constrained property optimization.",
    "citationCount": 489,
    "pdf_filename": "2020_GraphAF__a_Flow_based_Autoregressive_Mod_036d743c.pdf"
  },
  "e9675f461418a9c591486e5d4cecd4b42addfd75": {
    "paperId": "e9675f461418a9c591486e5d4cecd4b42addfd75",
    "title": "Learning Gradient Fields for Shape Generation",
    "year": 2020,
    "authors": "Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao, Serge J. Belongie",
    "abstract": "In this work, we propose a novel technique to generate shapes from point cloud data. A point cloud can be viewed as samples from a distribution of 3D points whose density is concentrated near the surface of the shape. Point cloud generation thus amounts to moving randomly sampled points to high-density areas. We generate point clouds by performing stochastic gradient ascent on an unnormalized probability density, thereby moving sampled points toward the high-likelihood regions. Our model directly predicts the gradient of the log density field and can be trained with a simple objective adapted from score-based generative models. We show that our method can reach state-of-the-art performance for point cloud auto-encoding and generation, while also allowing for extraction of a high-quality implicit surface. Code is available at this https URL.",
    "citationCount": 313,
    "pdf_filename": "2020_Learning_Gradient_Fields_for_Shape_Gener_e9675f46.pdf"
  },
  "59106abf8f69046e7b97968e71e2a5c2ba72599d": {
    "paperId": "59106abf8f69046e7b97968e71e2a5c2ba72599d",
    "title": "DeepSMOTE: Fusing Deep Learning and SMOTE for Imbalanced Data",
    "year": 2021,
    "authors": "Damien Dablain, B. Krawczyk, N. Chawla",
    "abstract": "Despite over two decades of progress, imbalanced data is still considered a significant challenge for contemporary machine learning models. Modern advances in deep learning have further magnified the importance of the imbalanced data problem, especially when learning from images. Therefore, there is a need for an oversampling method that is specifically tailored to deep learning models, can work on raw images while preserving their properties, and is capable of generating high-quality, artificial images that can enhance minority classes and balance the training set. We propose Deep synthetic minority oversampling technique (SMOTE), a novel oversampling algorithm for deep learning models that leverages the properties of the successful SMOTE algorithm. It is simple, yet effective in its design. It consists of three major components: 1) an encoder/decoder framework; 2) SMOTE-based oversampling; and 3) a dedicated loss function that is enhanced with a penalty term. An important advantage of DeepSMOTE over generative adversarial network (GAN)-based oversampling is that DeepSMOTE does not require a discriminator, and it generates high-quality artificial images that are both information-rich and suitable for visual inspection. DeepSMOTE code is publicly available at https://github.com/dd1github/DeepSMOTE.",
    "citationCount": 390,
    "pdf_filename": "2021_DeepSMOTE__Fusing_Deep_Learning_and_SMOT_59106abf.pdf"
  },
  "807059587a5b59401b065cfd618eef149d0d2fc5": {
    "paperId": "807059587a5b59401b065cfd618eef149d0d2fc5",
    "title": "SemiCDNet: A Semisupervised Convolutional Neural Network for Change Detection in High Resolution Remote-Sensing Images",
    "year": 2020,
    "authors": "Daifeng Peng, L. Bruzzone, Yongjun Zhang, H. Guan, H. Ding",
    "abstract": "Change detection (CD) is one of the main applications of remote sensing. With the increasing popularity of deep learning, most recent developments of CD methods have introduced the use of deep learning techniques to increase the accuracy and automation level over traditional methods. However, when using supervised CD methods, a large amount of labeled data is needed to train deep convolutional networks with millions of parameters. These labeled data are difficult to acquire for CD tasks. To address this limitation, a novel semisupervised convolutional network for CD (SemiCDNet) is proposed based on a generative adversarial network (GAN). First, both the labeled data and unlabeled data are input into the segmentation network to produce initial predictions and entropy maps. Then, to exploit the potential of unlabeled data, two discriminators are adopted to enforce the feature distribution consistency of segmentation maps and entropy maps between the labeled and unlabeled data. During the competitive training, the generator is continuously regularized by utilizing the unlabeled information, thus improving its generalization capability. The effectiveness and reliability of our proposed method are verified on two high-resolution remote sensing data sets. Extensive experimental results demonstrate the superiority of the proposed method against other state-of-the-art approaches.",
    "citationCount": 323,
    "pdf_filename": "2020_SemiCDNet__A_Semisupervised_Convolutiona_80705958.pdf"
  },
  "ebb85974e06c4879b451fdfcb4f472a09471935b": {
    "paperId": "ebb85974e06c4879b451fdfcb4f472a09471935b",
    "title": "AudioGen: Textually Guided Audio Generation",
    "year": 2022,
    "authors": "F. Kreuk, Gabriel Synnaeve, Adam Polyak, Uriel Singer, Alexandre D'efossez",
    "abstract": "We tackle the problem of generating audio samples conditioned on descriptive text captions. In this work, we propose AaudioGen, an auto-regressive generative model that generates audio samples conditioned on text inputs. AudioGen operates on a learnt discrete audio representation. The task of text-to-audio generation poses multiple challenges. Due to the way audio travels through a medium, differentiating ``objects'' can be a difficult task (e.g., separating multiple people simultaneously speaking). This is further complicated by real-world recording conditions (e.g., background noise, reverberation, etc.). Scarce text annotations impose another constraint, limiting the ability to scale models. Finally, modeling high-fidelity audio requires encoding audio at high sampling rate, leading to extremely long sequences. To alleviate the aforementioned challenges we propose an augmentation technique that mixes different audio samples, driving the model to internally learn to separate multiple sources. We curated 10 datasets containing different types of audio and text annotations to handle the scarcity of text-audio data points. For faster inference, we explore the use of multi-stream modeling, allowing the use of shorter sequences while maintaining a similar bitrate and perceptual quality. We apply classifier-free guidance to improve adherence to text. Comparing to the evaluated baselines, AudioGen outperforms over both objective and subjective metrics. Finally, we explore the ability of the proposed method to generate audio continuation conditionally and unconditionally. Samples: https://felixkreuk.github.io/audiogen",
    "citationCount": 382,
    "pdf_filename": "2022_AudioGen__Textually_Guided_Audio_Generat_ebb85974.pdf"
  },
  "d694c4cfcadd2f9e72971703a807a28e3bef6b04": {
    "paperId": "d694c4cfcadd2f9e72971703a807a28e3bef6b04",
    "title": "On Data Augmentation for GAN Training",
    "year": 2020,
    "authors": "Ngoc-Trung Tran, Viet-Hung Tran, Ngoc-Bao Nguyen, Trung-Kien Nguyen, Ngai-Man Cheung",
    "abstract": "Recent successes in Generative Adversarial Networks (GAN) have affirmed the importance of using more data in GAN training. Yet it is expensive to collect data in many domains such as medical applications. Data Augmentation (DA) has been applied in these applications. In this work, we first argue that the classical DA approach could mislead the generator to learn the distribution of the augmented data, which could be different from that of the original data. We then propose a principled framework, termed Data Augmentation Optimized for GAN (DAG), to enable the use of augmented data in GAN training to improve the learning of the original distribution. We provide theoretical analysis to show that using our proposed DAG aligns with the original GAN in minimizing the Jensen–Shannon (JS) divergence between the original distribution and model distribution. Importantly, the proposed DAG effectively leverages the augmented data to improve the learning of discriminator and generator. We conduct experiments to apply DAG to different GAN models: unconditional GAN, conditional GAN, self-supervised GAN and CycleGAN using datasets of natural images and medical images. The results show that DAG achieves consistent and considerable improvements across these models. Furthermore, when DAG is used in some GAN models, the system establishes state-of-the-art Fréchet Inception Distance (FID) scores. Our code is available (https://github.com/tntrung/dag-gans).",
    "citationCount": 309,
    "pdf_filename": "2020_On_Data_Augmentation_for_GAN_Training_d694c4cf.pdf"
  },
  "f76a5b176f3435214eb87dd105f730f0b53672c3": {
    "paperId": "f76a5b176f3435214eb87dd105f730f0b53672c3",
    "title": "Self-Supervised Speech Representation Learning: A Review",
    "year": 2022,
    "authors": "Abdel-rahman Mohamed, Hung-yi Lee, Lasse Borgholt, Jakob Drachmann Havtorn, Joakim Edin",
    "abstract": "Although supervised deep learning has revolutionized speech and audio processing, it has necessitated the building of specialist models for individual tasks and application scenarios. It is likewise difficult to apply this to dialects and languages for which only limited labeled data is available. Self-supervised representation learning methods promise a single universal model that would benefit a wide variety of tasks and domains. Such methods have shown success in natural language processing and computer vision domains, achieving new levels of performance while reducing the number of labels required for many downstream scenarios. Speech representation learning is experiencing similar progress in three main categories: generative, contrastive, and predictive methods. Other approaches rely on multi-modal data for pre-training, mixing text or visual data streams with speech. Although self-supervised speech representation is still a nascent research area, it is closely related to acoustic word embedding and learning with zero lexical resources, both of which have seen active research for many years. This review presents approaches for self-supervised speech representation learning and their connection to other research areas. Since many current methods focus solely on automatic speech recognition as a downstream task, we review recent efforts on benchmarking learned representations to extend the application beyond speech recognition.",
    "citationCount": 432,
    "pdf_filename": "2022_Self_Supervised_Speech_Representation_Le_f76a5b17.pdf"
  },
  "bbc6531afdfe41fe8664002a80d9d73a07a080d2": {
    "paperId": "bbc6531afdfe41fe8664002a80d9d73a07a080d2",
    "title": "GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting",
    "year": 2023,
    "authors": "Yiwen Chen, Zilong Chen, Chi Zhang, Feng Wang, Xiaofeng Yang",
    "abstract": "3D editing plays a crucial role in many areas such as gaming and virtual reality. Traditional 3D editing methods, which rely on representations like meshes and point clouds, often fall short in realistically depicting complex scenes. On the other hand, methods based on implicit 3D representations, like Neural Radiance Field (NeRF), render complex scenes effectively but suffer from slow processing speeds and limited control over specific scene areas. In response to these challenges, our paper presents GaussianEditor, the first 3D editing algorithm based on Gaussian Splatting (GS), a novel 3D representation. GaussianEditor enhances precision and control in editing through our proposed Gaussian semantic tracing, which traces the editing target throughout the training process. Additionally, we propose Hierarchical Gaussian splatting (HGS) to achieve stabilized and fine results under stochastic generative guidance from 2D diffusion models. We also develop editing strategies for efficient object removal and integration, a challenging task for existing methods. Our comprehensive experiments demonstrate GaussianEditor's superior control, effective, and efficient performance, marking a significant advancement in 3D editing.",
    "citationCount": 309,
    "pdf_filename": "2023_GaussianEditor__Swift_and_Controllable_3_bbc6531a.pdf"
  },
  "897f3bb5eacaa80359e81ff33378e1110e20ae95": {
    "paperId": "897f3bb5eacaa80359e81ff33378e1110e20ae95",
    "title": "All are Worth Words: A ViT Backbone for Diffusion Models",
    "year": 2022,
    "authors": "Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li",
    "abstract": "Vision transformers (ViT) have shown promise in various vision tasks while the U-Net based on a convolutional neural network (CNN) remains dominant in diffusion models. We design a simple and general ViT-based architecture (named U-ViT) for image generation with diffusion models. U-ViT is characterized by treating all inputs including the time, condition and noisy image patches as tokens and employing long skip connections between shallow and deep layers. We evaluate U-ViT in unconditional and classconditional image generation, as well as text-to-image generation tasks, where U-ViT is comparable if not superior to a CNN-based U-Net of a similar size. In particular, latent diffusion models with U-ViT achieve record-breaking FID scores of 2.29 in class-conditional image generation on ImageNet 256×256, and 5.48 in text-to-image generation on MS-COCO, among methods without accessing large external datasets during the training of generative models. Our results suggest that, for diffusion-based image modeling, the long skip connection is crucial while the down-sampling and upsampling operators in CNN-based U-Net are not always necessary. We believe that U-ViT can provide insights for future research on backbones in diffusion models and benefit generative modeling on large scale cross-modality datasets.",
    "citationCount": 481,
    "pdf_filename": "2022_All_are_Worth_Words__A_ViT_Backbone_for__897f3bb5.pdf"
  },
  "d15b27edf3630728cdb40f49946365d9011641cf": {
    "paperId": "d15b27edf3630728cdb40f49946365d9011641cf",
    "title": "Text2Mesh: Text-Driven Neural Stylization for Meshes",
    "year": 2021,
    "authors": "O. Michel, Roi Bar-On, Richard Liu, Sagie Benaim, Rana Hanocka",
    "abstract": "In this work, we develop intuitive controls for editing the style of 3D objects. Our framework, Text2Mesh, stylizes a 3D mesh by predicting color and local geometric details which conform to a target text prompt. We consider a disentangled representation of a 3D object using a fixed mesh input (content) coupled with a learned neural network, which we term a neural style field network (NSF). In order to modify style, we obtain a similarity score between a text prompt (describing style) and a stylized mesh by harnessing the representational power of CLIP. Text2Mesh requires neither a pre-trained generative model nor a specialized 3D mesh dataset. It can handle low-quality meshes (non-manifold, boundaries, etc.) with arbitrary genus, and does not require UV parameterization. We demonstrate the ability of our technique to synthesize a myriad of styles over a wide variety of 3D meshes. Our code and results are available in our project webpage: https://threedle.github.io/text2meshl.",
    "citationCount": 408,
    "pdf_filename": "2021_Text2Mesh__Text_Driven_Neural_Stylizatio_d15b27ed.pdf"
  },
  "0483be6c3ec6cd41ffe248f86effc7468d3ac7be": {
    "paperId": "0483be6c3ec6cd41ffe248f86effc7468d3ac7be",
    "title": "CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields",
    "year": 2021,
    "authors": "Can Wang, Menglei Chai, Mingming He, Dongdong Chen, Jing Liao",
    "abstract": "We present CLIP-NeRF, a multi-modal 3D object manipulation method for neural radiance fields (NeRF). By leveraging the joint language-image embedding space of the recent Contrastive Language-Image Pre-Training (CLIP) model, we propose a unified framework that allows manip-ulating NeRF in a user-friendly way, using either a short text prompt or an exemplar image. Specifically, to combine the novel view synthesis capability of NeRF and the controllable manipulation ability of latent representations from generative models, we introduce a disentangled conditional NeRF architecture that allows individual control over both shape and appearance. This is achieved by performing the shape conditioning via applying a learned deformation field to the positional encoding and deferring color conditioning to the volumetric rendering stage. To bridge this disentangled latent representation to the CLIP embedding, we design two code mappers that take a CLIP embedding as input and update the latent codes to reflect the targeted editing. The mappers are trained with a CLIP-based matching loss to ensure the manipulation accuracy. Furthermore, we propose an inverse optimization method that accurately projects an input image to the latent codes for manipulation to enable editing on real images. We evaluate our approach by extensive experiments on a variety of text prompts and exemplar images and also provide an intuitive interface for interactive editing.",
    "citationCount": 433,
    "pdf_filename": "2021_CLIP_NeRF__Text_and_Image_Driven_Manipul_0483be6c.pdf"
  },
  "ed4603ea341acc26cab24f41aa40524fb7779917": {
    "paperId": "ed4603ea341acc26cab24f41aa40524fb7779917",
    "title": "LaVie: High-Quality Video Generation with Cascaded Latent Diffusion Models",
    "year": 2023,
    "authors": "Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang",
    "abstract": "This work aims to learn a high-quality text-to-video (T2V) generative model by leveraging a pre-trained text-to-image (T2I) model as a basis. It is a highly desirable yet challenging task to simultaneously (a) accomplish the synthesis of visually realistic and temporally coherent videos while (b) preserving the strong creative generation nature of the pre-trained T2I model. To this end, we propose LaVie, an integrated video generation framework that operates on cascaded video latent diffusion models, comprising a base T2V model, a temporal interpolation model, and a video super-resolution model. Our key insights are two-fold: (1) We reveal that the incorporation of simple temporal self-attentions, coupled with rotary positional encoding, adequately captures the temporal correlations inherent in video data. (2) Additionally, we validate that the process of joint image-video fine-tuning plays a pivotal role in producing high-quality and creative outcomes. To enhance the performance of LaVie, we contribute a comprehensive and diverse video dataset named Vimeo25M, consisting of 25 million text-video pairs that prioritize quality, diversity, and aesthetic appeal. Extensive experiments demonstrate that LaVie achieves state-of-the-art performance both quantitatively and qualitatively. Furthermore, we showcase the versatility of pre-trained LaVie models in various long video generation and personalized video synthesis applications. Project page: https://github.com/Vchitect/LaVie/.",
    "citationCount": 304,
    "pdf_filename": "2023_LaVie__High_Quality_Video_Generation_wit_ed4603ea.pdf"
  },
  "05afe403fd398f774aed4e9872a0eca1dfa21d36": {
    "paperId": "05afe403fd398f774aed4e9872a0eca1dfa21d36",
    "title": "Focal Frequency Loss for Image Reconstruction and Synthesis",
    "year": 2020,
    "authors": "Liming Jiang, Bo Dai, Wayne Wu, Chen Change Loy",
    "abstract": "Image reconstruction and synthesis have witnessed remarkable progress thanks to the development of generative models. Nonetheless, gaps could still exist between the real and generated images, especially in the frequency domain. In this study, we show that narrowing gaps in the frequency domain can ameliorate image reconstruction and synthesis quality further. We propose a novel focal frequency loss, which allows a model to adaptively focus on frequency components that are hard to synthesize by down-weighting the easy ones. This objective function is complementary to existing spatial losses, offering great impedance against the loss of important frequency information due to the inherent bias of neural networks. We demonstrate the versatility and effectiveness of focal frequency loss to improve popular models, such as VAE, pix2pix, and SPADE, in both perceptual quality and quantitative performance. We further show its potential on StyleGAN2. 1, 2",
    "citationCount": 359,
    "pdf_filename": "2020_Focal_Frequency_Loss_for_Image_Reconstru_05afe403.pdf"
  },
  "1e4b6567ff66de6cdcbe58c863538241e2f62b45": {
    "paperId": "1e4b6567ff66de6cdcbe58c863538241e2f62b45",
    "title": "Aligning Text-to-Image Models using Human Feedback",
    "year": 2023,
    "authors": "Kimin Lee, Hao Liu, M. Ryu, Olivia Watkins, Yuqing Du",
    "abstract": "Deep generative models have shown impressive results in text-to-image synthesis. However, current text-to-image models often generate images that are inadequately aligned with text prompts. We propose a fine-tuning method for aligning such models using human feedback, comprising three stages. First, we collect human feedback assessing model output alignment from a set of diverse text prompts. We then use the human-labeled image-text dataset to train a reward function that predicts human feedback. Lastly, the text-to-image model is fine-tuned by maximizing reward-weighted likelihood to improve image-text alignment. Our method generates objects with specified colors, counts and backgrounds more accurately than the pre-trained model. We also analyze several design choices and find that careful investigations on such design choices are important in balancing the alignment-fidelity tradeoffs. Our results demonstrate the potential for learning from human feedback to significantly improve text-to-image models.",
    "citationCount": 368,
    "pdf_filename": "2023_Aligning_Text_to_Image_Models_using_Huma_1e4b6567.pdf"
  },
  "c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d": {
    "paperId": "c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d",
    "title": "Why Normalizing Flows Fail to Detect Out-of-Distribution Data",
    "year": 2020,
    "authors": "P. Kirichenko, Pavel Izmailov, A. Wilson",
    "abstract": "Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing flows are flexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a flow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing flows perform poorly for OOD detection. We demonstrate that flows learn local pixel correlations and generic image-to-latent-space transformations which are not specific to the target image dataset. We show that by modifying the architecture of flow coupling layers we can bias the flow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable flows to generate high-fidelity images can have a detrimental effect on OOD detection.",
    "citationCount": 308,
    "pdf_filename": "2020_Why_Normalizing_Flows_Fail_to_Detect_Out_c2eff53c.pdf"
  },
  "0c4f46e4dcae5527018e6432fb60cfe8c3354e97": {
    "paperId": "0c4f46e4dcae5527018e6432fb60cfe8c3354e97",
    "title": "VideoPoet: A Large Language Model for Zero-Shot Video Generation",
    "year": 2023,
    "authors": "D. Kondratyuk, Lijun Yu, Xiuye Gu, José Lezama, Jonathan Huang",
    "abstract": "We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/",
    "citationCount": 381,
    "pdf_filename": "2023_VideoPoet__A_Large_Language_Model_for_Ze_0c4f46e4.pdf"
  },
  "85ae09edef1dac1f147ca80a743e878a7a4e1547": {
    "paperId": "85ae09edef1dac1f147ca80a743e878a7a4e1547",
    "title": "ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation",
    "year": 2020,
    "authors": "Chuang Gan, Jeremy Schwartz, S. Alter, Martin Schrimpf, James Traer",
    "abstract": "We introduce ThreeDWorld (TDW), a platform for interactive multi-modal physical simulation. With TDW, users can simulate high-fidelity sensory data and physical interactions between mobile agents and objects in a wide variety of rich 3D environments. TDW has several unique properties: 1) realtime near photo-realistic image rendering quality; 2) a library of objects and environments with materials for high-quality rendering, and routines enabling user customization of the asset library; 3) generative procedures for efficiently building classes of new environments 4) high-fidelity audio rendering; 5) believable and realistic physical interactions for a wide variety of material types, including cloths, liquid, and deformable objects; 6) a range of \"avatar\" types that serve as embodiments of AI agents, with the option for user avatar customization; and 7) support for human interactions with VR devices. TDW also provides a rich API enabling multiple agents to interact within a simulation and return a range of sensor and physics data representing the state of the world. We present initial experiments enabled by the platform around emerging research directions in computer vision, machine learning, and cognitive science, including multi-modal physical scene understanding, multi-agent interactions, models that \"learn like a child\", and attention studies in humans and neural networks. The simulation platform will be made publicly available.",
    "citationCount": 347,
    "pdf_filename": "2020_ThreeDWorld__A_Platform_for_Interactive__85ae09ed.pdf"
  },
  "c5f7074a264356c9a022a8dff24df79d1db8c3d3": {
    "paperId": "c5f7074a264356c9a022a8dff24df79d1db8c3d3",
    "title": "ProGen: Language Modeling for Protein Generation",
    "year": 2020,
    "authors": "Ali Madani, Bryan McCann, N. Naik, N. Keskar, N. Anand",
    "abstract": "Generative modeling for protein engineering is key to solving fundamental problems in synthetic biology, medicine, and material science. We pose protein engineering as an unsupervised sequence generation problem in order to leverage the exponentially growing set of proteins that lack costly, structural annotations. We train a 1.2B-parameter language model, ProGen, on ∼280M protein sequences conditioned on taxonomic and keyword tags such as molecular function and cellular component. This provides ProGen with an unprecedented range of evolutionary sequence diversity and allows it to generate with fine-grained control as demonstrated by metrics based on primary sequence similarity, secondary structure accuracy, and conformational energy.",
    "citationCount": 312,
    "pdf_filename": "2020_ProGen__Language_Modeling_for_Protein_Ge_c5f7074a.pdf"
  },
  "62ad7ea9467bbcdbfe325b9ee561cab3908e4583": {
    "paperId": "62ad7ea9467bbcdbfe325b9ee561cab3908e4583",
    "title": "MEGA: Multilingual Evaluation of Generative AI",
    "year": 2023,
    "authors": "Kabir Ahuja, Rishav Hada, Millicent Ochieng, Prachi Jain, Harshita Diddee",
    "abstract": "Generative AI models have shown impressive performance on many Natural Language Processing tasks such as language understanding, reasoning, and language generation. An important question being asked by the AI community today is about the capabilities and limits of these models, and it is clear that evaluating generative AI is very challenging. Most studies on generative LLMs have been restricted to English and it is unclear how capable these models are at understanding and generating text in other languages. We present the first comprehensive benchmarking of generative LLMs - MEGA, which evaluates models on standard NLP benchmarks, covering 16 NLP datasets across 70 typologically diverse languages. We compare the performance of generative LLMs including Chat-GPT and GPT-4 to State of the Art (SOTA) non-autoregressive models on these tasks to determine how well generative models perform compared to the previous generation of LLMs. We present a thorough analysis of the performance of models across languages and tasks and discuss challenges in improving the performance of generative LLMs on low-resource languages. We create a framework for evaluating generative LLMs in the multilingual setting and provide directions for future progress in the field.",
    "citationCount": 337,
    "pdf_filename": "2023_MEGA__Multilingual_Evaluation_of_Generat_62ad7ea9.pdf"
  },
  "ea5865334a2ab386e76f22e0b4775aa904fe6920": {
    "paperId": "ea5865334a2ab386e76f22e0b4775aa904fe6920",
    "title": "The impact of Generative AI (GenAI) on practices, policies and research direction in education: a case of ChatGPT and Midjourney",
    "year": 2023,
    "authors": "Thomas K. F. Chiu",
    "abstract": "Abstract Generative artificial intelligence (GenAI) tools have become increasingly accessible and have impacted school education in numerous ways. However, most of the discussions occur in higher education. In schools, teachers’ perspectives are crucial for making sense of innovative technologies. Accordingly, this qualitative study aims to investigate how GenAI changes our school education from the perspectives of teachers and leaders. It used four domains – learning, teaching, assessment, and administration – as the initial framework suggested in a systematic literature review study on AI in education. The participants were 88 school teachers and leaders of different backgrounds. They completed a survey and joined a focus group to share how ChatGPT and Midjounery had a GenAI effect on school education. Thematic analysis identified four main themes and 12 subthemes. The findings provide three suggestions for practices: know-it-all attitude, new prerequisite knowledge, interdisciplinary teaching, and three implications for policy: new assessment, AI education, and professional standards. They also further suggest six future research directions for GenAI in education.",
    "citationCount": 452,
    "pdf_filename": "2023_The_impact_of_Generative_AI__GenAI__on_p_ea586533.pdf"
  },
  "223cdf1198a045c049f2359ad9d1db77e8028e80": {
    "paperId": "223cdf1198a045c049f2359ad9d1db77e8028e80",
    "title": "Art and the science of generative AI",
    "year": 2023,
    "authors": "Ziv Epstein, Aaron Hertzmann, L. Herman, Robert Mahari, M. Frank",
    "abstract": "Understanding shifts in creative work will help guide AI’s impact on the media ecosystem The capabilities of a new class of tools, colloquially known as generative artificial intelligence (AI), is a topic of much debate. One prominent application thus far is the production of high-quality artistic media for visual arts, concept art, music, and literature, as well as video and animation. For example, diffusion models can synthesize high-quality images (1), and large language models (LLMs) can produce sensible-sounding and impressive prose and verse in a wide range of contexts (2). The generative capabilities of these tools are likely to fundamentally alter the creative processes by which creators formulate ideas and put them into production. As creativity is reimagined, so too may be many sectors of society. Understanding the impact of generative AI—and making policy decisions around it—requires new interdisciplinary scientific inquiry into culture, economics, law, algorithms, and the interaction of technology and creativity.",
    "citationCount": 458,
    "pdf_filename": "2023_Art_and_the_science_of_generative_AI_223cdf11.pdf"
  },
  "bd166912fa16cec04e3ee044a0d0fb6e3ac6fe33": {
    "paperId": "bd166912fa16cec04e3ee044a0d0fb6e3ac6fe33",
    "title": "Regulating ChatGPT and other Large Generative AI Models",
    "year": 2023,
    "authors": "P. Hacker, A. Engel, M. Mauer",
    "abstract": "Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.",
    "citationCount": 411,
    "pdf_filename": "2023_Regulating_ChatGPT_and_other_Large_Gener_bd166912.pdf"
  },
  "f75f924f53082736b5ecd85b7198f7d79e42e4ae": {
    "paperId": "f75f924f53082736b5ecd85b7198f7d79e42e4ae",
    "title": "Unlocking the Power of ChatGPT: A Framework for Applying Generative AI in Education",
    "year": 2023,
    "authors": "Jiahong Su (苏嘉红), Weipeng Yang (杨伟鹏)",
    "abstract": "Purpose Artificial intelligence (AI) chatbots, such as ChatGPT and GPT-4, developed by OpenAI, have the potential to revolutionize education. This study explores the potential benefits and challenges of using ChatGPT in education (or “educative AI”). Design/Approach/Methods This paper proposes a theoretical framework called “IDEE” for educative AI such as using ChatGPT and other generative AI in education, which includes identifying the desired outcomes, determining the appropriate level of automation, ensuring ethical considerations, and evaluating effectiveness. Findings The benefits of using ChatGPT in education or more generally, educative AI, include a more personalized and efficient learning experience for students as well as easier and faster feedback for teachers. However, challenges such as the untested effectiveness of the technology, limitations in the quality of data, and ethical and safety concerns must also be considered. Originality/Value This study explored the opportunities and challenges of using ChatGPT in education within the proposed theoretical framework.",
    "citationCount": 400,
    "pdf_filename": "2023_Unlocking_the_Power_of_ChatGPT__A_Framew_f75f924f.pdf"
  },
  "cdae0d5333b00e006a5e9f209a394ae46a3a0cc3": {
    "paperId": "cdae0d5333b00e006a5e9f209a394ae46a3a0cc3",
    "title": "The Power of Generative AI: A Review of Requirements, Models, Input-Output Formats, Evaluation Metrics, and Challenges",
    "year": 2023,
    "authors": "A. Bandi, Pydi Venkata Satya Ramesh Adapa, Yudu Eswar Vinay Pratap Kumar Kuchi",
    "abstract": "Generative artificial intelligence (AI) has emerged as a powerful technology with numerous applications in various domains. There is a need to identify the requirements and evaluation metrics for generative AI models designed for specific tasks. The purpose of the research aims to investigate the fundamental aspects of generative AI systems, including their requirements, models, input–output formats, and evaluation metrics. The study addresses key research questions and presents comprehensive insights to guide researchers, developers, and practitioners in the field. Firstly, the requirements necessary for implementing generative AI systems are examined and categorized into three distinct categories: hardware, software, and user experience. Furthermore, the study explores the different types of generative AI models described in the literature by presenting a taxonomy based on architectural characteristics, such as variational autoencoders (VAEs), generative adversarial networks (GANs), diffusion models, transformers, language models, normalizing flow models, and hybrid models. A comprehensive classification of input and output formats used in generative AI systems is also provided. Moreover, the research proposes a classification system based on output types and discusses commonly used evaluation metrics in generative AI. The findings contribute to advancements in the field, enabling researchers, developers, and practitioners to effectively implement and evaluate generative AI models for various applications. The significance of the research lies in understanding that generative AI system requirements are crucial for effective planning, design, and optimal performance. A taxonomy of models aids in selecting suitable options and driving advancements. Classifying input–output formats enables leveraging diverse formats for customized systems, while evaluation metrics establish standardized methods to assess model quality and performance.",
    "citationCount": 367,
    "pdf_filename": "2023_The_Power_of_Generative_AI__A_Review_of__cdae0d53.pdf"
  },
  "1f22de83d912176cb8857efa1c6d65b14d6a2f5c": {
    "paperId": "1f22de83d912176cb8857efa1c6d65b14d6a2f5c",
    "title": "ChatGPT is not all you need. A State of the Art Review of large Generative AI models",
    "year": 2023,
    "authors": "Roberto Gozalo-Brizuela, E.C. Garrido-Merchán",
    "abstract": "During the last two years there has been a plethora of large generative models such as ChatGPT or Stable Diffusion that have been published. Concretely, these models are able to perform tasks such as being a general question and answering system or automatically creating artistic images that are revolutionizing several sectors. Consequently, the implications that these generative models have in the industry and society are enormous, as several job positions may be transformed. For example, Generative AI is capable of transforming effectively and creatively texts to images, like the DALLE-2 model; text to 3D images, like the Dreamfusion model; images to text, like the Flamingo model; texts to video, like the Phenaki model; texts to audio, like the AudioLM model; texts to other texts, like ChatGPT; texts to code, like the Codex model; texts to scientific texts, like the Galactica model or even create algorithms like AlphaTensor. This work consists on an attempt to describe in a concise way the main models are sectors that are affected by generative AI and to provide a taxonomy of the main generative models published recently.",
    "citationCount": 317,
    "pdf_filename": "2023_ChatGPT_is_not_all_you_need__A_State_of__1f22de83.pdf"
  },
  "b867ec2add2a3ef26ab2c3080d5f7d4d400d8270": {
    "paperId": "b867ec2add2a3ef26ab2c3080d5f7d4d400d8270",
    "title": "The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and millennial generation teachers?",
    "year": 2023,
    "authors": "C. Chan, Katherine K. W. Lee",
    "abstract": "This study aimed to explore the experiences, perceptions, knowledge, concerns, and intentions of Generation Z (Gen Z) students with Generation X (Gen X) and Generation Y (Gen Y) teachers regarding the use of generative AI (GenAI) in higher education. A sample of students and teachers were recruited to investigate the above using a survey consisting of both open and closed questions. The findings showed that Gen Z participants were generally optimistic about the potential benefits of GenAI, including enhanced productivity, efficiency, and personalized learning, and expressed intentions to use GenAI for various educational purposes. Gen X and Gen Y teachers acknowledged the potential benefits of GenAI but expressed heightened concerns about overreliance, ethical and pedagogical implications, emphasizing the need for proper guidelines and policies to ensure responsible use of the technology. The study highlighted the importance of combining technology with traditional teaching methods to provide a more effective learning experience. Implications of the findings include the need to develop evidence-based guidelines and policies for GenAI integration, foster critical thinking and digital literacy skills among students, and promote responsible use of GenAI technologies in higher education.",
    "citationCount": 379,
    "pdf_filename": "2023_The_AI_generation_gap__Are_Gen_Z_student_b867ec2a.pdf"
  },
  "7bd7431f0fa8ad5738cb2e481e8d415857b66107": {
    "paperId": "7bd7431f0fa8ad5738cb2e481e8d415857b66107",
    "title": "Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT",
    "year": 2023,
    "authors": "Rosario Michel-Villarreal, E. Vilalta-Perdomo, D. Salinas-Navarro, Ricardo Thierry-Aguilera, F. S. Gerardou",
    "abstract": "ChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT’s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes.",
    "citationCount": 481,
    "pdf_filename": "2023_Challenges_and_Opportunities_of_Generati_7bd7431f.pdf"
  },
  "35ccd924de9e8483bdcf144cbf2edf09be157b7e": {
    "paperId": "35ccd924de9e8483bdcf144cbf2edf09be157b7e",
    "title": "Text-to-image Diffusion Models in Generative AI: A Survey",
    "year": 2023,
    "authors": "Chenshuang Zhang, Chaoning Zhang, Mengchun Zhang, In-So Kweon",
    "abstract": "This survey reviews the progress of diffusion models in generating images from text, ~\\textit{i.e.} text-to-image diffusion models. As a self-contained work, this survey starts with a brief introduction of how diffusion models work for image synthesis, followed by the background for text-conditioned image synthesis. Based on that, we present an organized review of pioneering methods and their improvements on text-to-image generation. We further summarize applications beyond image generation, such as text-guided generation for various modalities like videos, and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.",
    "citationCount": 364,
    "pdf_filename": "2023_Text_to_image_Diffusion_Models_in_Genera_35ccd924.pdf"
  },
  "98478ac589e5b40a20630ff54bb4eec4ab4c5f6b": {
    "paperId": "98478ac589e5b40a20630ff54bb4eec4ab4c5f6b",
    "title": "GAIA-1: A Generative World Model for Autonomous Driving",
    "year": 2023,
    "authors": "Anthony Hu, Lloyd Russell, Hudson Yeo, Zak Murez, George Fedoseev",
    "abstract": "Autonomous driving promises transformative improvements to transportation, but building systems capable of safely navigating the unstructured complexity of real-world scenarios remains challenging. A critical problem lies in effectively predicting the various potential outcomes that may emerge in response to the vehicle's actions as the world evolves. To address this challenge, we introduce GAIA-1 ('Generative AI for Autonomy'), a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features. Our approach casts world modeling as an unsupervised sequence modeling problem by mapping the inputs to discrete tokens, and predicting the next token in the sequence. Emerging properties from our model include learning high-level structures and scene dynamics, contextual awareness, generalization, and understanding of geometry. The power of GAIA-1's learned representation that captures expectations of future events, combined with its ability to generate realistic samples, provides new possibilities for innovation in the field of autonomy, enabling enhanced and accelerated training of autonomous driving technology.",
    "citationCount": 384,
    "pdf_filename": "2023_GAIA_1__A_Generative_World_Model_for_Aut_98478ac5.pdf"
  },
  "e03dc5bd72bea7d1db03de380d4c43b7e610fbee": {
    "paperId": "e03dc5bd72bea7d1db03de380d4c43b7e610fbee",
    "title": "Evaluating Verifiability in Generative Search Engines",
    "year": 2023,
    "authors": "Nelson F. Liu, Tianyi Zhang, Percy Liang",
    "abstract": "Generative search engines directly generate responses to user queries, along with in-line citations. A prerequisite trait of a trustworthy generative search engine is verifiability, i.e., systems should cite comprehensively (high citation recall; all statements are fully supported by citations) and accurately (high citation precision; every cite supports its associated statement). We conduct human evaluation to audit four popular generative search engines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse set of queries from a variety of sources (e.g., historical Google user queries, dynamically-collected open-ended questions on Reddit, etc.). We find that responses from existing generative search engines are fluent and appear informative, but frequently contain unsupported statements and inaccurate citations: on average, a mere 51.5% of generated sentences are fully supported by citations and only 74.5% of citations support their associated sentence. We believe that these results are concerningly low for systems that may serve as a primary tool for information-seeking users, especially given their facade of trustworthiness. We hope that our results further motivate the development of trustworthy generative search engines and help researchers and users better understand the shortcomings of existing commercial systems.",
    "citationCount": 309,
    "pdf_filename": "2023_Evaluating_Verifiability_in_Generative_S_e03dc5bd.pdf"
  },
  "c5ab57bc7dd7695e699b017f4efebc78a77897ec": {
    "paperId": "c5ab57bc7dd7695e699b017f4efebc78a77897ec",
    "title": "Transforming Education: A Comprehensive Review of Generative Artificial Intelligence in Educational Settings through Bibliometric and Content Analysis",
    "year": 2023,
    "authors": "Zied Bahroun, Chiraz Anane, Vian Ahmed, Andrew Zacca",
    "abstract": "In the ever-evolving era of technological advancements, generative artificial intelligence (GAI) emerges as a transformative force, revolutionizing education. This review paper, guided by the PRISMA framework, presents a comprehensive analysis of GAI in education, synthesizing key insights from a selection of 207 research papers to identify research gaps and future directions in the field. This study begins with a content analysis that explores GAI’s transformative impact in specific educational domains, including medical education and engineering education. The versatile applications of GAI encompass assessment, personalized learning support, and intelligent tutoring systems. Ethical considerations, interdisciplinary collaboration, and responsible technology use are highlighted, emphasizing the need for transparent GAI models and addressing biases. Subsequently, a bibliometric analysis of GAI in education is conducted, examining prominent AI tools, research focus, geographic distribution, and interdisciplinary collaboration. ChatGPT emerges as a dominant GAI tool, and the analysis reveals significant and exponential growth in GAI research in 2023. Moreover, this paper identifies promising future research directions, such as GAI-enhanced curriculum design and longitudinal studies tracking its long-term impact on learning outcomes. These findings provide a comprehensive understanding of GAI’s potential in reshaping education and offer valuable insights to researchers, educators, and policymakers interested in the intersection of GAI and education.",
    "citationCount": 424,
    "pdf_filename": "2023_Transforming_Education__A_Comprehensive__c5ab57bc.pdf"
  },
  "0e98bd81aadc503e77411e17eafd9bfe58ac33a4": {
    "paperId": "0e98bd81aadc503e77411e17eafd9bfe58ac33a4",
    "title": "Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge.",
    "year": 2023,
    "authors": "Zahir Kanjee, Byron Crowe, A. Rodman",
    "abstract": "\n This study assesses the diagnostic accuracy of the Generative Pre-trained Transformer 4 (GPT-4) artificial intelligence (AI) model in a series of challenging cases.\n",
    "citationCount": 310,
    "pdf_filename": "2023_Accuracy_of_a_Generative_Artificial_Inte_0e98bd81.pdf"
  },
  "603d3f90fc40f79ff51258f0295de3ec5107f73e": {
    "paperId": "603d3f90fc40f79ff51258f0295de3ec5107f73e",
    "title": "AI models collapse when trained on recursively generated data",
    "year": 2024,
    "authors": "Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson",
    "abstract": "Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet. Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.",
    "citationCount": 482,
    "pdf_filename": "2024_AI_models_collapse_when_trained_on_recur_603d3f90.pdf"
  },
  "81e8666325b02b1287d4fdcf33232c74e7144f9a": {
    "paperId": "81e8666325b02b1287d4fdcf33232c74e7144f9a",
    "title": "The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review",
    "year": 2024,
    "authors": "Chunpeng Zhai, Santoso Wibowo, Lily D. Li",
    "abstract": "The growing integration of artificial intelligence (AI) dialogue systems within educational and research settings highlights the importance of learning aids. Despite examination of the ethical concerns associated with these technologies, there is a noticeable gap in investigations on how these ethical issues of AI contribute to students’ over-reliance on AI dialogue systems, and how such over-reliance affects students’ cognitive abilities. Overreliance on AI occurs when users accept AI-generated recommendations without question, leading to errors in task performance in the context of decision-making. This typically arises when individuals struggle to assess the reliability of AI or how much trust to place in its suggestions. This systematic review investigates how students’ over-reliance on AI dialogue systems, particularly those embedded with generative models for academic research and learning, affects their critical cognitive capabilities including decision-making, critical thinking, and analytical reasoning. By using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, our systematic review evaluated a body of literature addressing the contributing factors and effects of such over-reliance within educational and research contexts. The comprehensive literature review spanned 14 articles retrieved from four distinguished databases: ProQuest, IEEE Xplore, ScienceDirect, and Web of Science. Our findings indicate that over-reliance stemming from ethical issues of AI impacts cognitive abilities, as individuals increasingly favor fast and optimal solutions over slow ones constrained by practicality. This tendency explains why users prefer efficient cognitive shortcuts, or heuristics, even amidst the ethical issues presented by AI technologies.",
    "citationCount": 494,
    "pdf_filename": "2024_The_effects_of_over_reliance_on_AI_dialo_81e86663.pdf"
  },
  "15abedb29536d50afeeec739a25358255cbda3e8": {
    "paperId": "15abedb29536d50afeeec739a25358255cbda3e8",
    "title": "The Impact of AI on Developer Productivity: Evidence from GitHub Copilot",
    "year": 2023,
    "authors": "Sida Peng, Eirini Kalliamvakou, Peter Cihon, Mert Demirer",
    "abstract": "Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.",
    "citationCount": 415,
    "pdf_filename": "2023_The_Impact_of_AI_on_Developer_Productivi_15abedb2.pdf"
  },
  "304f8b4edea01fdb5a2f7f8b998c83188deeccff": {
    "paperId": "304f8b4edea01fdb5a2f7f8b998c83188deeccff",
    "title": "Towards Generalist Biomedical AI",
    "year": 2023,
    "authors": "Tao Tu, Shekoofeh Azizi, Danny Driess, Mike Schaekermann, Mohamed Amin",
    "abstract": "Medicine is inherently multimodal, with rich data modalities spanning text, imaging, genomics, and more. Generalist biomedical artificial intelligence (AI) systems that flexibly encode, integrate, and interpret this data at scale can potentially enable impactful applications ranging from scientific discovery to care delivery. To enable the development of these models, we first curate MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses 14 diverse tasks such as medical question answering, mammography and dermatology image interpretation, radiology report generation and summarization, and genomic variant calling. We then introduce Med-PaLM Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI system. Med-PaLM M is a large multimodal generative model that flexibly encodes and interprets biomedical data including clinical language, imaging, and genomics with the same set of model weights. Med-PaLM M reaches performance competitive with or exceeding the state of the art on all MultiMedBench tasks, often surpassing specialist models by a wide margin. We also report examples of zero-shot generalization to novel medical concepts and tasks, positive transfer learning across tasks, and emergent zero-shot medical reasoning. To further probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist evaluation of model-generated (and human) chest X-ray reports and observe encouraging performance across model scales. In a side-by-side ranking on 246 retrospective chest X-rays, clinicians express a pairwise preference for Med-PaLM M reports over those produced by radiologists in up to 40.50% of cases, suggesting potential clinical utility. While considerable work is needed to validate these models in real-world use cases, our results represent a milestone towards the development of generalist biomedical AI systems.",
    "citationCount": 386,
    "pdf_filename": "2023_Towards_Generalist_Biomedical_AI_304f8b4e.pdf"
  },
  "370a9fff56ff5b9a54c96b818cff34b9c59e1b67": {
    "paperId": "370a9fff56ff5b9a54c96b818cff34b9c59e1b67",
    "title": "Leadership is needed for ethical ChatGPT: Character, assessment, and learning using artificial intelligence (AI)",
    "year": 2023,
    "authors": "J. Crawford, Michael Cowling, Kelly-Ann Allen",
    "abstract": "The OpenAI’s ChatGPT-3, or Chat Generative Pre-Trained Transformer was released in November 2022 without significant warning, and has taken higher education by storm since. The artificial intelligence (AI)-powered chatbot has caused alarm for practitioners seeking to detect authenticity of student work. Whereas some educational doomsayers predict the end of education in its current form, we propose an alternate early view. We identify in this commentary a position where educators can leverage AI like ChatGPT to build supportive learning environments for students who have cultivated good character. Such students know how to use ChatGPT for good, and can engage effectively with the ChatGPT application. In building our ChatGPT argument, we acknowledge the existing literature on plagiarism and academic integrity, and consider leadership as a root support mechanism, character development as an antidote, and authentic assessment as an enabler. In doing so, we highlight that while ChatGPT – like papermills, and degree factories before it – can be used to cheat on university exams, it can also be used to support deeper learning and better learning outcomes for students. In doing so, we offer a commentary that offers opportunities for practitioners, and research potential for scholars.",
    "citationCount": 403,
    "pdf_filename": "2023_Leadership_is_needed_for_ethical_ChatGPT_370a9fff.pdf"
  },
  "bd3558bc203b5006d5bcdc214bfcc65430c576d1": {
    "paperId": "bd3558bc203b5006d5bcdc214bfcc65430c576d1",
    "title": "Testing of detection tools for AI-generated text",
    "year": 2023,
    "authors": "Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, T. Foltýnek, J. Guerrero-Dib",
    "abstract": "Recent advances in generative pre-trained transformer large language models have emphasised the potential risks of unfair use of artificial intelligence (AI) generated content in an academic environment and intensified efforts in searching for solutions to detect such content. The paper examines the general functionality of detection tools for AI-generated text and evaluates them based on accuracy and error type analysis. Specifically, the study seeks to answer research questions about whether existing detection tools can reliably differentiate between human-written text and ChatGPT-generated text, and whether machine translation and content obfuscation techniques affect the detection of AI-generated text. The research covers 12 publicly available tools and two commercial systems (Turnitin and PlagiarismCheck) that are widely used in the academic setting. The researchers conclude that the available detection tools are neither accurate nor reliable and have a main bias towards classifying the output as human-written rather than detecting AI-generated text. Furthermore, content obfuscation techniques significantly worsen the performance of tools. The study makes several significant contributions. First, it summarises up-to-date similar scientific and non-scientific efforts in the field. Second, it presents the result of one of the most comprehensive tests conducted so far, based on a rigorous research methodology, an original document set, and a broad coverage of tools. Third, it discusses the implications and drawbacks of using detection tools for AI-generated text in academic settings.",
    "citationCount": 317,
    "pdf_filename": "2023_Testing_of_detection_tools_for_AI_genera_bd3558bc.pdf"
  },
  "2b5d234efd26e7377698cf16c901601a3d3c4e56": {
    "paperId": "2b5d234efd26e7377698cf16c901601a3d3c4e56",
    "title": "CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities",
    "year": 2022,
    "authors": "Mina Lee, Percy Liang, Qian Yang",
    "abstract": "Large language models (LMs) offer unprecedented language generation capabilities and exciting opportunities for interaction design. However, their highly context-dependent capabilities are difficult to grasp and are often subjectively interpreted. In this paper, we argue that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs’ generative capabilities. Exemplifying this approach, we present CoAuthor, a dataset designed for revealing GPT-3’s capabilities in assisting creative and argumentative writing. CoAuthor captures rich interactions between 63 writers and four instances of GPT-3 across 1445 writing sessions. We demonstrate that CoAuthor can address questions about GPT-3’s language, ideation, and collaboration capabilities, and reveal its contribution as a writing “collaborator” under various definitions of good collaboration. Finally, we discuss how this work may facilitate a more principled discussion around LMs’ promises and pitfalls in relation to interaction design. The dataset and an interface for replaying the writing sessions are publicly available at https://coauthor.stanford.edu.",
    "citationCount": 438,
    "pdf_filename": "2022_CoAuthor__Designing_a_Human_AI_Collabora_2b5d234e.pdf"
  },
  "34276d30da30285f4ad348848ec746457730899a": {
    "paperId": "34276d30da30285f4ad348848ec746457730899a",
    "title": "InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models",
    "year": 2024,
    "authors": "Jiale Xu, Weihao Cheng, Yiming Gao, Xintao Wang, Shenghua Gao",
    "abstract": "We present InstantMesh, a feed-forward framework for instant 3D mesh generation from a single image, featuring state-of-the-art generation quality and significant training scalability. By synergizing the strengths of an off-the-shelf multiview diffusion model and a sparse-view reconstruction model based on the LRM architecture, InstantMesh is able to create diverse 3D assets within 10 seconds. To enhance the training efficiency and exploit more geometric supervisions, e.g, depths and normals, we integrate a differentiable iso-surface extraction module into our framework and directly optimize on the mesh representation. Experimental results on public datasets demonstrate that InstantMesh significantly outperforms other latest image-to-3D baselines, both qualitatively and quantitatively. We release all the code, weights, and demo of InstantMesh, with the intention that it can make substantial contributions to the community of 3D generative AI and empower both researchers and content creators.",
    "citationCount": 332,
    "pdf_filename": "2024_InstantMesh__Efficient_3D_Mesh_Generatio_34276d30.pdf"
  },
  "186c2b2386799fa599e2d77bc6945f7da66e5fab": {
    "paperId": "186c2b2386799fa599e2d77bc6945f7da66e5fab",
    "title": "Zero123++: a Single Image to Consistent Multi-view Diffusion Base Model",
    "year": 2023,
    "authors": "Ruoxi Shi, Hansheng Chen, Zhuoyang Zhang, Minghua Liu, Chao Xu",
    "abstract": "We report Zero123++, an image-conditioned diffusion model for generating 3D-consistent multi-view images from a single input view. To take full advantage of pretrained 2D generative priors, we develop various conditioning and training schemes to minimize the effort of finetuning from off-the-shelf image diffusion models such as Stable Diffusion. Zero123++ excels in producing high-quality, consistent multi-view images from a single image, overcoming common issues like texture degradation and geometric misalignment. Furthermore, we showcase the feasibility of training a ControlNet on Zero123++ for enhanced control over the generation process. The code is available at https://github.com/SUDO-AI-3D/zero123plus.",
    "citationCount": 489,
    "pdf_filename": "2023_Zero123____a_Single_Image_to_Consistent__186c2b23.pdf"
  },
  "53b04ccd2a001467d7ce168e9ce20b16a9466a69": {
    "paperId": "53b04ccd2a001467d7ce168e9ce20b16a9466a69",
    "title": "Fairness And Bias in Artificial Intelligence: A Brief Survey of Sources, Impacts, And Mitigation Strategies",
    "year": 2023,
    "authors": "Emilio Ferrara",
    "abstract": "The significant advancements in applying artificial intelligence (AI) to healthcare decision-making, medical diagnosis, and other domains have simultaneously raised concerns about the fairness and bias of AI systems. This is particularly critical in areas like healthcare, employment, criminal justice, credit scoring, and increasingly, in generative AI models (GenAI) that produce synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including generative biases that affect the representation of individuals in synthetic data. This survey study offers a succinct, comprehensive overview of fairness and bias in AI, addressing their sources, impacts, and mitigation strategies. We review sources of bias, such as data, algorithm, and human decision biases—highlighting the emergent issue of generative AI bias, where models may reproduce and amplify societal stereotypes. We assess the societal impact of biased AI systems, focusing on perpetuating inequalities and reinforcing harmful stereotypes, especially as generative AI becomes more prevalent in creating content that influences public perception. We explore various proposed mitigation strategies, discuss the ethical considerations of their implementation, and emphasize the need for interdisciplinary collaboration to ensure effectiveness. Through a systematic literature review spanning multiple academic disciplines, we present definitions of AI bias and its different types, including a detailed look at generative AI bias. We discuss the negative impacts of AI bias on individuals and society and provide an overview of current approaches to mitigate AI bias, including data pre-processing, model selection, and post-processing. We emphasize the unique challenges presented by generative AI models and the importance of strategies specifically tailored to address these. Addressing bias in AI requires a holistic approach involving diverse and representative datasets, enhanced transparency and accountability in AI systems, and the exploration of alternative AI paradigms that prioritize fairness and ethical considerations. This survey contributes to the ongoing discussion on developing fair and unbiased AI systems by providing an overview of the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the emerging field of generative AI.",
    "citationCount": 475,
    "pdf_filename": "2023_Fairness_And_Bias_in_Artificial_Intellig_53b04ccd.pdf"
  },
  "eecb4dbf218d08d43a727c7e79f86a296502f117": {
    "paperId": "eecb4dbf218d08d43a727c7e79f86a296502f117",
    "title": "Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial",
    "year": 2023,
    "authors": "B. Meskó",
    "abstract": "Prompt engineering is a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks. With the emergence of LLMs, the most popular one being ChatGPT that has attracted the attention of over a 100 million users in only 2 months, artificial intelligence (AI), especially generative AI, has become accessible for the masses. This is an unprecedented paradigm shift not only because of the use of AI becoming more widespread but also due to the possible implications of LLMs in health care. As more patients and medical professionals use AI-based tools, LLMs being the most popular representatives of that group, it seems inevitable to address the challenge to improve this skill. This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs.",
    "citationCount": 468,
    "pdf_filename": "2023_Prompt_Engineering_as_an_Important_Emerg_eecb4dbf.pdf"
  },
  "40c318400809abf5e50aba5a5a80c8012a7715d5": {
    "paperId": "40c318400809abf5e50aba5a5a80c8012a7715d5",
    "title": "GPTScore: Evaluate as You Desire",
    "year": 2023,
    "authors": "Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, Pengfei Liu",
    "abstract": "Generative Artificial Intelligence (AI) has enabled the development of sophisticated models that are capable of producing high-caliber text, images, and other outputs through the utilization of large pre-trained models.Nevertheless, assessing the quality of the generation is an even more arduous task than the generation itself, and this issue has not been given adequate consideration recently.This paper proposes a novel evaluation framework, GPTScore, which utilizes the emergent abilities (e.g., in-context learning, zero-shot instruction) of generative pre-trained models to score generated texts. There are 19 pre-trained models explored in this paper, ranging in size from 80M (e.g., Flan-T5-small) to 175B (e.g., GPT3).Experimental results on four text generation tasks, 22 evaluation aspects, and corresponding 37 datasets demonstrate that this approach can effectively allow us to achieve what one desires to evaluate for texts simply by natural language instructions.This nature helps us overcome several long-standing challenges in text evaluation–how to achieve customized, multi-faceted evaluation without model training. We make our code publicly available.",
    "citationCount": 382,
    "pdf_filename": "2023_GPTScore__Evaluate_as_You_Desire_40c31840.pdf"
  },
  "e01515c6138bc525f7aec30fc85f2adf028d4156": {
    "paperId": "e01515c6138bc525f7aec30fc85f2adf028d4156",
    "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
    "year": 2023,
    "authors": "Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen",
    "abstract": "Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.",
    "citationCount": 391,
    "pdf_filename": "2023_Principle_Driven_Self_Alignment_of_Langu_e01515c6.pdf"
  },
  "1342e6383e2b88d6df23ea429f599cebe99a2e02": {
    "paperId": "1342e6383e2b88d6df23ea429f599cebe99a2e02",
    "title": "How Artificial Intelligence Is Shaping Medical Imaging Technology: A Survey of Innovations and Applications",
    "year": 2023,
    "authors": "Luís Pinto-Coelho",
    "abstract": "The integration of artificial intelligence (AI) into medical imaging has guided in an era of transformation in healthcare. This literature review explores the latest innovations and applications of AI in the field, highlighting its profound impact on medical diagnosis and patient care. The innovation segment explores cutting-edge developments in AI, such as deep learning algorithms, convolutional neural networks, and generative adversarial networks, which have significantly improved the accuracy and efficiency of medical image analysis. These innovations have enabled rapid and accurate detection of abnormalities, from identifying tumors during radiological examinations to detecting early signs of eye disease in retinal images. The article also highlights various applications of AI in medical imaging, including radiology, pathology, cardiology, and more. AI-based diagnostic tools not only speed up the interpretation of complex images but also improve early detection of disease, ultimately delivering better outcomes for patients. Additionally, AI-based image processing facilitates personalized treatment plans, thereby optimizing healthcare delivery. This literature review highlights the paradigm shift that AI has brought to medical imaging, highlighting its role in revolutionizing diagnosis and patient care. By combining cutting-edge AI techniques and their practical applications, it is clear that AI will continue shaping the future of healthcare in profound and positive ways.",
    "citationCount": 336,
    "pdf_filename": "2023_How_Artificial_Intelligence_Is_Shaping_M_1342e638.pdf"
  },
  "16d83e930a4dab2d49f5d276838ddce79df3f787": {
    "paperId": "16d83e930a4dab2d49f5d276838ddce79df3f787",
    "title": "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models",
    "year": 2023,
    "authors": "Emilio Ferrara",
    "abstract": "As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",
    "citationCount": 327,
    "pdf_filename": "2023_Should_ChatGPT_be_Biased__Challenges_and_16d83e93.pdf"
  },
  "fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20": {
    "paperId": "fb5c11bbf63884f75d2da615fbf37a3bcfa2bd20",
    "title": "Wordcraft: Story Writing With Large Language Models",
    "year": 2022,
    "authors": "Ann Yuan, Andy Coenen, Emily Reif, Daphne Ippolito",
    "abstract": "The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers’ custom requests expressed in natural language (such as ”rewrite this text to be more Dickensian”), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.",
    "citationCount": 372,
    "pdf_filename": "2022_Wordcraft__Story_Writing_With_Large_Lang_fb5c11bb.pdf"
  },
  "2ceac7a1587a321eaba63b91607e70b71f8c90a6": {
    "paperId": "2ceac7a1587a321eaba63b91607e70b71f8c90a6",
    "title": "Artificial Intelligence and COVID-19: Deep Learning Approaches for Diagnosis and Treatment",
    "year": 2020,
    "authors": "M. Jamshidi, A. Lalbakhsh, J. Talla, Z. Peroutka, F. Hadjilooei",
    "abstract": "COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19’s spread in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to 5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning (DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs), Extreme Learning Machine (ELM), and Long/Short Term Memory (LSTM). It delineates an integrated bioinformatics approach in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers. The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of the COVID-19 disease. The most recent related publications and medical reports were investigated with the purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs for each platform, including various forms of the data, such as clinical data and medical imaging which can improve the performance of the introduced approaches toward the best responses in practical applications.",
    "citationCount": 410,
    "pdf_filename": "2020_Artificial_Intelligence_and_COVID_19__De_2ceac7a1.pdf"
  },
  "3707939a856655fcabf0acd5cba1a1009987b439": {
    "paperId": "3707939a856655fcabf0acd5cba1a1009987b439",
    "title": "Generative Verifiers: Reward Modeling as Next-Token Prediction",
    "year": 2024,
    "authors": "Lunjun Zhang, Arian Hosseini, Hritik Bansal, Mehran Kazemi, Aviral Kumar",
    "abstract": "Verifiers or reward models are often used to enhance the reasoning performance of large language models (LLMs). A common approach is the Best-of-N method, where N candidate solutions generated by the LLM are ranked by a verifier, and the best one is selected. While LLM-based verifiers are typically trained as discriminative classifiers to score solutions, they do not utilize the text generation capabilities of pretrained LLMs. To overcome this limitation, we instead propose training verifiers using the ubiquitous next-token prediction objective, jointly on verification and solution generation. Compared to standard verifiers, such generative verifiers (GenRM) can benefit from several advantages of LLMs: they integrate seamlessly with instruction tuning, enable chain-of-thought reasoning, and can utilize additional test-time compute via majority voting for better verification. We demonstrate that GenRM outperforms discriminative, DPO verifiers, and LLM-as-a-Judge, resulting in large performance gains with Best-of-N, namely 5% $\\rightarrow$ 45.3% on algorithmic tasks and 73% $\\rightarrow$ 93.4% on GSM8K. In easy-to-hard generalization settings, we observe improvements of 28% $\\rightarrow$ 44.6% on MATH, and 37.9% $\\rightarrow$ 53.5% on MMLU abstract algebra. Furthermore, we find that training GenRM with synthetic verification rationales is sufficient to pick out subtle errors on math problems. Finally, we demonstrate that GenRM scales favorably with model size and test-time compute.",
    "citationCount": 322,
    "pdf_filename": "2024_Generative_Verifiers__Reward_Modeling_as_3707939a.pdf"
  },
  "0fafac05423aa187d85cc12bce1865aefc787700": {
    "paperId": "0fafac05423aa187d85cc12bce1865aefc787700",
    "title": "Towards Universal Fake Image Detectors that Generalize Across Generative Models",
    "year": 2023,
    "authors": "Utkarsh Ojha, Yuheng Li, Yong Jae Lee",
    "abstract": "With generative models proliferating at a rapid rate, there is a growing need for general purpose fake image detectors. In this work, we first show that the existing paradigm, which consists of training a deep network for real-vs-fake classification, fails to detect fake images from newer breeds of generative models when trained to detect GAN fake images. Upon analysis, we find that the resulting classifier is asymmetrically tuned to detect patterns that make an image fake. The real class becomes a ‘sink’ class holding anything that is not fake, including generated images from models not accessible during training. Building upon this discovery, we propose to perform real-vs-fake classification without learning; i.e., using a feature space not explicitly trained to distinguish real from fake images. We use nearest neighbor and linear probing as instantiations of this idea. When given access to the feature space of a large pretrained vision-language model, the very simple baseline of nearest neighbor classification has surprisingly good generalization ability in detecting fake images from a wide variety of generative models; e.g., it improves upon the SoTA [50] by +15.07 mAP and +25.90% acc when tested on unseen diffusion and autoregressive models. Our code, models, and data can be found at https://github.com/Yuheng-Li/UniversalFakeDetect",
    "citationCount": 391,
    "pdf_filename": "2023_Towards_Universal_Fake_Image_Detectors_t_0fafac05.pdf"
  },
  "ad9146d98ae95bbeeef460abe083ecc2c4798672": {
    "paperId": "ad9146d98ae95bbeeef460abe083ecc2c4798672",
    "title": "Splitwise: Efficient Generative LLM Inference Using Phase Splitting",
    "year": 2023,
    "authors": "Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Aashaka Shah",
    "abstract": "Generative large language model (LLM) applications are growing rapidly, leading to large-scale deployments of expensive and power-hungry GPUs. Our characterization of LLM inference shows that each inference request undergoes two phases: a compute-intensive prompt computation phase and a memory intensive token generation phase, each with distinct latency, throughput, memory, and power characteristics. Despite state-of-the-art batching and scheduling, the token generation phase underutilizes compute resources. Unlike prompt computation, token generation does not need the compute capability of the latest GPUs and can be run with lower power and cost. Based on these insights, we propose Splitwise, a model deployment and scheduling technique that splits the two phases of LLM inference requests on to separate machines. Splitwise enables phase-specific resource management using hardware that is well suited for each phase. Request state is transferred efficiently between machines using optimized network libraries on the fast back-plane interconnects available in today’s GPU clusters. Using Splitwise, we design homogeneous and heterogeneous LLM inference clusters optimized for throughput, cost, and power Compared to current designs, Splitwise clusters achieve up to $1.4 \\times$ higher throughput at $\\mathbf{2 0 \\%}$ lower cost. Alternatively, they can deliver $2.35 \\times$ more throughput under the same power and cost budgets.",
    "citationCount": 408,
    "pdf_filename": "2023_Splitwise__Efficient_Generative_LLM_Infe_ad9146d9.pdf"
  },
  "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5": {
    "paperId": "4b1b5e219fb41a7413599c3b2ca6a7fdf045d1a5",
    "title": "Generative Multimodal Models are In-Context Learners",
    "year": 2023,
    "authors": "Quan Sun, Yufeng Cui, Xiaosong Zhang, Fan Zhang, Qiying Yu",
    "abstract": "The human ability to easily solve multimodal tasks in context (i.e., with only a few demonstrations or simple instructions), is what current multimodal systems have largely struggled to imitate. In this work, we demonstrate that the task-agnostic in-context learning capabilities of large multimodal models can be significantly enhanced by effective scaling-up. We introduce Emu2, a generative multimodal model with 37 billion parameters, trained on large-scale multimodal sequences with a unified autoregressive objective. Emu2 exhibits strong multimodal in-context learning abilities, even emerging to solve tasks that require on-the-fly reasoning, such as visual prompting and object-grounded generation. The model sets a new record on multiple multimodal understanding tasks in few-shot settings. When instruction-tuned to follow specific instructions, Emu2 further achieves new state-of-the-art on challenging tasks such as question answering benchmarks for large multimodal models and open-ended subject-driven generation. These achievements demonstrate that Emu2 can serve as a base model and general-purpose interface for a wide range of multimodal tasks. Code and models are publicly available to facilitate future research.",
    "citationCount": 397,
    "pdf_filename": "2023_Generative_Multimodal_Models_are_In_Cont_4b1b5e21.pdf"
  },
  "eb35863662544c977780299c21e669555ae83e81": {
    "paperId": "eb35863662544c977780299c21e669555ae83e81",
    "title": "3DShape2VecSet: A 3D Shape Representation for Neural Fields and Generative Diffusion Models",
    "year": 2023,
    "authors": "Biao Zhang, Jiapeng Tang, M. Nießner, Peter Wonka",
    "abstract": "We introduce 3DShape2VecSet, a novel shape representation for neural fields designed for generative diffusion models. Our shape representation can encode 3D shapes given as surface models or point clouds, and represents them as neural fields. The concept of neural fields has previously been combined with a global latent vector, a regular grid of latent vectors, or an irregular grid of latent vectors. Our new representation encodes neural fields on top of a set of vectors. We draw from multiple concepts, such as the radial basis function representation, and the cross attention and self-attention function, to design a learnable representation that is especially suitable for processing with transformers. Our results show improved performance in 3D shape encoding and 3D shape generative modeling tasks. We demonstrate a wide variety of generative applications: unconditioned generation, category-conditioned generation, text-conditioned generation, point-cloud completion, and image-conditioned generation. Code: https://1zb.github.io/3DShape2VecSet/.",
    "citationCount": 319,
    "pdf_filename": "2023_3DShape2VecSet__A_3D_Shape_Representatio_eb358636.pdf"
  },
  "05b15934d837dc84afa96824742d3dcc7ec88e09": {
    "paperId": "05b15934d837dc84afa96824742d3dcc7ec88e09",
    "title": "Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold",
    "year": 2023,
    "authors": "Xingang Pan, A. Tewari, Thomas Leimkühler, Lingjie Liu, Abhimitra Meka",
    "abstract": "Synthesizing visual content that meets users’ needs often requires flexible and precise controllability of the pose, shape, expression, and layout of the generated objects. Existing approaches gain controllability of generative adversarial networks (GANs) via manually annotated training data or a prior 3D model, which often lack flexibility, precision, and generality. In this work, we study a powerful yet much less explored way of controlling GANs, that is, to \"drag\" any points of the image to precisely reach target points in a user-interactive manner, as shown in Fig.1. To achieve this, we propose DragGAN, which consists of two main components: 1) a feature-based motion supervision that drives the handle point to move towards the target position, and 2) a new point tracking approach that leverages the discriminative generator features to keep localizing the position of the handle points. Through DragGAN, anyone can deform an image with precise control over where pixels go, thus manipulating the pose, shape, expression, and layout of diverse categories such as animals, cars, humans, landscapes, etc. As these manipulations are performed on the learned generative image manifold of a GAN, they tend to produce realistic outputs even for challenging scenarios such as hallucinating occluded content and deforming shapes that consistently follow the object’s rigidity. Both qualitative and quantitative comparisons demonstrate the advantage of DragGAN over prior approaches in the tasks of image manipulation and point tracking. We also showcase the manipulation of real images through GAN inversion.",
    "citationCount": 308,
    "pdf_filename": "2023_Drag_Your_GAN__Interactive_Point_based_M_05b15934.pdf"
  },
  "993df7df129f8d18816877d69923d7df7b347d85": {
    "paperId": "993df7df129f8d18816877d69923d7df7b347d85",
    "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
    "year": 2023,
    "authors": "Dongfu Jiang, Xiang Ren, Bill Yuchen Lin",
    "abstract": "We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.",
    "citationCount": 466,
    "pdf_filename": "2023_LLM_Blender__Ensembling_Large_Language_M_993df7df.pdf"
  },
  "cb89947993021a3ee3c9f2bb926f6cab71d39793": {
    "paperId": "cb89947993021a3ee3c9f2bb926f6cab71d39793",
    "title": "Human Motion Diffusion as a Generative Prior",
    "year": 2023,
    "authors": "Yonatan Shafir, Guy Tevet, Roy Kapon, Amit H. Bermano",
    "abstract": "Recent work has demonstrated the significant potential of denoising diffusion models for generating human motion, including text-to-motion capabilities. However, these methods are restricted by the paucity of annotated motion data, a focus on single-person motions, and a lack of detailed control. In this paper, we introduce three forms of composition based on diffusion priors: sequential, parallel, and model composition. Using sequential composition, we tackle the challenge of long sequence generation. We introduce DoubleTake, an inference-time method with which we generate long animations consisting of sequences of prompted intervals and their transitions, using a prior trained only for short clips. Using parallel composition, we show promising steps toward two-person generation. Beginning with two fixed priors as well as a few two-person training examples, we learn a slim communication block, ComMDM, to coordinate interaction between the two resulting motions. Lastly, using model composition, we first train individual priors to complete motions that realize a prescribed motion for a given joint. We then introduce DiffusionBlending, an interpolation mechanism to effectively blend several such models to enable flexible and efficient fine-grained joint and trajectory-level control and editing. We evaluate the composition methods using an off-the-shelf motion diffusion model, and further compare the results to dedicated models trained for these specific tasks.",
    "citationCount": 310,
    "pdf_filename": "2023_Human_Motion_Diffusion_as_a_Generative_P_cb899479.pdf"
  },
  "e154dd91de91558f9d671370754eace62a54c911": {
    "paperId": "e154dd91de91558f9d671370754eace62a54c911",
    "title": "A study of generative large language model for medical research and healthcare",
    "year": 2023,
    "authors": "C.A.I. Peng, Xi Yang, Aokun Chen, Kaleb E. Smith, Nima M. Pournejatian",
    "abstract": "There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural language processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians’ Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability ( p  = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance ( p  = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them ( p  < 0.001). This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare.",
    "citationCount": 361,
    "pdf_filename": "2023_A_study_of_generative_large_language_mod_e154dd91.pdf"
  },
  "33161a5a9b5dcb635b5a97475e6a6209a69ada7d": {
    "paperId": "33161a5a9b5dcb635b5a97475e6a6209a69ada7d",
    "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
    "year": 2024,
    "authors": "Chris Lu, Cong Lu, R. T. Lange, J. Foerster, Jeff Clune",
    "abstract": "One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aides to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist",
    "citationCount": 448,
    "pdf_filename": "2024_The_AI_Scientist__Towards_Fully_Automate_33161a5a.pdf"
  },
  "b767c165e7e9621c38c98c247856087f76e9f340": {
    "paperId": "b767c165e7e9621c38c98c247856087f76e9f340",
    "title": "Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education",
    "year": 2024,
    "authors": "Yoshija Walter",
    "abstract": "The present discussion examines the transformative impact of Artificial Intelligence (AI) in educational settings, focusing on the necessity for AI literacy, prompt engineering proficiency, and enhanced critical thinking skills. The introduction of AI into education marks a significant departure from conventional teaching methods, offering personalized learning and support for diverse educational requirements, including students with special needs. However, this integration presents challenges, including the need for comprehensive educator training and curriculum adaptation to align with societal structures. AI literacy is identified as crucial, encompassing an understanding of AI technologies and their broader societal impacts. Prompt engineering is highlighted as a key skill for eliciting specific responses from AI systems, thereby enriching educational experiences and promoting critical thinking. There is detailed analysis of strategies for embedding these skills within educational curricula and pedagogical practices. This is discussed through a case-study based on a Swiss university and a narrative literature review, followed by practical suggestions of how to implement AI in the classroom.",
    "citationCount": 461,
    "pdf_filename": "2024_Embracing_the_future_of_Artificial_Intel_b767c165.pdf"
  },
  "a779f5dd28c8aaab0e1bdceeb6700f17d655c0a4": {
    "paperId": "a779f5dd28c8aaab0e1bdceeb6700f17d655c0a4",
    "title": "The Role of AI in Hospitals and Clinics: Transforming Healthcare in the 21st Century",
    "year": 2024,
    "authors": "Shiva Maleki Varnosfaderani, Mohamad Forouzanfar",
    "abstract": "As healthcare systems around the world face challenges such as escalating costs, limited access, and growing demand for personalized care, artificial intelligence (AI) is emerging as a key force for transformation. This review is motivated by the urgent need to harness AI’s potential to mitigate these issues and aims to critically assess AI’s integration in different healthcare domains. We explore how AI empowers clinical decision-making, optimizes hospital operation and management, refines medical image analysis, and revolutionizes patient care and monitoring through AI-powered wearables. Through several case studies, we review how AI has transformed specific healthcare domains and discuss the remaining challenges and possible solutions. Additionally, we will discuss methodologies for assessing AI healthcare solutions, ethical challenges of AI deployment, and the importance of data privacy and bias mitigation for responsible technology use. By presenting a critical assessment of AI’s transformative potential, this review equips researchers with a deeper understanding of AI’s current and future impact on healthcare. It encourages an interdisciplinary dialogue between researchers, clinicians, and technologists to navigate the complexities of AI implementation, fostering the development of AI-driven solutions that prioritize ethical standards, equity, and a patient-centered approach.",
    "citationCount": 437,
    "pdf_filename": "2024_The_Role_of_AI_in_Hospitals_and_Clinics__a779f5dd.pdf"
  },
  "325d8e9501af05e594bd668b6cd6d43ed42c8b4d": {
    "paperId": "325d8e9501af05e594bd668b6cd6d43ed42c8b4d",
    "title": "InternVideo: General Video Foundation Models via Generative and Discriminative Learning",
    "year": 2022,
    "authors": "Yi Wang, Kunchang Li, Yizhuo Li, Yinan He, Bingkun Huang",
    "abstract": "The foundation models have recently shown excellent performance on a variety of downstream tasks in computer vision. However, most existing vision foundation models simply focus on image-level pretraining and adpation, which are limited for dynamic and complex video-level understanding tasks. To fill the gap, we present general video foundation models, InternVideo, by taking advantage of both generative and discriminative self-supervised video learning. Specifically, InternVideo efficiently explores masked video modeling and video-language contrastive learning as the pretraining objectives, and selectively coordinates video representations of these two complementary frameworks in a learnable manner to boost various video applications. Without bells and whistles, InternVideo achieves state-of-the-art performance on 39 video datasets from extensive tasks including video action recognition/detection, video-language alignment, and open-world video applications. Especially, our methods can obtain 91.1% and 77.2% top-1 accuracy on the challenging Kinetics-400 and Something-Something V2 benchmarks, respectively. All of these results effectively show the generality of our InternVideo for video understanding. The code will be released at https://github.com/OpenGVLab/InternVideo .",
    "citationCount": 432,
    "pdf_filename": "2022_InternVideo__General_Video_Foundation_Mo_325d8e95.pdf"
  },
  "8fe6a16df99a87f79fc0cb0fbd1af44f79f7885f": {
    "paperId": "8fe6a16df99a87f79fc0cb0fbd1af44f79f7885f",
    "title": "DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models",
    "year": 2022,
    "authors": "Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover",
    "abstract": "With recent advancements in diffusion models, users can generate high-quality images by writing text prompts in natural language. However, generating images with desired details requires proper prompts, and it is often unclear how a model reacts to different prompts or what the best prompts are. To help researchers tackle these critical challenges, we introduce DiffusionDB, the first large-scale text-to-image prompt dataset totaling 6.5TB, containing 14 million images generated by Stable Diffusion, 1.8 million unique prompts, and hyperparameters specified by real users. We analyze the syntactic and semantic characteristics of prompts. We pinpoint specific hyperparameter values and prompt styles that can lead to model errors and present evidence of potentially harmful model usage, such as the generation of misinformation. The unprecedented scale and diversity of this human-actuated dataset provide exciting research opportunities in understanding the interplay between prompts and generative models, detecting deepfakes, and designing human-AI interaction tools to help users more easily use these models. DiffusionDB is publicly available at: https://poloclub.github.io/diffusiondb.",
    "citationCount": 377,
    "pdf_filename": "2022_DiffusionDB__A_Large_scale_Prompt_Galler_8fe6a16d.pdf"
  },
  "a6f6fef883b0d21eb095caf80b5f61eadec873ef": {
    "paperId": "a6f6fef883b0d21eb095caf80b5f61eadec873ef",
    "title": "Speech Enhancement and Dereverberation With Diffusion-Based Generative Models",
    "year": 2022,
    "authors": "Julius Richter, Simon Welker, Jean-Marie Lemercier, Bunlong Lay, Timo Gerkmann",
    "abstract": "In this work, we build upon our previous publication and use diffusion-based generative models for speech enhancement. We present a detailed overview of the diffusion process that is based on a stochastic differential equation and delve into an extensive theoretical examination of its implications. Opposed to usual conditional generation tasks, we do not start the reverse process from pure Gaussian noise but from a mixture of noisy speech and Gaussian noise. This matches our forward process which moves from clean speech to noisy speech by including a drift term. We show that this procedure enables using only 30 diffusion steps to generate high-quality clean speech estimates. By adapting the network architecture, we are able to significantly improve the speech enhancement performance, indicating that the network, rather than the formalism, was the main limitation of our original approach. In an extensive cross-dataset evaluation, we show that the improved method can compete with recent discriminative models and achieves better generalization when evaluating on a different corpus than used for training. We complement the results with an instrumental evaluation using real-world noisy recordings and a listening experiment, in which our proposed method is rated best. Examining different sampler configurations for solving the reverse process allows us to balance the performance and computational speed of the proposed method. Moreover, we show that the proposed method is also suitable for dereverberation and thus not limited to additive background noise removal.",
    "citationCount": 304,
    "pdf_filename": "2022_Speech_Enhancement_and_Dereverberation_W_a6f6fef8.pdf"
  },
  "ab15463babf98fffc6f683fe2026de0725b5e1a9": {
    "paperId": "ab15463babf98fffc6f683fe2026de0725b5e1a9",
    "title": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
    "year": 2024,
    "authors": "Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng",
    "abstract": "Advancements in model algorithms, the growth of foundational models, and access to high-quality datasets have propelled the evolution of Artificial Intelligence Generated Content (AIGC). Despite its notable successes, AIGC still faces hurdles such as updating knowledge, handling long-tail data, mitigating data leakage, and managing high training and inference costs. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores, leading to higher accuracy and better robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator, distilling the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research. Github: https://github.com/PKU-DAIR/RAG-Survey.",
    "citationCount": 425,
    "pdf_filename": "2024_Retrieval_Augmented_Generation_for_AI_Ge_ab15463b.pdf"
  },
  "fe34137e5cc07235eae65ce53a54cd226b9f8b23": {
    "paperId": "fe34137e5cc07235eae65ce53a54cd226b9f8b23",
    "title": "MAGVIT: Masked Generative Video Transformer",
    "year": 2022,
    "authors": "Lijun Yu, Yong Cheng, Kihyuk Sohn, José Lezama, Han Zhang",
    "abstract": "We introduce the MAsked Generative VIdeo Transformer, MAGVIT, to tackle various video synthesis tasks with a single model. We introduce a 3D tokenizer to quantize a video into spatial-temporal visual tokens and propose an embedding method for masked video token modeling to facilitate multi-task learning. We conduct extensive experiments to demonstrate the quality, efficiency, and flexibility of MAGVIT. Our experiments show that (i) MAGVIT performs favorably against state-of-the-art approaches and establishes the best-published FVD on three video generation benchmarks, including the challenging Kinetics-600. (ii) MAGVIT outperforms existing methods in inference time by two orders of magnitude against diffusion models and by 60x against autoregressive models. (iii) A single MAGVIT model supports ten diverse generation tasks and generalizes across videos from different visual domains. The source code and trained models will be released to the public at https://magvit.cs.cmu.edu.",
    "citationCount": 323,
    "pdf_filename": "2022_MAGVIT__Masked_Generative_Video_Transfor_fe34137e.pdf"
  },
  "35a29c47d5292e8967e5a9a8a21b23d8637b7d07": {
    "paperId": "35a29c47d5292e8967e5a9a8a21b23d8637b7d07",
    "title": "A Survey on Generative Diffusion Models",
    "year": 2022,
    "authors": "Hanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen",
    "abstract": "Deep generative models have unlocked another profound realm of human creativity. By capturing and generalizing patterns within data, we have entered the epoch of all-encompassing Artificial Intelligence for General Creativity (AIGC). Notably, diffusion models, recognized as one of the paramount generative models, materialize human ideation into tangible instances across diverse domains, encompassing imagery, text, speech, biology, and healthcare. To provide advanced and comprehensive insights into diffusion, this survey comprehensively elucidates its developmental trajectory and future directions from three distinct angles: the fundamental formulation of diffusion, algorithmic enhancements, and the manifold applications of diffusion. Each layer is meticulously explored to offer a profound comprehension of its evolution. Structured and summarized approaches are presented here.",
    "citationCount": 387,
    "pdf_filename": "2022_A_Survey_on_Generative_Diffusion_Models_35a29c47.pdf"
  },
  "ab8169d6e4dfabfe7c30ebec1bb871bf3e1551cd": {
    "paperId": "ab8169d6e4dfabfe7c30ebec1bb871bf3e1551cd",
    "title": "GAIA: a benchmark for General AI Assistants",
    "year": 2023,
    "authors": "G. Mialon, Clémentine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun",
    "abstract": "We introduce GAIA, a benchmark for General AI Assistants that, if solved, would represent a milestone in AI research. GAIA proposes real-world questions that require a set of fundamental abilities such as reasoning, multi-modality handling, web browsing, and generally tool-use proficiency. GAIA questions are conceptually simple for humans yet challenging for most advanced AIs: we show that human respondents obtain 92\\% vs. 15\\% for GPT-4 equipped with plugins. This notable performance disparity contrasts with the recent trend of LLMs outperforming humans on tasks requiring professional skills in e.g. law or chemistry. GAIA's philosophy departs from the current trend in AI benchmarks suggesting to target tasks that are ever more difficult for humans. We posit that the advent of Artificial General Intelligence (AGI) hinges on a system's capability to exhibit similar robustness as the average human does on such questions. Using GAIA's methodology, we devise 466 questions and their answer. We release our questions while retaining answers to 300 of them to power a leader-board available at https://huggingface.co/gaia-benchmark.",
    "citationCount": 393,
    "pdf_filename": "2023_GAIA__a_benchmark_for_General_AI_Assista_ab8169d6.pdf"
  },
  "1c13af186d1e177b85ef1ec3fc7b8d33ec314cfd": {
    "paperId": "1c13af186d1e177b85ef1ec3fc7b8d33ec314cfd",
    "title": "Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense",
    "year": 2023,
    "authors": "Kalpesh Krishna, Yixiao Song, Marzena Karpinska, J. Wieting, Mohit Iyyer",
    "abstract": "The rise in malicious usage of large language models, such as fake content creation and academic plagiarism, has motivated the development of approaches that identify AI-generated text, including those based on watermarking or outlier detection. However, the robustness of these detection algorithms to paraphrases of AI-generated text remains unclear. To stress test these detectors, we build a 11B parameter paraphrase generation model (DIPPER) that can paraphrase paragraphs, condition on surrounding context, and control lexical diversity and content reordering. Using DIPPER to paraphrase text generated by three large language models (including GPT3.5-davinci-003) successfully evades several detectors, including watermarking, GPTZero, DetectGPT, and OpenAI's text classifier. For example, DIPPER drops detection accuracy of DetectGPT from 70.3% to 4.6% (at a constant false positive rate of 1%), without appreciably modifying the input semantics. To increase the robustness of AI-generated text detection to paraphrase attacks, we introduce a simple defense that relies on retrieving semantically-similar generations and must be maintained by a language model API provider. Given a candidate text, our algorithm searches a database of sequences previously generated by the API, looking for sequences that match the candidate text within a certain threshold. We empirically verify our defense using a database of 15M generations from a fine-tuned T5-XXL model and find that it can detect 80% to 97% of paraphrased generations across different settings while only classifying 1% of human-written sequences as AI-generated. We open-source our models, code and data.",
    "citationCount": 421,
    "pdf_filename": "2023_Paraphrasing_evades_detectors_of_AI_gene_1c13af18.pdf"
  },
  "5ee8bb4fc80a291b2e416a2a879e7153a783d7e9": {
    "paperId": "5ee8bb4fc80a291b2e416a2a879e7153a783d7e9",
    "title": "Can AI-Generated Text be Reliably Detected?",
    "year": 2023,
    "authors": "Vinu Sankar Sadasivan, Aounon Kumar, S. Balasubramanian, Wenxiao Wang, S. Feizi",
    "abstract": "Large Language Models (LLMs) perform impressively well in various applications. However, the potential for misuse of these models in activities such as plagiarism, generating fake news, and spamming has raised concern about their responsible use. Consequently, the reliable detection of AI-generated text has become a critical area of research. AI text detectors have shown to be effective under their specific settings. In this paper, we stress-test the robustness of these AI text detectors in the presence of an attacker. We introduce recursive paraphrasing attack to stress test a wide range of detection schemes, including the ones using the watermarking as well as neural network-based detectors, zero shot classifiers, and retrieval-based detectors. Our experiments conducted on passages, each approximately 300 tokens long, reveal the varying sensitivities of these detectors to our attacks. Our findings indicate that while our recursive paraphrasing method can significantly reduce detection rates, it only slightly degrades text quality in many cases, highlighting potential vulnerabilities in current detection systems in the presence of an attacker. Additionally, we investigate the susceptibility of watermarked LLMs to spoofing attacks aimed at misclassifying human-written text as AI-generated. We demonstrate that an attacker can infer hidden AI text signatures without white-box access to the detection method, potentially leading to reputational risks for LLM developers. Finally, we provide a theoretical framework connecting the AUROC of the best possible detector to the Total Variation distance between human and AI text distributions. This analysis offers insights into the fundamental challenges of reliable detection as language models continue to advance. Our code is publicly available at https://github.com/vinusankars/Reliability-of-AI-text-detectors.",
    "citationCount": 475,
    "pdf_filename": "2023_Can_AI_Generated_Text_be_Reliably_Detect_5ee8bb4f.pdf"
  },
  "7c39adb2049e79951dd6b92c970abaa4d81819b1": {
    "paperId": "7c39adb2049e79951dd6b92c970abaa4d81819b1",
    "title": "On Generative Spoken Language Modeling from Raw Audio",
    "year": 2021,
    "authors": "Kushal Lakhotia, Evgeny Kharitonov, Wei-Ning Hsu, Yossi Adi, Adam Polyak",
    "abstract": "Abstract We introduce Generative Spoken Language Modeling, the task of learning the acoustic and linguistic characteristics of a language from raw audio (no text, no labels), and a set of metrics to automatically evaluate the learned representations at acoustic and linguistic levels for both encoding and generation. We set up baseline systems consisting of a discrete speech encoder (returning pseudo-text units), a generative language model (trained on pseudo- text), and a speech decoder (generating a waveform from pseudo-text) all trained without supervision and validate the proposed metrics with human evaluation. Across 3 speech encoders (CPC, wav2vec 2.0, HuBERT), we find that the number of discrete units (50, 100, or 200) matters in a task-dependent and encoder- dependent way, and that some combinations approach text-based systems.1",
    "citationCount": 421,
    "pdf_filename": "2021_On_Generative_Spoken_Language_Modeling_f_7c39adb2.pdf"
  },
  "a9194aa117acabe333aaaf330cf71c66094ced51": {
    "paperId": "a9194aa117acabe333aaaf330cf71c66094ced51",
    "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "year": 2021,
    "authors": "A. Jalal, Marius Arvinte, G. Daras, E. Price, A. Dimakis",
    "abstract": "The CSGM framework (Bora-Jalal-Price-Dimakis'17) has shown that deep generative priors can be powerful tools for solving inverse problems. However, to date this framework has been empirically successful only on certain datasets (for example, human faces and MNIST digits), and it is known to perform poorly on out-of-distribution samples. In this paper, we present the first successful application of the CSGM framework on clinical MRI data. We train a generative prior on brain scans from the fastMRI dataset, and show that posterior sampling via Langevin dynamics achieves high quality reconstructions. Furthermore, our experiments and theory show that posterior sampling is robust to changes in the ground-truth distribution and measurement process. Our code and models are available at: \\url{https://github.com/utcsilab/csgm-mri-langevin}.",
    "citationCount": 405,
    "pdf_filename": "2021_Robust_Compressed_Sensing_MRI_with_Deep__a9194aa1.pdf"
  },
  "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904": {
    "paperId": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
    "title": "Few-shot Learning with Multilingual Generative Language Models",
    "year": 2021,
    "authors": "Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen",
    "abstract": "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples.",
    "citationCount": 351,
    "pdf_filename": "2021_Few_shot_Learning_with_Multilingual_Gene_4724ebee.pdf"
  },
  "39c2ae603902ea664adf9e74914117f79df2e612": {
    "paperId": "39c2ae603902ea664adf9e74914117f79df2e612",
    "title": "Large Scale Image Completion via Co-Modulated Generative Adversarial Networks",
    "year": 2021,
    "authors": "Shengyu Zhao, Jianwei Cui, Yilun Sheng, Yue Dong, Xiao Liang",
    "abstract": "Numerous task-specific variants of conditional generative adversarial networks have been developed for image completion. Yet, a serious limitation remains that all existing algorithms tend to fail when handling large-scale missing regions. To overcome this challenge, we propose a generic new approach that bridges the gap between image-conditional and recent modulated unconditional generative architectures via co-modulation of both conditional and stochastic style representations. Also, due to the lack of good quantitative metrics for image completion, we propose the new Paired/Unpaired Inception Discriminative Score (P-IDS/U-IDS), which robustly measures the perceptual fidelity of inpainted images compared to real images via linear separability in a feature space. Experiments demonstrate superior performance in terms of both quality and diversity over state-of-the-art methods in free-form image completion and easy generalization to image-to-image translation. Code is available at https://github.com/zsyzzsoft/co-mod-gan.",
    "citationCount": 327,
    "pdf_filename": "2021_Large_Scale_Image_Completion_via_Co_Modu_39c2ae60.pdf"
  },
  "600ff4c4ae9fc506c86673c5ecce4fa90803e987": {
    "paperId": "600ff4c4ae9fc506c86673c5ecce4fa90803e987",
    "title": "RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback",
    "year": 2023,
    "authors": "Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard",
    "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences, but gathering high-quality preference labels is expensive. RL from AI Feedback (RLAIF), introduced in Bai et al., offers a promising alternative that trains the reward model (RM) on preferences generated by an off-the-shelf LLM. Across the tasks of summarization, helpful dialogue generation, and harmless dialogue generation, we show that RLAIF achieves comparable performance to RLHF. Furthermore, we take a step towards\"self-improvement\"by demonstrating that RLAIF can outperform a supervised fine-tuned baseline even when the AI labeler is the same size as the policy, or even the exact same checkpoint as the initial policy. Finally, we introduce direct-RLAIF (d-RLAIF) - a technique that circumvents RM training by obtaining rewards directly from an off-the-shelf LLM during RL, which achieves superior performance to canonical RLAIF. Our results suggest that RLAIF can achieve performance on-par with using human feedback, offering a potential solution to the scalability limitations of RLHF.",
    "citationCount": 474,
    "pdf_filename": "2023_RLAIF_vs__RLHF__Scaling_Reinforcement_Le_600ff4c4.pdf"
  },
  "baedb763204fb1b35330d3ba706539b9f90dc738": {
    "paperId": "baedb763204fb1b35330d3ba706539b9f90dc738",
    "title": "Teacher support and student motivation to learn with Artificial Intelligence (AI) based chatbot",
    "year": 2023,
    "authors": "Thomas K. F. Chiu, Benjamin Luke Moorhouse, C. Chai, Murod Ismailov",
    "abstract": "ABSTRACT As Artificial Intelligence (AI) advances technologically, it will inevitably bring many changes to classroom practices. However, research on AI in education reflects a weak connection to pedagogical perspectives or instructional approaches, particularly in K-12 education. AI technologies may benefit motivated and advanced students. Understanding the teacher’s role of student motivation in mediating and supporting learning with AI technologies in the classroom is needed. This study used self-determination theory as the undergirding framework to investigate how teacher support moderates the effects of student expertise on needs satisfactions and intrinsic motivation to learn with AI technologies. This experimental study involved 123 Grade 10 students, and used chatbots as AI-based technologies in the experiment. The analyses revealed that intrinsic motivation and competence to learn with the chatbot depended on both teacher support and student expertise (i.e. self-regulated learning and digital literacy), and the teacher support better satisfied the need for relatedness, and it less satisfied the need for autonomy. The findings refined our understanding about the application of self-determination theory and expand the pedagogical and design considerations of AI application and instructional practices.",
    "citationCount": 419,
    "pdf_filename": "2023_Teacher_support_and_student_motivation_t_baedb763.pdf"
  },
  "90e41626b8c78600da70c4350c67c3a10525cb37": {
    "paperId": "90e41626b8c78600da70c4350c67c3a10525cb37",
    "title": "MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data",
    "year": 2023,
    "authors": "T. Han, L. Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser",
    "abstract": "As large language models (LLMs) like OpenAI's GPT series continue to make strides, we witness the emergence of artificial intelligence applications in an ever-expanding range of fields. In medicine, these LLMs hold considerable promise for improving medical workflows, diagnostics, patient care, and education. Yet, there is an urgent need for open-source models that can be deployed on-premises to safeguard patient privacy. In our work, we present an innovative dataset consisting of over 160,000 entries, specifically crafted to fine-tune LLMs for effective medical applications. We investigate the impact of fine-tuning these datasets on publicly accessible pre-trained LLMs, and subsequently, we juxtapose the performance of pre-trained-only models against the fine-tuned models concerning the examinations that future medical doctors must pass to achieve certification.",
    "citationCount": 373,
    "pdf_filename": "2023_MedAlpaca____An_Open_Source_Collection_o_90e41626.pdf"
  },
  "ba00908f841ab4326adc8d9879c0b97ce6152faa": {
    "paperId": "ba00908f841ab4326adc8d9879c0b97ce6152faa",
    "title": "Role of AI chatbots in education: systematic literature review",
    "year": 2023,
    "authors": "Lasha Labadze, Maya Grigolia, Lela Machaidze",
    "abstract": "AI chatbots shook the world not long ago with their potential to revolutionize education systems in a myriad of ways. AI chatbots can provide immediate support by answering questions, offering explanations, and providing additional resources. Chatbots can also act as virtual teaching assistants, supporting educators through various means. In this paper, we try to understand the full benefits of AI chatbots in education, their opportunities, challenges, potential limitations, concerns, and prospects of using AI chatbots in educational settings. We conducted an extensive search across various academic databases, and after applying specific predefined criteria, we selected a final set of 67 relevant studies for review. The research findings emphasize the numerous benefits of integrating AI chatbots in education, as seen from both students' and educators' perspectives. We found that students primarily gain from AI-powered chatbots in three key areas: homework and study assistance, a personalized learning experience, and the development of various skills. For educators, the main advantages are the time-saving assistance and improved pedagogy. However, our research also emphasizes significant challenges and critical factors that educators need to handle diligently. These include concerns related to AI applications such as reliability, accuracy, and ethical considerations.",
    "citationCount": 490,
    "pdf_filename": "2023_Role_of_AI_chatbots_in_education__system_ba00908f.pdf"
  },
  "86f57997b389c0206d3a24ee0eb192de3f029833": {
    "paperId": "86f57997b389c0206d3a24ee0eb192de3f029833",
    "title": "Enhancing academic writing skills and motivation: assessing the efficacy of ChatGPT in AI-assisted language learning for EFL students",
    "year": 2023,
    "authors": "Cuiping Song, Yanping Song",
    "abstract": "Introduction This mixed-methods study evaluates the impact of AI-assisted language learning on Chinese English as a Foreign Language (EFL) students’ writing skills and writing motivation. As artificial intelligence (AI) becomes more prevalent in educational settings, understanding its effects on language learning outcomes is crucial. Methods The study employs a comprehensive approach, combining quantitative and qualitative methods. The quantitative phase utilizes a pre-test and post-test design to assess writing skills. Fifty EFL students, matched for proficiency, are randomly assigned to experimental (AI-assisted instruction via ChatGPT) or control (traditional instruction) groups. Writing samples are evaluated using established scoring rubrics. Concurrently, semi-structured interviews are conducted with a subset of participants to explore writing motivation and experiences with AI-assisted learning. Results Quantitative analysis reveals significant improvements in both writing skills and motivation among students who received AI-assisted instruction compared to the control group. The experimental group demonstrates enhanced proficiency in various aspects of writing, including organization, coherence, grammar, and vocabulary. Qualitative findings showcase diverse perspectives, ranging from recognition of AI’s innovative instructional role and its positive influence on writing skills and motivation to concerns about contextual accuracy and over-reliance. Participants also reflect on the long-term impact and sustainability of AI-assisted instruction, emphasizing the need for ongoing development and adaptation of AI tools. Discussion The nuanced findings offer a comprehensive understanding of AI’s transformative potential in education. These insights have practical implications for practitioners and researchers, emphasizing the benefits, challenges, and the evolving nature of AI’s role in language instruction.",
    "citationCount": 407,
    "pdf_filename": "2023_Enhancing_academic_writing_skills_and_mo_86f57997.pdf"
  },
  "a75ab5f2a344cdad2cf2d307556aa8fba7606b23": {
    "paperId": "a75ab5f2a344cdad2cf2d307556aa8fba7606b23",
    "title": "The impact of AI writing tools on the content and organization of students’ writing: EFL teachers’ perspective",
    "year": 2023,
    "authors": "Utami Widiati, Diyenti Rusdin, Inda Indrawati, Marzuki, Nadaraj Govender",
    "abstract": "Abstract The primary objective of this study was to examine the range of available Artificial Intelligence (AI) writing tools and assess their influence on student writing, particularly in terms of content and organization, as perceived by English as a Foreign Language (EFL) teachers. Utilizing a qualitative approach, the research was constructed within a case study design. The data was collected via semi-structured interviews, targeting information about the diversity of AI writing tools and their impact on students” writing quality. The study gathered data from four EFL teachers across three distinct universities in Indonesia, shedding light on the variety of AI writing tools used in their classrooms. These included applications like Quillbot, WordTune, Jenni, Chat-GPT, Paperpal, Copy.ai, and Essay Writer. Furthermore, these teachers unanimously agreed that the AI writing tools positively improved their students’ writing quality, particularly enhancing the quality of their content and organization. The findings of this study imply that integrating AI writing tools can prove beneficial in elevating the quality of EFL student writing. In response to this study’s limitations, recommendations for future research were also addressed.",
    "citationCount": 307,
    "pdf_filename": "2023_The_impact_of_AI_writing_tools_on_the_co_a75ab5f2.pdf"
  },
  "409dc9f1801947f85c53231cba346f0e314cb208": {
    "paperId": "409dc9f1801947f85c53231cba346f0e314cb208",
    "title": "Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality",
    "year": 2023,
    "authors": "Fabrizio Dell'Acqua, Edward McFowland, Ethan R. Mollick, Hila Lifshitz-Assaf, Katherine C. Kellogg",
    "abstract": "The public release of Large Language Models (LLMs) has sparked tremendous interest in how humans will use Artificial Intelligence (AI) to accomplish a variety of tasks. In our study conducted with Boston Consulting Group, a global management consulting firm, we examine the performance implications of AI on realistic, complex, and knowledge-intensive tasks. The pre-registered experiment involved 758 consultants comprising about 7% of the individual contributor-level consultants at the company. After establishing a performance baseline on a similar task, subjects were randomly assigned to one of three conditions: no AI access, GPT-4 AI access, or GPT-4 AI access with a prompt engineering overview. We suggest that the capabilities of AI create a “jagged technological frontier” where some tasks are easily done by AI, while others, though seemingly similar in difficulty level, are outside the current capability of AI. For each one of a set of 18 realistic consulting tasks within the frontier of AI capabilities, consultants using AI were significantly more productive (they completed 12.2% more tasks on average, and completed tasks 25.1% more quickly), and produced significantly higher quality results (more than 40% higher quality compared to a control group). Consultants across the skills distribution benefited significantly from having AI augmentation, with those below the average performance threshold increasing by 43% and those above increasing by 17% compared to their own scores. For a task selected to be outside the frontier, however, consultants using AI were 19 percentage points less likely to produce correct solutions compared to those without AI. Further, our analysis shows the emergence of two distinctive patterns of successful AI use by humans along a spectrum of humanAI integration. One set of consultants acted as “Centaurs,” like the mythical halfhorse/half-human creature, dividing and delegating their solution-creation activities to the AI or to themselves. Another set of consultants acted more like “Cyborgs,” completely integrating their task flow with the AI and continually interacting with the technology.",
    "citationCount": 456,
    "pdf_filename": "2023_Navigating_the_Jagged_Technological_Fron_409dc9f1.pdf"
  },
  "1fc3a53d9665a639eeb6d7645a7f95965d2b1fb1": {
    "paperId": "1fc3a53d9665a639eeb6d7645a7f95965d2b1fb1",
    "title": "Teachers’ AI digital competencies and twenty-first century skills in the post-pandemic world",
    "year": 2023,
    "authors": "D. Ng, J. Leung, Jiahong Su, R. Ng, S. Chu",
    "abstract": "The pandemic has catalyzed a significant shift to online/blended teaching and learning where teachers apply emerging technologies to enhance their students’ learning outcomes. Artificial intelligence (AI) technology has gained its popularity in online learning environments during the pandemic to assist students’ learning. However, many of these AI tools are new to teachers. They may not have rich technical knowledge to use AI educational applications to facilitate their teaching, not to mention developing students’ AI digital capabilities. As such, there is a growing need for teachers to equip themselves with adequate digital competencies so as to use and teach AI in their teaching environments. There are few existing frameworks informing teachers of necessary AI competencies. This study first explores the opportunities and challenges of employing AI systems and how they can enhance teaching, learning and assessment. Then, aligning with generic digital competency frameworks, the DigCompEdu framework and P21’s framework for twenty-first century learning were adapted and revised to accommodate AI technologies. Recommendations are proposed to support educators and researchers to promote AI education in their classrooms and academia.",
    "citationCount": 362,
    "pdf_filename": "2023_Teachers__AI_digital_competencies_and_tw_1fc3a53d.pdf"
  },
  "47966b673a145dfba9880c207ab4e21d692ab563": {
    "paperId": "47966b673a145dfba9880c207ab4e21d692ab563",
    "title": "Survey of Explainable AI Techniques in Healthcare",
    "year": 2023,
    "authors": "A. Chaddad, Jihao Peng, Jian Xu, A. Bouridane",
    "abstract": "Artificial intelligence (AI) with deep learning models has been widely applied in numerous domains, including medical imaging and healthcare tasks. In the medical field, any judgment or decision is fraught with risk. A doctor will carefully judge whether a patient is sick before forming a reasonable explanation based on the patient’s symptoms and/or an examination. Therefore, to be a viable and accepted tool, AI needs to mimic human judgment and interpretation skills. Specifically, explainable AI (XAI) aims to explain the information behind the black-box model of deep learning that reveals how the decisions are made. This paper provides a survey of the most recent XAI techniques used in healthcare and related medical imaging applications. We summarize and categorize the XAI types, and highlight the algorithms used to increase interpretability in medical imaging topics. In addition, we focus on the challenging XAI problems in medical applications and provide guidelines to develop better interpretations of deep learning models using XAI concepts in medical image and text analysis. Furthermore, this survey provides future directions to guide developers and researchers for future prospective investigations on clinical topics, particularly on applications with medical imaging.",
    "citationCount": 375,
    "pdf_filename": "2023_Survey_of_Explainable_AI_Techniques_in_H_47966b67.pdf"
  },
  "4c48b91583a3ec5bc35137b02873d5f98a8430a3": {
    "paperId": "4c48b91583a3ec5bc35137b02873d5f98a8430a3",
    "title": "\"What Can ChatGPT Do?\" Analyzing Early Reactions to the Innovative AI Chatbot on Twitter",
    "year": 2023,
    "authors": "Viriya Taecharungroj",
    "abstract": "In this study, the author collected tweets about ChatGPT, an innovative AI chatbot, in the first month after its launch. A total of 233,914 English tweets were analyzed using the latent Dirichlet allocation (LDA) topic modeling algorithm to answer the question “what can ChatGPT do?”. The results revealed three general topics: news, technology, and reactions. The author also identified five functional domains: creative writing, essay writing, prompt writing, code writing, and answering questions. The analysis also found that ChatGPT has the potential to impact technologies and humans in both positive and negative ways. In conclusion, the author outlines four key issues that need to be addressed as a result of this AI advancement: the evolution of jobs, a new technological landscape, the quest for artificial general intelligence, and the progress-ethics conundrum.",
    "citationCount": 405,
    "pdf_filename": "2023__What_Can_ChatGPT_Do___Analyzing_Early_R_4c48b915.pdf"
  },
  "fdb117c68332d23cb1bd57e3cc36b8c9cfbdcbf7": {
    "paperId": "fdb117c68332d23cb1bd57e3cc36b8c9cfbdcbf7",
    "title": "Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions",
    "year": 2023,
    "authors": "Jiawei Zhou, Yixuan Zhang, Qianni Luo, Andrea G. Parker, M. de Choudhury",
    "abstract": "Large language models have abilities in creating high-volume human-like texts and can be used to generate persuasive misinformation. However, the risks remain under-explored. To address the gap, this work first examined characteristics of AI-generated misinformation (AI-misinfo) compared with human creations, and then evaluated the applicability of existing solutions. We compiled human-created COVID-19 misinformation and abstracted it into narrative prompts for a language model to output AI-misinfo. We found significant linguistic differences within human-AI pairs, and patterns of AI-misinfo in enhancing details, communicating uncertainties, drawing conclusions, and simulating personal tones. While existing models remained capable of classifying AI-misinfo, a significant performance drop compared to human-misinfo was observed. Results suggested that existing information assessment guidelines had questionable applicability, as AI-misinfo tended to meet criteria in evidence credibility, source transparency, and limitation acknowledgment. We discuss implications for practitioners, researchers, and journalists, as AI can create new challenges to the societal problem of misinformation.",
    "citationCount": 316,
    "pdf_filename": "2023_Synthetic_Lies__Understanding_AI_Generat_fdb117c6.pdf"
  },
  "4c067037dba2c25ccbaf59ce2b3aea0d4c046521": {
    "paperId": "4c067037dba2c25ccbaf59ce2b3aea0d4c046521",
    "title": "AI literacy in K-12: a systematic literature review",
    "year": 2023,
    "authors": "Lorena Casal-Otero, Alejandro Catalá, Carmen Fernández-Morante, M. Taboada, Beatriz Cebreiro",
    "abstract": "The successful irruption of AI-based technology in our daily lives has led to a growing educational, social, and political interest in training citizens in AI. Education systems now need to train students at the K-12 level to live in a society where they must interact with AI. Thus, AI literacy is a pedagogical and cognitive challenge at the K-12 level. This study aimed to understand how AI is being integrated into K-12 education worldwide. We conducted a search process following the systematic literature review method using Scopus. 179 documents were reviewed, and two broad groups of AI literacy approaches were identified, namely learning experience and theoretical perspective. The first group covered experiences in learning technical, conceptual and applied skills in a particular domain of interest. The second group revealed that significant efforts are being made to design models that frame AI literacy proposals. There were hardly any experiences that assessed whether students understood AI concepts after the learning experience. Little attention has been paid to the undesirable consequences of an indiscriminate and insufficiently thought-out application of AI. A competency framework is required to guide the didactic proposals designed by educational institutions and define a curriculum reflecting the sequence and academic continuity, which should be modular, personalized and adjusted to the conditions of the schools. Finally, AI literacy can be leveraged to enhance the learning of disciplinary core subjects by integrating AI into the teaching process of those subjects, provided the curriculum is co-designed with teachers.",
    "citationCount": 321,
    "pdf_filename": "2023_AI_literacy_in_K_12__a_systematic_litera_4c067037.pdf"
  },
  "b47f132fd09632cfc986a99caa70c8f2f958e88d": {
    "paperId": "b47f132fd09632cfc986a99caa70c8f2f958e88d",
    "title": "Connecting the Dots in Trustworthy Artificial Intelligence: From AI Principles, Ethics, and Key Requirements to Responsible AI Systems and Regulation",
    "year": 2023,
    "authors": "Natalia Díaz Rodríguez, J. Ser, Mark Coeckelbergh, Marcos L'opez de Prado, E. Herrera-Viedma",
    "abstract": "Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society.",
    "citationCount": 423,
    "pdf_filename": "2023_Connecting_the_Dots_in_Trustworthy_Artif_b47f132f.pdf"
  },
  "608a698276123a3a3747cdcbbabe6343892f12e0": {
    "paperId": "608a698276123a3a3747cdcbbabe6343892f12e0",
    "title": "Integration of IoT-Enabled Technologies and Artificial Intelligence (AI) for Smart City Scenario: Recent Advancements and Future Trends",
    "year": 2023,
    "authors": "M. Alahi, A. Sukkuea, F. Tina, A. Nag, W. Kurdthongmee",
    "abstract": "As the global population grows, and urbanization becomes more prevalent, cities often struggle to provide convenient, secure, and sustainable lifestyles due to the lack of necessary smart technologies. Fortunately, the Internet of Things (IoT) has emerged as a solution to this challenge by connecting physical objects using electronics, sensors, software, and communication networks. This has transformed smart city infrastructures, introducing various technologies that enhance sustainability, productivity, and comfort for urban dwellers. By leveraging Artificial Intelligence (AI) to analyze the vast amount of IoT data available, new opportunities are emerging to design and manage futuristic smart cities. In this review article, we provide an overview of smart cities, defining their characteristics and exploring the architecture of IoT. A detailed analysis of various wireless communication technologies employed in smart city applications is presented, with extensive research conducted to determine the most appropriate communication technologies for specific use cases. The article also sheds light on different AI algorithms and their suitability for smart city applications. Furthermore, the integration of IoT and AI in smart city scenarios is discussed, emphasizing the potential contributions of 5G networks coupled with AI in advancing modern urban environments. This article contributes to the existing literature by highlighting the tremendous opportunities presented by integrating IoT and AI, paving the way for the development of smart cities that significantly enhance the quality of life for urban dwellers while promoting sustainability and productivity. By exploring the potential of IoT, AI, and their integration, this review article provides valuable insights into the future of smart cities, demonstrating how these technologies can positively impact urban environments and the well-being of their inhabitants.",
    "citationCount": 330,
    "pdf_filename": "2023_Integration_of_IoT_Enabled_Technologies__608a6982.pdf"
  },
  "c082ccfcfe1afc696e371374146ba9380b84061e": {
    "paperId": "c082ccfcfe1afc696e371374146ba9380b84061e",
    "title": "The Role of ChatGPT in Data Science: How AI-Assisted Conversational Interfaces Are Revolutionizing the Field",
    "year": 2023,
    "authors": "Hossein Hassani, E. Silva",
    "abstract": "ChatGPT, a conversational AI interface that utilizes natural language processing and machine learning algorithms, is taking the world by storm and is the buzzword across many sectors today. Given the likely impact of this model on data science, through this perspective article, we seek to provide an overview of the potential opportunities and challenges associated with using ChatGPT in data science, provide readers with a snapshot of its advantages, and stimulate interest in its use for data science projects. The paper discusses how ChatGPT can assist data scientists in automating various aspects of their workflow, including data cleaning and preprocessing, model training, and result interpretation. It also highlights how ChatGPT has the potential to provide new insights and improve decision-making processes by analyzing unstructured data. We then examine the advantages of ChatGPT’s architecture, including its ability to be fine-tuned for a wide range of language-related tasks and generate synthetic data. Limitations and issues are also addressed, particularly around concerns about bias and plagiarism when using ChatGPT. Overall, the paper concludes that the benefits outweigh the costs and ChatGPT has the potential to greatly enhance the productivity and accuracy of data science workflows and is likely to become an increasingly important tool for intelligence augmentation in the field of data science. ChatGPT can assist with a wide range of natural language processing tasks in data science, including language translation, sentiment analysis, and text classification. However, while ChatGPT can save time and resources compared to training a model from scratch, and can be fine-tuned for specific use cases, it may not perform well on certain tasks if it has not been specifically trained for them. Additionally, the output of ChatGPT may be difficult to interpret, which could pose challenges for decision-making in data science applications.",
    "citationCount": 301,
    "pdf_filename": "2023_The_Role_of_ChatGPT_in_Data_Science__How_c082ccfc.pdf"
  },
  "ba2f73db4e38324f751fbf30f7dde0bf4e7fa520": {
    "paperId": "ba2f73db4e38324f751fbf30f7dde0bf4e7fa520",
    "title": "Knowledge Distillation in Iterative Generative Models for Improved Sampling Speed",
    "year": 2021,
    "authors": "Eric Luhman, Troy Luhman",
    "abstract": "Iterative generative models, such as noise conditional score networks and denoising diffusion probabilistic models, produce high quality samples by gradually denoising an initial noise vector. However, their denoising process has many steps, making them 2-3 orders of magnitude slower than other generative models such as GANs and VAEs. In this paper, we establish a novel connection between knowledge distillation and image generation with a technique that distills a multi-step denoising process into a single step, resulting in a sampling speed similar to other single-step generative models. Our Denoising Student generates high quality samples comparable to GANs on the CIFAR-10 and CelebA datasets, without adversarial training. We demonstrate that our method scales to higher resolutions through experiments on 256 x 256 LSUN. Code and checkpoints are available at https://github.com/tcl9876/Denoising_Student",
    "citationCount": 339,
    "pdf_filename": "2021_Knowledge_Distillation_in_Iterative_Gene_ba2f73db.pdf"
  },
  "89bc95b30f147fd24dac91f43be1f2c3541f02ea": {
    "paperId": "89bc95b30f147fd24dac91f43be1f2c3541f02ea",
    "title": "Protein design and variant prediction using autoregressive generative models",
    "year": 2021,
    "authors": "Jung-Eun Shin, Adam J. Riesselman, Aaron W. Kollasch, Conor McMahon, Elana Simon",
    "abstract": "The ability to design functional sequences and predict effects of variation is central to protein engineering and biotherapeutics. State-of-art computational methods rely on models that leverage evolutionary information but are inadequate for important applications where multiple sequence alignments are not robust. Such applications include the prediction of variant effects of indels, disordered proteins, and the design of proteins such as antibodies due to the highly variable complementarity determining regions. We introduce a deep generative model adapted from natural language processing for prediction and design of diverse functional sequences without the need for alignments. The model performs state-of-art prediction of missense and indel effects and we successfully design and test a diverse 105-nanobody library that shows better expression than a 1000-fold larger synthetic library. Our results demonstrate the power of the alignment-free autoregressive model in generalizing to regions of sequence space traditionally considered beyond the reach of prediction and design. The ability to design functional sequences is central to protein engineering and biotherapeutics. Here the authors introduce a deep generative alignment-free model for sequence design applied to highly variable regions and design and test a diverse nanobody library with improved properties for selection experiments.",
    "citationCount": 335,
    "pdf_filename": "2021_Protein_design_and_variant_prediction_us_89bc95b3.pdf"
  },
  "6d96fe3d9f2d098d98de3222e50fe60def327bd4": {
    "paperId": "6d96fe3d9f2d098d98de3222e50fe60def327bd4",
    "title": "AttentionFGAN: Infrared and Visible Image Fusion Using Attention-Based Generative Adversarial Networks",
    "year": 2021,
    "authors": "Jing Li, Hongtao Huo, Chang Li, Renhua Wang, Qi Feng",
    "abstract": "Infrared and visible image fusion aims to describe the same scene from different aspects by combining complementary information of multi-modality images. The existing Generative adversarial networks (GAN) based infrared and visible image fusion methods cannot perceive the most discriminative regions, and hence fail to highlight the typical parts existing in infrared and visible images. To this end, we integrate multi-scale attention mechanism into both generator and discriminator of GAN to fuse infrared and visible images (AttentionFGAN). The multi-scale attention mechanism aims to not only capture comprehensive spatial information to help generator focus on the foreground target information of infrared image and background detail information of visible image, but also constrain the discriminators focus more on the attention regions rather than the whole input image. The generator of AttentionFGAN consists of two multi-scale attention networks and an image fusion network. Two multi-scale attention networks capture the attention maps of infrared and visible images respectively, so that the fusion network can reconstruct the fused image by paying more attention to the typical regions of source images. Besides, two discriminators are adopted to force the fused result keep more intensity and texture information from infrared and visible image respectively. Moreover, to keep more information of attention region from source images, an attention loss function is designed. Finally, the ablation experiments illustrate the effectiveness of the key parts of our method, and extensive qualitative and quantitative experiments on three public datasets demonstrate the advantages and effectiveness of AttentionFGAN compared with the other state-of-the-art methods.",
    "citationCount": 309,
    "pdf_filename": "2021_AttentionFGAN__Infrared_and_Visible_Imag_6d96fe3d.pdf"
  },
  "67655143fdd9dafe018870e1915149111c8c81b6": {
    "paperId": "67655143fdd9dafe018870e1915149111c8c81b6",
    "title": "Assessing the Accuracy and Reliability of AI-Generated Medical Responses: An Evaluation of the Chat-GPT Model",
    "year": 2023,
    "authors": "Douglas B. Johnson, Rachel S Goodman, J. Patrinely, Cosby A Stone, Eli Zimmerman",
    "abstract": "Background: Natural language processing models such as ChatGPT can generate text-based content and are poised to become a major information source in medicine and beyond. The accuracy and completeness of ChatGPT for medical queries is not known. Methods: Thirty-three physicians across 17 specialties generated 284 medical questions that they subjectively classified as easy, medium, or hard with either binary (yes/no) or descriptive answers. The physicians then graded ChatGPT-generated answers to these questions for accuracy (6-point Likert scale; range 1 – completely incorrect to 6 – completely correct) and completeness (3-point Likert scale; range 1 – incomplete to 3 - complete plus additional context). Scores were summarized with descriptive statistics and compared using Mann-Whitney U or Kruskal-Wallis testing. Results: Across all questions (n=284), median accuracy score was 5.5 (between almost completely and completely correct) with mean score of 4.8 (between mostly and almost completely correct). Median completeness score was 3 (complete and comprehensive) with mean score of 2.5. For questions rated easy, medium, and hard, median accuracy scores were 6, 5.5, and 5 (mean 5.0, 4.7, and 4.6; p=0.05). Accuracy scores for binary and descriptive questions were similar (median 6 vs. 5; mean 4.9 vs. 4.7; p=0.07). Of 36 questions with scores of 1-2, 34 were re-queried/re-graded 8-17 days later with substantial improvement (median 2 vs. 4; p<0.01). Conclusions: ChatGPT generated largely accurate information to diverse medical queries as judged by academic physician specialists although with important limitations. Further research and model development are needed to correct inaccuracies and for validation.",
    "citationCount": 410,
    "pdf_filename": "2023_Assessing_the_Accuracy_and_Reliability_o_67655143.pdf"
  },
  "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6": {
    "paperId": "07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6",
    "title": "GeDi: Generative Discriminator Guided Sequence Generation",
    "year": 2020,
    "authors": "Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, N. Keskar, Shafiq R. Joty",
    "abstract": "While large-scale language models (LMs) are able to imitate the distribution of natural language well enough to generate realistic text, it is difficult to control which regions of the distribution they generate. This is especially problematic because datasets used for training large LMs usually contain significant toxicity, hate, bias, and negativity. We propose GeDi as an efficient method for using smaller LMs as generative discriminators to guide generation from large LMs to make them safer and more controllable. GeDi guides generation at each step by computing classification probabilities for all possible next tokens via Bayes rule by normalizing over two class-conditional distributions; one conditioned on the desired attribute, or control code, and another conditioned on the undesired attribute, or anti control code. We find that GeDi gives stronger controllability than the state of the art method while also achieving generation speeds more than 30 times faster. Additionally, training GeDi on only four topics allows us to controllably generate new topics zero-shot from just a keyword, unlocking a new capability that previous controllable generation methods do not have. Lastly, we show that GeDi can make GPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic quality, making it by far the most practical existing method for detoxifying large language models while maintaining a fast generation speed.",
    "citationCount": 450,
    "pdf_filename": "2020_GeDi__Generative_Discriminator_Guided_Se_07bcda1d.pdf"
  },
  "0119a57cf88ef16e6dc291252fae340bb6b3953c": {
    "paperId": "0119a57cf88ef16e6dc291252fae340bb6b3953c",
    "title": "CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning",
    "year": 2020,
    "authors": "Bill Yuchen Lin, Ming Shen, Wangchunshu Zhou, Pei Zhou, Chandra Bhagavatula",
    "abstract": "Recently, large-scale pre-trained language models have demonstrated impressive performance on several commonsense-reasoning benchmark datasets. However, building machines with commonsense to compose realistically plausible sentences remains challenging. In this paper, we present a constrained text generation task, CommonGen associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts (e.g., dog, frisbee, catch, throw); the task is to generate a coherent sentence describing an everyday scenario using these concepts (e.g., “a man throws a frisbee and his dog catches it”). The CommonGen task is challenging because it inherently requires 1) relational reasoning with background commonsense knowledge and 2) compositional generalization ability to work on unseen concept combinations. Our dataset, constructed through a combination of crowdsourced and existing caption corpora, consists of 77k commonsense descriptions over 35k unique concept-sets. Experiments show that there is a large gap between state-of-the-art text generation models (e.g., T5) and human performance (31.6% v.s. 63.5% in SPICE metric). Furthermore, we demonstrate that the learned generative commonsense reasoning capability can be transferred to improve downstream tasks such as CommonsenseQA (76.9% to 78.4 in dev accuracy) by generating additional context.",
    "citationCount": 389,
    "pdf_filename": "2020_CommonGen__A_Constrained_Text_Generation_0119a57c.pdf"
  },
  "b95baf93d1cfb406b50aa370ce5ba18788b5891d": {
    "paperId": "b95baf93d1cfb406b50aa370ce5ba18788b5891d",
    "title": "Cosmos World Foundation Model Platform for Physical AI",
    "year": 2025,
    "authors": "Nvidia Niket Agarwal, Arslan Ali, Maciej Bala, Yogesh Balaji, Erik Barker",
    "abstract": "Physical AI needs to be trained digitally first. It needs a digital twin of itself, the policy model, and a digital twin of the world, the world model. In this paper, we present the Cosmos World Foundation Model Platform to help developers build customized world models for their Physical AI setups. We position a world foundation model as a general-purpose world model that can be fine-tuned into customized world models for downstream applications. Our platform covers a video curation pipeline, pre-trained world foundation models, examples of post-training of pre-trained world foundation models, and video tokenizers. To help Physical AI builders solve the most critical problems of our society, we make Cosmos open-source and our models open-weight with permissive licenses available via https://github.com/nvidia-cosmos/cosmos-predict1.",
    "citationCount": 324,
    "pdf_filename": "2025_Cosmos_World_Foundation_Model_Platform_f_b95baf93.pdf"
  },
  "4df3b534beeba05ba930814162ea6e19948c5fcd": {
    "paperId": "4df3b534beeba05ba930814162ea6e19948c5fcd",
    "title": "Watch Your Up-Convolution: CNN Based Generative Deep Neural Networks Are Failing to Reproduce Spectral Distributions",
    "year": 2020,
    "authors": "Ricard Durall, Margret Keuper, Janis Keuper",
    "abstract": "Generative convolutional deep neural networks, e.g. popular GAN architectures, are relying on convolution based up-sampling methods to produce non-scalar outputs like images or video sequences. In this paper, we show that common up-sampling methods, i.e. known as up-convolution or transposed convolution, are causing the inability of such models to reproduce spectral distributions of natural training data correctly. This effect is independent of the underlying architecture and we show that it can be used to easily detect generated data like deepfakes with up to 100% accuracy on public benchmarks. To overcome this drawback of current generative models, we propose to add a novel spectral regularization term to the training optimization objective. We show that this approach not only allows to train spectral consistent GANs that are avoiding high frequency errors. Also, we show that a correct approximation of the frequency spectrum has positive effects on the training stability and output quality of generative networks.",
    "citationCount": 415,
    "pdf_filename": "2020_Watch_Your_Up_Convolution__CNN_Based_Gen_4df3b534.pdf"
  },
  "b16492ec402d3d38b2d61de9c4ad37f03966ab9f": {
    "paperId": "b16492ec402d3d38b2d61de9c4ad37f03966ab9f",
    "title": "Permutation Invariant Graph Generation via Score-Based Generative Modeling",
    "year": 2020,
    "authors": "Chenhao Niu, Yang Song, Jiaming Song, Shengjia Zhao, Aditya Grover",
    "abstract": "Learning generative models for graph-structured data is challenging because graphs are discrete, combinatorial, and the underlying data distribution is invariant to the ordering of nodes. However, most of the existing generative models for graphs are not invariant to the chosen ordering, which might lead to an undesirable bias in the learned distribution. To address this difficulty, we propose a permutation invariant approach to modeling graphs, using the recent framework of score-based generative modeling. In particular, we design a permutation equivariant, multi-channel graph neural network to model the gradient of the data distribution at the input graph (a.k.a., the score function). This permutation equivariant model of gradients implicitly defines a permutation invariant distribution for graphs. We train this graph neural network with score matching and sample from it with annealed Langevin dynamics. In our experiments, we first demonstrate the capacity of this new architecture in learning discrete graph algorithms. For graph generation, we find that our learning approach achieves better or comparable results to existing models on benchmark datasets.",
    "citationCount": 322,
    "pdf_filename": "2020_Permutation_Invariant_Graph_Generation_v_b16492ec.pdf"
  },
  "29b70c9b187bcda6cd25a2d50b6d6a554a38ea10": {
    "paperId": "29b70c9b187bcda6cd25a2d50b6d6a554a38ea10",
    "title": "A U-Net Based Discriminator for Generative Adversarial Networks",
    "year": 2020,
    "authors": "Edgar Schönfeld, B. Schiele, A. Khoreva",
    "abstract": "Among the major remaining challenges for generative adversarial networks (GANs) is the capacity to synthesize globally and locally coherent images with object shapes and textures indistinguishable from real images. To target this issue we propose an alternative U-Net based discriminator architecture, borrowing the insights from the segmentation literature. The proposed U-Net based architecture allows to provide detailed per-pixel feedback to the generator while maintaining the global coherence of synthesized images, by providing the global image feedback as well. Empowered by the per-pixel response of the discriminator, we further propose a per-pixel consistency regularization technique based on the CutMix data augmentation, encouraging the U-Net discriminator to focus more on semantic and structural changes between real and fake images. This improves the U-Net discriminator training, further enhancing the quality of generated samples. The novel discriminator improves over the state of the art in terms of the standard distribution and image quality metrics, enabling the generator to synthesize images with varying structure, appearance and levels of detail, maintaining global and local realism. Compared to the BigGAN baseline, we achieve an average improvement of 2.7 FID points across FFHQ, CelebA, and the proposed COCO-Animals dataset.",
    "citationCount": 323,
    "pdf_filename": "2020_A_U_Net_Based_Discriminator_for_Generati_29b70c9b.pdf"
  },
  "296e32a86e1711269289004b140f6d3e0f250348": {
    "paperId": "296e32a86e1711269289004b140f6d3e0f250348",
    "title": "Equivariant Flows: exact likelihood generative learning for symmetric densities",
    "year": 2020,
    "authors": "Jonas Köhler, Leon Klein, F. Noé",
    "abstract": "Normalizing flows are exact-likelihood generative neural networks which approximately transform samples from a simple prior distribution to samples of the probability distribution of interest. Recent work showed that such generative models can be utilized in statistical mechanics to sample equilibrium states of many-body systems in physics and chemistry. To scale and generalize these results, it is essential that the natural symmetries in the probability density - in physics defined by the invariances of the target potential - are built into the flow. We provide a theoretical sufficient criterion showing that the distribution generated by equivariant normalizing flows is invariant with respect to these symmetries by design. Furthermore, we propose building blocks for flows which preserve symmetries which are usually found in physical/chemical many-body particle systems. Using benchmark systems motivated from molecular physics, we demonstrate that those symmetry preserving flows can provide better generalization capabilities and sampling efficiency.",
    "citationCount": 309,
    "pdf_filename": "2020_Equivariant_Flows__exact_likelihood_gene_296e32a8.pdf"
  },
  "05ba96cc8ce02f065fc5bdf74e7907f5e13a9b03": {
    "paperId": "05ba96cc8ce02f065fc5bdf74e7907f5e13a9b03",
    "title": "Generative Adversarial Networks (GANs)",
    "year": 2020,
    "authors": "Divya Saxena, Jiannong Cao",
    "abstract": "Generative Adversarial Networks (GANs) is a novel class of deep generative models that has recently gained significant attention. GANs learn complex and high-dimensional distributions implicitly over images, audio, and data. However, there exist major challenges in training of GANs, i.e., mode collapse, non-convergence, and instability, due to inappropriate design of network architectre, use of objective function, and selection of optimization algorithm. Recently, to address these challenges, several solutions for better design and optimization of GANs have been investigated based on techniques of re-engineered network architectures, new objective functions, and alternative optimization algorithms. To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these solutions. In this study, we perform a comprehensive survey of the advancements in GANs design and optimization solutions proposed to handle GANs challenges. We first identify key research issues within each design and optimization technique and then propose a new taxonomy to structure solutions by key research issues. In accordance with the taxonomy, we provide a detailed discussion on different GANs variants proposed within each solution and their relationships. Finally, based on the insights gained, we present promising research directions in this rapidly growing field.",
    "citationCount": 368,
    "pdf_filename": "2020_Generative_Adversarial_Networks__GANs__05ba96cc.pdf"
  },
  "c76750c3fe9011cc62e8c73df07c126711f51d1c": {
    "paperId": "c76750c3fe9011cc62e8c73df07c126711f51d1c",
    "title": "Reliable Fidelity and Diversity Metrics for Generative Models",
    "year": 2020,
    "authors": "Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi, Jaejun Yoo",
    "abstract": "Devising indicative evaluation metrics for the image generation task remains an open problem. The most widely used metric for measuring the similarity between real and generated images has been the Frechet Inception Distance (FID) score. Because it does not differentiate the fidelity and diversity aspects of the generated images, recent papers have introduced variants of precision and recall metrics to diagnose those properties separately. In this paper, we show that even the latest version of the precision and recall metrics are not reliable yet. For example, they fail to detect the match between two identical distributions, they are not robust against outliers, and the evaluation hyperparameters are selected arbitrarily. We propose density and coverage metrics that solve the above issues. We analytically and experimentally show that density and coverage provide more interpretable and reliable signals for practitioners than the existing metrics. Code: this https URL.",
    "citationCount": 488,
    "pdf_filename": "2020_Reliable_Fidelity_and_Diversity_Metrics__c76750c3.pdf"
  },
  "d54d8c402785006faaf5de19e81f04eb484a3aa2": {
    "paperId": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
    "title": "A Survey on Generative Adversarial Networks: Variants, Applications, and Training",
    "year": 2020,
    "authors": "Abdul Jabbar, Xi Li, Bourahla Omar",
    "abstract": "The Generative Models have gained considerable attention in unsupervised learning via a new and practical framework called Generative Adversarial Networks (GAN) due to their outstanding data generation capability. Many GAN models have been proposed, and several practical applications have emerged in various domains of computer vision and machine learning. Despite GANs excellent success, there are still obstacles to stable training. The problems are Nash equilibrium, internal covariate shift, mode collapse, vanishing gradient, and lack of proper evaluation metrics. Therefore, stable training is a crucial issue in different applications for the success of GANs. Herein, we survey several training solutions proposed by different researchers to stabilize GAN training. We discuss (I) the original GAN model and its modified versions, (II) a detailed analysis of various GAN applications in different domains, and (III) a detailed study about the various GAN training obstacles as well as training solutions. Finally, we reveal several issues as well as research outlines to the topic.",
    "citationCount": 315,
    "pdf_filename": "2020_A_Survey_on_Generative_Adversarial_Netwo_d54d8c40.pdf"
  },
  "f281ad6573ed8ea7fb3116a3747b0e80ef522ea9": {
    "paperId": "f281ad6573ed8ea7fb3116a3747b0e80ef522ea9",
    "title": "Trust in AI and Its Role in the Acceptance of AI Technologies",
    "year": 2022,
    "authors": "Hyesun Choung, Prabu David, Arun Ross",
    "abstract": "Abstract As AI-enhanced technologies become common in a variety of domains, there is an increasing need to define and examine the trust that users have in such technologies. Given the progress in the development of AI, a correspondingly sophisticated understanding of trust in the technology is required. This paper addresses this need by explaining the role of trust in the intention to use AI technologies. Study 1 examined the role of trust in the use of AI voice assistants based on survey responses from college students. A path analysis confirmed that trust had a significant effect the on intention to use AI, which operated through perceived usefulness and participants’ attitude toward voice assistants. In Study 2, using data from a representative sample of the U.S. population, different dimensions of trust were examined using exploratory factor analysis, which yielded two dimensions: human-like trust and functionality trust. The results of the path analyses from Study 1 were replicated in Study 2, confirming the indirect effect of trust and the effects of perceived usefulness, ease of use, and attitude on intention to use. Further, both dimensions of trust shared a similar pattern of effects within the model, with functionality-related trust exhibiting a greater total impact on usage intention than human-like trust. Overall, the role of trust in the acceptance of AI technologies was significant across both studies. This research contributes to the advancement and application of the TAM in AI-related applications and offers a multidimensional measure of trust that can be utilized in the future study of trustworthy AI.",
    "citationCount": 478,
    "pdf_filename": "2022_Trust_in_AI_and_Its_Role_in_the_Acceptan_f281ad65.pdf"
  },
  "5fe0a4af3bd1479d5e39fbda2215c86bce54722b": {
    "paperId": "5fe0a4af3bd1479d5e39fbda2215c86bce54722b",
    "title": "Generative Language Modeling for Automated Theorem Proving",
    "year": 2020,
    "authors": "Stanislas Polu, I. Sutskever",
    "abstract": "We explore the application of transformer-based language models to automated theorem proving. This work is motivated by the possibility that a major limitation of automated theorem provers compared to humans -- the generation of original mathematical terms -- might be addressable via generation from language models. We present an automated prover and proof assistant, GPT-f, for the Metamath formalization language, and analyze its performance. GPT-f found new short proofs that were accepted into the main Metamath library, which is to our knowledge, the first time a deep-learning based system has contributed proofs that were adopted by a formal mathematics community.",
    "citationCount": 367,
    "pdf_filename": "2020_Generative_Language_Modeling_for_Automat_5fe0a4af.pdf"
  },
  "d7bca917b753b996074203cc77ba45935b7c62d7": {
    "paperId": "d7bca917b753b996074203cc77ba45935b7c62d7",
    "title": "ProcTHOR: Large-Scale Embodied AI Using Procedural Generation",
    "year": 2022,
    "authors": "Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador",
    "abstract": "Massive datasets and high-capacity models have driven many recent advancements in computer vision and natural language understanding. This work presents a platform to enable similar success stories in Embodied AI. We propose ProcTHOR, a framework for procedural generation of Embodied AI environments. ProcTHOR enables us to sample arbitrarily large datasets of diverse, interactive, customizable, and performant virtual environments to train and evaluate embodied agents across navigation, interaction, and manipulation tasks. We demonstrate the power and potential of ProcTHOR via a sample of 10,000 generated houses and a simple neural model. Models trained using only RGB images on ProcTHOR, with no explicit mapping and no human task supervision produce state-of-the-art results across 6 embodied AI benchmarks for navigation, rearrangement, and arm manipulation, including the presently running Habitat 2022, AI2-THOR Rearrangement 2022, and RoboTHOR challenges. We also demonstrate strong 0-shot results on these benchmarks, via pre-training on ProcTHOR with no fine-tuning on the downstream benchmark, often beating previous state-of-the-art systems that access the downstream training data.",
    "citationCount": 350,
    "pdf_filename": "2022_ProcTHOR__Large_Scale_Embodied_AI_Using__d7bca917.pdf"
  },
  "7d1e512888a2fa4e838c12a02ae7fce867d322a8": {
    "paperId": "7d1e512888a2fa4e838c12a02ae7fce867d322a8",
    "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale",
    "year": 2022,
    "authors": "Samyam Rajbhandari, Conglong Li, Z. Yao, Minjia Zhang, Reza Yazdani Aminabadi",
    "abstract": "As the training of giant dense models hits the boundary on the availability and capability of the hardware resources today, Mixture-of-Experts (MoE) models become one of the most promising model architectures due to their significant training cost reduction compared to a quality-equivalent dense model. Its training cost saving is demonstrated from encoder-decoder models (prior works) to a 5x saving for auto-aggressive language models (this work along with parallel explorations). However, due to the much larger model size and unique architecture, how to provide fast MoE model inference remains challenging and unsolved, limiting its practical usage. To tackle this, we present DeepSpeed-MoE, an end-to-end MoE training and inference solution as part of the DeepSpeed library, including novel MoE architecture designs and model compression techniques that reduce MoE model size by up to 3.7x, and a highly optimized inference system that provides 7.3x better latency and cost compared to existing MoE inference solutions. DeepSpeed-MoE offers an unprecedented scale and efficiency to serve massive MoE models with up to 4.5x faster and 9x cheaper inference compared to quality-equivalent dense models. We hope our innovations and systems help open a promising path to new directions in the large model landscape, a shift from dense to sparse MoE models, where training and deploying higher-quality models with fewer resources becomes more widely possible.",
    "citationCount": 414,
    "pdf_filename": "2022_DeepSpeed_MoE__Advancing_Mixture_of_Expe_7d1e5128.pdf"
  },
  "aaec96d6e9a0a4877dde4382dc7889d47c074524": {
    "paperId": "aaec96d6e9a0a4877dde4382dc7889d47c074524",
    "title": "GHUM & GHUML: Generative 3D Human Shape and Articulated Pose Models",
    "year": 2020,
    "authors": "Hongyi Xu, Eduard Gabriel Bazavan, Andrei Zanfir, W. Freeman, R. Sukthankar",
    "abstract": "We present a statistical, articulated 3D human shape modeling pipeline, within a fully trainable, modular, deep learning framework. Given high-resolution complete 3D body scans of humans, captured in various poses, together with additional closeups of their head and facial expressions, as well as hand articulation, and given initial, artist designed, gender neutral rigged quad-meshes, we train all model parameters including non-linear shape spaces based on variational auto-encoders, pose-space deformation correctives, skeleton joint center predictors, and blend skinning functions, in a single consistent learning loop. The models are simultaneously trained with all the 3d dynamic scan data (over 60,000 diverse human configurations in our new dataset) in order to capture correlations and ensure consistency of various components. Models support facial expression analysis, as well as body (with detailed hand) shape and pose estimation. We provide fully train-able generic human models of different resolutions- the moderate-resolution GHUM consisting of 10,168 vertices and the low-resolution GHUML(ite) of 3,194 vertices–, run comparisons between them, analyze the impact of different components and illustrate their reconstruction from image data. The models will be available for research.",
    "citationCount": 364,
    "pdf_filename": "2020_GHUM___GHUML__Generative_3D_Human_Shape__aaec96d6.pdf"
  },
  "8aa6119a85e28dc84024fc64764ffb687c52a6f3": {
    "paperId": "8aa6119a85e28dc84024fc64764ffb687c52a6f3",
    "title": "Fusing Blockchain and AI With Metaverse: A Survey",
    "year": 2022,
    "authors": "Qinglin Yang, Yetong Zhao, Huawei Huang, Zehui Xiong, Jiawen Kang",
    "abstract": "Metaverse as the latest buzzword has attracted great attention from both industry and academia. Metaverse seamlessly integrates the real world with the virtual world and allows avatars to carry out rich activities including creation, display, entertainment, social networking, and trading. Thus, it is promising to build an exciting digital world and to transform a better physical world through the exploration of the metaverse. In this survey, we dive into the metaverse by discussing how Blockchain and Artificial Intelligence (AI) fuse with it through investigating the state-of-the-art studies across the metaverse components, digital currencies, AI applications in the virtual world, and blockchain-empowered technologies. Further exploitation and interdisciplinary research on the fusion of AI and Blockchain towards metaverse will definitely require collaboration from both academia and industries. We wish that our survey can help researchers, engineers, and educators build an open, fair, and rational future metaverse.",
    "citationCount": 348,
    "pdf_filename": "2022_Fusing_Blockchain_and_AI_With_Metaverse__8aa6119a.pdf"
  },
  "ff437a9a44dbce3faf9534454a9bbdbc12bac3c2": {
    "paperId": "ff437a9a44dbce3faf9534454a9bbdbc12bac3c2",
    "title": "Artificial Intelligence (AI) and Internet of Medical Things (IoMT) Assisted Biomedical Systems for Intelligent Healthcare",
    "year": 2022,
    "authors": "Pandiaraj Manickam, Siva Ananth Mariappan, S. Murugesan, Shekhar Hansda, A. Kaushik",
    "abstract": "Artificial intelligence (AI) is a modern approach based on computer science that develops programs and algorithms to make devices intelligent and efficient for performing tasks that usually require skilled human intelligence. AI involves various subsets, including machine learning (ML), deep learning (DL), conventional neural networks, fuzzy logic, and speech recognition, with unique capabilities and functionalities that can improve the performances of modern medical sciences. Such intelligent systems simplify human intervention in clinical diagnosis, medical imaging, and decision-making ability. In the same era, the Internet of Medical Things (IoMT) emerges as a next-generation bio-analytical tool that combines network-linked biomedical devices with a software application for advancing human health. In this review, we discuss the importance of AI in improving the capabilities of IoMT and point-of-care (POC) devices used in advanced healthcare sectors such as cardiac measurement, cancer diagnosis, and diabetes management. The role of AI in supporting advanced robotic surgeries developed for advanced biomedical applications is also discussed in this article. The position and importance of AI in improving the functionality, detection accuracy, decision-making ability of IoMT devices, and evaluation of associated risks assessment is discussed carefully and critically in this review. This review also encompasses the technological and engineering challenges and prospects for AI-based cloud-integrated personalized IoMT devices for designing efficient POC biomedical systems suitable for next-generation intelligent healthcare.",
    "citationCount": 379,
    "pdf_filename": "2022_Artificial_Intelligence__AI__and_Interne_ff437a9a.pdf"
  },
  "661ace6792a03bd6ed1b67e14a66ae5b330a97df": {
    "paperId": "661ace6792a03bd6ed1b67e14a66ae5b330a97df",
    "title": "Learning design to support student-AI collaboration: perspectives of leading teachers for AI in education",
    "year": 2022,
    "authors": "Jae Hyun Kim, Hyunkyung Lee, Y. Cho",
    "abstract": "Preparing students to collaborate with AI remains a challenging goal. As AI technologies are new to K-12 schools, there is a lack of studies that inform how to design learning when AI is introduced as a collaborative learning agent to classrooms. The present study, therefore, aimed to explore teachers’ perspectives on what (1) curriculum design, (2) student-AI interaction, and (3) learning environments are required to design student-AI collaboration (SAC) in learning and (4) how SAC would evolve. Through in-depth interviews with 10 Korean leading teachers in AI in Education (AIED), the study found that teachers perceived capacity and subject-matter knowledge building as the optimal learning goals for SAC. SAC can be facilitated through interdisciplinary learning, authentic problem solving, and creative tasks in tandem with process-oriented assessment and collaboration performance assessment. While teachers expressed instruction on AI principles, data literacy, error analysis, AI ethics, and AI experiences in daily life were crucial support, AI needs to offer an instructional scaffolding and possess attributes as a learning mate to enhance student-AI interaction. In addition, teachers highlighted systematic AIED policy, flexible school system, the culture of collaborative learning, and a safe to fail environment are significant. Teachers further anticipated students would develop collaboration with AI through three stages: (1) learn about AI, (2) learn from AI, and (3) learn together. These findings can provide a more holistic understanding of the AIED and implications for the educational policies, educational AI design as well as instructional design that are aimed at enhancing SAC in learning.",
    "citationCount": 362,
    "pdf_filename": "2022_Learning_design_to_support_student_AI_co_661ace67.pdf"
  },
  "6fb5ca0ff6821a92b080d0654d245d2407484701": {
    "paperId": "6fb5ca0ff6821a92b080d0654d245d2407484701",
    "title": "The Roles of Personality Traits, AI Anxiety, and Demographic Factors in Attitudes toward Artificial Intelligence",
    "year": 2022,
    "authors": "Feridun Kaya, F. Aydın, A. Schepman, P. Rodway, Okan Yeti̇şensoy",
    "abstract": "Abstract The present study adapted the General Attitudes toward Artificial Intelligence Scale (GAAIS) to Turkish and investigated the impact of personality traits, artificial intelligence anxiety, and demographics on attitudes toward artificial intelligence. The sample consisted of 259 female (74%) and 91 male (26%) individuals aged between 18 and 51 (Mean = 24.23). Measures taken were demographics, the Ten-Item Personality Inventory, the Artificial Intelligence Anxiety Scale, and the General Attitudes toward Artificial Intelligence Scale. The Turkish GAAIS had good validity and reliability. Hierarchical Multiple Linear Regression Analyses showed that positive attitudes toward artificial intelligence were significantly predicted by the level of computer use (β = 0.139, p = 0.013), level of knowledge about artificial intelligence (β = 0.119, p = 0.029), and AI learning anxiety (β = −0.172, p = 0.004). Negative attitudes toward artificial intelligence were significantly predicted by agreeableness (β = 0.120, p = 0.019), AI configuration anxiety (β = −0.379, p < 0.001), and AI learning anxiety (β = −0.211, p < 0.001). Personality traits, AI anxiety, and demographics play important roles in attitudes toward AI. Results are discussed in light of the previous research and theoretical explanations.",
    "citationCount": 358,
    "pdf_filename": "2022_The_Roles_of_Personality_Traits__AI_Anxi_6fb5ca0f.pdf"
  },
  "dca3bc28a7d404b28780a813ea7072eda809e6c0": {
    "paperId": "dca3bc28a7d404b28780a813ea7072eda809e6c0",
    "title": "Programming Is Hard - Or at Least It Used to Be: Educational Opportunities and Challenges of AI Code Generation",
    "year": 2022,
    "authors": "Brett A. Becker, Paul Denny, James Finnie-Ansley, Andrew Luxton-Reilly, J. Prather",
    "abstract": "The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.",
    "citationCount": 350,
    "pdf_filename": "2022_Programming_Is_Hard___Or_at_Least_It_Use_dca3bc28.pdf"
  },
  "abf29f519a62bc62fc4650e03af735d61cc58bba": {
    "paperId": "abf29f519a62bc62fc4650e03af735d61cc58bba",
    "title": "Teachers' trust in AI-powered educational technology and a professional development program to improve it",
    "year": 2022,
    "authors": "Tanya Nazaretsky, Moriah Ariely, Mutlu Cukurova, Giora Alexandron",
    "abstract": "Evidence from various domains underlines the critical role that human factors, and especially trust, play in adopting technology by practitioners. In the case of Artificial Intelligence (AI) powered tools, the issue is even more complex due to practitioners' AI-specific misconceptions, myths and fears (e.g., mass unemployment and privacy violations). In recent years, AI has been incorporated increasingly into K-12 education. However, little research has been conducted on the trust and attitudes of K-12 teachers towards the use and adoption of AI-powered Educational Technology (AI-EdTech). This paper sheds light on teachers' trust in AI-EdTech and presents effective professional development strategies to increase teachers' trust and willingness to apply AI-EdTech in their classrooms. Our experiments with K-12 science teachers were conducted around their interactions with a specific AI-powered assessment tool (termed AI-Grader) using both synthetic and real data. The results indicate that presenting teachers with some explanations of (i) how AI makes decisions, particularly compared to the human experts, and (ii) how AI can",
    "citationCount": 321,
    "pdf_filename": "2022_Teachers__trust_in_AI_powered_educationa_abf29f51.pdf"
  },
  "fe7c42d5e0e73769e35903f542d0d98020e7511c": {
    "paperId": "fe7c42d5e0e73769e35903f542d0d98020e7511c",
    "title": "Opportunities and Adoption Challenges of AI in the Construction Industry: A PRISMA Review",
    "year": 2022,
    "authors": "Massimo Regona, Tan Yigitcanlar, Bo Xia, R. Li",
    "abstract": "Artificial intelligence (AI) is a powerful technology with a range of capabilities, which are beginning to become apparent in all industries nowadays. The increased popularity of AI in the construction industry, however, is rather limited in comparison to other industry sectors. Moreover, despite AI being a hot topic in built environment research, there are limited review studies that investigate the reasons for the low-level AI adoption in the construction industry. This study aims to reduce this gap by identifying the adoption challenges of AI, along with the opportunities offered, for the construction industry. To achieve the aim, the study adopts a systematic literature review approach using the PRISMA protocol. In addition, the systematic review of the literature focuses on the planning, design, and construction stages of the construction project lifecycle. The results of the review reveal that (a) AI is particularly beneficial in the planning stage as the success of construction projects depends on accurate events, risks, and cost forecasting; (b) the major opportunity in adopting AI is to reduce the time spent on repetitive tasks by using big data analytics and improving the work processes; and (c) the biggest challenge to incorporate AI on a construction site is the fragmented nature of the industry, which has resulted in issues of data acquisition and retention. The findings of the study inform a range of parties that operate in the construction industry concerning the opportunities and challenges of AI adaptability and help increase the market acceptance of AI practices.",
    "citationCount": 334,
    "pdf_filename": "2022_Opportunities_and_Adoption_Challenges_of_fe7c42d5.pdf"
  },
  "9543d4b9c6f71bdececdad7f397ad68cac359d2d": {
    "paperId": "9543d4b9c6f71bdececdad7f397ad68cac359d2d",
    "title": "The Role of AI in Drug Discovery: Challenges, Opportunities, and Strategies",
    "year": 2022,
    "authors": "Alexandre Blanco-González, Alfonso Cabezon, Alejandro Seco-González, Daniel Conde-Torres, Paula Antelo-Riveiro",
    "abstract": "Artificial intelligence (AI) has the potential to revolutionize the drug discovery process, offering improved efficiency, accuracy, and speed. However, the successful application of AI is dependent on the availability of high-quality data, the addressing of ethical concerns, and the recognition of the limitations of AI-based approaches. In this article, the benefits, challenges, and drawbacks of AI in this field are reviewed, and possible strategies and approaches for overcoming the present obstacles are proposed. The use of data augmentation, explainable AI, and the integration of AI with traditional experimental methods, as well as the potential advantages of AI in pharmaceutical research, are also discussed. Overall, this review highlights the potential of AI in drug discovery and provides insights into the challenges and opportunities for realizing its potential in this field. Note from the human authors: This article was created to test the ability of ChatGPT, a chatbot based on the GPT-3.5 language model, in terms of assisting human authors in writing review articles. The text generated by the AI following our instructions (see Supporting Information) was used as a starting point, and its ability to automatically generate content was evaluated. After conducting a thorough review, the human authors practically rewrote the manuscript, striving to maintain a balance between the original proposal and the scientific criteria. The advantages and limitations of using AI for this purpose are discussed in the last section.",
    "citationCount": 366,
    "pdf_filename": "2022_The_Role_of_AI_in_Drug_Discovery__Challe_9543d4b9.pdf"
  },
  "f17fabd53bccc1ee7360dbb72e050b4a347d4304": {
    "paperId": "f17fabd53bccc1ee7360dbb72e050b4a347d4304",
    "title": "AI-big data analytics for building automation and management systems: a survey, actual challenges and future perspectives",
    "year": 2022,
    "authors": "Yassine Himeur, Mariam Elnour, F. Fadli, N. Meskin, I. Petri",
    "abstract": "In theory, building automation and management systems (BAMSs) can provide all the components and functionalities required for analyzing and operating buildings. However, in reality, these systems can only ensure the control of heating ventilation and air conditioning system systems. Therefore, many other tasks are left to the operator, e.g. evaluating buildings’ performance, detecting abnormal energy consumption, identifying the changes needed to improve efficiency, ensuring the security and privacy of end-users, etc. To that end, there has been a movement for developing artificial intelligence (AI) big data analytic tools as they offer various new and tailor-made solutions that are incredibly appropriate for practical buildings’ management. Typically, they can help the operator in (i) analyzing the tons of connected equipment data; and; (ii) making intelligent, efficient, and on-time decisions to improve the buildings’ performance. This paper presents a comprehensive systematic survey on using AI-big data analytics in BAMSs. It covers various AI-based tasks, e.g. load forecasting, water management, indoor environmental quality monitoring, occupancy detection, etc. The first part of this paper adopts a well-designed taxonomy to overview existing frameworks. A comprehensive review is conducted about different aspects, including the learning process, building environment, computing platforms, and application scenario. Moving on, a critical discussion is performed to identify current challenges. The second part aims at providing the reader with insights into the real-world application of AI-big data analytics. Thus, three case studies that demonstrate the use of AI-big data analytics in BAMSs are presented, focusing on energy anomaly detection in residential and office buildings and energy and performance optimization in sports facilities. Lastly, future directions and valuable recommendations are identified to improve the performance and reliability of BAMSs in intelligent buildings.",
    "citationCount": 331,
    "pdf_filename": "2022_AI_big_data_analytics_for_building_autom_f17fabd5.pdf"
  },
  "3a8c344f67d5081ead5f7dd5ebf0f760d69fc01d": {
    "paperId": "3a8c344f67d5081ead5f7dd5ebf0f760d69fc01d",
    "title": "Reporting guideline for the early stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI",
    "year": 2022,
    "authors": "B. Vasey, M. Nagendran, Bruce Campbell, D. Clifton, Gary S. Collins",
    "abstract": "A growing number of artificial intelligence (AI)-based clinical decision support systems are showing promising performance in preclinical, in silico, evaluation, but few have yet demonstrated real benefit to patient care. Early stage clinical evaluation is important to assess an AI system’s actual clinical performance at small scale, ensure its safety, evaluate the human factors surrounding its use, and pave the way to further large scale trials. However, the reporting of these early studies remains inadequate. The present statement provides a multistakeholder, consensus-based reporting guideline for the Developmental and Exploratory Clinical Investigations of DEcision support systems driven by Artificial Intelligence (DECIDE-AI). We conducted a two round, modified Delphi process to collect and analyse expert opinion on the reporting of early clinical evaluation of AI systems. Experts were recruited from 20 predefined stakeholder categories. The final composition and wording of the guideline was determined at a virtual consensus meeting. The checklist and the Explanation & Elaboration (E&E) sections were refined based on feedback from a qualitative evaluation process. 123 experts participated in the first round of Delphi, 138 in the second, 16 in the consensus meeting, and 16 in the qualitative evaluation. The DECIDE-AI reporting guideline comprises 17 AI specific reporting items (made of 28 subitems) and 10 generic reporting items, with an E&E paragraph provided for each. Through consultation and consensus with a range of stakeholders, we have developed a guideline comprising key items that should be reported in early stage clinical studies of AI-based decision support systems in healthcare. By providing an actionable checklist of minimal reporting items, the DECIDE-AI guideline will facilitate the appraisal of these studies and replicability of their findings.",
    "citationCount": 320,
    "pdf_filename": "2022_Reporting_guideline_for_the_early_stage__3a8c344f.pdf"
  },
  "0c6c9c901d9c10639a12067804dc90c282fc0b92": {
    "paperId": "0c6c9c901d9c10639a12067804dc90c282fc0b92",
    "title": "A Survey on the Convergence of Edge Computing and AI for UAVs: Opportunities and Challenges",
    "year": 2022,
    "authors": "P. McEnroe, Shen Wang, Madhusanka Liyanage",
    "abstract": "The latest 5G mobile networks have enabled many exciting Internet of Things (IoT) applications that employ unmanned aerial vehicles (UAVs/drones). The success of most UAV-based IoT applications is heavily dependent on artificial intelligence (AI) technologies, for instance, computer vision and path planning. These AI methods must process data and provide decisions while ensuring low latency and low energy consumption. However, the existing cloud-based AI paradigm finds it difficult to meet these strict UAV requirements. Edge AI, which runs AI on-device or on edge servers close to users, can be suitable for improving UAV-based IoT services. This article provides a comprehensive analysis of the impact of edge AI on key UAV technical aspects (i.e., autonomous navigation, formation control, power management, security and privacy, computer vision, and communication) and applications (i.e., delivery systems, civil infrastructure inspection, precision agriculture, search and rescue (SAR) operations, acting as aerial wireless base stations (BSs), and drone light shows). As guidance for researchers and practitioners, this article also explores UAV-based edge AI implementation challenges, lessons learned, and future research directions.",
    "citationCount": 303,
    "pdf_filename": "2022_A_Survey_on_the_Convergence_of_Edge_Comp_0c6c9c90.pdf"
  },
  "84fae4c57e9f65459cf404866f83ff0b70fd7b75": {
    "paperId": "84fae4c57e9f65459cf404866f83ff0b70fd7b75",
    "title": "PolyGen: An Autoregressive Generative Model of 3D Meshes",
    "year": 2020,
    "authors": "C. Nash, Yaroslav Ganin, A. Eslami, P. Battaglia",
    "abstract": "Polygon meshes are an efficient representation of 3D geometry, and are of central importance in computer graphics, robotics and games development. Existing learning-based approaches have avoided the challenges of working with 3D meshes, instead using alternative object representations that are more compatible with neural architectures and training approaches. We present an approach which models the mesh directly, predicting mesh vertices and faces sequentially using a Transformer-based architecture. Our model can condition on a range of inputs, including object classes, voxels, and images, and because the model is probabilistic it can produce samples that capture uncertainty in ambiguous scenarios. We show that the model is capable of producing high-quality, usable meshes, and establish log-likelihood benchmarks for the mesh-modelling task. We also evaluate the conditional models on surface reconstruction metrics against alternative methods, and demonstrate competitive performance despite not training directly on this task.",
    "citationCount": 304,
    "pdf_filename": "2020_PolyGen__An_Autoregressive_Generative_Mo_84fae4c5.pdf"
  },
  "d6954c43aa1ca197319c45d3988bc8fcec3de976": {
    "paperId": "d6954c43aa1ca197319c45d3988bc8fcec3de976",
    "title": "GitHub Copilot AI pair programmer: Asset or Liability?",
    "year": 2022,
    "authors": "Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh, M. Desmarais",
    "abstract": "Automatic program synthesis is a long-lasting dream in software engineering. Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product. Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively. In this paper, we study the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot's proposed solutions with those of human programmers on a set of programming tasks. For the former, we assess the performance and functionality of Copilot in solving selected fundamental problems in computer science, like sorting and implementing data structures. In the latter, a dataset of programming problems with human-provided solutions is used. The results show that Copilot is capable of providing solutions for almost all fundamental algorithmic problems, however, some solutions are buggy and non-reproducible. Moreover, Copilot has some difficulties in combining multiple methods to generate a solution. Comparing Copilot to humans, our results show that the correct ratio of humans' solutions is greater than Copilot's suggestions, while the buggy solutions generated by Copilot require less effort to be repaired.",
    "citationCount": 429,
    "pdf_filename": "2022_GitHub_Copilot_AI_pair_programmer__Asset_d6954c43.pdf"
  },
  "264b9b136889da3b4d7e50ef58c77678b35dc3e0": {
    "paperId": "264b9b136889da3b4d7e50ef58c77678b35dc3e0",
    "title": "Human-Centered AI",
    "year": 2021,
    "authors": "Hollen Barmer, R. Dzombak, M. Gaston, Vijaykumar Palat, F. Redner",
    "abstract": "We identify three specific areas of focus to advance human-centered AI:• Designers and systems must understand the context of use and sense changes over time: Successful AI Engineering depends on the team’s ability to identify and articulate the desired system outcome and understand human and contextual factors affecting the outcome. The system itself must be able to learn when shifts in context have occurred. What are the best ways to maintain clarity around operational intent and mechanisms for adapting and evolving systems based on dynamic contexts and user needs?• Development of tools, processes, and practices to scope and facilitate human-machine teaming: Implementation of AI systems entails high levels of interdependence between human and machine. Adoption of AI systems requires the primary users to interact with and understand systems, gaining appropriate levels of trust. Every AI system needs to be designed to recognize boundaries and unfamiliar scenarios, and to provide transparency regarding its limitations.• Methods, mechanisms, and mindsets to engage in critical oversight: AI systems learn through data and observations, rather than being explicitly programmed for a deterministic outcome. Critical and reflective oversight by organizations, teams, and individuals that create and use AI systems is needed to uphold ethical principles and proactively consider the risks of bias, misuse, abuse, and unintended consequences through design, development, and ongoing deployment.For each area, we identify ongoing work as well and challenges and opportunities in developing and deploying AI systems with confidence.",
    "citationCount": 375,
    "pdf_filename": "2021_Human_Centered_AI_264b9b13.pdf"
  },
  "c79ba865574cb9635dbca135cec99ee56125778c": {
    "paperId": "c79ba865574cb9635dbca135cec99ee56125778c",
    "title": "Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making",
    "year": 2021,
    "authors": "Xinru Wang, Ming Yin",
    "abstract": "This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy—improve people’s understanding of the AI model, help people recognize the model uncertainty, and support people’s calibrated trust in the model. Through randomized controlled experiments, we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making.",
    "citationCount": 349,
    "pdf_filename": "2021_Are_Explanations_Helpful__A_Comparative__c79ba865.pdf"
  },
  "c8965761083d80ff762ce76c08df92d66e01f37d": {
    "paperId": "c8965761083d80ff762ce76c08df92d66e01f37d",
    "title": "Expanding Explainability: Towards Social Transparency in AI systems",
    "year": 2021,
    "authors": "Upol Ehsan, Q. Liao, Michael J. Muller, Mark O. Riedl, Justin D. Weisz",
    "abstract": "As AI-powered systems increasingly mediate consequential decision-making, their explainability is critical for end-users to take informed and accountable actions. Explanations in human-human interactions are socially-situated. AI systems are often socio-organizationally embedded. However, Explainable AI (XAI) approaches have been predominantly algorithm-centered. We take a developmental step towards socially-situated XAI by introducing and exploring Social Transparency (ST), a sociotechnically informed perspective that incorporates the socio-organizational context into explaining AI-mediated decision-making. To explore ST conceptually, we conducted interviews with 29 AI users and practitioners grounded in a speculative design scenario. We suggested constitutive design elements of ST and developed a conceptual framework to unpack ST’s effect and implications at the technical, decision-making, and organizational level. The framework showcases how ST can potentially calibrate trust in AI, improve decision-making, facilitate organizational collective actions, and cultivate holistic explainability. Our work contributes to the discourse of Human-Centered XAI by expanding the design space of XAI.",
    "citationCount": 470,
    "pdf_filename": "2021_Expanding_Explainability__Towards_Social_c8965761.pdf"
  },
  "70043a0b612b6253b37df7d363b3bf2ec3d581c7": {
    "paperId": "70043a0b612b6253b37df7d363b3bf2ec3d581c7",
    "title": "Trustworthy AI: From Principles to Practices",
    "year": 2021,
    "authors": "Bo Li, Peng Qi, Bo Liu, Shuai Di, Jingen Liu",
    "abstract": "The rapid development of Artificial Intelligence (AI) technology has enabled the deployment of various systems based on it. However, many current AI systems are found vulnerable to imperceptible attacks, biased against underrepresented groups, lacking in user privacy protection. These shortcomings degrade user experience and erode people’s trust in all AI systems. In this review, we provide AI practitioners with a comprehensive guide for building trustworthy AI systems. We first introduce the theoretical framework of important aspects of AI trustworthiness, including robustness, generalization, explainability, transparency, reproducibility, fairness, privacy preservation, and accountability. To unify currently available but fragmented approaches toward trustworthy AI, we organize them in a systematic approach that considers the entire lifecycle of AI systems, ranging from data acquisition to model development, to system development and deployment, finally to continuous monitoring and governance. In this framework, we offer concrete action items for practitioners and societal stakeholders (e.g., researchers, engineers, and regulators) to improve AI trustworthiness. Finally, we identify key opportunities and challenges for the future development of trustworthy AI systems, where we identify the need for a paradigm shift toward comprehensively trustworthy AI systems.",
    "citationCount": 493,
    "pdf_filename": "2021_Trustworthy_AI__From_Principles_to_Pract_70043a0b.pdf"
  },
  "629ae83d63f558e16b530441d765dc822d2949e1": {
    "paperId": "629ae83d63f558e16b530441d765dc822d2949e1",
    "title": "AI and the Everything in the Whole Wide World Benchmark",
    "year": 2021,
    "authors": "Inioluwa Deborah Raji, Emily M. Bender, Amandalynne Paullada, Emily L. Denton, A. Hanna",
    "abstract": "There is a tendency across different subfields in AI to valorize a small collection of influential benchmarks. These benchmarks operate as stand-ins for a range of anointed common problems that are frequently framed as foundational milestones on the path towards flexible and generalizable AI systems. State-of-the-art performance on these benchmarks is widely understood as indicative of progress towards these long-term goals. In this position paper, we explore the limits of such benchmarks in order to reveal the construct validity issues in their framing as the functionally\"general\"broad measures of progress they are set up to be.",
    "citationCount": 386,
    "pdf_filename": "2021_AI_and_the_Everything_in_the_Whole_Wide__629ae83d.pdf"
  },
  "9a1f352ef21044700c180882038c28c3b2361914": {
    "paperId": "9a1f352ef21044700c180882038c28c3b2361914",
    "title": "Data collection and quality challenges in deep learning: a data-centric AI perspective",
    "year": 2021,
    "authors": "Steven Euijong Whang, Yuji Roh, Hwanjun Song, Jae-Gil Lee",
    "abstract": "Data-centric AI is at the center of a fundamental shift in software engineering where machine learning becomes the new software, powered by big data and computing infrastructure. Here, software engineering needs to be re-thought where data become a first-class citizen on par with code. One striking observation is that a significant portion of the machine learning process is spent on data preparation. Without good data, even the best machine learning algorithms cannot perform well. As a result, data-centric AI practices are now becoming mainstream. Unfortunately, many datasets in the real world are small, dirty, biased, and even poisoned. In this survey, we study the research landscape for data collection and data quality primarily for deep learning applications. Data collection is important because there is lesser need for feature engineering for recent deep learning approaches, but instead more need for large amounts of data. For data quality, we study data validation, cleaning, and integration techniques. Even if the data cannot be fully cleaned, we can still cope with imperfect data during model training using robust model training techniques. In addition, while bias and fairness have been less studied in traditional data management research, these issues become essential topics in modern machine learning applications. We thus study fairness measures and unfairness mitigation techniques that can be applied before, during, or after model training. We believe that the data management community is well poised to solve these problems.",
    "citationCount": 440,
    "pdf_filename": "2021_Data_collection_and_quality_challenges_i_9a1f352e.pdf"
  },
  "d3b9a465ded4172e5056939debb4dae674c68af8": {
    "paperId": "d3b9a465ded4172e5056939debb4dae674c68af8",
    "title": "Understanding and Creating Art with AI: Review and Outlook",
    "year": 2021,
    "authors": "E. Cetinic, James She",
    "abstract": "Technologies related to artificial intelligence (AI) have a strong impact on the changes of research and creative practices in visual arts. The growing number of research initiatives and creative applications that emerge in the intersection of AI and art motivates us to examine and discuss the creative and explorative potentials of AI technologies in the context of art. This article provides an integrated review of two facets of AI and art: (1) AI is used for art analysis and employed on digitized artwork collections, or (2) AI is used for creative purposes and generating novel artworks. In the context of AI-related research for art understanding, we present a comprehensive overview of artwork datasets and recent works that address a variety of tasks such as classification, object detection, similarity retrieval, multimodal representations, and computational aesthetics, among others. In relation to the role of AI in creating art, we address various practical and theoretical aspects of AI Art and consolidate related works that deal with those topics in detail. Finally, we provide a concise outlook on the future progression and potential impact of AI technologies on our understanding and creation of art.",
    "citationCount": 397,
    "pdf_filename": "2021_Understanding_and_Creating_Art_with_AI___d3b9a465.pdf"
  },
  "9c404d02aefd850ac3d5a8bdc5860738e6cd2b04": {
    "paperId": "9c404d02aefd850ac3d5a8bdc5860738e6cd2b04",
    "title": "A Survey of Embodied AI: From Simulators to Research Tasks",
    "year": 2021,
    "authors": "Jiafei Duan, Samson Yu, Tangyao Li, Huaiyu Zhu, Cheston Tan",
    "abstract": "There has been an emerging paradigm shift from the era of “internet AI” to “embodied AI,” where AI algorithms and agents no longer learn from datasets of images, videos or text curated primarily from the internet. Instead, they learn through interactions with their environments from an egocentric perception similar to humans. Consequently, there has been substantial growth in the demand for embodied AI simulators to support various embodied AI research tasks. This growing interest in embodied AI is beneficial to the greater pursuit of Artificial General Intelligence (AGI), but there has not been a contemporary and comprehensive survey of this field. This paper aims to provide an encyclopedic survey for the field of embodied AI, from its simulators to its research. By evaluating nine current embodied AI simulators with our proposed seven features, this paper aims to understand the simulators in their provision for use in embodied AI research and their limitations. Lastly, this paper surveys the three main research tasks in embodied AI – visual exploration, visual navigation and embodied question answering (QA), covering the state-of-the-art approaches, evaluation metrics and datasets. Finally, with the new insights revealed through surveying the field, the paper will provide suggestions for simulator-for-task selections and recommendations for the future directions of the field.",
    "citationCount": 399,
    "pdf_filename": "2021_A_Survey_of_Embodied_AI__From_Simulators_9c404d02.pdf"
  },
  "cc1697038a9fcca37977b3b0e1bd9d434d3d9a3e": {
    "paperId": "cc1697038a9fcca37977b3b0e1bd9d434d3d9a3e",
    "title": "AI-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions",
    "year": 2021,
    "authors": "Iqbal H. Sarker, Md. Hasan Furhad, Raza Nowrozy",
    "abstract": "Artificial intelligence (AI) is one of the key technologies of the Fourth Industrial Revolution (or Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular AI techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these AI methods, in this paper, we present a comprehensive view on “AI-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such AI methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or AI-based technical point of view.",
    "citationCount": 365,
    "pdf_filename": "2021_AI_Driven_Cybersecurity__An_Overview__Se_cc169703.pdf"
  },
  "cbfbe5ca594755b562539022b0d7fd49dc1299a1": {
    "paperId": "cbfbe5ca594755b562539022b0d7fd49dc1299a1",
    "title": "Who is afraid of black box algorithms? On the epistemological and ethical basis of trust in medical AI",
    "year": 2021,
    "authors": "J. M. Durán, K. Jongsma",
    "abstract": "The use of black box algorithms in medicine has raised scholarly concerns due to their opaqueness and lack of trustworthiness. Concerns about potential bias, accountability and responsibility, patient autonomy and compromised trust transpire with black box algorithms. These worries connect epistemic concerns with normative issues. In this paper, we outline that black box algorithms are less problematic for epistemic reasons than many scholars seem to believe. By outlining that more transparency in algorithms is not always necessary, and by explaining that computational processes are indeed methodologically opaque to humans, we argue that the reliability of algorithms provides reasons for trusting the outcomes of medical artificial intelligence (AI). To this end, we explain how computational reliabilism, which does not require transparency and supports the reliability of algorithms, justifies the belief that results of medical AI are to be trusted. We also argue that several ethical concerns remain with black box algorithms, even when the results are trustworthy. Having justified knowledge from reliable indicators is, therefore, necessary but not sufficient for normatively justifying physicians to act. This means that deliberation about the results of reliable algorithms is required to find out what is a desirable action. Thus understood, we argue that such challenges should not dismiss the use of black box algorithms altogether but should inform the way in which these algorithms are designed and implemented. When physicians are trained to acquire the necessary skills and expertise, and collaborate with medical informatics and data scientists, black box algorithms can contribute to improving medical care.",
    "citationCount": 363,
    "pdf_filename": "2021_Who_is_afraid_of_black_box_algorithms__O_cbfbe5ca.pdf"
  },
  "10154f7763e08e29eea6310820fb110179b0f366": {
    "paperId": "10154f7763e08e29eea6310820fb110179b0f366",
    "title": "Disparities in dermatology AI performance on a diverse, curated clinical image set",
    "year": 2021,
    "authors": "R. Daneshjou, Kailas Vodrahalli, Weixin Liang, R. Novoa, Melissa Jenkins",
    "abstract": "An estimated 3 billion people lack access to dermatological care globally. Artificial intelligence (AI) may aid in triaging skin diseases and identifying malignancies. However, most AI models have not been assessed on images of diverse skin tones or uncommon diseases. Thus, we created the Diverse Dermatology Images (DDI) dataset—the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. We show that state-of-the-art dermatology AI models exhibit substantial limitations on the DDI dataset, particularly on dark skin tones and uncommon diseases. We find that dermatologists, who often label AI datasets, also perform worse on images of dark skin tones and uncommon diseases. Fine-tuning AI models on the DDI images closes the performance gap between light and dark skin tones. These findings identify important weaknesses and biases in dermatology AI that should be addressed for reliable application to diverse patients and diseases.",
    "citationCount": 323,
    "pdf_filename": "2021_Disparities_in_dermatology_AI_performanc_10154f77.pdf"
  },
  "8ee8d51b5c29f6aadd0b6dcff2a475373a3a021b": {
    "paperId": "8ee8d51b5c29f6aadd0b6dcff2a475373a3a021b",
    "title": "The Role of AI, Machine Learning, and Big Data in Digital Twinning: A Systematic Literature Review, Challenges, and Opportunities",
    "year": 2021,
    "authors": "M. M. Rathore, Syed Attique Shah, Dhirendra Shukla, Elmahdi Bentafat, S. Bakiras",
    "abstract": "Digital twinning is one of the top ten technology trends in the last couple of years, due to its high applicability in the industrial sector. The integration of big data analytics and artificial intelligence/machine learning (AI-ML) techniques with digital twinning, further enriches its significance and research potential with new opportunities and unique challenges. To date, a number of scientific models have been designed and implemented related to this evolving topic. However, there is no systematic review of digital twinning, particularly focusing on the role of AI-ML and big data, to guide the academia and industry towards future developments. Therefore, this article emphasizes the role of big data and AI-ML in the creation of digital twins (DTs) or DT-based systems for various industrial applications, by highlighting the current state-of-the-art deployments. We performed a systematic review on top of multidisciplinary electronic bibliographic databases, in addition to existing patents in the field. Also, we identified development-tools that can facilitate various levels of the digital twinning. Further, we designed a big data driven and AI-enriched reference architecture that leads developers to a complete DT-enabled system. Finally, we highlighted the research potential of AI-ML for digital twinning by unveiling challenges and current opportunities.",
    "citationCount": 346,
    "pdf_filename": "2021_The_Role_of_AI__Machine_Learning__and_Bi_8ee8d51b.pdf"
  },
  "6a85586fb2c87f303f2da32ba5f1863db2a31072": {
    "paperId": "6a85586fb2c87f303f2da32ba5f1863db2a31072",
    "title": "AI in Finance: Challenges, Techniques, and Opportunities",
    "year": 2021,
    "authors": "Longbing Cao",
    "abstract": "AI in finance refers to the applications of AI techniques in financial businesses. This area has attracted attention for decades, with both classic and modern AI techniques applied to increasingly broader areas of finance, economy, and society. In contrast to reviews on discussing the problems, aspects, and opportunities of finance benefited from specific or some new-generation AI and data science (AIDS) techniques or the progress of applying specific techniques to resolving certain financial problems, this review offers a comprehensive and dense landscape of the overwhelming challenges, techniques, and opportunities of AIDS research in finance over the past decades. The challenges of financial businesses and data are first outlined, followed by a comprehensive categorization and a dense overview of the decades of AIDS research in finance. We then structure and illustrate the data-driven analytics and learning of financial businesses and data. A comparison, criticism, and discussion of classic versus modern AIDS techniques for finance follows. Finally, the open issues and opportunities to address future AIDS-empowered finance and finance-motivated AIDS research are discussed.",
    "citationCount": 332,
    "pdf_filename": "2021_AI_in_Finance__Challenges__Techniques__a_6a85586f.pdf"
  },
  "43dd4b095a267ed20251a40bceca1e447458016c": {
    "paperId": "43dd4b095a267ed20251a40bceca1e447458016c",
    "title": "Do as AI say: susceptibility in deployment of clinical decision-aids",
    "year": 2021,
    "authors": "S. Gaube, Harini Suresh, M. Raue, Alexander Merritt, S. Berkowitz",
    "abstract": "Artificial intelligence (AI) models for decision support have been developed for clinical settings such as radiology, but little work evaluates the potential impact of such systems. In this study, physicians received chest X-rays and diagnostic advice, some of which was inaccurate, and were asked to evaluate advice quality and make diagnoses. All advice was generated by human experts, but some was labeled as coming from an AI system. As a group, radiologists rated advice as lower quality when it appeared to come from an AI system; physicians with less task-expertise did not. Diagnostic accuracy was significantly worse when participants received inaccurate advice, regardless of the purported source. This work raises important considerations for how advice, AI and non-AI, should be deployed in clinical environments.",
    "citationCount": 336,
    "pdf_filename": "2021_Do_as_AI_say__susceptibility_in_deployme_43dd4b09.pdf"
  },
  "c0cd4b4844c31a27a7900a754d0a91b160b00e55": {
    "paperId": "c0cd4b4844c31a27a7900a754d0a91b160b00e55",
    "title": "Advancing mathematics by guiding human intuition with AI",
    "year": 2021,
    "authors": "A. Davies, Petar Velickovic, Lars Buesing, Sam Blackwell, Daniel Zheng",
    "abstract": "The practice of mathematics involves discovering patterns and using these to formulate and prove conjectures, resulting in theorems. Since the 1960s, mathematicians have used computers to assist in the discovery of patterns and formulation of conjectures1, most famously in the Birch and Swinnerton-Dyer conjecture2, a Millennium Prize Problem3. Here we provide examples of new fundamental results in pure mathematics that have been discovered with the assistance of machine learning—demonstrating a method by which machine learning can aid mathematicians in discovering new conjectures and theorems. We propose a process of using machine learning to discover potential patterns and relations between mathematical objects, understanding them with attribution techniques and using these observations to guide intuition and propose conjectures. We outline this machine-learning-guided framework and demonstrate its successful application to current research questions in distinct areas of pure mathematics, in each case showing how it led to meaningful mathematical contributions on important open problems: a new connection between the algebraic and geometric structure of knots, and a candidate algorithm predicted by the combinatorial invariance conjecture for symmetric groups4. Our work may serve as a model for collaboration between the fields of mathematics and artificial intelligence (AI) that can achieve surprising results by leveraging the respective strengths of mathematicians and machine learning. A framework through which machine learning can guide mathematicians in discovering new conjectures and theorems is presented and shown to yield mathematical insight on important open problems in different areas of pure mathematics.",
    "citationCount": 499,
    "pdf_filename": "2021_Advancing_mathematics_by_guiding_human_i_c0cd4b48.pdf"
  },
  "58bb221c1e375f254826b7b7341f74057e87676c": {
    "paperId": "58bb221c1e375f254826b7b7341f74057e87676c",
    "title": "Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI",
    "year": 2020,
    "authors": "Michael A. Madaio, Luke Stark, Jennifer Wortman Vaughan, Hanna M. Wallach",
    "abstract": "Many organizations have published principles intended to guide the ethical development and deployment of AI systems; however, their abstract nature makes them difficult to operationalize. Some organizations have therefore produced AI ethics checklists, as well as checklists for more specific concepts, such as fairness, as applied to AI systems. But unless checklists are grounded in practitioners' needs, they may be misused. To understand the role of checklists in AI ethics, we conducted an iterative co-design process with 48 practitioners, focusing on fairness. We co-designed an AI fairness checklist and identified desiderata and concerns for AI fairness checklists in general. We found that AI fairness checklists could provide organizational infrastructure for formalizing ad-hoc processes and empowering individual advocates. We highlight aspects of organizational culture that may impact the efficacy of AI fairness checklists, and suggest future design directions.",
    "citationCount": 447,
    "pdf_filename": "2020_Co_Designing_Checklists_to_Understand_Or_58bb221c.pdf"
  },
  "d3e8b100038c2bf3983ffae96a56c6af0793a62f": {
    "paperId": "d3e8b100038c2bf3983ffae96a56c6af0793a62f",
    "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence",
    "year": 2020,
    "authors": "Shakir Mohamed, Marie-Therese Png, William S. Isaac",
    "abstract": "This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. While the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us, ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all.",
    "citationCount": 489,
    "pdf_filename": "2020_Decolonial_AI__Decolonial_Theory_as_Soci_d3e8b100.pdf"
  },
  "8ee7ba1cc742cb5bfdeeabebcaa913e57a8ec42c": {
    "paperId": "8ee7ba1cc742cb5bfdeeabebcaa913e57a8ec42c",
    "title": "AI enabled sign language recognition and VR space bidirectional communication using triboelectric smart glove",
    "year": 2021,
    "authors": "Feng Wen, Zixuan Zhang, Tianyiyi He, Chengkuo Lee",
    "abstract": "Sign language recognition, especially the sentence recognition, is of great significance for lowering the communication barrier between the hearing/speech impaired and the non-signers. The general glove solutions, which are employed to detect motions of our dexterous hands, only achieve recognizing discrete single gestures (i.e., numbers, letters, or words) instead of sentences, far from satisfying the meet of the signers’ daily communication. Here, we propose an artificial intelligence enabled sign language recognition and communication system comprising sensing gloves, deep learning block, and virtual reality interface. Non-segmentation and segmentation assisted deep learning model achieves the recognition of 50 words and 20 sentences. Significantly, the segmentation approach splits entire sentence signals into word units. Then the deep learning model recognizes all word elements and reversely reconstructs and recognizes sentences. Furthermore, new/never-seen sentences created by new-order word elements recombination can be recognized with an average correct rate of 86.67%. Finally, the sign language recognition results are projected into virtual space and translated into text and audio, allowing the remote and bidirectional communication between signers and non-signers. Though wearable gloves are widely used for gesture associated applications (e.g. sign language recognition), sentence identification of sign language remains a challenge. Here, the authors report AI-enabled recognition system helps barrier-free communication between signers and non-signers.",
    "citationCount": 383,
    "pdf_filename": "2021_AI_enabled_sign_language_recognition_and_8ee7ba1c.pdf"
  },
  "f3d3bed63fb51315e2726837363ab3c9e89769eb": {
    "paperId": "f3d3bed63fb51315e2726837363ab3c9e89769eb",
    "title": "SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis",
    "year": 2020,
    "authors": "E. Cambria, Yang Li, Frank Xing, Soujanya Poria, Kenneth Kwok",
    "abstract": "Deep learning has unlocked new paths towards the emulation of the peculiarly-human capability of learning from examples. While this kind of bottom-up learning works well for tasks such as image classification or object detection, it is not as effective when it comes to natural language processing. Communication is much more than learning a sequence of letters and words: it requires a basic understanding of the world and social norms, cultural awareness, commonsense knowledge, etc.; all things that we mostly learn in a top-down manner. In this work, we integrate top-down and bottom-up learning via an ensemble of symbolic and subsymbolic AI tools, which we apply to the interesting problem of polarity detection from text. In particular, we integrate logical reasoning within deep learning architectures to build a new version of SenticNet, a commonsense knowledge base for sentiment analysis.",
    "citationCount": 441,
    "pdf_filename": "2020_SenticNet_6__Ensemble_Application_of_Sym_f3d3bed6.pdf"
  },
  "97d69e7e8c04714bf58dcbe5ae7454db69b657a7": {
    "paperId": "97d69e7e8c04714bf58dcbe5ae7454db69b657a7",
    "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence",
    "year": 2020,
    "authors": "G. Marcus",
    "abstract": "Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust AI than is currently possible.",
    "citationCount": 422,
    "pdf_filename": "2020_The_Next_Decade_in_AI__Four_Steps_Toward_97d69e7e.pdf"
  },
  "829e36b23f7b42e109f84b5b761052498b291962": {
    "paperId": "829e36b23f7b42e109f84b5b761052498b291962",
    "title": "A Survey of the State of Explainable AI for Natural Language Processing",
    "year": 2020,
    "authors": "Marina Danilevsky, Kun Qian, R. Aharonov, Yannis Katsis, B. Kawas",
    "abstract": "Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.",
    "citationCount": 426,
    "pdf_filename": "2020_A_Survey_of_the_State_of_Explainable_AI__829e36b2.pdf"
  },
  "b6328d4664aed6b5d7e824f1867b653069d6f252": {
    "paperId": "b6328d4664aed6b5d7e824f1867b653069d6f252",
    "title": "In AI We Trust: Ethics, Artificial Intelligence, and Reliability",
    "year": 2020,
    "authors": "M. Ryan",
    "abstract": "One of the main difficulties in assessing artificial intelligence (AI) is the tendency for people to anthropomorphise it. This becomes particularly problematic when we attach human moral activities to AI. For example, the European Commission’s High-level Expert Group on AI (HLEG) have adopted the position that we should establish a relationship of trust with AI and should cultivate trustworthy AI (HLEG AI Ethics guidelines for trustworthy AI, 2019, p. 35). Trust is one of the most important and defining activities in human relationships, so proposing that AI should be trusted, is a very serious claim. This paper will show that AI cannot be something that has the capacity to be trusted according to the most prevalent definitions of trust because it does not possess emotive states or can be held responsible for their actions—requirements of the affective and normative accounts of trust. While AI meets all of the requirements of the rational account of trust, it will be shown that this is not actually a type of trust at all, but is instead, a form of reliance. Ultimately, even complex machines such as AI should not be viewed as trustworthy as this undermines the value of interpersonal trust, anthropomorphises AI, and diverts responsibility from those developing and using them.",
    "citationCount": 400,
    "pdf_filename": "2020_In_AI_We_Trust__Ethics__Artificial_Intel_b6328d46.pdf"
  },
  "0efdc031c42c031f3092f3a4f85ae2e0a6c9cac4": {
    "paperId": "0efdc031c42c031f3092f3a4f85ae2e0a6c9cac4",
    "title": "AI-Mediated Communication: Definition, Research Agenda, and Ethical Considerations",
    "year": 2020,
    "authors": "Jeffrey T. Hancock, Mor Naaman, K. Levy",
    "abstract": "\n We define Artificial Intelligence-Mediated Communication (AI-MC) as interpersonal communication in which an intelligent agent operates on behalf of a communicator by modifying, augmenting, or generating messages to accomplish communication goals. The recent advent of AI-MC raises new questions about how technology may shape human communication and requires re-evaluation – and potentially expansion – of many of Computer-Mediated Communication’s (CMC) key theories, frameworks, and findings. A research agenda around AI-MC should consider the design of these technologies and the psychological, linguistic, relational, policy and ethical implications of introducing AI into human–human communication. This article aims to articulate such an agenda.",
    "citationCount": 391,
    "pdf_filename": "2020_AI_Mediated_Communication__Definition__R_0efdc031.pdf"
  },
  "62c3142956d54db158d190ce691e3c13e7897412": {
    "paperId": "62c3142956d54db158d190ce691e3c13e7897412",
    "title": "Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims",
    "year": 2020,
    "authors": "Miles Brundage, S. Avin, Jasmine Wang, Haydn Belfield, Gretchen Krueger",
    "abstract": "With the recent wave of progress in artificial intelligence (AI) has come a growing awareness of the large-scale impacts of AI systems, and recognition that existing regulations and norms in industry and academia are insufficient to ensure responsible AI development. In order for AI developers to earn trust from system users, customers, civil society, governments, and other stakeholders that they are building AI responsibly, they will need to make verifiable claims to which they can be held accountable. Those outside of a given organization also need effective means of scrutinizing such claims. This report suggests various steps that different stakeholders can take to improve the verifiability of claims made about AI systems and their associated development processes, with a focus on providing evidence about the safety, security, fairness, and privacy protection of AI systems. We analyze ten mechanisms for this purpose--spanning institutions, software, and hardware--and make recommendations aimed at implementing, exploring, or improving those mechanisms.",
    "citationCount": 409,
    "pdf_filename": "2020_Toward_Trustworthy_AI_Development__Mecha_62c31429.pdf"
  },
  "47f7e6326f7ee042966130f673743abbb99b8a7f": {
    "paperId": "47f7e6326f7ee042966130f673743abbb99b8a7f",
    "title": "AI in Medical Imaging Informatics: Current Challenges and Future Directions",
    "year": 2020,
    "authors": "A. Panayides, A. Amini, N. Filipovic, Ashish Sharma, S. Tsaftaris",
    "abstract": "This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.",
    "citationCount": 431,
    "pdf_filename": "2020_AI_in_Medical_Imaging_Informatics__Curre_47f7e632.pdf"
  },
  "47a8355e76c3675c481f135cce3a5911c74aeac3": {
    "paperId": "47a8355e76c3675c481f135cce3a5911c74aeac3",
    "title": "Communication-Efficient Edge AI: Algorithms and Systems",
    "year": 2020,
    "authors": "Yuanming Shi, Kai Yang, Tao Jiang, Jun Zhang, K. Letaief",
    "abstract": "Artificial intelligence (AI) has achieved remarkable breakthroughs in a wide range of fields, ranging from speech processing, image classification to drug discovery. This is driven by the explosive growth of data, advances in machine learning (especially deep learning), and the easy access to powerful computing resources. Particularly, the wide scale deployment of edge devices (e.g., IoT devices) generates an unprecedented scale of data, which provides the opportunity to derive accurate models and develop various intelligent applications at the network edge. However, such enormous data cannot all be sent to the cloud for processing, due to the varying channel quality, traffic congestion and/or privacy concerns, and the enormous energy consumption. By pushing inference and training processes of AI models to edge nodes, edge AI has emerged as a promising alternative. AI at the edge requires close cooperation among edge devices, such as smart phones and smart vehicles, and edge servers at the wireless access points and base stations, which however result in heavy communication overheads. In this paper, we present a comprehensive survey of the recent developments in various techniques for overcoming these communication challenges. Specifically, we first identify key communication challenges in edge AI systems. We then introduce communication-efficient techniques, from both algorithmic and system perspectives for training and inference tasks at the network edge. Potential future research directions are also highlighted.",
    "citationCount": 383,
    "pdf_filename": "2020_Communication_Efficient_Edge_AI__Algorit_47a8355e.pdf"
  },
  "d5901f15a0214b50e6a0085337e49a9b966775a7": {
    "paperId": "d5901f15a0214b50e6a0085337e49a9b966775a7",
    "title": "Neurosymbolic AI: the 3rd wave",
    "year": 2020,
    "authors": "A. Garcez, L. Lamb",
    "abstract": "Current advances in Artificial Intelligence (AI) and Machine Learning have achieved unprecedented impact across research communities and industry. Nevertheless, concerns around trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neurosymbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability by offering symbolic representations for neural models. In this paper, we relate recent and early research in neurosymbolic AI with the objective of identifying the most important ingredients of neurosymbolic AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. Finally, this review identifies promising directions and challenges for the next decade of AI research from the perspective of neurosymbolic computing, commonsense reasoning and causal explanation.",
    "citationCount": 388,
    "pdf_filename": "2020_Neurosymbolic_AI__the_3rd_wave_d5901f15.pdf"
  },
  "9517f4d78929978050fd5c2a3c10e9178c3db7a8": {
    "paperId": "9517f4d78929978050fd5c2a3c10e9178c3db7a8",
    "title": "Molecular representations in AI-driven drug discovery: a review and practical guide",
    "year": 2020,
    "authors": "Laurianne David, Amol Thakkar, Rocío Mercado, O. Engkvist",
    "abstract": "The technological advances of the past century, marked by the computer revolution and the advent of high-throughput screening technologies in drug discovery, opened the path to the computational analysis and visualization of bioactive molecules. For this purpose, it became necessary to represent molecules in a syntax that would be readable by computers and understandable by scientists of various fields. A large number of chemical representations have been developed over the years, their numerosity being due to the fast development of computers and the complexity of producing a representation that encompasses all structural and chemical characteristics. We present here some of the most popular electronic molecular and macromolecular representations used in drug discovery, many of which are based on graph representations. Furthermore, we describe applications of these representations in AI-driven drug discovery. Our aim is to provide a brief guide on structural representations that are essential to the practice of AI in drug discovery. This review serves as a guide for researchers who have little experience with the handling of chemical representations and plan to work on applications at the interface of these fields.",
    "citationCount": 407,
    "pdf_filename": "2020_Molecular_representations_in_AI_driven_d_9517f4d7.pdf"
  },
  "c463e0a0b9a4c53ad6a90d5254bb9bc03de14033": {
    "paperId": "c463e0a0b9a4c53ad6a90d5254bb9bc03de14033",
    "title": "Emerging challenges in AI and the need for AI ethics education",
    "year": 2020,
    "authors": "J. Borenstein, A. Howard",
    "abstract": "Artificial Intelligence (AI) is reshaping the world in profound ways; some of its impacts are certainly beneficial but widespread and lasting harms can result from the technology as well. The integration of AI into various aspects of human life is underway, and the complex ethical concerns emerging from the design, deployment, and use of the technology serves as a reminder that it is time to revisit what future developers and designers, along with professionals, are learning when it comes to AI. It is of paramount importance to train future members of the AI community, and other stakeholders as well, to reflect on the ways in which AI might impact people’s lives and to embrace their responsibilities to enhance its benefits while mitigating its potential harms. This could occur in part through the fuller and more systematic inclusion of AI ethics into the curriculum. In this paper, we briefly describe different approaches to AI ethics and offer a set of recommendations related to AI ethics pedagogy.",
    "citationCount": 360,
    "pdf_filename": "2020_Emerging_challenges_in_AI_and_the_need_f_c463e0a0.pdf"
  },
  "b4c77c51c576b84035192f20a9af3063dcc6d946": {
    "paperId": "b4c77c51c576b84035192f20a9af3063dcc6d946",
    "title": "Ready or Not, AI Comes— An Interview Study of Organizational AI Readiness Factors",
    "year": 2020,
    "authors": "Jan Jöhnk, Malte Weißert, K. Wyrtki",
    "abstract": "Artificial intelligence (AI) offers organizations much potential. Considering the manifold application areas, AI’s inherent complexity, and new organizational necessities, companies encounter pitfalls when adopting AI. An informed decision regarding an organization’s readiness increases the probability of successful AI adoption and is important to successfully leverage AI’s business value. Thus, companies need to assess whether their assets, capabilities, and commitment are ready for the individual AI adoption purpose. Research on AI readiness and AI adoption is still in its infancy. Consequently, researchers and practitioners lack guidance on the adoption of AI. The paper presents five categories of AI readiness factors and their illustrative actionable indicators. The AI readiness factors are deduced from an in-depth interview study with 25 AI experts and triangulated with both scientific and practitioner literature. Thus, the paper provides a sound set of organizational AI readiness factors, derives corresponding indicators for AI readiness assessments, and discusses the general implications for AI adoption. This is a first step toward conceptualizing relevant organizational AI readiness factors and guiding purposeful decisions in the entire AI adoption process for both research and practice.",
    "citationCount": 341,
    "pdf_filename": "2020_Ready_or_Not__AI_Comes__An_Interview_Stu_b4c77c51.pdf"
  },
  "ff01b2693fbd604e435d63e70a45bf321b4a8f1d": {
    "paperId": "ff01b2693fbd604e435d63e70a45bf321b4a8f1d",
    "title": "Why Fairness Cannot Be Automated: Bridging the Gap Between EU Non-Discrimination Law and AI",
    "year": 2020,
    "authors": "Sandra Wachter, B. Mittelstadt, Chris Russell",
    "abstract": "In recent years a substantial literature has emerged concerning bias, discrimination, and fairness in AI and machine learning. Connecting this work to existing legal non-discrimination frameworks is essential to create tools and methods that are practically useful across divergent legal regimes. While much work has been undertaken from an American legal perspective, comparatively little has mapped the effects and requirements of EU law. This Article addresses this critical gap between legal, technical, and organisational notions of algorithmic fairness. Through analysis of EU non-discrimination law and jurisprudence of the European Court of Justice (ECJ) and national courts, we identify a critical incompatibility between European notions of discrimination and existing work on algorithmic and automat-ed fairness. A clear gap exists between statistical measures of fairness as embedded in myriad fairness toolkits and governance mechanisms and the context-sensitive, often intuitive and ambiguous discrimination metrics and evidential requirements used by the ECJ; we refer to this approach as “contextual equality.”This Article makes three contributions. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU’s current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Many of the concepts fundamental to bringing a claim, such as the composition of the disadvantaged and advantaged group, the severity and type of harm suffered, and requirements for the relevance and admissibility of evidence, require normative or political choices to be made by the judiciary on a case-by-case basis. We show that automating fairness or non-discrimination in Europe may be impossible because the law, by design, does not provide a static or homogenous framework suited to testing for discrimination in AI systems.Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Equivalent signalling mechanisms and agency do not exist in algorithmic systems. Compared to traditional forms of discrimination, automated discrimination is more abstract and unintuitive, subtle, intangible, and difficult to detect. The increasing use of algorithms disrupts traditional legal remedies and procedures for detection, investigation, prevention, and correction of discrimination which have predominantly relied upon intuition. Consistent assessment procedures that define a common standard for statistical evidence to detect and assess prima facie automated discrimination are urgently needed to support judges, regulators, system controllers and developers, and claimants.Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. A ‘gold standard’ for assessment of prima facie discrimination has been advanced by the European Court of Justice but not yet translated into standard assessment procedures for automated discrimination. We propose ‘conditional demographic disparity’ (CDD) as a standard baseline statistical measurement that aligns with the Court’s ‘gold standard’. Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of auto-mated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law.",
    "citationCount": 335,
    "pdf_filename": "2020_Why_Fairness_Cannot_Be_Automated__Bridgi_ff01b269.pdf"
  },
  "4cf99ce2fd012f494399f028f763422b8ad97a91": {
    "paperId": "4cf99ce2fd012f494399f028f763422b8ad97a91",
    "title": "Contributions and Risks of Artificial Intelligence (AI) in Building Smarter Cities: Insights from a Systematic Review of the Literature",
    "year": 2020,
    "authors": "Tan Yigitcanlar, K. Desouza, Luke Butler, Farnoosh Roozkhosh",
    "abstract": "Artificial intelligence (AI) is one of the most disruptive technologies of our time. Interest in the use of AI for urban innovation continues to grow. Particularly, the rise of smart cities—urban locations that are enabled by community, technology, and policy to deliver productivity, innovation, livability, wellbeing, sustainability, accessibility, good governance, and good planning—has increased the demand for AI-enabled innovations. There is, nevertheless, no scholarly work that provides a comprehensive review on the topic. This paper generates insights into how AI can contribute to the development of smarter cities. A systematic review of the literature is selected as the methodologic approach. Results are categorized under the main smart city development dimensions, i.e., economy, society, environment, and governance. The findings of the systematic review containing 93 articles disclose that: (a) AI in the context of smart cities is an emerging field of research and practice. (b) The central focus of the literature is on AI technologies, algorithms, and their current and prospective applications. (c) AI applications in the context of smart cities mainly concentrate on business efficiency, data analytics, education, energy, environmental sustainability, health, land use, security, transport, and urban management areas. (d) There is limited scholarly research investigating the risks of wider AI utilization. (e) Upcoming disruptions of AI in cities and societies have not been adequately examined. Current and potential contributions of AI to the development of smarter cities are outlined in this paper to inform scholars of prospective areas for further research.",
    "citationCount": 366,
    "pdf_filename": "2020_Contributions_and_Risks_of_Artificial_In_4cf99ce2.pdf"
  },
  "3157ccb0c9812a6ee22a6c5c4cebfae3be42b148": {
    "paperId": "3157ccb0c9812a6ee22a6c5c4cebfae3be42b148",
    "title": "Use of AI-based tools for healthcare purposes: a survey study from consumers’ perspectives",
    "year": 2020,
    "authors": "Pouyan Esmaeilzadeh",
    "abstract": "Background Several studies highlight the effects of artificial intelligence (AI) systems on healthcare delivery. AI-based tools may improve prognosis, diagnostics, and care planning. It is believed that AI will be an integral part of healthcare services in the near future and will be incorporated into several aspects of clinical care. Thus, many technology companies and governmental projects have invested in producing AI-based clinical tools and medical applications. Patients can be one of the most important beneficiaries and users of AI-based applications whose perceptions may affect the widespread use of AI-based tools. Patients should be ensured that they will not be harmed by AI-based devices, and instead, they will be benefited by using AI technology for healthcare purposes. Although AI can enhance healthcare outcomes, possible dimensions of concerns and risks should be addressed before its integration with routine clinical care. Methods We develop a model mainly based on value perceptions due to the specificity of the healthcare field. This study aims at examining the perceived benefits and risks of AI medical devices with clinical decision support (CDS) features from consumers’ perspectives. We use an online survey to collect data from 307 individuals in the United States. Results The proposed model identifies the sources of motivation and pressure for patients in the development of AI-based devices. The results show that technological, ethical (trust factors), and regulatory concerns significantly contribute to the perceived risks of using AI applications in healthcare. Of the three categories, technological concerns (i.e., performance and communication feature) are found to be the most significant predictors of risk beliefs. Conclusions This study sheds more light on factors affecting perceived risks and proposes some recommendations on how to practically reduce these concerns. The findings of this study provide implications for research and practice in the area of AI-based CDS. Regulatory agencies, in cooperation with healthcare institutions, should establish normative standard and evaluation guidelines for the implementation and use of AI in healthcare. Regular audits and ongoing monitoring and reporting systems can be used to continuously evaluate the safety, quality, transparency, and ethical factors of AI-based services.",
    "citationCount": 332,
    "pdf_filename": "2020_Use_of_AI_based_tools_for_healthcare_pur_3157ccb0.pdf"
  },
  "4244da5fc9b7e57ae7bb0c1b4c08c662af595a23": {
    "paperId": "4244da5fc9b7e57ae7bb0c1b4c08c662af595a23",
    "title": "Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems",
    "year": 2020,
    "authors": "Zana Buçinca, Phoebe Lin, Krzysztof Z Gajos, Elena L. Glassman",
    "abstract": "Explainable artificially intelligent (XAI) systems form part of sociotechnical systems, e.g., human+AI teams tasked with making decisions. Yet, current XAI systems are rarely evaluated by measuring the performance of human+AI teams on actual decision-making tasks. We conducted two online experiments and one in-person think-aloud study to evaluate two currently common techniques for evaluating XAI systems: (1) using proxy, artificial tasks such as how well humans predict the AI's decision from the given explanations, and (2) using subjective measures of trust and preference as predictors of actual performance. The results of our experiments demonstrate that evaluations with proxy tasks did not predict the results of the evaluations with the actual decision-making tasks. Further, the subjective measures on evaluations with actual decision-making tasks did not predict the objective performance on those same tasks. Our results suggest that by employing misleading evaluation methods, our field may be inadvertently slowing its progress toward developing human+AI teams that can reliably perform better than humans or AIs alone.",
    "citationCount": 314,
    "pdf_filename": "2020_Proxy_tasks_and_subjective_measures_can__4244da5f.pdf"
  },
  "73a6e1234a3a38bef93f9097d59f01d5032cbc92": {
    "paperId": "73a6e1234a3a38bef93f9097d59f01d5032cbc92",
    "title": "Artificial Intelligence (AI) and Big Data for Coronavirus (COVID-19) Pandemic: A Survey on the State-of-the-Arts",
    "year": 2020,
    "authors": "Viet Quoc Pham, Dinh C. Nguyen, Thien Huynh-The, W. Hwang, P. Pathirana",
    "abstract": "The very first infected novel coronavirus case (COVID-19) was found in Hubei, China in Dec. 2019. The COVID-19 pandemic has spread over 214 countries and areas in the world, and has significantly affected every aspect of our daily lives. At the time of writing this article, the numbers of infected cases and deaths still increase significantly and have no sign of a well-controlled situation, e.g., as of 13 July 2020, from a total number of around 13.1 million positive cases, 571,527 deaths were reported in the world. Motivated by recent advances and applications of artificial intelligence (AI) and big data in various areas, this paper aims at emphasizing their importance in responding to the COVID-19 outbreak and preventing the severe effects of the COVID-19 pandemic. We firstly present an overview of AI and big data, then identify the applications aimed at fighting against COVID-19, next highlight challenges and issues associated with state-of-the-art solutions, and finally come up with recommendations for the communications to effectively control the COVID-19 situation. It is expected that this paper provides researchers and communities with new insights into the ways AI and big data improve the COVID-19 situation, and drives further studies in stopping the COVID-19 outbreak.",
    "citationCount": 317,
    "pdf_filename": "2020_Artificial_Intelligence__AI__and_Big_Dat_73a6e123.pdf"
  },
  "de5d889a2aca12aafd71bdeac5c6a3bee9539b4f": {
    "paperId": "de5d889a2aca12aafd71bdeac5c6a3bee9539b4f",
    "title": "How Do AI-driven Chatbots Impact User Experience? Examining Gratifications, Perceived Privacy Risk, Satisfaction, Loyalty, and Continued Use",
    "year": 2020,
    "authors": "Yang Cheng, Hua Jiang",
    "abstract": "ABSTRACT This study examined how artificial intelligence (AI)-driven chatbots impact user experience. It collected survey data from 1,064 consumers who used any chatbot service from the top 30 brands in the U.S. Results indicated that utilitarian (information), hedonic (entertainment), technology (media appeal), and social (social presence) gratifications obtained from chatbot use positively predicted users’ satisfaction with chatbot services of their selected brand. In contrast, perceived privacy risk associated with chatbot use reduced user satisfaction. Data also demonstrated that user satisfaction positively affected both the continued use intention of chatbot services and customer loyalty. Implications of this study are discussed.",
    "citationCount": 310,
    "pdf_filename": "2020_How_Do_AI_driven_Chatbots_Impact_User_Ex_de5d889a.pdf"
  },
  "081d4a3f110609cf4ab430c3b5468e7f02d6e4a7": {
    "paperId": "081d4a3f110609cf4ab430c3b5468e7f02d6e4a7",
    "title": "Close Encounters of the AI Kind: Use of AI Influencers As Brand Endorsers",
    "year": 2020,
    "authors": "Veronica L. Thomas, Kendra Fowler",
    "abstract": "Abstract Brand endorsers can contribute to a brand’s success or failure (in the case of endorser transgressions). Recent advancements in technology have produced new, nonhuman alternatives to traditional celebrity endorsers. These new endorsers rely on artificial intelligence (AI) to interact with and influence consumers. Two studies demonstrate that AI influencers can produce positive brand benefits similar to those produced by human celebrity endorsers. Moreover, just like their human counterparts, AI influencers can also commit transgressions that result in degradation of the endorsed brand. Importantly, though, AI influencers differ from human celebrity endorsers in that consumers are less likely to view them as unique entities (as tested in a pilot study). Thus, consumers are more likely to perceive a transgression committed by an AI influencer as behavior applicable to all AI influencers, but they are less likely to view celebrity endorser behaviors as interchangeable. As such, after an AI influencer has committed a transgression, replacing the AI influencer with a celebrity endorser attenuates negative brand perceptions, an effect which cannot be realized if the replacement is another AI influencer.",
    "citationCount": 309,
    "pdf_filename": "2020_Close_Encounters_of_the_AI_Kind__Use_of__081d4a3f.pdf"
  },
  "e0ce6638f4a1936a64c6435aa197f112484fd052": {
    "paperId": "e0ce6638f4a1936a64c6435aa197f112484fd052",
    "title": "AI-Driven Tools for Coronavirus Outbreak: Need of Active Learning and Cross-Population Train/Test Models on Multitudinal/Multimodal Data",
    "year": 2020,
    "authors": "K. Santosh",
    "abstract": "The novel coronavirus (COVID-19) outbreak, which was identified in late 2019, requires special attention because of its future epidemics and possible global threats. Beside clinical procedures and treatments, since Artificial Intelligence (AI) promises a new paradigm for healthcare, several different AI tools that are built upon Machine Learning (ML) algorithms are employed for analyzing data and decision-making processes. This means that AI-driven tools help identify COVID-19 outbreaks as well as forecast their nature of spread across the globe. However, unlike other healthcare issues, for COVID-19, to detect COVID-19, AI-driven tools are expected to have active learning-based cross-population train/test models that employs multitudinal and multimodal data, which is the primary purpose of the paper.",
    "citationCount": 311,
    "pdf_filename": "2020_AI_Driven_Tools_for_Coronavirus_Outbreak_e0ce6638.pdf"
  },
  "928fa44848bb6ef2b483c254b4f5185c935c4345": {
    "paperId": "928fa44848bb6ef2b483c254b4f5185c935c4345",
    "title": "A comprehensive survey of AI-enabled phishing attacks detection techniques",
    "year": 2020,
    "authors": "A. Basit, Maham Zafar, Xuan Liu, A. R. Javed, Z. Jalil",
    "abstract": "In recent times, a phishing attack has become one of the most prominent attacks faced by internet users, governments, and service-providing organizations. In a phishing attack, the attacker(s) collects the client’s sensitive data (i.e., user account login details, credit/debit card numbers, etc.) by using spoofed emails or fake websites. Phishing websites are common entry points of online social engineering attacks, including numerous frauds on the websites. In such types of attacks, the attacker(s) create website pages by copying the behavior of legitimate websites and sends URL(s) to the targeted victims through spam messages, texts, or social networking. To provide a thorough understanding of phishing attack(s), this paper provides a literature review of Artificial Intelligence (AI) techniques: Machine Learning, Deep Learning, Hybrid Learning, and Scenario-based techniques for phishing attack detection. This paper also presents the comparison of different studies detecting the phishing attack for each AI technique and examines the qualities and shortcomings of these methodologies. Furthermore, this paper provides a comprehensive set of current challenges of phishing attacks and future research direction in this domain.",
    "citationCount": 309,
    "pdf_filename": "2020_A_comprehensive_survey_of_AI_enabled_phi_928fa448.pdf"
  },
  "821fde6dc36d1264c765d249d4247ea66daff55f": {
    "paperId": "821fde6dc36d1264c765d249d4247ea66daff55f",
    "title": "Edge Machine Learning for AI-Enabled IoT Devices: A Review",
    "year": 2020,
    "authors": "M. Merenda, Carlo Porcaro, D. Iero",
    "abstract": "In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors’ data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”.",
    "citationCount": 359,
    "pdf_filename": "2020_Edge_Machine_Learning_for_AI_Enabled_IoT_821fde6d.pdf"
  },
  "cffd8f947ba03644f62baea31c64c8920b06288e": {
    "paperId": "cffd8f947ba03644f62baea31c64c8920b06288e",
    "title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?",
    "year": 2020,
    "authors": "Peter Hase, Mohit Bansal",
    "abstract": "Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A model is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods: (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases: LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how explanations influence simulatability across a variety of explanation methods and data domains. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current methods.",
    "citationCount": 324,
    "pdf_filename": "2020_Evaluating_Explainable_AI__Which_Algorit_cffd8f94.pdf"
  },
  "8fdb305a31cc52c7ef4bd11b01b5f8f63751f32c": {
    "paperId": "8fdb305a31cc52c7ef4bd11b01b5f8f63751f32c",
    "title": "Industry 4.0 in Finance: The Impact of Artificial Intelligence (AI) on Digital Financial Inclusion",
    "year": 2020,
    "authors": "David Mhlanga",
    "abstract": "This study sought to investigate the impact of AI on digital financial inclusion. Digital financial inclusion is becoming central in the debate on how to ensure that people who are at the lower levels of the pyramid become financially active. Fintech companies are using AI and its various applications to ensure that the goal of digital financial inclusion is realized that is to ensure that low-income earners, the poor, women, youths, small businesses participate in the mainstream financial market. This study used conceptual and documentary analysis of peer-reviewed journals, reports and other authoritative documents on AI and digital financial inclusion to assess the impact of AI on digital financial inclusion. The present study discovered that AI has a strong influence on digital financial inclusion in areas related to risk detection, measurement and management, addressing the problem of information asymmetry, availing customer support and helpdesk through chatbots and fraud detection and cybersecurity. Therefore, it is recommended that financial institutions and non-financial institutions and governments across the world adopt and scale up the use of AI tools and applications as they present benefits in the quest to ensure that the vulnerable groups of people who are not financially active do participate in the formal financial market with minimum challenges and maximum benefits.",
    "citationCount": 307,
    "pdf_filename": "2020_Industry_4_0_in_Finance__The_Impact_of_A_8fdb305a.pdf"
  },
  "7c663204f4b1f5c0a112bce0d84b21e1c1b7f798": {
    "paperId": "7c663204f4b1f5c0a112bce0d84b21e1c1b7f798",
    "title": "Artificial intelligence for education: Knowledge and its assessment in AI-enabled learning ecologies",
    "year": 2020,
    "authors": "B. Cope, M. Kalantzis, Duane Searsmith",
    "abstract": "Abstract Over the past ten years, we have worked in a collaboration between educators and computer scientists at the University of Illinois to imagine futures for education in the context of what is loosely called “artificial intelligence.” Unhappy with the first generation of digital learning environments, our agenda has been to design alternatives and research their implementation. Our starting point has been to ask, what is the nature of machine intelligence, and what are its limits and potentials in education? This paper offers some tentative answers, first conceptually, and then practically in an overview of the results of a number of experimental implementations documented in greater detail elsewhere. Our key finding is that artificial intelligence—in the context of the practices of electronic computing developing over the past three quarters of a century—will never in any sense “take over” the role of teacher, because how it works and what it does are so profoundly different from human intelligence. However, within the limits that we describe in this paper, it offers the potential to transform education in ways that—counterintuitively perhaps—make education more human, not less.",
    "citationCount": 348,
    "pdf_filename": "2020_Artificial_intelligence_for_education__K_7c663204.pdf"
  },
  "f4f6bf7c3d708102359e86730df15e514e201854": {
    "paperId": "f4f6bf7c3d708102359e86730df15e514e201854",
    "title": "Explainable AI Methods - A Brief Overview",
    "year": 2020,
    "authors": "Andreas Holzinger, Anna Saranti, Christoph Molnar, P. Biecek, W. Samek",
    "abstract": ". Explainable Artiﬁcial Intelligence (xAI) is an established ﬁeld with a vibrant community that has developed a variety of very successful approaches to explain and interpret predictions of complex machine learning models such as deep neural networks. In this article, we brieﬂy introduce a few selected methods and discuss them in a short, clear and concise way. The goal of this article is to give beginners, especially application engineers and data scientists, a quick overview of the state of the art in this current topic. The following 17 methods are covered in this chapter: LIME, Anchors, GraphLIME, LRP, DTD, PDA, TCAV, XGNN, SHAP, ASV, Break-Down, Shapley Flow, Textual Explanations of Visual Models, Integrated Gradients, Causal Models, Mean-ingful Perturbations, and X-NeSyL.",
    "citationCount": 321,
    "pdf_filename": "2020_Explainable_AI_Methods___A_Brief_Overvie_f4f6bf7c.pdf"
  },
  "2296629527ebbd6f8c897df7cf5cdbac3f0cc15b": {
    "paperId": "2296629527ebbd6f8c897df7cf5cdbac3f0cc15b",
    "title": "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
    "year": 2024,
    "authors": "A. Ustun, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D'souza",
    "abstract": "Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models. We open-source our instruction datasets and our model at https://hf.co/CohereForAI/aya-101",
    "citationCount": 306,
    "pdf_filename": "2024_Aya_Model__An_Instruction_Finetuned_Open_22966295.pdf"
  },
  "6b238b17e419c7dd3912b9845449496bfb0a571a": {
    "paperId": "6b238b17e419c7dd3912b9845449496bfb0a571a",
    "title": "Accurate predictions on small data with a tabular foundation model",
    "year": 2025,
    "authors": "Noah Hollmann, Samuel G. Müller, Lennart Purucker, Arjun Krishnakumar, Max Körfer",
    "abstract": "Tabular data, spreadsheets organized in rows and columns, are ubiquitous across scientific fields, from biomedicine to particle physics to economics and climate science1,2. The fundamental prediction task of filling in missing values of a label column based on the rest of the columns is essential for various applications as diverse as biomedical risk models, drug discovery and materials science. Although deep learning has revolutionized learning from raw data and led to numerous high-profile success stories3, 4–5, gradient-boosted decision trees6, 7, 8–9 have dominated tabular data for the past 20 years. Here we present the Tabular Prior-data Fitted Network (TabPFN), a tabular foundation model that outperforms all previous methods on datasets with up to 10,000 samples by a wide margin, using substantially less training time. In 2.8 s, TabPFN outperforms an ensemble of the strongest baselines tuned for 4 h in a classification setting. As a generative transformer-based foundation model, this model also allows fine-tuning, data generation, density estimation and learning reusable embeddings. TabPFN is a learning algorithm that is itself learned across millions of synthetic datasets, demonstrating the power of this approach for algorithm development. By improving modelling abilities across diverse fields, TabPFN has the potential to accelerate scientific discovery and enhance important decision-making in various domains. Tabular Prior-data Fitted Network, a tabular foundation model, provides accurate predictions on small data and outperforms all previous methods on datasets with up to 10,000 samples by a wide margin.",
    "citationCount": 406,
    "pdf_filename": "2025_Accurate_predictions_on_small_data_with__6b238b17.pdf"
  },
  "14969de024c6e2e396fae835d737602733d9418a": {
    "paperId": "14969de024c6e2e396fae835d737602733d9418a",
    "title": "Open-Sora: Democratizing Efficient Video Production for All",
    "year": 2024,
    "authors": "Zangwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen, Shenggui Li",
    "abstract": "Vision and language are the two foundational senses for humans, and they build up our cognitive ability and intelligence. While significant breakthroughs have been made in AI language ability, artificial visual intelligence, especially the ability to generate and simulate the world we see, is far lagging behind. To facilitate the development and accessibility of artificial visual intelligence, we created Open-Sora, an open-source video generation model designed to produce high-fidelity video content. Open-Sora supports a wide spectrum of visual generation tasks, including text-to-image generation, text-to-video generation, and image-to-video generation. The model leverages advanced deep learning architectures and training/inference techniques to enable flexible video synthesis, which could generate video content of up to 15 seconds, up to 720p resolution, and arbitrary aspect ratios. Specifically, we introduce Spatial-Temporal Diffusion Transformer (STDiT), an efficient diffusion framework for videos that decouples spatial and temporal attention. We also introduce a highly compressive 3D autoencoder to make representations compact and further accelerate training with an ad hoc training strategy. Through this initiative, we aim to foster innovation, creativity, and inclusivity within the community of AI content creation. By embracing the open-source principle, Open-Sora democratizes full access to all the training/inference/data preparation codes as well as model weights. All resources are publicly available at: https://github.com/hpcaitech/Open-Sora.",
    "citationCount": 441,
    "pdf_filename": "2024_Open_Sora__Democratizing_Efficient_Video_14969de0.pdf"
  },
  "2797cbda8c845504119b62ee25deb1500ec2dfaf": {
    "paperId": "2797cbda8c845504119b62ee25deb1500ec2dfaf",
    "title": "DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence",
    "year": 2024,
    "authors": "DeepSeek-AI, Qihao Zhu, Daya Guo, Zhihong Shao, Dejian Yang",
    "abstract": "We present DeepSeek-Coder-V2, an open-source Mixture-of-Experts (MoE) code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks. Specifically, DeepSeek-Coder-V2 is further pre-trained from an intermediate checkpoint of DeepSeek-V2 with additional 6 trillion tokens. Through this continued pre-training, DeepSeek-Coder-V2 substantially enhances the coding and mathematical reasoning capabilities of DeepSeek-V2, while maintaining comparable performance in general language tasks. Compared to DeepSeek-Coder-33B, DeepSeek-Coder-V2 demonstrates significant advancements in various aspects of code-related tasks, as well as reasoning and general capabilities. Additionally, DeepSeek-Coder-V2 expands its support for programming languages from 86 to 338, while extending the context length from 16K to 128K. In standard benchmark evaluations, DeepSeek-Coder-V2 achieves superior performance compared to closed-source models such as GPT4-Turbo, Claude 3 Opus, and Gemini 1.5 Pro in coding and math benchmarks.",
    "citationCount": 341,
    "pdf_filename": "2024_DeepSeek_Coder_V2__Breaking_the_Barrier__2797cbda.pdf"
  },
  "5c7f465d162aade4a4c0eefb02fd7aadeebdaf58": {
    "paperId": "5c7f465d162aade4a4c0eefb02fd7aadeebdaf58",
    "title": "LLM Evaluators Recognize and Favor Their Own Generations",
    "year": 2024,
    "authors": "Arjun Panickssery, Samuel R. Bowman, Shi Feng",
    "abstract": "Self-evaluation using large language models (LLMs) has proven valuable not only in benchmarking but also methods like reward modeling, constitutional AI, and self-refinement. But new biases are introduced due to the same LLM acting as both the evaluator and the evaluatee. One such bias is self-preference, where an LLM evaluator scores its own outputs higher than others' while human annotators consider them of equal quality. But do LLMs actually recognize their own outputs when they give those texts higher scores, or is it just a coincidence? In this paper, we investigate if self-recognition capability contributes to self-preference. We discover that, out of the box, LLMs such as GPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from other LLMs and humans. By fine-tuning LLMs, we discover a linear correlation between self-recognition capability and the strength of self-preference bias; using controlled experiments, we show that the causal explanation resists straightforward confounders. We discuss how self-recognition can interfere with unbiased evaluations and AI safety more generally.",
    "citationCount": 330,
    "pdf_filename": "2024_LLM_Evaluators_Recognize_and_Favor_Their_5c7f465d.pdf"
  },
  "d4999c6f04c357414f66066f0fa06be14faa8efc": {
    "paperId": "d4999c6f04c357414f66066f0fa06be14faa8efc",
    "title": "The Faiss library",
    "year": 2024,
    "authors": "Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy",
    "abstract": "Vector databases typically manage large collections of embedding vectors. Currently, AI applications are growing rapidly, and so is the number of embeddings that need to be stored and indexed. The Faiss library is dedicated to vector similarity search, a core functionality of vector databases. Faiss is a toolkit of indexing methods and related primitives used to search, cluster, compress and transform vectors. This paper describes the trade-off space of vector search and the design principles of Faiss in terms of structure, approach to optimization and interfacing. We benchmark key features of the library and discuss a few selected applications to highlight its broad applicability.",
    "citationCount": 360,
    "pdf_filename": "2024_The_Faiss_library_d4999c6f.pdf"
  },
  "697ba06bfcabbbde6292d979b87b2642115f1099": {
    "paperId": "697ba06bfcabbbde6292d979b87b2642115f1099",
    "title": "ARTIFICIAL INTELLIGENCE IN EDUCATION: CHALLENGES AND OPPORTUNITIES FOR SUSTAINABLE DEVELOPMENT",
    "year": 2025,
    "authors": "S. A. Vakhabova, Valery V. Kosulin, Ana Zizaeva",
    "abstract": "The article analyzes the role of artificial intelligence (AI) in the transformation of the educational sphere in the context of achieving the Sustainable Development Goals (SDGs). The purpose of the study is a comprehensive assessment of the potential benefits and risks of introducing AI into education in terms of their impact on sustainable development. Tasks include: identification of key AI application opportunities to improve the quality, accessibility, and inclusivity of education (SDG 4); analysis of issues related to ethics, algorithm bias, digital inequality, and the need for retraining; assessment of the impact of AI on the formation of competencies necessary for a sustainable future. The results show the significant potential of AI in personalizing learning, automating routine tasks, and providing access to knowledge, but also reveal serious risks of exacerbating social inequality (SDG 10) and ethical dilemmas. The scientific novelty lies in the systematic consideration of the relationship between the introduction of AI in education and the achievement of the SDGs, offering a balanced view of the challenges and opportunities. The practical significance lies in the formulation of recommendations for policy makers, educators, and developers on responsible and sustainability-oriented implementation of AI in educational systems.",
    "citationCount": 375,
    "pdf_filename": "2025_ARTIFICIAL_INTELLIGENCE_IN_EDUCATION__CH_697ba06b.pdf"
  },
  "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97": {
    "paperId": "5d4a6ce39cfe7bfc6305cba86464efff8bc20c97",
    "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
    "year": 2024,
    "authors": "Mohaimenul Azam Khan Raiaan, Md. Saddam Hossain Mukta, Kaniz Fatema, Nur Mohammad Fahad, S. Sakib",
    "abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.",
    "citationCount": 450,
    "pdf_filename": "2024_A_Review_on_Large_Language_Models__Archi_5d4a6ce3.pdf"
  },
  "ded4c8e6aef584d7b5f799fd8dcdba015ef6a284": {
    "paperId": "ded4c8e6aef584d7b5f799fd8dcdba015ef6a284",
    "title": "Digital twins for health: a scoping review",
    "year": 2024,
    "authors": "Evangelia Katsoulakis, Qi Wang, Huanmei Wu, L. Shahriyari, Richard Fletcher",
    "abstract": "The use of digital twins (DTs) has proliferated across various fields and industries, with a recent surge in the healthcare sector. The concept of digital twin for health (DT4H) holds great promise to revolutionize the entire healthcare system, including management and delivery, disease treatment and prevention, and health well-being maintenance, ultimately improving human life. The rapid growth of big data and continuous advancement in data science (DS) and artificial intelligence (AI) have the potential to significantly expedite DT research and development by providing scientific expertise, essential data, and robust cybertechnology infrastructure. Although various DT initiatives have been underway in the industry, government, and military, DT4H is still in its early stages. This paper presents an overview of the current applications of DTs in healthcare, examines consortium research centers and their limitations, and surveys the current landscape of emerging research and development opportunities in healthcare. We envision the emergence of a collaborative global effort among stakeholders to enhance healthcare and improve the quality of life for millions of individuals worldwide through pioneering research and development in the realm of DT technology.",
    "citationCount": 310,
    "pdf_filename": "2024_Digital_twins_for_health__a_scoping_revi_ded4c8e6.pdf"
  },
  "315d7a58fada47c5729645f0af8ddfaa0743f82f": {
    "paperId": "315d7a58fada47c5729645f0af8ddfaa0743f82f",
    "title": "Exploiting Diffusion Prior for Real-World Image Super-Resolution",
    "year": 2023,
    "authors": "Jianyi Wang, Zongsheng Yue, Shangchen Zhou, Kelvin C. K. Chan, Chen Change Loy",
    "abstract": "We present a novel approach to leverage prior knowledge encapsulated in pre-trained text-to-image diffusion models for blind super-resolution. Specifically, by employing our time-aware encoder, we can achieve promising restoration results without altering the pre-trained synthesis model, thereby preserving the generative prior and minimizing training cost. To remedy the loss of fidelity caused by the inherent stochasticity of diffusion models, we employ a controllable feature wrapping module that allows users to balance quality and fidelity by simply adjusting a scalar value during the inference process. Moreover, we develop a progressive aggregation sampling strategy to overcome the fixed-size constraints of pre-trained diffusion models, enabling adaptation to resolutions of any size. A comprehensive evaluation of our method using both synthetic and real-world benchmarks demonstrates its superiority over current state-of-the-art approaches. Code and models are available at https://github.com/IceClear/StableSR.",
    "citationCount": 470,
    "pdf_filename": "2023_Exploiting_Diffusion_Prior_for_Real_Worl_315d7a58.pdf"
  },
  "99bd96961a880adad88d087c9dc45f6cfbae1ea6": {
    "paperId": "99bd96961a880adad88d087c9dc45f6cfbae1ea6",
    "title": "Generating Human Motion from Textual Descriptions with Discrete Representations",
    "year": 2023,
    "authors": "Jianrong Zhang, Yangsong Zhang, Xiaodong Cun, Shaoli Huang, Yong Zhang",
    "abstract": "In this work, we investigate a simple and must-known conditional generative framework based on Vector Quantised-Variational AutoEncoder (VQ-VAE) and Generative Pre-trained Transformer (GPT) for human motion generation from textural descriptions. We show that a simple CNN-based VQ-VAE with commonly used training recipes (EMA and Code Reset) allows us to obtain high-quality discrete representations. For GPT, we incorporate a simple corruption strategy during the training to alleviate training-testing discrepancy. Despite its simplicity, our T2M-GPT shows better performance than competitive approaches, including recent diffusion-based approaches. For example, on HumanML3D, which is currently the largest dataset, we achieve comparable performance on the consistency between text and generated motion (R-Precision), but with FID 0.116 largely outperforming MotionDiffuse of 0.630. Additionally, we conduct analyses on HumanML3D and observe that the dataset size is a limitation of our approach. Our work suggests that VQ-VAE still remains a competitive approach for human motion generation. Our implementation is available on the project page: https://mael-zys.github.io/T2M-GPT/.",
    "citationCount": 491,
    "pdf_filename": "2023_Generating_Human_Motion_from_Textual_Des_99bd9696.pdf"
  },
  "985f0c89c5a607742ec43c1fdc2cbfe54541cbad": {
    "paperId": "985f0c89c5a607742ec43c1fdc2cbfe54541cbad",
    "title": "Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation",
    "year": 2023,
    "authors": "Lijun Yu, José Lezama, N. B. Gundavarapu, Luca Versari, Kihyuk Sohn",
    "abstract": "While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.",
    "citationCount": 484,
    "pdf_filename": "2023_Language_Model_Beats_Diffusion____Tokeni_985f0c89.pdf"
  },
  "5501d00310b06e00351295529498cc684187148d": {
    "paperId": "5501d00310b06e00351295529498cc684187148d",
    "title": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models",
    "year": 2023,
    "authors": "Tyna Eloundou, Sam Manning, Pamela Mishkin, Daniel Rock",
    "abstract": "We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.",
    "citationCount": 489,
    "pdf_filename": "2023_GPTs_are_GPTs__An_Early_Look_at_the_Labo_5501d003.pdf"
  },
  "4ec53531cc7c4cde9437dda51ffb173367bb7e25": {
    "paperId": "4ec53531cc7c4cde9437dda51ffb173367bb7e25",
    "title": "Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma",
    "year": 2023,
    "authors": "Y. Yeo, Jamil S. Samaan, Wee Han Ng, Peng-Sheng Ting, H. Trivedi",
    "abstract": "Background: Patients with cirrhosis and hepatocellular carcinoma (HCC) require extensive care. Personalized education can improve their outcomes. ChatGPT (Generative Pre-trained Transformer), a natural language processing model, has shown potential to provide professional yet patient-freindly responses. Aim: To examine the accuracy and reproducibility of ChatGPT in responding to questions regarding knowledge, management, and emotional support for cirrhosis and HCC. Method: ChatGPT's responses to 164 frequently asked questions were independently graded by two transplant hepatologists, with a third reviewer resolving any discrepancies. We also compared the performance of ChatGPT on two previously validated and published questionnaires to the physicians or trainees who were tested in the included publications. Furthermore, we formulated the 26 quality measures of cirrhosis management into questions and tested ChatGPT's knowledge in cirrhosis care. Finally, the capacity to provide emotional support to patients or caregivers was tested. Results: ChatGPT regurgitated extensive knowledge about both cirrhosis and HCC, but for questions with correct responses, only a small proportion was labelled as comprehensive. The performance was better in basic knowledge, lifestyle, and treatment than in the domains of diagnosis and preventive medicine. For the quality measures, the model answered 76.9% of questions correctly but failed to specify the cut-off values for making medical decisions and treatment durations. When compared to physicians/trainees, ChatGPT fell short in knowledge of guidelines varying across geographic regions, such as HCC screening criteria. The model also provided practical and multifaceted advice to patients and caregivers regarding the next steps and adjusting to a new diagnosis. Conclusion: In summary, we analyzed the areas of robustness and limitations of ChatGPT's responses on the management of cirrhosis and HCC and relevant emotional support. ChatGPT may have a role as an adjunct informational tool for patients and physicians to improve outcomes.",
    "citationCount": 491,
    "pdf_filename": "2023_Assessing_the_performance_of_ChatGPT_in__4ec53531.pdf"
  },
  "14ccb8bcceb6de10eda6ad08bec242a4f2946497": {
    "paperId": "14ccb8bcceb6de10eda6ad08bec242a4f2946497",
    "title": "FateZero: Fusing Attentions for Zero-shot Text-based Video Editing",
    "year": 2023,
    "authors": "Chenyang Qi, Xiaodong Cun, Yong Zhang, Chenyang Lei, Xintao Wang",
    "abstract": "The diffusion-based generative models have achieved remarkable success in text-based image generation. However, since it contains enormous randomness in generation progress, it is still challenging to apply such models for real-world visual content editing, especially in videos. In this paper, we propose FateZero, a zero-shot text-based editing method on real-world videos without per-prompt training or use-specific mask. To edit videos consistently, we propose several techniques based on the pre-trained models. Firstly, in contrast to the straightforward DDIM inversion technique, our approach captures intermediate attention maps during inversion, which effectively retain both structural and motion information. These maps are directly fused in the editing process rather than generated during denoising. To further minimize semantic leakage of the source video, we then fuse self-attentions with a blending mask obtained by cross-attention features from the source prompt. Furthermore, we have implemented a reform of the self-attention mechanism in denoising UNet by introducing spatial-temporal attention to ensure frame consistency. Yet succinct, our method is the first one to show the ability of zero-shot text-driven video style and local attribute editing from the trained text-to-image model. We also have a better zero-shot shape-aware editing ability based on the text-to-video model [52]. Extensive experiments demonstrate our superior temporal consistency and editing capability than previous works.",
    "citationCount": 452,
    "pdf_filename": "2023_FateZero__Fusing_Attentions_for_Zero_sho_14ccb8bc.pdf"
  },
  "7ee862c9de83ded9358deec49e3d5b951d59ca4c": {
    "paperId": "7ee862c9de83ded9358deec49e3d5b951d59ca4c",
    "title": "GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment",
    "year": 2023,
    "authors": "Dhruba Ghosh, H. Hajishirzi, Ludwig Schmidt",
    "abstract": "Recent breakthroughs in diffusion models, multimodal pretraining, and efficient finetuning have led to an explosion of text-to-image generative models. Given human evaluation is expensive and difficult to scale, automated methods are critical for evaluating the increasingly large number of new models. However, most current automated evaluation metrics like FID or CLIPScore only offer a holistic measure of image quality or image-text alignment, and are unsuited for fine-grained or instance-level analysis. In this paper, we introduce GenEval, an object-focused framework to evaluate compositional image properties such as object co-occurrence, position, count, and color. We show that current object detection models can be leveraged to evaluate text-to-image models on a variety of generation tasks with strong human agreement, and that other discriminative vision models can be linked to this pipeline to further verify properties like object color. We then evaluate several open-source text-to-image models and analyze their relative generative capabilities on our benchmark. We find that recent models demonstrate significant improvement on these tasks, though they are still lacking in complex capabilities such as spatial relations and attribute binding. Finally, we demonstrate how GenEval might be used to help discover existing failure modes, in order to inform development of the next generation of text-to-image models. Our code to run the GenEval framework is publicly available at https://github.com/djghosh13/geneval.",
    "citationCount": 441,
    "pdf_filename": "2023_GenEval__An_Object_Focused_Framework_for_7ee862c9.pdf"
  },
  "083bab4a967c2221d9f4da9110fe37d8ca679078": {
    "paperId": "083bab4a967c2221d9f4da9110fe37d8ca679078",
    "title": "DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors",
    "year": 2023,
    "authors": "Jinbo Xing, Menghan Xia, Yong Zhang, Haoxin Chen, Gongye Liu",
    "abstract": "Animating a still image offers an engaging visual experience. Traditional image animation techniques mainly focus on animating natural scenes with stochastic dynamics (e.g. clouds and fluid) or domain-specific motions (e.g. human hair or body motions), and thus limits their applicability to more general visual content. To overcome this limitation, we explore the synthesis of dynamic content for open-domain images, converting them into animated videos. The key idea is to utilize the motion prior of text-to-video diffusion models by incorporating the image into the generative process as guidance. Given an image, we first project it into a text-aligned rich context representation space using a query transformer, which facilitates the video model to digest the image content in a compatible fashion. However, some visual details still struggle to be preserved in the resultant videos. To supplement with more precise image information, we further feed the full image to the diffusion model by concatenating it with the initial noises. Experimental results show that our proposed method can produce visually convincing and more logical&natural motions, as well as higher conformity to the input image. Comparative evaluation demonstrates the notable superiority of our approach over existing competitors.",
    "citationCount": 390,
    "pdf_filename": "2023_DynamiCrafter__Animating_Open_domain_Ima_083bab4a.pdf"
  },
  "dc7b2a39421f93ae134fbb43ef62763056ebe1c7": {
    "paperId": "dc7b2a39421f93ae134fbb43ef62763056ebe1c7",
    "title": "Shap-E: Generating Conditional 3D Implicit Functions",
    "year": 2023,
    "authors": "Heewoo Jun, Alex Nichol",
    "abstract": "We present Shap-E, a conditional generative model for 3D assets. Unlike recent work on 3D generative models which produce a single output representation, Shap-E directly generates the parameters of implicit functions that can be rendered as both textured meshes and neural radiance fields. We train Shap-E in two stages: first, we train an encoder that deterministically maps 3D assets into the parameters of an implicit function; second, we train a conditional diffusion model on outputs of the encoder. When trained on a large dataset of paired 3D and text data, our resulting models are capable of generating complex and diverse 3D assets in a matter of seconds. When compared to Point-E, an explicit generative model over point clouds, Shap-E converges faster and reaches comparable or better sample quality despite modeling a higher-dimensional, multi-representation output space. We release model weights, inference code, and samples at https://github.com/openai/shap-e.",
    "citationCount": 405,
    "pdf_filename": "2023_Shap_E__Generating_Conditional_3D_Implic_dc7b2a39.pdf"
  },
  "459c82205d2a27a8542bba7a4d478a8a23be2f5d": {
    "paperId": "459c82205d2a27a8542bba7a4d478a8a23be2f5d",
    "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent",
    "year": 2023,
    "authors": "Weiwei Sun, Lingyong Yan, Xinyu Ma, Pengjie Ren, Dawei Yin",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable zero-shot generalization across various language-related tasks, including search engines. However, existing work utilizes the generative ability of LLMs for Information Retrieval (IR) rather than direct passage ranking. The discrepancy between the pre-training objectives of LLMs and the ranking objective poses another challenge. In this paper, we first investigate generative LLMs such as ChatGPT and GPT-4 for relevance ranking in IR. Surprisingly, our experiments reveal that properly instructed LLMs can deliver competitive, even superior results to state-of-the-art supervised methods on popular IR benchmarks. Furthermore, to address concerns about data contamination of LLMs, we collect a new test set called NovelEval, based on the latest knowledge and aiming to verify the model's ability to rank unknown knowledge. Finally, to improve efficiency in real-world applications, we delve into the potential for distilling the ranking capabilities of ChatGPT into small specialized models using a permutation distillation scheme. Our evaluation results turn out that a distilled 440M model outperforms a 3B supervised model on the BEIR benchmark. The code to reproduce our results is available at www.github.com/sunnweiwei/RankGPT.",
    "citationCount": 410,
    "pdf_filename": "2023_Is_ChatGPT_Good_at_Search__Investigating_459c8220.pdf"
  },
  "a9e00c216ce69325a15fd139da0624978e54058a": {
    "paperId": "a9e00c216ce69325a15fd139da0624978e54058a",
    "title": "Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale",
    "year": 2023,
    "authors": "Matt Le, Apoorv Vyas, Bowen Shi, B. Karrer, Leda Sari",
    "abstract": "Large-scale generative models such as GPT and DALL-E have revolutionized the research community. These models not only generate high fidelity outputs, but are also generalists which can solve tasks not explicitly taught. In contrast, speech generative models are still primitive in terms of scale and task generalization. In this paper, we present Voicebox, the most versatile text-guided generative model for speech at scale. Voicebox is a non-autoregressive flow-matching model trained to infill speech, given audio context and text, trained on over 50K hours of speech that are not filtered or enhanced. Similar to GPT, Voicebox can perform many different tasks through in-context learning, but is more flexible as it can also condition on future context. Voicebox can be used for mono or cross-lingual zero-shot text-to-speech synthesis, noise removal, content editing, style conversion, and diverse sample generation. In particular, Voicebox outperforms the state-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9% vs 1.9% word error rates) and audio similarity (0.580 vs 0.681) while being up to 20 times faster. Audio samples can be found in \\url{https://voicebox.metademolab.com}.",
    "citationCount": 412,
    "pdf_filename": "2023_Voicebox__Text_Guided_Multilingual_Unive_a9e00c21.pdf"
  },
  "4161ad2d2495d8af1d62dc5e71882bde642cd1c1": {
    "paperId": "4161ad2d2495d8af1d62dc5e71882bde642cd1c1",
    "title": "Large Language Models Are State-of-the-Art Evaluators of Translation Quality",
    "year": 2023,
    "authors": "Tom Kocmi, C. Federmann",
    "abstract": "We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate seven versions of GPT models, including ChatGPT. We show that our method for translation quality assessment only works with GPT 3.5 and larger models. Comparing to results from WMT22’s Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.",
    "citationCount": 441,
    "pdf_filename": "2023_Large_Language_Models_Are_State_of_the_A_4161ad2d.pdf"
  },
  "6d1433f3342fbee85ad1e2809e62734aec5c3853": {
    "paperId": "6d1433f3342fbee85ad1e2809e62734aec5c3853",
    "title": "Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models",
    "year": 2023,
    "authors": "Rongjie Huang, Jia-Bin Huang, Dongchao Yang, Yi Ren, Luping Liu",
    "abstract": "Large-scale multimodal generative modeling has created milestones in text-to-image and text-to-video generation. Its application to audio still lags behind for two main reasons: the lack of large-scale datasets with high-quality text-audio pairs, and the complexity of modeling long continuous audio data. In this work, we propose Make-An-Audio with a prompt-enhanced diffusion model that addresses these gaps by 1) introducing pseudo prompt enhancement with a distill-then-reprogram approach, it alleviates data scarcity with orders of magnitude concept compositions by using language-free audios; 2) leveraging spectrogram autoencoder to predict the self-supervised audio representation instead of waveforms. Together with robust contrastive language-audio pretraining (CLAP) representations, Make-An-Audio achieves state-of-the-art results in both objective and subjective benchmark evaluation. Moreover, we present its controllability and generalization for X-to-Audio with\"No Modality Left Behind\", for the first time unlocking the ability to generate high-definition, high-fidelity audios given a user-defined modality input. Audio samples are available at https://Text-to-Audio.github.io",
    "citationCount": 418,
    "pdf_filename": "2023_Make_An_Audio__Text_To_Audio_Generation__6d1433f3.pdf"
  },
  "c9dbdae8146b9f97e254f5d26fd6efde96eaa703": {
    "paperId": "c9dbdae8146b9f97e254f5d26fd6efde96eaa703",
    "title": "Med-Flamingo: a Multimodal Medical Few-shot Learner",
    "year": 2023,
    "authors": "Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Cyril Zakka",
    "abstract": "Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models (VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering (VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluation for generative medical VQA where physicians review the problems and blinded generations in an interactive app. Med-Flamingo improves performance in generative medical VQA by up to 20\\% in clinician's rating and firstly enables multimodal medical few-shot adaptations, such as rationale generation. We release our model, code, and evaluation app under https://github.com/snap-stanford/med-flamingo.",
    "citationCount": 404,
    "pdf_filename": "2023_Med_Flamingo__a_Multimodal_Medical_Few_s_c9dbdae8.pdf"
  },
  "6c323c535365e1c7cbfd9703cbec3b5650a3346b": {
    "paperId": "6c323c535365e1c7cbfd9703cbec3b5650a3346b",
    "title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs",
    "year": 2023,
    "authors": "Suyu Ge, Yunan Zhang, Liyuan Liu, Minjia Zhang, Jiawei Han",
    "abstract": "In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility.",
    "citationCount": 351,
    "pdf_filename": "2023_Model_Tells_You_What_to_Discard__Adaptiv_6c323c53.pdf"
  },
  "40a7c44d1cfaa9faf1f731a6f93a889fab5426da": {
    "paperId": "40a7c44d1cfaa9faf1f731a6f93a889fab5426da",
    "title": "Who's Harry Potter? Approximate Unlearning in LLMs",
    "year": 2023,
    "authors": "Ronen Eldan, M. Russinovich",
    "abstract": "Large language models (LLMs) are trained on massive internet corpora that often contain copyrighted content. This poses legal and ethical challenges for the developers and users of these models, as well as the original authors and publishers. In this paper, we propose a novel technique for unlearning a subset of the training data from a LLM, without having to retrain it from scratch. We evaluate our technique on the task of unlearning the Harry Potter books from the Llama2-7b model (a generative language model recently open-sourced by Meta). While the model took over 184K GPU-hours to pretrain, we show that in about 1 GPU hour of finetuning, we effectively erase the model's ability to generate or recall Harry Potter-related content, while its performance on common benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains almost unaffected. We make our fine-tuned model publicly available on HuggingFace for community evaluation. To the best of our knowledge, this is the first paper to present an effective technique for unlearning in generative language models. Our technique consists of three main components: First, we use a reinforced model that is further trained on the target data to identify the tokens that are most related to the unlearning target, by comparing its logits with those of a baseline model. Second, we replace idiosyncratic expressions in the target data with generic counterparts, and leverage the model's own predictions to generate alternative labels for every token. These labels aim to approximate the next-token predictions of a model that has not been trained on the target data. Third, we finetune the model on these alternative labels, which effectively erases the original text from the model's memory whenever it is prompted with its context.",
    "citationCount": 303,
    "pdf_filename": "2023_Who_s_Harry_Potter__Approximate_Unlearni_40a7c44d.pdf"
  },
  "46943551a72ab1bf608067b63cb2668049b4b199": {
    "paperId": "46943551a72ab1bf608067b63cb2668049b4b199",
    "title": "Denoising Diffusion Models for Plug-and-Play Image Restoration",
    "year": 2023,
    "authors": "Yuanzhi Zhu, K. Zhang, Jingyun Liang, Jiezhang Cao, B. Wen",
    "abstract": "Plug-and-play Image Restoration (IR) has been widely recognized as a flexible and interpretable method for solving various inverse problems by utilizing any off-the-shelf denoiser as the implicit image prior. However, most existing methods focus on discriminative Gaussian denoisers. Although diffusion models have shown impressive performance for high-quality image synthesis, their potential to serve as a generative denoiser prior to the plug-and-play IR methods remains to be further explored. While several other attempts have been made to adopt diffusion models for image restoration, they either fail to achieve satisfactory results or typically require an unacceptable number of Neural Function Evaluations (NFEs) during inference. This paper proposes DiffPIR, which integrates the traditional plug-and-play method into the diffusion sampling framework. Compared to plug-and-play IR methods that rely on discriminative Gaussian denoisers, DiffPIR is expected to inherit the generative ability of diffusion models. Experimental results on three representative IR tasks, including super-resolution, image deblurring, and inpainting, demonstrate that DiffPIR achieves state-of-the-art performance on both the FFHQ and ImageNet datasets in terms of reconstruction faithfulness and perceptual quality with no more than 100 NFEs. The source code is available at https://github.com/yuanzhi-zhu/DiffPIR",
    "citationCount": 319,
    "pdf_filename": "2023_Denoising_Diffusion_Models_for_Plug_and__46943551.pdf"
  },
  "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2": {
    "paperId": "4538e353dd98f396c8facc29ebb72e9b1ba5f7c2",
    "title": "Synthetic Data from Diffusion Models Improves ImageNet Classification",
    "year": 2023,
    "authors": "Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, David J. Fleet",
    "abstract": "Deep generative models are becoming increasingly powerful, now generating diverse high fidelity photo-realistic samples given text prompts. Have they reached the point where models of natural images can be used for generative data augmentation, helping to improve challenging discriminative tasks? We show that large-scale text-to image diffusion models can be fine-tuned to produce class conditional models with SOTA FID (1.76 at 256x256 resolution) and Inception Score (239 at 256x256). The model also yields a new SOTA in Classification Accuracy Scores (64.96 for 256x256 generative samples, improving to 69.24 for 1024x1024 samples). Augmenting the ImageNet training set with samples from the resulting models yields significant improvements in ImageNet classification accuracy over strong ResNet and Vision Transformer baselines.",
    "citationCount": 381,
    "pdf_filename": "2023_Synthetic_Data_from_Diffusion_Models_Imp_4538e353.pdf"
  },
  "2824f18b3aeaae51b3fbe0d629c9b8a728da86d7": {
    "paperId": "2824f18b3aeaae51b3fbe0d629c9b8a728da86d7",
    "title": "High-resolution image reconstruction with latent diffusion models from human brain activity",
    "year": 2023,
    "authors": "Yu Takagi, Shinji Nishimoto",
    "abstract": "Reconstructing visual experiences from human brain activity offers a unique way to understand how the brain represents the world, and to interpret the connection between computer vision models and our visual system. While deep generative models have recently been employed for this task, reconstructing realistic images with high semantic fidelity is still a challenging problem. Here, we propose a new method based on a diffusion model (DM) to reconstruct images from human brain activity obtained via functional magnetic resonance imaging (fMRI). More specifically, we rely on a latent diffusion model (LDM) termed Stable Diffusion. This model reduces the computational cost of DMs, while preserving their high generative performance. We also characterize the inner mechanisms of the LDM by studying how its different components (such as the latent vector of image Z, conditioning inputs C, and different elements of the denoising U-Net) relate to distinct brain functions. We show that our proposed method can reconstruct high-resolution images with high fidelity in straight-forward fashion, without the need for any additional training and fine-tuning of complex deep-learning models. We also provide a quantitative interpretation of different LDM components from a neuroscientific perspective. Overall, our study proposes a promising method for reconstructing images from human brain activity, and provides a new framework for understanding DMs. Please check out our webpage at https://sites.google.com/view/stablediffusion-with-brain/.",
    "citationCount": 319,
    "pdf_filename": "2023_High_resolution_image_reconstruction_wit_2824f18b.pdf"
  },
  "fbebb1a5d72aec2a6b13fc909f781f6ba9b04925": {
    "paperId": "fbebb1a5d72aec2a6b13fc909f781f6ba9b04925",
    "title": "Diffusion Self-Guidance for Controllable Image Generation",
    "year": 2023,
    "authors": "Dave Epstein, A. Jabri, Ben Poole, Alexei A. Efros, Aleksander Holynski",
    "abstract": "Large-scale generative models are capable of producing high-quality images from detailed text descriptions. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides greater control over generated images by guiding the internal representations of diffusion models. We demonstrate that properties such as the shape, location, and appearance of objects can be extracted from these representations and used to steer sampling. Self-guidance works similarly to classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We show how a simple set of properties can be composed to perform challenging image manipulations, such as modifying the position or size of objects, merging the appearance of objects in one image with the layout of another, composing objects from many images into one, and more. We also show that self-guidance can be used to edit real images. For results and an interactive demo, see our project page at https://dave.ml/selfguidance/",
    "citationCount": 335,
    "pdf_filename": "2023_Diffusion_Self_Guidance_for_Controllable_fbebb1a5.pdf"
  },
  "1e05c5427d6a35a3b1bf37fb955f2ea94995a71d": {
    "paperId": "1e05c5427d6a35a3b1bf37fb955f2ea94995a71d",
    "title": "Effective Data Augmentation With Diffusion Models",
    "year": 2023,
    "authors": "Brandon Trabucco, Kyle Doherty, Max Gurinas, R. Salakhutdinov",
    "abstract": "Data augmentation is one of the most prevalent tools in deep learning, underpinning many recent advances, including those from classification, generative models, and representation learning. The standard approach to data augmentation combines simple transformations like rotations and flips to generate new images from existing ones. However, these new images lack diversity along key semantic axes present in the data. Current augmentations cannot alter the high-level semantic attributes, such as animal species present in a scene, to enhance the diversity of data. We address the lack of diversity in data augmentation with image-to-image transformations parameterized by pre-trained text-to-image diffusion models. Our method edits images to change their semantics using an off-the-shelf diffusion model, and generalizes to novel visual concepts from a few labelled examples. We evaluate our approach on few-shot image classification tasks, and on a real-world weed recognition task, and observe an improvement in accuracy in tested domains.",
    "citationCount": 333,
    "pdf_filename": "2023_Effective_Data_Augmentation_With_Diffusi_1e05c542.pdf"
  },
  "26e5b933b8f60bd749d428b5ff813b2abcd765d8": {
    "paperId": "26e5b933b8f60bd749d428b5ff813b2abcd765d8",
    "title": "Composer: Creative and Controllable Image Synthesis with Composable Conditions",
    "year": 2023,
    "authors": "Lianghua Huang, Di Chen, Yu Liu, Yujun Shen, Deli Zhao",
    "abstract": "Recent large-scale generative models learned on big data are capable of synthesizing incredible images yet suffer from limited controllability. This work offers a new generation paradigm that allows flexible control of the output image, such as spatial layout and palette, while maintaining the synthesis quality and model creativity. With compositionality as the core idea, we first decompose an image into representative factors, and then train a diffusion model with all these factors as the conditions to recompose the input. At the inference stage, the rich intermediate representations work as composable elements, leading to a huge design space (i.e., exponentially proportional to the number of decomposed factors) for customizable content creation. It is noteworthy that our approach, which we call Composer, supports various levels of conditions, such as text description as the global information, depth map and sketch as the local guidance, color histogram for low-level details, etc. Besides improving controllability, we confirm that Composer serves as a general framework and facilitates a wide range of classical generative tasks without retraining. Code and models will be made available.",
    "citationCount": 347,
    "pdf_filename": "2023_Composer__Creative_and_Controllable_Imag_26e5b933.pdf"
  },
  "ca1d87f926eb7d2aba6eb9836f2d76dfce9e2079": {
    "paperId": "ca1d87f926eb7d2aba6eb9836f2d76dfce9e2079",
    "title": "A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation",
    "year": 2023,
    "authors": "A. Khan, Omkar Chaudhari, Rohitash Chandra",
    "abstract": "Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other. Ensemble learning combines multiple models to obtain a robust model and has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, and the evaluation of different combinations would enable a better understanding and guidance for different application domains. In this paper, we present a computational study to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We present a general framework that evaluates 9 data augmentation and 9 ensemble learning methods for CI problems. Our objective is to identify the most effective combination for improving classification performance on imbalanced datasets. The results indicate that combinations of data augmentation methods with ensemble learning can significantly improve classification performance on imbalanced datasets. We find that traditional data augmentation methods such as the synthetic minority oversampling technique (SMOTE) and random oversampling (ROS) are not only better in performance for selected CI problems, but also computationally less expensive than GANs. Our study is vital for the development of novel models for handling imbalanced datasets.",
    "citationCount": 340,
    "pdf_filename": "2023_A_review_of_ensemble_learning_and_data_a_ca1d87f9.pdf"
  },
  "977a5bf61c63b2c1f83d0c85aaab37c10703db6f": {
    "paperId": "977a5bf61c63b2c1f83d0c85aaab37c10703db6f",
    "title": "RingMo: A Remote Sensing Foundation Model With Masked Image Modeling",
    "year": 2023,
    "authors": "Xian Sun, Peijin Wang, Wanxuan Lu, Zicong Zhu, Xiaonan Lu",
    "abstract": "Deep learning approaches have contributed to the rapid development of remote sensing (RS) image interpretation. The most widely used training paradigm is to use ImageNet pretrained models to process RS data for specified tasks. However, there are issues such as domain gap between natural and RS scenes and the poor generalization capacity of RS models. It makes sense to develop a foundation model with general RS feature representation. Since a large amount of unlabeled data is available, the self-supervised method has more development significance than the fully supervised method in RS. However, most of the current self-supervised methods use contrastive learning, whose performance is sensitive to data augmentation, additional information, and selection of positive and negative pairs. In this article, we leverage the benefits of generative self-supervised learning (SSL) for RS images and propose an RS foundation model framework called RingMo, which consists of two parts. First, a large-scale dataset is constructed by collecting two million RS images from satellite and aerial platforms, covering multiple scenes and objects around the world. Second, we propose an RS foundation model training method designed for dense and small objects in complicated RS scenes. We show that the foundation model trained on our dataset with RingMo method achieves state-of-the-art (SOTA) on eight datasets across four downstream tasks, demonstrating the effectiveness of the proposed framework. Through in-depth exploration, we believe it is time for RS researchers to embrace generative SSL and leverage its general representation capabilities to speed up the development of RS applications.",
    "citationCount": 303,
    "pdf_filename": "2023_RingMo__A_Remote_Sensing_Foundation_Mode_977a5bf6.pdf"
  },
  "c3d14e7a319ab764297a60112ce74af201762a73": {
    "paperId": "c3d14e7a319ab764297a60112ce74af201762a73",
    "title": "Learning Interactive Real-World Simulators",
    "year": 2023,
    "authors": "Mengjiao Yang, Yilun Du, Kamyar Ghasemipour, Jonathan Tompson, D. Schuurmans",
    "abstract": "Generative models trained on internet data have revolutionized how text, image, and video content can be created. Perhaps the next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents. Applications of a real-world simulator range from controllable content creation in games and movies, to training embodied agents purely in simulation that can be directly deployed in the real world. We explore the possibility of learning a universal simulator (UniSim) of real-world interaction through generative modeling. We first make the important observation that natural datasets available for learning a real-world simulator are often rich along different dimensions (e.g., abundant objects in image data, densely sampled actions in robotics data, and diverse movements in navigation data). With careful orchestration of diverse datasets, each providing a different aspect of the overall experience, we can simulate the visual outcome of both high-level instructions such as\"open the drawer\"and low-level controls from otherwise static scenes and objects. We use the simulator to train both high-level vision-language policies and low-level reinforcement learning policies, each of which can be deployed in the real world in zero shot after training purely in simulation. We also show that other types of intelligence such as video captioning models can benefit from training with simulated experience, opening up even wider applications. Video demos can be found at https://universal-simulator.github.io.",
    "citationCount": 314,
    "pdf_filename": "2023_Learning_Interactive_Real_World_Simulato_c3d14e7a.pdf"
  },
  "7e6ead7750a54fe676e3478e976393367a57d2ae": {
    "paperId": "7e6ead7750a54fe676e3478e976393367a57d2ae",
    "title": "Investigating the Impact of User Trust on the Adoption and Use of ChatGPT: Survey Analysis",
    "year": 2023,
    "authors": "Avishek Choudhury, Hamid Shamszare",
    "abstract": "Background ChatGPT (Chat Generative Pre-trained Transformer) has gained popularity for its ability to generate human-like responses. It is essential to note that overreliance or blind trust in ChatGPT, especially in high-stakes decision-making contexts, can have severe consequences. Similarly, lacking trust in the technology can lead to underuse, resulting in missed opportunities. Objective This study investigated the impact of users’ trust in ChatGPT on their intent and actual use of the technology. Four hypotheses were tested: (1) users’ intent to use ChatGPT increases with their trust in the technology; (2) the actual use of ChatGPT increases with users’ intent to use the technology; (3) the actual use of ChatGPT increases with users’ trust in the technology; and (4) users’ intent to use ChatGPT can partially mediate the effect of trust in the technology on its actual use. Methods This study distributed a web-based survey to adults in the United States who actively use ChatGPT (version 3.5) at least once a month between February 2023 through March 2023. The survey responses were used to develop 2 latent constructs: Trust and Intent to Use, with Actual Use being the outcome variable. The study used partial least squares structural equation modeling to evaluate and test the structural model and hypotheses. Results In the study, 607 respondents completed the survey. The primary uses of ChatGPT were for information gathering (n=219, 36.1%), entertainment (n=203, 33.4%), and problem-solving (n=135, 22.2%), with a smaller number using it for health-related queries (n=44, 7.2%) and other activities (n=6, 1%). Our model explained 50.5% and 9.8% of the variance in Intent to Use and Actual Use, respectively, with path coefficients of 0.711 and 0.221 for Trust on Intent to Use and Actual Use, respectively. The bootstrapped results failed to reject all 4 null hypotheses, with Trust having a significant direct effect on both Intent to Use (β=0.711, 95% CI 0.656-0.764) and Actual Use (β=0.302, 95% CI 0.229-0.374). The indirect effect of Trust on Actual Use, partially mediated by Intent to Use, was also significant (β=0.113, 95% CI 0.001-0.227). Conclusions Our results suggest that trust is critical to users’ adoption of ChatGPT. It remains crucial to highlight that ChatGPT was not initially designed for health care applications. Therefore, an overreliance on it for health-related advice could potentially lead to misinformation and subsequent health risks. Efforts must be focused on improving the ChatGPT’s ability to distinguish between queries that it can safely handle and those that should be redirected to human experts (health care professionals). Although risks are associated with excessive trust in artificial intelligence–driven chatbots such as ChatGPT, the potential risks can be reduced by advocating for shared accountability and fostering collaboration between developers, subject matter experts, and human factors researchers.",
    "citationCount": 300,
    "pdf_filename": "2023_Investigating_the_Impact_of_User_Trust_o_7e6ead77.pdf"
  },
  "85cc48276c69924d3e92ddb38facb7d92be9a4a6": {
    "paperId": "85cc48276c69924d3e92ddb38facb7d92be9a4a6",
    "title": "Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4",
    "year": 2023,
    "authors": "Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou",
    "abstract": "Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as\"advanced\"at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. With early access to the GPT-4 API we are able to conduct intense experiments on the GPT-4 model. The results show GPT-4 yields even higher performance on most logical reasoning datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known datasets like LogiQA and ReClor. However, the performance drops significantly when handling newly released and out-of-distribution datasets. Logical reasoning remains challenging for ChatGPT and GPT-4, especially on out-of-distribution and natural language inference datasets. We release the prompt-style logical reasoning datasets as a benchmark suite and name it LogiEval.",
    "citationCount": 302,
    "pdf_filename": "2023_Evaluating_the_Logical_Reasoning_Ability_85cc4827.pdf"
  },
  "10c64e5aaff9f70dffc8c29a577376d085e9340b": {
    "paperId": "10c64e5aaff9f70dffc8c29a577376d085e9340b",
    "title": "A Review of the Role of Artificial Intelligence in Healthcare",
    "year": 2023,
    "authors": "Ahmed Al Kuwaiti, Khalid Nazer, Abdullah Al-Reedy, Shaher Z. Al-Shehri, Afnan Almuhanna",
    "abstract": "Artificial intelligence (AI) applications have transformed healthcare. This study is based on a general literature review uncovering the role of AI in healthcare and focuses on the following key aspects: (i) medical imaging and diagnostics, (ii) virtual patient care, (iii) medical research and drug discovery, (iv) patient engagement and compliance, (v) rehabilitation, and (vi) other administrative applications. The impact of AI is observed in detecting clinical conditions in medical imaging and diagnostic services, controlling the outbreak of coronavirus disease 2019 (COVID-19) with early diagnosis, providing virtual patient care using AI-powered tools, managing electronic health records, augmenting patient engagement and compliance with the treatment plan, reducing the administrative workload of healthcare professionals (HCPs), discovering new drugs and vaccines, spotting medical prescription errors, extensive data storage and analysis, and technology-assisted rehabilitation. Nevertheless, this science pitch meets several technical, ethical, and social challenges, including privacy, safety, the right to decide and try, costs, information and consent, access, and efficacy, while integrating AI into healthcare. The governance of AI applications is crucial for patient safety and accountability and for raising HCPs’ belief in enhancing acceptance and boosting significant health consequences. Effective governance is a prerequisite to precisely address regulatory, ethical, and trust issues while advancing the acceptance and implementation of AI. Since COVID-19 hit the global health system, the concept of AI has created a revolution in healthcare, and such an uprising could be another step forward to meet future healthcare needs.",
    "citationCount": 458,
    "pdf_filename": "2023_A_Review_of_the_Role_of_Artificial_Intel_10c64e5a.pdf"
  },
  "075efdce76763d5e42f49adb7119af9589a67b6b": {
    "paperId": "075efdce76763d5e42f49adb7119af9589a67b6b",
    "title": "Fake news, disinformation and misinformation in social media: a review",
    "year": 2023,
    "authors": "Esma Aïmeur, Sabrine Amri, Gilles Brassard",
    "abstract": "Online social networks (OSNs) are rapidly growing and have become a huge source of all kinds of global and local news for millions of users. However, OSNs are a double-edged sword. Although the great advantages they offer such as unlimited easy communication and instant news and information, they can also have many disadvantages and issues. One of their major challenging issues is the spread of fake news. Fake news identification is still a complex unresolved issue. Furthermore, fake news detection on OSNs presents unique characteristics and challenges that make finding a solution anything but trivial. On the other hand, artificial intelligence (AI) approaches are still incapable of overcoming this challenging problem. To make matters worse, AI techniques such as machine learning and deep learning are leveraged to deceive people by creating and disseminating fake content. Consequently, automatic fake news detection remains a huge challenge, primarily because the content is designed in a way to closely resemble the truth, and it is often hard to determine its veracity by AI alone without additional information from third parties. This work aims to provide a comprehensive and systematic review of fake news research as well as a fundamental review of existing approaches used to detect and prevent fake news from spreading via OSNs. We present the research problem and the existing challenges, discuss the state of the art in existing approaches for fake news detection, and point out the future research directions in tackling the challenges.",
    "citationCount": 454,
    "pdf_filename": "2023_Fake_news__disinformation_and_misinforma_075efdce.pdf"
  },
  "2f656b588aefb576928b1a700a404b31fc4a0640": {
    "paperId": "2f656b588aefb576928b1a700a404b31fc4a0640",
    "title": "The opportunities and challenges of ChatGPT in education",
    "year": 2023,
    "authors": "Ibrahim Adeshola, Adeola Praise Adepoju",
    "abstract": "ABSTRACT The launch of OpenAI ChatGPT's language-generation model has raised alarms within many sectors, especially the academic sector. Several academicians have urged universities to develop new forms of assessment after the launch of ChatGPT, which solves academic questions in less than a few minutes. Academic cheating is not a new phenomenon, and the use of AI-generated text to cheat on assignments is a new type of cheating that poses unique challenges. This study used the Latent Dirichlet Allocation (LDA) method for topic modeling and the Valence Aware Dictionary for Sentiment Reasoning (VADER) method for sentiment analysis. After data preprocessing, 3870 tweets were still available out of the originally 10,000 tweets that were extracted for the study. The VADER sentiment analysis results revealed that 2013 tweets were categorized as “positive,” with the remaining 804 and 1053 tweets categorized as “negative” and “neutral.” The analysis's findings indicate that the majority of people have favorable things to say about ChatGPT. As a result, educational institutions can mitigate the disruptive effects of this technology and promote academic integrity by developing clear policies and guidelines and designing assessments that include limited AI-generated text.",
    "citationCount": 355,
    "pdf_filename": "2023_The_opportunities_and_challenges_of_Chat_2f656b58.pdf"
  },
  "d4177489596748e43aa571f59556097f2cc4c8be": {
    "paperId": "d4177489596748e43aa571f59556097f2cc4c8be",
    "title": "GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts",
    "year": 2023,
    "authors": "Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing",
    "abstract": "Large language models (LLMs) have recently experienced tremendous popularity and are widely used from casual conversations to AI-driven programming. However, despite their considerable success, LLMs are not entirely reliable and can give detailed guidance on how to conduct harmful or illegal activities. While safety measures can reduce the risk of such outputs, adversarial jailbreak attacks can still exploit LLMs to produce harmful content. These jailbreak templates are typically manually crafted, making large-scale testing challenging. In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzing framework inspired by the AFL fuzzing framework. Instead of manual engineering, GPTFuzz automates the generation of jailbreak templates for red-teaming LLMs. At its core, GPTFuzz starts with human-written templates as initial seeds, then mutates them to produce new templates. We detail three key components of GPTFuzz: a seed selection strategy for balancing efficiency and variability, mutate operators for creating semantically equivalent or similar sentences, and a judgment model to assess the success of a jailbreak attack. We evaluate GPTFuzz against various commercial and open-source LLMs, including ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Our results indicate that GPTFuzz consistently produces jailbreak templates with a high success rate, surpassing human-crafted templates. Remarkably, GPTFuzz achieves over 90% attack success rates against ChatGPT and Llama-2 models, even with suboptimal initial seed templates. We anticipate that GPTFuzz will be instrumental for researchers and practitioners in examining LLM robustness and will encourage further exploration into enhancing LLM safety.",
    "citationCount": 478,
    "pdf_filename": "2023_GPTFUZZER__Red_Teaming_Large_Language_Mo_d4177489.pdf"
  },
  "a8c6a60f0b44ec06344d6b7a9570369dc3484465": {
    "paperId": "a8c6a60f0b44ec06344d6b7a9570369dc3484465",
    "title": "Fairness of artificial intelligence in healthcare: review and recommendations",
    "year": 2023,
    "authors": "Daiju Ueda, Taichi Kakinuma, S. Fujita, K. Kamagata, Y. Fushimi",
    "abstract": "In this review, we address the issue of fairness in the clinical integration of artificial intelligence (AI) in the medical field. As the clinical adoption of deep learning algorithms, a subfield of AI, progresses, concerns have arisen regarding the impact of AI biases and discrimination on patient health. This review aims to provide a comprehensive overview of concerns associated with AI fairness; discuss strategies to mitigate AI biases; and emphasize the need for cooperation among physicians, AI researchers, AI developers, policymakers, and patients to ensure equitable AI integration. First, we define and introduce the concept of fairness in AI applications in healthcare and radiology, emphasizing the benefits and challenges of incorporating AI into clinical practice. Next, we delve into concerns regarding fairness in healthcare, addressing the various causes of biases in AI and potential concerns such as misdiagnosis, unequal access to treatment, and ethical considerations. We then outline strategies for addressing fairness, such as the importance of diverse and representative data and algorithm audits. Additionally, we discuss ethical and legal considerations such as data privacy, responsibility, accountability, transparency, and explainability in AI. Finally, we present the Fairness of Artificial Intelligence Recommendations in healthcare (FAIR) statement to offer best practices. Through these efforts, we aim to provide a foundation for discussing the responsible and equitable implementation and deployment of AI in healthcare.",
    "citationCount": 319,
    "pdf_filename": "2023_Fairness_of_artificial_intelligence_in_h_a8c6a60f.pdf"
  },
  "f5275c61736781d236abe6700b822f1ea62f982e": {
    "paperId": "f5275c61736781d236abe6700b822f1ea62f982e",
    "title": "Diffusion Model Alignment Using Direct Preference Optimization",
    "year": 2023,
    "authors": "Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou",
    "abstract": "Large language models (LLMs) are fine-tuned using human comparison data with Reinforcement Learning from Human Feedback (RLHF) methods to make them better aligned with users' preferences. In contrast to LLMs, human preference learning has not been widely explored in text-to-image diffusion models; the best existing approach is to fine-tune a pretrained model using carefully curated high quality images and captions to improve visual appeal and text alignment. We propose Diffusion-DPO, a method to align diffusion models to human preferences by directly optimizing on human comparison data. Diffusion-DPO is adapted from the recently developed Direct Preference Optimization (DPO) [36], a simpler alternative to RLHF which directly optimizes a policy that best satisfies human preferences under a classification objective. We re-formulate DPO to account for a diffusion model notion of likelihood, utilizing the evidence lower bound to derive a differentiable objective. Using the Pick-a-Pic dataset of 851K crowdsourced pairwise preferences, we fine-tune the base model of the state-of-the-art Stable Diffusion XL (SDXL)-1.0 model with Diffusion-DPO. Our fine-tuned base model significantly outperforms both base SDXL-1.0 and the larger SDXL-1.0 model consisting of an additional refinement model in human evaluation, improving visual appeal and prompt alignment. We also develop a variant that uses AI feedback and has comparable performance to training on human preferences, opening the door for scaling of diffusion model alignment methods.",
    "citationCount": 471,
    "pdf_filename": "2023_Diffusion_Model_Alignment_Using_Direct_P_f5275c61.pdf"
  },
  "8d9ffc2fa44a5af4cb8ceaadd7fc709b0cb59988": {
    "paperId": "8d9ffc2fa44a5af4cb8ceaadd7fc709b0cb59988",
    "title": "To use or not to use ChatGPT in higher education? A study of students’ acceptance and use of technology",
    "year": 2023,
    "authors": "Artur Strzelecki",
    "abstract": "ABSTRACT ChatGPT is an AI tool that assisted in writing, learning, solving assessments and could do so in a conversational way. The purpose of the study was to develop a model that examined the predictors of adoption and use of ChatGPT among higher education students. The proposed model was based on a previous theory of technology adoption. Seven predictors were selected to build a model that predicted the behavioral intention and use behavior of ChatGPT. The partial-least squares method of structural equation modeling was used for data analysis. The model was found to be reliable and valid, and the results were based on a self-reported data of 534 students from a Polish state university. Nine out of ten proposed hypotheses were confirmed by the results. Habit was found to be the best predictor of behavioral intention, followed by performance expectancy and hedonic motivation. The dominant determinant of use behavior was behavioral intention, followed by personal innovativeness. The research highlighted the need for further examination of how AI tools could be adopted in learning and teaching.",
    "citationCount": 498,
    "pdf_filename": "2023_To_use_or_not_to_use_ChatGPT_in_higher_e_8d9ffc2f.pdf"
  },
  "3fb3ea8fbc211752cedc0106f4b6940327b3c7e0": {
    "paperId": "3fb3ea8fbc211752cedc0106f4b6940327b3c7e0",
    "title": "Redefining Radiology: A Review of Artificial Intelligence Integration in Medical Imaging",
    "year": 2023,
    "authors": "Reabal Najjar",
    "abstract": "This comprehensive review unfolds a detailed narrative of Artificial Intelligence (AI) making its foray into radiology, a move that is catalysing transformational shifts in the healthcare landscape. It traces the evolution of radiology, from the initial discovery of X-rays to the application of machine learning and deep learning in modern medical image analysis. The primary focus of this review is to shed light on AI applications in radiology, elucidating their seminal roles in image segmentation, computer-aided diagnosis, predictive analytics, and workflow optimisation. A spotlight is cast on the profound impact of AI on diagnostic processes, personalised medicine, and clinical workflows, with empirical evidence derived from a series of case studies across multiple medical disciplines. However, the integration of AI in radiology is not devoid of challenges. The review ventures into the labyrinth of obstacles that are inherent to AI-driven radiology—data quality, the ’black box’ enigma, infrastructural and technical complexities, as well as ethical implications. Peering into the future, the review contends that the road ahead for AI in radiology is paved with promising opportunities. It advocates for continuous research, embracing avant-garde imaging technologies, and fostering robust collaborations between radiologists and AI developers. The conclusion underlines the role of AI as a catalyst for change in radiology, a stance that is firmly rooted in sustained innovation, dynamic partnerships, and a steadfast commitment to ethical responsibility.",
    "citationCount": 470,
    "pdf_filename": "2023_Redefining_Radiology__A_Review_of_Artifi_3fb3ea8f.pdf"
  },
  "f54faf827b5ccd529bd602659f607db6560dfb85": {
    "paperId": "f54faf827b5ccd529bd602659f607db6560dfb85",
    "title": "Adaptive Learning Using Artificial Intelligence in e-Learning: A Literature Review",
    "year": 2023,
    "authors": "Ilie Gligorea, Marius Cioca, Romana Oancea, A. Gorski, Hortensia Gorski",
    "abstract": "The rapid evolution of e-learning platforms, propelled by advancements in artificial intelligence (AI) and machine learning (ML), presents a transformative potential in education. This dynamic landscape necessitates an exploration of AI/ML integration in adaptive learning systems to enhance educational outcomes. This study aims to map the current utilization of AI/ML in e-learning for adaptive learning, elucidating the benefits and challenges of such integration and assessing its impact on student engagement, retention, and performance. A comprehensive literature review was conducted, focusing on articles published from 2010 onwards, to document the integration of AI/ML in e-learning. The review analyzed 63 articles, employing a systematic approach to evaluate the deployment of adaptive learning algorithms and their educational implications. Findings reveal that AI/ML algorithms are instrumental in personalizing learning experiences. These technologies have been shown to optimize learning paths, enhance engagement, and improve academic performance, with some studies reporting increased test scores. The integration of AI/ML in e-learning platforms significantly contributes to the personalization and effectiveness of the educational process. Despite challenges like data privacy and the complexity of AI/ML systems, the results underscore the potential of adaptive learning to revolutionize education by catering to individual learner needs.",
    "citationCount": 468,
    "pdf_filename": "2023_Adaptive_Learning_Using_Artificial_Intel_f54faf82.pdf"
  },
  "992be993d9dba7000b0a415a44c5e43042fe2452": {
    "paperId": "992be993d9dba7000b0a415a44c5e43042fe2452",
    "title": "ChatGPT for (Finance) Research: The Bananarama Conjecture",
    "year": 2023,
    "authors": "M. Dowling, B. Lucey",
    "abstract": "We show, based on ratings by finance journal reviewers of generated output, that the recently released AI chatbot ChatGPT can significantly assist with finance research. In principle, these results should be generalisable across research domains. There are clear advantages for idea generation and data identification. The technology, however, is weaker on literature synthesis and developing appropriate testing frameworks. Importantly, we further demonstrate that the extent of private data and researcher domain expertise input, are key factors in determining the quality of output. We conclude by considering the implications, particularly the ethical implications, which arise from this new technology.",
    "citationCount": 479,
    "pdf_filename": "2023_ChatGPT_for__Finance__Research__The_Bana_992be993.pdf"
  },
  "57be0eee785bbfd669c1f51e9a3681105b7f82be": {
    "paperId": "57be0eee785bbfd669c1f51e9a3681105b7f82be",
    "title": "The Benefits and Challenges of ChatGPT: An Overview",
    "year": 2023,
    "authors": "Jianyang Deng, Yijia Lin",
    "abstract": "This paper provides an overview of ChatGPT, a natural language processing (NLP) system developed by Open AI. It discusses the features of ChatGPT, its benefits, and its challenges. The paper also provides an analysis of the potential applications of ChatGPT and its limitations. The paper concludes that ChatGPT is a powerful NLP system that can generate human-like conversations, but it has some challenges that must be addressed.",
    "citationCount": 473,
    "pdf_filename": "2023_The_Benefits_and_Challenges_of_ChatGPT___57be0eee.pdf"
  },
  "2cbea7615ebecea2c414d8fbad47d5d258a5c3b4": {
    "paperId": "2cbea7615ebecea2c414d8fbad47d5d258a5c3b4",
    "title": "Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning",
    "year": 2022,
    "authors": "Zhendong Wang, Jonathan J. Hunt, Mingyuan Zhou",
    "abstract": "Offline reinforcement learning (RL), which aims to learn an optimal policy using a previously collected static dataset, is an important paradigm of RL. Standard RL methods often perform poorly in this regime due to the function approximation errors on out-of-distribution actions. While a variety of regularization methods have been proposed to mitigate this issue, they are often constrained by policy classes with limited expressiveness that can lead to highly suboptimal solutions. In this paper, we propose representing the policy as a diffusion model, a recent class of highly-expressive deep generative models. We introduce Diffusion Q-learning (Diffusion-QL) that utilizes a conditional diffusion model to represent the policy. In our approach, we learn an action-value function and we add a term maximizing action-values into the training loss of the conditional diffusion model, which results in a loss that seeks optimal actions that are near the behavior policy. We show the expressiveness of the diffusion model-based policy, and the coupling of the behavior cloning and policy improvement under the diffusion model both contribute to the outstanding performance of Diffusion-QL. We illustrate the superiority of our method compared to prior works in a simple 2D bandit example with a multimodal behavior policy. We then show that our method can achieve state-of-the-art performance on the majority of the D4RL benchmark tasks.",
    "citationCount": 489,
    "pdf_filename": "2022_Diffusion_Policies_as_an_Expressive_Poli_2cbea761.pdf"
  },
  "d92c797f587ce7f1b001920ab9e6b7d31960bd77": {
    "paperId": "d92c797f587ce7f1b001920ab9e6b7d31960bd77",
    "title": "RemoteCLIP: A Vision Language Foundation Model for Remote Sensing",
    "year": 2023,
    "authors": "F. Liu, Delong Chen, Zhan-Rong Guan, Xiaocong Zhou, Jiale Zhu",
    "abstract": "General-purpose foundation models have led to recent breakthroughs in artificial intelligence (AI). In remote sensing, self-supervised learning (SSL) and masked image modeling (MIM) have been adopted to build foundation models. However, these models primarily learn low-level features and require annotated data for fine-tuning. Moreover, they are inapplicable for retrieval and zero-shot applications due to the lack of language understanding. To address these limitations, we propose RemoteCLIP, the first vision-language foundation model for remote sensing that aims to learn robust visual features with rich semantics and aligned text embeddings for seamless downstream application. To address the scarcity of pretraining data, we leverage data scaling which converts heterogeneous annotations into a unified image-caption data format based on box-to-caption (B2C) and mask-to-box (M2B) conversion. By further incorporating unmanned aerial vehicle (UAV) imagery, we produce a $12\\times $ larger pretraining dataset than the combination of all available datasets. RemoteCLIP can be applied to a variety of downstream tasks, including zero-shot image classification, linear probing, k-NN classification, few-shot classification, image-text retrieval, and object counting in remote sensing images. Evaluation of 16 datasets, including a newly introduced RemoteCount benchmark to test the object counting ability, shows that RemoteCLIP consistently outperforms baseline foundation models across different model scales. Impressively, RemoteCLIP beats the state-of-the-art (SOTA) method by 9.14% mean recall on the RSITMD dataset and 8.92% on the RSICD dataset. For zero-shot classification, our RemoteCLIP outperforms the contrastive language image pretraining (CLIP) baseline by up to 6.39% average accuracy on 12 downstream datasets.",
    "citationCount": 409,
    "pdf_filename": "2023_RemoteCLIP__A_Vision_Language_Foundation_d92c797f.pdf"
  },
  "5814bd146b37e13115af4330caf3a751159a156f": {
    "paperId": "5814bd146b37e13115af4330caf3a751159a156f",
    "title": "BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs",
    "year": 2023,
    "authors": "Sheng Zhang, Yanbo Xu, N. Usuyama, J. Bagga, Robert Tinn",
    "abstract": "Biomedical data is inherently multimodal, comprising physical measurements and natural language narratives. A generalist biomedical AI model needs to simultaneously process different modalities of data, including text and images. Therefore, training an effective generalist biomedical model requires high-quality multimodal data, such as parallel image-text pairs. Here, we present PMC-15M, a novel dataset that is two orders of magnitude larger than existing biomedical multimodal datasets such as MIMIC-CXR, and spans a diverse range of biomedical image types. PMC-15M contains 15 million biomedical image-text pairs collected from 4.4 million scientific articles. Based on PMC-15M, we have pretrained BiomedCLIP, a multimodal foundation model, with domain-specific adaptations tailored to biomedical vision-language processing. We conducted extensive experiments and ablation studies on standard biomedical imaging tasks from retrieval to classification to visual question-answering (VQA). BiomedCLIP achieved new state-of-the-art results in a wide range of standard datasets, substantially outperforming prior approaches. Intriguingly, by large-scale pretraining on diverse biomedical image types, BiomedCLIP even outperforms state-of-the-art radiology-specific models such as BioViL in radiology-specific tasks such as RSNA pneumonia detection. In summary, BiomedCLIP is a fully open-access foundation model that achieves state-of-the-art performance on various biomedical tasks, paving the way for transformative multimodal biomedical discovery and applications. We release our models at https://aka.ms/biomedclip to facilitate future research in multimodal biomedical AI.",
    "citationCount": 399,
    "pdf_filename": "2023_BiomedCLIP__a_multimodal_biomedical_foun_5814bd14.pdf"
  },
  "e6423c211fea2945aa71e1ac5ea24f8f595b4b0a": {
    "paperId": "e6423c211fea2945aa71e1ac5ea24f8f595b4b0a",
    "title": "Towards Understanding Sycophancy in Language Models",
    "year": 2023,
    "authors": "Mrinank Sharma, Meg Tong, Tomasz Korbak, D. Duvenaud, Amanda Askell",
    "abstract": "Human feedback is commonly utilized to finetune AI assistants. But human feedback may also encourage model responses that match user beliefs over truthful ones, a behaviour known as sycophancy. We investigate the prevalence of sycophancy in models whose finetuning procedure made use of human feedback, and the potential role of human preference judgments in such behavior. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophancy across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a non-negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Overall, our results indicate that sycophancy is a general behavior of state-of-the-art AI assistants, likely driven in part by human preference judgments favoring sycophantic responses.",
    "citationCount": 435,
    "pdf_filename": "2023_Towards_Understanding_Sycophancy_in_Lang_e6423c21.pdf"
  },
  "025ca4c125d6ecabc816a56f160e5c992abc76d9": {
    "paperId": "025ca4c125d6ecabc816a56f160e5c992abc76d9",
    "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
    "year": 2023,
    "authors": "Haoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Jie Huang",
    "abstract": "With the rapid progress of large language models (LLMs), many downstream NLP tasks can be well solved given appropriate prompts. Though model developers and researchers work hard on dialog safety to avoid generating harmful content from LLMs, it is still challenging to steer AI-generated content (AIGC) for the human good. As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring. In this paper, we study the privacy threats from OpenAI's ChatGPT and the New Bing enhanced by ChatGPT and show that application-integrated LLMs may cause new privacy threats. To this end, we conduct extensive experiments to support our claims and discuss LLMs' privacy implications.",
    "citationCount": 426,
    "pdf_filename": "2023_Multi_step_Jailbreaking_Privacy_Attacks__025ca4c1.pdf"
  },
  "1b1220f7f62ce1862bb5530a8c24568970814412": {
    "paperId": "1b1220f7f62ce1862bb5530a8c24568970814412",
    "title": "Chatbots in Education and Research: A Critical Examination of Ethical Implications and Solutions",
    "year": 2023,
    "authors": "C. Kooli",
    "abstract": "A new era of education and research based on chatbots and artificial intelligence is quickly growing. However, the application of these new systems is associated with several challenges and limitations, mainly related to ethics. This paper explores the potential use of AI systems and chatbots in the academic field and their impact on research and education from an ethical perspective. Through a qualitative methodology, the researcher perform exploratory research and data collection based on expert analysis and interpretation. The researcher conducted a comprehensive review of the main potential challenges associated with the use of chatbots in education and research to identify current practices, challenges, and opportunities. This explorative work provides a foundational understanding of the studied topic. It also helps us to better understand the subjective experiences and perspectives of the observed phenomenon, and uncovers their meanings and proposes potential solutions to the observed issues. This study examines the advantages and limitations of AI systems and chatbots, as well as their role in supporting human expertise and judgment. The paper also discusses the ethical challenges related to the use of AI systems and chatbots in research, as well as the potential for misuse and exploitation. It also proposes effective solutions to the observed ethical dilemmas. The research admits that we live in a new era of AI-based education and research. The observed technological advancements will definitely shift research processes and transform educative systems, especially in term of assessments. Digital assessments are going to disappear and assessment methods need to be more creative and innovative. The paper highlights the necessity of adaptation to the new reality of AI systems and chatbots. Co-living, sustainability and continuous adaptation to the development of these systems will become a matter of emergency. Raising awareness, adopting appropriate legislations and solidifying ethical values will strengthen research and protect educational systems. The presence of AI systems and chatbots in education needs to be considered as an opportunity for development rather than a threat.",
    "citationCount": 416,
    "pdf_filename": "2023_Chatbots_in_Education_and_Research__A_Cr_1b1220f7.pdf"
  },
  "372fe9428dff788274081b00634d484db0c2fda4": {
    "paperId": "372fe9428dff788274081b00634d484db0c2fda4",
    "title": "ChatGPT Goes to Law School",
    "year": 2023,
    "authors": "Jonathan H. Choi, Kristin E. Hickman, Amy B. Monahan, D. Schwarcz",
    "abstract": "How well can AI models write law school exams without human assistance? To find out",
    "citationCount": 455,
    "pdf_filename": "2023_ChatGPT_Goes_to_Law_School_372fe942.pdf"
  },
  "7d648061157109e8a1a8b382b15ded7ffe690c25": {
    "paperId": "7d648061157109e8a1a8b382b15ded7ffe690c25",
    "title": "Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers",
    "year": 2023,
    "authors": "C. Gao, F. Howard, N. Markov, E. Dyer, S. Ramesh",
    "abstract": "Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. We gathered fifth research abstracts from five high-impact factor medical journals and asked ChatGPT to generate research abstracts based on their titles and journals. Most generated abstracts were detected using an AI output detector, ‘GPT-2 Output Detector’, with % ‘fake’ scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% ‘fake’ [12.73%, 99.98%] compared with median 0.02% [IQR 0.02%, 0.09%] for the original abstracts. The AUROC of the AI output detector was 0.94. Generated abstracts scored lower than original abstracts when run through a plagiarism detector website and iThenticate (higher scores meaning more matching text found). When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, though abstracts they suspected were generated were vaguer and more formulaic. ChatGPT writes believable scientific abstracts, though with completely generated data. Depending on publisher-specific guidelines, AI output detectors may serve as an editorial tool to help maintain scientific standards. The boundaries of ethical and acceptable use of large language models to help scientific writing are still being discussed, and different journals and conferences are adopting varying policies.",
    "citationCount": 455,
    "pdf_filename": "2023_Comparing_scientific_abstracts_generated_7d648061.pdf"
  },
  "1f3cea63caa1c773f8e1676967271dac4166b4c7": {
    "paperId": "1f3cea63caa1c773f8e1676967271dac4166b4c7",
    "title": "TEMOS: Generating diverse human motions from textual descriptions",
    "year": 2022,
    "authors": "Mathis Petrovich, Michael J. Black, Gul Varol",
    "abstract": "We address the problem of generating diverse 3D human motions from textual descriptions. This challenging task requires joint modeling of both modalities: understanding and extracting useful human-centric information from the text, and then generating plausible and realistic sequences of human poses. In contrast to most previous work which focuses on generating a single, deterministic, motion from a textual description, we design a variational approach that can produce multiple diverse human motions. We propose TEMOS, a text-conditioned generative model leveraging variational autoencoder (VAE) training with human motion data, in combination with a text encoder that produces distribution parameters compatible with the VAE latent space. We show the TEMOS framework can produce both skeleton-based animations as in prior work, as well more expressive SMPL body motions. We evaluate our approach on the KIT Motion-Language benchmark and, despite being relatively straightforward, demonstrate significant improvements over the state of the art. Code and models are available on our webpage.",
    "citationCount": 499,
    "pdf_filename": "2022_TEMOS__Generating_diverse_human_motions__1f3cea63.pdf"
  },
  "ef669bb2d0a3e957a91c1dde85ce01c6984ad7d6": {
    "paperId": "ef669bb2d0a3e957a91c1dde85ce01c6984ad7d6",
    "title": "Blended Latent Diffusion",
    "year": 2022,
    "authors": "Omri Avrahami, Ohad Fried, Dani Lischinski",
    "abstract": "The tremendous progress in neural image generation, coupled with the emergence of seemingly omnipotent vision-language models has finally enabled text-based interfaces for creating and editing images. Handling generic images requires a diverse underlying generative model, hence the latest works utilize diffusion models, which were shown to surpass GANs in terms of diversity. One major drawback of diffusion models, however, is their relatively slow inference time. In this paper, we present an accelerated solution to the task of local text-driven editing of generic images, where the desired edits are confined to a user-provided mask. Our solution leverages a text-to-image Latent Diffusion Model (LDM), which speeds up diffusion by operating in a lower-dimensional latent space and eliminating the need for resource-intensive CLIP gradient calculations at each diffusion step. We first enable LDM to perform local image edits by blending the latents at each step, similarly to Blended Diffusion. Next we propose an optimization-based solution for the inherent inability of LDM to accurately reconstruct images. Finally, we address the scenario of performing local edits using thin masks. We evaluate our method against the available baselines both qualitatively and quantitatively and demonstrate that in addition to being faster, it produces more precise results.",
    "citationCount": 474,
    "pdf_filename": "2022_Blended_Latent_Diffusion_ef669bb2.pdf"
  },
  "8284283b8ff21861d8a04a61c2a8370c234b5b20": {
    "paperId": "8284283b8ff21861d8a04a61c2a8370c234b5b20",
    "title": "Measuring EFL learners’ use of ChatGPT in informal digital learning of English based on the technology acceptance model",
    "year": 2023,
    "authors": "Guangxian Liu, Chaojun Ma",
    "abstract": "ABSTRACT Purpose: This study aims to generate empirical insights into the extent to which ChatGPT, a highly capable AI chatbot building on OpenAI's GPT family, is perceived and leveraged by EFL learners beyond the classroom. Design/Methodology: This quantitative cross-sectional investigation draws upon the technology acceptance model (TAM) as developed by (Davis, F. D. 1989. “Perceived Usefulness, Perceived Ease of use, and User Acceptance of Information Technology.” Management Information System Quarterly 13 (3): 983–1003) to conceptualize EFL learners’ attitudes, intentions, and actual behaviors of using ChatGPT in their informal digital learning of English. A total of 405 EFL learners answered the revised TAM questionnaire with scales including Perceived Ease of Use, Perceived Usefulness, Attitude, Behavioral Intention, and Actual Use. Findings: The results of structural equation modeling analyses indicated that while Perceived Ease of Use fails to predict learners’ Attitude directly, it can influence Attitude through the full mediator Perceived Usefulness. It was also found that learners who take positive attitudes toward the usefulness of ChatGPT tend to demonstrate a higher level of Behavioral Intention, which positively and strongly predicts their Actual Use of ChatGPT in English learning outside the classroom. Originality/value: This study provides empirical evidence that supports the potential of ChatGPT as a powerful language-learning tool that EFL learners should utilize to participate in the ecological CALL creatively and productively.",
    "citationCount": 332,
    "pdf_filename": "2023_Measuring_EFL_learners__use_of_ChatGPT_i_8284283b.pdf"
  },
  "42b323b6df79e49c9bf5cee2a91398a7fa3d594d": {
    "paperId": "42b323b6df79e49c9bf5cee2a91398a7fa3d594d",
    "title": "Knowledge Graphs: Opportunities and Challenges",
    "year": 2023,
    "authors": "Ciyuan Peng, Feng Xia, Mehdi Naseriparsa, Francesco Osborne",
    "abstract": "With the explosive growth of artificial intelligence (AI) and big data, it has become vitally important to organize and represent the enormous volume of knowledge appropriately. As graph data, knowledge graphs accumulate and convey knowledge of the real world. It has been well-recognized that knowledge graphs effectively represent complex information; hence, they rapidly gain the attention of academia and industry in recent years. Thus to develop a deeper understanding of knowledge graphs, this paper presents a systematic overview of this field. Specifically, we focus on the opportunities and challenges of knowledge graphs. We first review the opportunities of knowledge graphs in terms of two aspects: (1) AI systems built upon knowledge graphs; (2) potential application fields of knowledge graphs. Then, we thoroughly discuss severe technical challenges in this field, such as knowledge graph embeddings, knowledge acquisition, knowledge graph completion, knowledge fusion, and knowledge reasoning. We expect that this survey will shed new light on future research and the development of knowledge graphs.",
    "citationCount": 409,
    "pdf_filename": "2023_Knowledge_Graphs__Opportunities_and_Chal_42b323b6.pdf"
  },
  "556505a06b7d09fd4e8b415d56561d950a6790c2": {
    "paperId": "556505a06b7d09fd4e8b415d56561d950a6790c2",
    "title": "Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for Cross-City Semantic Segmentation using High-Resolution Domain Adaptation Networks",
    "year": 2023,
    "authors": "D. Hong, Bing Zhang, Hao Li, Yuxuan Li, Jing Yao",
    "abstract": "Artificial intelligence (AI) approaches nowadays have gained remarkable success in single-modality-dominated remote sensing (RS) applications, especially with an emphasis on individual urban environments (e.g., single cities or regions). Yet these AI models tend to meet the performance bottleneck in the case studies across cities or regions, due to the lack of diverse RS information and cutting-edge solutions with high generalization ability. To this end, we build a new set of multimodal remote sensing benchmark datasets (including hyperspectral, multispectral, SAR) for the study purpose of the cross-city semantic segmentation task (called C2Seg dataset), which consists of two cross-city scenes, i.e., Berlin-Augsburg (in Germany) and Beijing-Wuhan (in China). Beyond the single city, we propose a high-resolution domain adaptation network, HighDAN for short, to promote the AI model's generalization ability from the multi-city environments. HighDAN is capable of retaining the spatially topological structure of the studied urban scene well in a parallel high-to-low resolution fusion fashion but also closing the gap derived from enormous differences of RS image representations between different cities by means of adversarial learning. In addition, the Dice loss is considered in HighDAN to alleviate the class imbalance issue caused by factors across cities. Extensive experiments conducted on the C2Seg dataset show the superiority of our HighDAN in terms of segmentation performance and generalization ability, compared to state-of-the-art competitors. The C2Seg dataset and the semantic segmentation toolbox (involving the proposed HighDAN) will be available publicly at https://github.com/danfenghong.",
    "citationCount": 430,
    "pdf_filename": "2023_Cross_City_Matters__A_Multimodal_Remote__556505a0.pdf"
  },
  "6f9f5e84221b991756500676031e0ebb4dc00b0d": {
    "paperId": "6f9f5e84221b991756500676031e0ebb4dc00b0d",
    "title": "What ChatGPT means for universities: Perceptions of scholars and students",
    "year": 2023,
    "authors": "Articles Info",
    "abstract": "This study investigates the implications of ChatGPT, an AI-powered language model, for students and universities by examining the perceptions of scholars and students. The responses of seven scholars and 14 PhD students from four countries – Turkey, Sweden, Canada and Australia – are analysed using a thematic content analysis approach. Nine key themes emerge from the findings. According to their frequency of recurrence, these themes are: “Evolution of learning and education systems”, “changing role of educators”, “impact on assessment and evaluation”, “ethical and social considerations”, “future of work and employability”, “personalized learning”, “digital literacy and AI integration”, “AI as an extension of the human brain”, and “importance of human characteristics”. The potential benefits of AI in education as well as the challenges and barriers that may arise from its integration are discussed in the context of existing literature. Based on these findings, suggestions for future research include further exploration of the ethical implications of AI for education, the development of strategies to manage privacy concerns, and the investigation of how educational institutions can best prepare for the integration of AI technologies. The paper concludes by emphasizing the importance of understanding the potential opportunities and challenges associated with AI in higher education and the need for continued research in this area.",
    "citationCount": 334,
    "pdf_filename": "2023_What_ChatGPT_means_for_universities__Per_6f9f5e84.pdf"
  },
  "534c58762e69d7afbcb0f6a7e53c07484f6d4891": {
    "paperId": "534c58762e69d7afbcb0f6a7e53c07484f6d4891",
    "title": "Towards Measuring the Representation of Subjective Global Opinions in Language Models",
    "year": 2023,
    "authors": "Esin Durmus, Karina Nyugen, Thomas Liao, Nicholas Schiefer, Amanda Askell",
    "abstract": "Large language models (LLMs) may not equitably represent diverse global perspectives on societal issues. In this paper, we develop a quantitative framework to evaluate whose opinions model-generated responses are more similar to. We first build a dataset, GlobalOpinionQA, comprised of questions and answers from cross-national surveys designed to capture diverse opinions on global issues across different countries. Next, we define a metric that quantifies the similarity between LLM-generated survey responses and human responses, conditioned on country. With our framework, we run three experiments on an LLM trained to be helpful, honest, and harmless with Constitutional AI. By default, LLM responses tend to be more similar to the opinions of certain populations, such as those from the USA, and some European and South American countries, highlighting the potential for biases. When we prompt the model to consider a particular country's perspective, responses shift to be more similar to the opinions of the prompted populations, but can reflect harmful cultural stereotypes. When we translate GlobalOpinionQA questions to a target language, the model's responses do not necessarily become the most similar to the opinions of speakers of those languages. We release our dataset for others to use and build on. Our data is at https://huggingface.co/datasets/Anthropic/llm_global_opinions. We also provide an interactive visualization at https://llmglobalvalues.anthropic.com.",
    "citationCount": 326,
    "pdf_filename": "2023_Towards_Measuring_the_Representation_of__534c5876.pdf"
  },
  "28bedb69141bb969614861c697ff17aef17d29f4": {
    "paperId": "28bedb69141bb969614861c697ff17aef17d29f4",
    "title": "Re-Thinking Data Strategy and Integration for Artificial Intelligence: Concepts, Opportunities, and Challenges",
    "year": 2023,
    "authors": "Abdulaziz Aldoseri, K. Al-Khalifa, Abdel Magid Hamouda",
    "abstract": "The use of artificial intelligence (AI) is becoming more prevalent across industries such as healthcare, finance, and transportation. Artificial intelligence is based on the analysis of large datasets and requires a continuous supply of high-quality data. However, using data for AI is not without challenges. This paper comprehensively reviews and critically examines the challenges of using data for AI, including data quality, data volume, privacy and security, bias and fairness, interpretability and explainability, ethical concerns, and technical expertise and skills. This paper examines these challenges in detail and offers recommendations on how companies and organizations can address them. By understanding and addressing these challenges, organizations can harness the power of AI to make smarter decisions and gain competitive advantage in the digital age. It is expected, since this review article provides and discusses various strategies for data challenges for AI over the last decade, that it will be very helpful to the scientific research community to create new and novel ideas to rethink our approaches to data strategies for AI.",
    "citationCount": 377,
    "pdf_filename": "2023_Re_Thinking_Data_Strategy_and_Integratio_28bedb69.pdf"
  },
  "4d0c07cce3fe08c63a195ff8719a9dcbf4badb8a": {
    "paperId": "4d0c07cce3fe08c63a195ff8719a9dcbf4badb8a",
    "title": "Convolutional Neural Networks: A Survey",
    "year": 2023,
    "authors": "M. Krichen",
    "abstract": "Artificial intelligence (AI) has become a cornerstone of modern technology, revolutionizing industries from healthcare to finance. Convolutional neural networks (CNNs) are a subset of AI that have emerged as a powerful tool for various tasks including image recognition, speech recognition, natural language processing (NLP), and even in the field of genomics, where they have been utilized to classify DNA sequences. This paper provides a comprehensive overview of CNNs and their applications in image recognition tasks. It first introduces the fundamentals of CNNs, including the layers of CNNs, convolution operation (Conv_Op), Feat_Maps, activation functions (Activ_Func), and training methods. It then discusses several popular CNN architectures such as LeNet, AlexNet, VGG, ResNet, and InceptionNet, and compares their performance. It also examines when to use CNNs, their advantages and limitations, and provides recommendations for developers and data scientists, including preprocessing the data, choosing appropriate hyperparameters (Hyper_Param), and evaluating model performance. It further explores the existing platforms and libraries for CNNs such as TensorFlow, Keras, PyTorch, Caffe, and MXNet, and compares their features and functionalities. Moreover, it estimates the cost of using CNNs and discusses potential cost-saving strategies. Finally, it reviews recent developments in CNNs, including attention mechanisms, capsule networks, transfer learning, adversarial training, quantization and compression, and enhancing the reliability and efficiency of CNNs through formal methods. The paper is concluded by summarizing the key takeaways and discussing the future directions of CNN research and development.",
    "citationCount": 419,
    "pdf_filename": "2023_Convolutional_Neural_Networks__A_Survey_4d0c07cc.pdf"
  },
  "b4cff79e22f2da53cf59e1f47726168c2020d1bc": {
    "paperId": "b4cff79e22f2da53cf59e1f47726168c2020d1bc",
    "title": "Artificial Intelligence–Based Chatbots for Promoting Health Behavioral Changes: Systematic Review",
    "year": 2023,
    "authors": "A. Aggarwal, C. Tam, Dezhi Wu, Xiaoming Li, S. Qiao",
    "abstract": "Background Artificial intelligence (AI)–based chatbots can offer personalized, engaging, and on-demand health promotion interventions. Objective The aim of this systematic review was to evaluate the feasibility, efficacy, and intervention characteristics of AI chatbots for promoting health behavior change. Methods A comprehensive search was conducted in 7 bibliographic databases (PubMed, IEEE Xplore, ACM Digital Library, PsycINFO, Web of Science, Embase, and JMIR publications) for empirical articles published from 1980 to 2022 that evaluated the feasibility or efficacy of AI chatbots for behavior change. The screening, extraction, and analysis of the identified articles were performed by following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Results Of the 15 included studies, several demonstrated the high efficacy of AI chatbots in promoting healthy lifestyles (n=6, 40%), smoking cessation (n=4, 27%), treatment or medication adherence (n=2, 13%), and reduction in substance misuse (n=1, 7%). However, there were mixed results regarding feasibility, acceptability, and usability. Selected behavior change theories and expert consultation were used to develop the behavior change strategies of AI chatbots, including goal setting, monitoring, real-time reinforcement or feedback, and on-demand support. Real-time user-chatbot interaction data, such as user preferences and behavioral performance, were collected on the chatbot platform to identify ways of providing personalized services. The AI chatbots demonstrated potential for scalability by deployment through accessible devices and platforms (eg, smartphones and Facebook Messenger). The participants also reported that AI chatbots offered a nonjudgmental space for communicating sensitive information. However, the reported results need to be interpreted with caution because of the moderate to high risk of internal validity, insufficient description of AI techniques, and limitation for generalizability. Conclusions AI chatbots have demonstrated the efficacy of health behavior change interventions among large and diverse populations; however, future studies need to adopt robust randomized control trials to establish definitive conclusions.",
    "citationCount": 348,
    "pdf_filename": "2023_Artificial_Intelligence_Based_Chatbots_f_b4cff79e.pdf"
  },
  "1813fd41011df17a789084c6323f61791d6ff066": {
    "paperId": "1813fd41011df17a789084c6323f61791d6ff066",
    "title": "Ethical Considerations of Using ChatGPT in Health Care",
    "year": 2023,
    "authors": "Chang-Jhan Wang, Siru Liu, Han Yang, Jiulin Guo, Yuxuan Wu",
    "abstract": "ChatGPT has promising applications in health care, but potential ethical issues need to be addressed proactively to prevent harm. ChatGPT presents potential ethical challenges from legal, humanistic, algorithmic, and informational perspectives. Legal ethics concerns arise from the unclear allocation of responsibility when patient harm occurs and from potential breaches of patient privacy due to data collection. Clear rules and legal boundaries are needed to properly allocate liability and protect users. Humanistic ethics concerns arise from the potential disruption of the physician-patient relationship, humanistic care, and issues of integrity. Overreliance on artificial intelligence (AI) can undermine compassion and erode trust. Transparency and disclosure of AI-generated content are critical to maintaining integrity. Algorithmic ethics raise concerns about algorithmic bias, responsibility, transparency and explainability, as well as validation and evaluation. Information ethics include data bias, validity, and effectiveness. Biased training data can lead to biased output, and overreliance on ChatGPT can reduce patient adherence and encourage self-diagnosis. Ensuring the accuracy, reliability, and validity of ChatGPT-generated content requires rigorous validation and ongoing updates based on clinical practice. To navigate the evolving ethical landscape of AI, AI in health care must adhere to the strictest ethical standards. Through comprehensive ethical guidelines, health care professionals can ensure the responsible use of ChatGPT, promote accurate and reliable information exchange, protect patient privacy, and empower patients to make informed decisions about their health care.",
    "citationCount": 368,
    "pdf_filename": "2023_Ethical_Considerations_of_Using_ChatGPT__1813fd41.pdf"
  },
  "dedfe929d182cc3537a9ed765d589b4735ce062a": {
    "paperId": "dedfe929d182cc3537a9ed765d589b4735ce062a",
    "title": "On the Planning Abilities of Large Language Models - A Critical Investigation",
    "year": 2023,
    "authors": "Karthik Valmeekam, Matthew Marquez, S. Sreedharan, Subbarao Kambhampati",
    "abstract": "Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs as a source of heuristic guidance for other agents (AI planners) in their planning tasks. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs' ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of ~12% across the domains. However, the results in the heuristic mode show more promise. In the heuristic mode, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation.",
    "citationCount": 325,
    "pdf_filename": "2023_On_the_Planning_Abilities_of_Large_Langu_dedfe929.pdf"
  },
  "bc873623197ac01caecdeadcb0d36fd8de7040fa": {
    "paperId": "bc873623197ac01caecdeadcb0d36fd8de7040fa",
    "title": "The impact of ChatGPT on higher education",
    "year": 2023,
    "authors": "Juan M. Dempere, K. Modugu, Allam Hesham, Lakshmana Kumar Ramasamy",
    "abstract": "This study explores the effects of Artificial Intelligence (AI) chatbots, with a particular focus on OpenAI’s ChatGPT, on Higher Education Institutions (HEIs). With the rapid advancement of AI, understanding its implications in the educational sector becomes paramount.Utilizing databases like PubMed, IEEE Xplore, and Google Scholar, we systematically searched for literature on AI chatbots’ impact on HEIs. Our criteria prioritized peer-reviewed articles, prominent media outlets, and English publications, excluding tangential AI chatbot mentions. After selection, data extraction focused on authors, study design, and primary findings. The analysis combined descriptive and thematic approaches, emphasizing patterns and applications of AI chatbots in HEIs.The literature review revealed diverse perspectives on ChatGPT’s potential in education. Notable benefits include research support, automated grading, and enhanced human-computer interaction. However, concerns such as online testing security, plagiarism, and broader societal and economic impacts like job displacement, the digital literacy gap, and AI-induced anxiety were identified. The study also underscored the transformative architecture of ChatGPT and its versatile applications in the educational sector. Furthermore, potential advantages like streamlined enrollment, improved student services, teaching enhancements, research aid, and increased student retention were highlighted. Conversely, risks such as privacy breaches, misuse, bias, misinformation, decreased human interaction, and accessibility issues were identified.While AI’s global expansion is undeniable, there is a pressing need for balanced regulation in its application within HEIs. Faculty members are encouraged to utilize AI tools like ChatGPT proactively and ethically to mitigate risks, especially academic fraud. Despite the study’s limitations, including an incomplete representation of AI’s overall effect on education and the absence of concrete integration guidelines, it is evident that AI technologies like ChatGPT present both significant benefits and risks. The study advocates for a thoughtful and responsible integration of such technologies within HEIs.",
    "citationCount": 333,
    "pdf_filename": "2023_The_impact_of_ChatGPT_on_higher_educatio_bc873623.pdf"
  },
  "4cd3ae84e24cfff89ef022e36991df314aac83e2": {
    "paperId": "4cd3ae84e24cfff89ef022e36991df314aac83e2",
    "title": "Will ChatGPT get you caught? Rethinking of Plagiarism Detection",
    "year": 2023,
    "authors": "M. Khalil, Erkan Er",
    "abstract": "The rise of Artificial Intelligence (AI) technology and its impact on education has been a topic of growing concern in recent years. The new generation AI systems such as chatbots have become more accessible on the Internet and stronger in terms of capabilities. The use of chatbots, particularly ChatGPT, for generating academic essays at schools and colleges has sparked fears among scholars. This study aims to explore the originality of contents produced by one of the most popular AI chatbots, ChatGPT. To this end, two popular plagiarism detection tools were used to evaluate the originality of 50 essays generated by ChatGPT on various topics. Our results manifest that ChatGPT has a great potential to generate sophisticated text outputs without being well caught by the plagiarism check software. In other words, ChatGPT can create content on many topics with high originality as if they were written by someone. These findings align with the recent concerns about students using chatbots for an easy shortcut to success with minimal or no effort. Moreover, ChatGPT was asked to verify if the essays were generated by itself, as an additional measure of plagiarism check, and it showed superior performance compared to the traditional plagiarism-detection tools. The paper discusses the need for institutions to consider appropriate measures to mitigate potential plagiarism issues and advise on the ongoing debate surrounding the impact of AI technology on education. Further implications are discussed in the paper.",
    "citationCount": 303,
    "pdf_filename": "2023_Will_ChatGPT_get_you_caught__Rethinking__4cd3ae84.pdf"
  },
  "19cd2250f419666d4df441bae7ade1dd9a2f6bf9": {
    "paperId": "19cd2250f419666d4df441bae7ade1dd9a2f6bf9",
    "title": "ChatGPT in Healthcare: A Taxonomy and Systematic Review",
    "year": 2023,
    "authors": "Jianning Li, Amin Dada, B. Puladi, J. Kleesiek, Jan Egger",
    "abstract": "The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the 'productization' of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the 'status quo' of ChatGPT in medical applications, for general readers, healthcare professionals as well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword 'ChatGPT'. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or 'passing' performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications.",
    "citationCount": 308,
    "pdf_filename": "2023_ChatGPT_in_Healthcare__A_Taxonomy_and_Sy_19cd2250.pdf"
  },
  "1ee074a4af366da2e58160a83b97783289b64812": {
    "paperId": "1ee074a4af366da2e58160a83b97783289b64812",
    "title": "AlphaFold2 and its applications in the fields of biology and medicine",
    "year": 2023,
    "authors": "Zhenyu Yang, Xiaoxi Zeng, Yi Zhao, Runsheng Chen",
    "abstract": "AlphaFold2 (AF2) is an artificial intelligence (AI) system developed by DeepMind that can predict three-dimensional (3D) structures of proteins from amino acid sequences with atomic-level accuracy. Protein structure prediction is one of the most challenging problems in computational biology and chemistry, and has puzzled scientists for 50 years. The advent of AF2 presents an unprecedented progress in protein structure prediction and has attracted much attention. Subsequent release of structures of more than 200 million proteins predicted by AF2 further aroused great enthusiasm in the science community, especially in the fields of biology and medicine. AF2 is thought to have a significant impact on structural biology and research areas that need protein structure information, such as drug discovery, protein design, prediction of protein function, et al. Though the time is not long since AF2 was developed, there are already quite a few application studies of AF2 in the fields of biology and medicine, with many of them having preliminarily proved the potential of AF2. To better understand AF2 and promote its applications, we will in this article summarize the principle and system architecture of AF2 as well as the recipe of its success, and particularly focus on reviewing its applications in the fields of biology and medicine. Limitations of current AF2 prediction will also be discussed.",
    "citationCount": 329,
    "pdf_filename": "2023_AlphaFold2_and_its_applications_in_the_f_1ee074a4.pdf"
  },
  "c0aec04ee86c0724d61c976f19590fbe9c615723": {
    "paperId": "c0aec04ee86c0724d61c976f19590fbe9c615723",
    "title": "Creating Large Language Model Applications Utilizing LangChain: A Primer on Developing LLM Apps Fast",
    "year": 2023,
    "authors": "Oguzhan Topsakal, T. Akinci",
    "abstract": "This study focuses on the utilization of Large Language Models (LLMs) for the rapid development of applications, with a spotlight on LangChain, an open-source software library. LLMs have been rapidly adopted due to their capabilities in a range of tasks, including essay composition, code writing, explanation, and debugging, with OpenAI’s ChatGPT popularizing their usage among millions ofusers. The crux of the study centers around LangChain, designed to expedite the development of bespoke AI applications using LLMs. LangChain has been widely recognized in the AI community for its ability to seamlessly interact with various data sources and applications. The paper provides an examination of LangChain's core features, including its components and chains, acting as modular abstractions and customizable, use-case-specific pipelines, respectively. Through a series of practical examples, the study elucidates the potential of this framework in fostering the swift development of LLM-based applications.",
    "citationCount": 301,
    "pdf_filename": "2023_Creating_Large_Language_Model_Applicatio_c0aec04e.pdf"
  },
  "c539f6ab5818bde96f61298856cb0c38f6268369": {
    "paperId": "c539f6ab5818bde96f61298856cb0c38f6268369",
    "title": "On Aliased Resizing and Surprising Subtleties in GAN Evaluation",
    "year": 2022,
    "authors": "Gaurav Parmar, Richard Zhang, Jun-Yan Zhu",
    "abstract": "Metrics for evaluating generative models aim to measure the discrepancy between real and generated images. The often-used Fréchet Inception Distance (FID) metric, for example, extracts “high-level” features using a deep network from the two sets. However, we find that the differences in “low-level” preprocessing, specifically image resizing and compression, can induce large variations and have unforeseen consequences. For instance, when resizing an image, e.g., with a bilinear or bicubic kernel, signal processing principles mandate adjusting prefilter width depending on the downsampling factor, to antialias to the appropriate bandwidth. However, commonly-used implementations use a fixed-width prefilter, resulting in aliasing artifacts. Such aliasing leads to corruptions in the feature extraction down-stream. Next, lossy compression, such as JPEG, is commonly used to reduce the file size of an image. Although designed to minimally degrade the perceptual quality of an image, the operation also produces variations downstream. Furthermore, we show that if compression is used on real training images, FID can actually improve if the generated images are also subsequently compressed. This paper shows that choices in low-level image processing have been an under-appreciated aspect of generative modeling. We identify and characterize variations in generative modeling development pipelines, provide recommendations based on signal processing principles, and release a reference implementation to facilitate future comparisons.",
    "citationCount": 450,
    "pdf_filename": "2022_On_Aliased_Resizing_and_Surprising_Subtl_c539f6ab.pdf"
  },
  "379e42895f6d40ab9e9559609f505aba89145a5d": {
    "paperId": "379e42895f6d40ab9e9559609f505aba89145a5d",
    "title": "Efficiently Scaling Transformer Inference",
    "year": 2022,
    "authors": "Reiner Pope, Sholto Douglas, A. Chowdhery, Jacob Devlin, James Bradbury",
    "abstract": "We study the problem of efficient generative inference for Transformer models, in one of its most challenging settings: large deep models, with tight latency targets and long sequence lengths. Better understanding of the engineering tradeoffs for inference for large Transformer-based models is important as use cases of these models are growing rapidly throughout application areas. We develop a simple analytical model for inference efficiency to select the best multi-dimensional partitioning techniques optimized for TPU v4 slices based on the application requirements. We combine these with a suite of low-level optimizations to achieve a new Pareto frontier on the latency and model FLOPS utilization (MFU) tradeoffs on 500B+ parameter models that outperforms the FasterTransformer suite of benchmarks. We further show that with appropriate partitioning, the lower memory requirements of multiquery attention (i.e. multiple query heads share single key/value head) enables scaling up to 32x larger context lengths. Finally, we achieve a low-batch-size latency of 29ms per token during generation (using int8 weight quantization) and a 76% MFU during large-batch-size processing of input tokens, while supporting a long 2048-token context length on the PaLM 540B parameter model.",
    "citationCount": 455,
    "pdf_filename": "2022_Efficiently_Scaling_Transformer_Inferenc_379e4289.pdf"
  },
  "25d3a4e048d0020ba9cffc6442ebd4e7bb548a55": {
    "paperId": "25d3a4e048d0020ba9cffc6442ebd4e7bb548a55",
    "title": "TabDDPM: Modelling Tabular Data with Diffusion Models",
    "year": 2022,
    "authors": "Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, Artem Babenko",
    "abstract": "Denoising diffusion probabilistic models are currently becoming the leading paradigm of generative modeling for many important data modalities. Being the most prevalent in the computer vision community, diffusion models have also recently gained some attention in other domains, including speech, NLP, and graph-like data. In this work, we investigate if the framework of diffusion models can be advantageous for general tabular problems, where datapoints are typically represented by vectors of heterogeneous features. The inherent heterogeneity of tabular data makes it quite challenging for accurate modeling, since the individual features can be of completely different nature, i.e., some of them can be continuous and some of them can be discrete. To address such data types, we introduce TabDDPM -- a diffusion model that can be universally applied to any tabular dataset and handles any type of feature. We extensively evaluate TabDDPM on a wide set of benchmarks and demonstrate its superiority over existing GAN/VAE alternatives, which is consistent with the advantage of diffusion models in other fields. Additionally, we show that TabDDPM is eligible for privacy-oriented setups, where the original datapoints cannot be publicly shared.",
    "citationCount": 381,
    "pdf_filename": "2022_TabDDPM__Modelling_Tabular_Data_with_Dif_25d3a4e0.pdf"
  },
  "7309bf7607f4b4339f4ae288f3ad4fc36d139b5a": {
    "paperId": "7309bf7607f4b4339f4ae288f3ad4fc36d139b5a",
    "title": "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions",
    "year": 2022,
    "authors": "Sitan Chen, Sinho Chewi, Jungshian Li, Yuanzhi Li, A. Salim",
    "abstract": "We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\\cdot$E 2. Our main result is that, assuming accurate score estimates, such SGMs can efficiently sample from essentially any realistic data distribution. In contrast to prior works, our results (1) hold for an $L^2$-accurate score estimate (rather than $L^\\infty$-accurate); (2) do not require restrictive functional inequality conditions that preclude substantial non-log-concavity; (3) scale polynomially in all relevant problem parameters; and (4) match state-of-the-art complexity guarantees for discretization of the Langevin diffusion, provided that the score error is sufficiently small. We view this as strong theoretical justification for the empirical success of SGMs. We also examine SGMs based on the critically damped Langevin diffusion (CLD). Contrary to conventional wisdom, we provide evidence that the use of the CLD does not reduce the complexity of SGMs.",
    "citationCount": 345,
    "pdf_filename": "2022_Sampling_is_as_easy_as_learning_the_scor_7309bf76.pdf"
  },
  "17d068e78e6f25e65cb08319b19b58279bb8b214": {
    "paperId": "17d068e78e6f25e65cb08319b19b58279bb8b214",
    "title": "Understanding Diffusion Models: A Unified Perspective",
    "year": 2022,
    "authors": "Calvin Luo",
    "abstract": "Diffusion models have shown incredible capabilities as generative models; indeed, they power the current state-of-the-art models on text-conditioned image generation such as Imagen and DALL-E 2. In this work we review, demystify, and unify the understanding of diffusion models across both variational and score-based perspectives. We first derive Variational Diffusion Models (VDM) as a special case of a Markovian Hierarchical Variational Autoencoder, where three key assumptions enable tractable computation and scalable optimization of the ELBO. We then prove that optimizing a VDM boils down to learning a neural network to predict one of three potential objectives: the original source input from any arbitrary noisification of it, the original source noise from any arbitrarily noisified input, or the score function of a noisified input at any arbitrary noise level. We then dive deeper into what it means to learn the score function, and connect the variational perspective of a diffusion model explicitly with the Score-based Generative Modeling perspective through Tweedie's Formula. Lastly, we cover how to learn a conditional distribution using diffusion models via guidance.",
    "citationCount": 447,
    "pdf_filename": "2022_Understanding_Diffusion_Models__A_Unifie_17d068e7.pdf"
  },
  "525f459f369032e2f2fa3eb1d60da34ab99191bc": {
    "paperId": "525f459f369032e2f2fa3eb1d60da34ab99191bc",
    "title": "Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise",
    "year": 2022,
    "authors": "Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie Li, Hamid Kazemi",
    "abstract": "Standard diffusion models involve an image transform -- adding Gaussian noise -- and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community's understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes. Our code is available at https://github.com/arpitbansal297/Cold-Diffusion-Models",
    "citationCount": 356,
    "pdf_filename": "2022_Cold_Diffusion__Inverting_Arbitrary_Imag_525f459f.pdf"
  },
  "04f5553934c458305a501d63323f1b841fd5d102": {
    "paperId": "04f5553934c458305a501d63323f1b841fd5d102",
    "title": "BigVGAN: A Universal Neural Vocoder with Large-Scale Training",
    "year": 2022,
    "authors": "Sang-gil Lee, Wei Ping, Boris Ginsburg, Bryan Catanzaro, Sung-Hoon Yoon",
    "abstract": "Despite recent progress in generative adversarial network (GAN)-based vocoders, where the model generates raw waveform conditioned on acoustic features, it is challenging to synthesize high-fidelity audio for numerous speakers across various recording environments. In this work, we present BigVGAN, a universal vocoder that generalizes well for various out-of-distribution scenarios without fine-tuning. We introduce periodic activation function and anti-aliased representation into the GAN generator, which brings the desired inductive bias for audio synthesis and significantly improves audio quality. In addition, we train our GAN vocoder at the largest scale up to 112M parameters, which is unprecedented in the literature. We identify and address the failure modes in large-scale GAN training for audio, while maintaining high-fidelity output without over-regularization. Our BigVGAN, trained only on clean speech (LibriTTS), achieves the state-of-the-art performance for various zero-shot (out-of-distribution) conditions, including unseen speakers, languages, recording environments, singing voices, music, and instrumental audio. We release our code and model at: https://github.com/NVIDIA/BigVGAN",
    "citationCount": 365,
    "pdf_filename": "2022_BigVGAN__A_Universal_Neural_Vocoder_with_04f55539.pdf"
  },
  "20f6fce7726e7b3ab4ca45ef40d92b79f093f825": {
    "paperId": "20f6fce7726e7b3ab4ca45ef40d92b79f093f825",
    "title": "AnoDDPM: Anomaly Detection with Denoising Diffusion Probabilistic Models using Simplex Noise",
    "year": 2022,
    "authors": "Julian Wyatt, Adam Leach, Sebastian M. Schmon, Chris G. Willcocks",
    "abstract": "Generative models have been shown to provide a powerful mechanism for anomaly detection by learning to model healthy or normal reference data which can subsequently be used as a baseline for scoring anomalies. In this work we consider denoising diffusion probabilistic models (DDPMs) for unsupervised anomaly detection. DDPMs have superior mode coverage over generative adversarial networks (GANs) and higher sample quality than variational autoencoders (VAEs). However, this comes at the expense of poor scalability and increased sampling times due to the long Markov chain sequences required. We observe that within reconstruction-based anomaly detection a full-length Markov chain diffusion is not required. This leads us to develop a novel partial diffusion anomaly detection strategy that scales to high-resolution imagery, named AnoDDPM. A secondary problem is that Gaussian diffusion fails to capture larger anomalies; therefore we develop a multi-scale simplex noise diffusion process that gives control over the target anomaly size. AnoDDPM with simplex noise is shown to significantly outperform both f-AnoGAN and Gaussian diffusion for the tumorous dataset of 22 T1-weighted MRI scans (CCBS Edinburgh) qualitatively and quantitatively (improvement of +25.5% Sørensen–Dice coefficient, +17.6% IoU and +7.4% AUC).",
    "citationCount": 370,
    "pdf_filename": "2022_AnoDDPM__Anomaly_Detection_with_Denoisin_20f6fce7.pdf"
  },
  "394bd431e522b86581086bcb5cd9be161cf1cdf4": {
    "paperId": "394bd431e522b86581086bcb5cd9be161cf1cdf4",
    "title": "Language Models are Realistic Tabular Data Generators",
    "year": 2022,
    "authors": "V. Borisov, Kathrin Sessler, Tobias Leemann, Martin Pawelczyk, Gjergji Kasneci",
    "abstract": "Tabular data is among the oldest and most ubiquitous forms of data. However, the generation of synthetic samples with the original data's characteristics remains a significant challenge for tabular data. While many generative models from the computer vision domain, such as variational autoencoders or generative adversarial networks, have been adapted for tabular data generation, less research has been directed towards recent transformer-based large language models (LLMs), which are also generative in nature. To this end, we propose GReaT (Generation of Realistic Tabular data), which exploits an auto-regressive generative LLM to sample synthetic and yet highly realistic tabular data. Furthermore, GReaT can model tabular data distributions by conditioning on any subset of features; the remaining features are sampled without additional overhead. We demonstrate the effectiveness of the proposed approach in a series of experiments that quantify the validity and quality of the produced data samples from multiple angles. We find that GReaT maintains state-of-the-art performance across numerous real-world and synthetic data sets with heterogeneous feature types coming in various sizes.",
    "citationCount": 321,
    "pdf_filename": "2022_Language_Models_are_Realistic_Tabular_Da_394bd431.pdf"
  },
  "05ce31d0e48c3e700b4fd606dbba3433ea83ab2b": {
    "paperId": "05ce31d0e48c3e700b4fd606dbba3433ea83ab2b",
    "title": "On The Detection of Synthetic Images Generated by Diffusion Models",
    "year": 2022,
    "authors": "Riccardo Corvi, D. Cozzolino, G. Zingarini, G. Poggi, Koki Nagano",
    "abstract": "Over the past decade, there has been tremendous progress in creating synthetic media, mainly thanks to the development of powerful methods based on generative adversarial networks (GAN). Very recently, methods based on diffusion models (DM) have been gaining the spotlight. In addition to providing an impressive level of photorealism, they enable the creation of text-based visual content, opening up new and exciting opportunities in many different application fields, from arts to video games. On the other hand, this property is an additional asset in the hands of malicious users, who can generate and distribute fake media perfectly adapted to their attacks, posing new challenges to the media forensic community. With this work, we seek to understand how difficult it is to distinguish synthetic images generated by diffusion models from pristine ones and whether current state-of-the-art detectors are suitable for the task. To this end, first we expose the forensics traces left by diffusion models, then study how current detectors, developed for GAN-generated images, perform on these new synthetic images, especially in challenging social-network scenarios involving image compression and resizing. Datasets and code are available at https:github.com/grip-unina/DMimageDetection.",
    "citationCount": 303,
    "pdf_filename": "2022_On_The_Detection_of_Synthetic_Images_Gen_05ce31d0.pdf"
  },
  "69beb616ffdc42afe86b7487c5db82b6d88638b8": {
    "paperId": "69beb616ffdc42afe86b7487c5db82b6d88638b8",
    "title": "Restoring Vision in Adverse Weather Conditions With Patch-Based Denoising Diffusion Models",
    "year": 2022,
    "authors": "Ozan Özdenizci, R. Legenstein",
    "abstract": "Image restoration under adverse weather conditions has been of significant interest for various computer vision applications. Recent successful methods rely on the current progress in deep neural network architectural designs (e.g., with vision transformers). Motivated by the recent progress achieved with state-of-the-art conditional generative models, we present a novel patch-based image restoration algorithm based on denoising diffusion probabilistic models. Our patch-based diffusion modeling approach enables size-agnostic image restoration by using a guided denoising process with smoothed noise estimates across overlapping patches during inference. We empirically evaluate our model on benchmark datasets for image desnowing, combined deraining and dehazing, and raindrop removal. We demonstrate our approach to achieve state-of-the-art performances on both weather-specific and multi-weather image restoration, and experimentally show strong generalization to real-world test images.",
    "citationCount": 370,
    "pdf_filename": "2022_Restoring_Vision_in_Adverse_Weather_Cond_69beb616.pdf"
  },
  "9b7b218b0f4e14f97260b6192add37da5e9ae2c5": {
    "paperId": "9b7b218b0f4e14f97260b6192add37da5e9ae2c5",
    "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models",
    "year": 2022,
    "authors": "Fan Bao, Chongxuan Li, Jun Zhu, Bo Zhang",
    "abstract": "Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose Analytic-DPM, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a 20x to 80x speed up.",
    "citationCount": 387,
    "pdf_filename": "2022_Analytic_DPM__an_Analytic_Estimate_of_th_9b7b218b.pdf"
  },
  "a02313d56a6f71be9aafe43628e0f3a1d0cb858e": {
    "paperId": "a02313d56a6f71be9aafe43628e0f3a1d0cb858e",
    "title": "Diffusion Models already have a Semantic Latent Space",
    "year": 2022,
    "authors": "Mingi Kwon, Jaeseok Jeong, Youngjung Uh",
    "abstract": "Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we introduce a principled design of the generative process for versatile editing and quality boost ing by quantifiable measures: editing strength of an interval and quality deficiency at a timestep. Our method is applicable to various architectures (DDPM++, iD- DPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN- bedroom, and METFACES). Project page: https://kwonminki.github.io/Asyrp/",
    "citationCount": 318,
    "pdf_filename": "2022_Diffusion_Models_already_have_a_Semantic_a02313d5.pdf"
  },
  "1f7ba0832203ab808fc8d6706836c591754b79da": {
    "paperId": "1f7ba0832203ab808fc8d6706836c591754b79da",
    "title": "On Neural Differential Equations",
    "year": 2022,
    "authors": "Patrick Kidger",
    "abstract": "The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.",
    "citationCount": 388,
    "pdf_filename": "2022_On_Neural_Differential_Equations_1f7ba083.pdf"
  },
  "0d08ffccc982781e310bb184397bbe64b9aef157": {
    "paperId": "0d08ffccc982781e310bb184397bbe64b9aef157",
    "title": "Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models",
    "year": 2022,
    "authors": "Sami Sarsa, Paul Denny, Arto Hellas, Juho Leinonen",
    "abstract": "This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.",
    "citationCount": 416,
    "pdf_filename": "2022_Automatic_Generation_of_Programming_Exer_0d08ffcc.pdf"
  },
  "3890d82362d07064687a4b5e9024fc4c92921998": {
    "paperId": "3890d82362d07064687a4b5e9024fc4c92921998",
    "title": "MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation",
    "year": 2022,
    "authors": "Vikram S. Voleti, Alexia Jolicoeur-Martineau, C. Pal",
    "abstract": "Video prediction is a challenging task. The quality of video frames from current state-of-the-art (SOTA) generative models tends to be poor and generalization beyond the training data is difficult. Furthermore, existing prediction frameworks are typically not capable of simultaneously handling other video-related tasks such as unconditional generation or interpolation. In this work, we devise a general-purpose framework called Masked Conditional Video Diffusion (MCVD) for all of these video synthesis tasks using a probabilistic conditional score-based denoising diffusion model, conditioned on past and/or future frames. We train the model in a manner where we randomly and independently mask all the past frames or all the future frames. This novel but straightforward setup allows us to train a single model that is capable of executing a broad range of video tasks, specifically: future/past prediction -- when only future/past frames are masked; unconditional generation -- when both past and future frames are masked; and interpolation -- when neither past nor future frames are masked. Our experiments show that this approach can generate high-quality frames for diverse types of videos. Our MCVD models are built from simple non-recurrent 2D-convolutional architectures, conditioning on blocks of frames and generating blocks of frames. We generate videos of arbitrary lengths autoregressively in a block-wise manner. Our approach yields SOTA results across standard video prediction and interpolation benchmarks, with computation times for training models measured in 1-12 days using $\\le$ 4 GPUs. Project page: https://mask-cond-video-diffusion.github.io ; Code : https://github.com/voletiv/mcvd-pytorch",
    "citationCount": 364,
    "pdf_filename": "2022_MCVD__Masked_Conditional_Video_Diffusion_3890d823.pdf"
  },
  "f9583f36414287bd4b7f34a9b178aa9cc3cd471a": {
    "paperId": "f9583f36414287bd4b7f34a9b178aa9cc3cd471a",
    "title": "Unsupervised Medical Image Translation With Adversarial Diffusion Models",
    "year": 2022,
    "authors": "Muzaffer Ozbey, S. Dar, H. Bedel, Onat Dalmaz, cSaban Ozturk",
    "abstract": "Imputation of missing images via source-to-target modality translation can improve diversity in medical imaging protocols. A pervasive approach for synthesizing target images involves one-shot mapping through generative adversarial networks (GAN). Yet, GAN models that implicitly characterize the image distribution can suffer from limited sample fidelity. Here, we propose a novel method based on adversarial diffusion modeling, SynDiff, for improved performance in medical image translation. To capture a direct correlate of the image distribution, SynDiff leverages a conditional diffusion process that progressively maps noise and source images onto the target image. For fast and accurate image sampling during inference, large diffusion steps are taken with adversarial projections in the reverse diffusion direction. To enable training on unpaired datasets, a cycle-consistent architecture is devised with coupled diffusive and non-diffusive modules that bilaterally translate between two modalities. Extensive assessments are reported on the utility of SynDiff against competing GAN and diffusion models in multi-contrast MRI and MRI-CT translation. Our demonstrations indicate that SynDiff offers quantitatively and qualitatively superior performance against competing baselines.",
    "citationCount": 386,
    "pdf_filename": "2022_Unsupervised_Medical_Image_Translation_W_f9583f36.pdf"
  },
  "522d00e2540df1c4a4c4b7f8da843ffd937f77c4": {
    "paperId": "522d00e2540df1c4a4c4b7f8da843ffd937f77c4",
    "title": "Structure-based drug design with equivariant diffusion models",
    "year": 2022,
    "authors": "Arne Schneuing, Yuanqi Du, Charles Harris, Arian R. Jamasb, Ilia Igashov",
    "abstract": "Structure-based drug design (SBDD) aims to design small-molecule ligands that bind with high affinity and specificity to pre-determined protein targets. Generative SBDD methods leverage structural data of drugs with their protein targets to propose new drug candidates. However, most existing methods focus exclusively on bottom-up de novo design of compounds or tackle other drug development challenges with task-specific models. The latter requires curation of suitable datasets, careful engineering of the models and retraining from scratch for each task. Here we show how a single pretrained diffusion model can be applied to a broader range of problems, such as off-the-shelf property optimization, explicit negative design and partial molecular design with inpainting. We formulate SBDD as a three-dimensional conditional generation problem and present DiffSBDD, an SE(3)-equivariant diffusion model that generates novel ligands conditioned on protein pockets. Furthermore, we show how additional constraints can be used to improve the generated drug candidates according to a variety of computational metrics. This work applies diffusion models to conditional molecule generation and shows how they can be used to tackle various structure-based drug design problems",
    "citationCount": 322,
    "pdf_filename": "2022_Structure_based_drug_design_with_equivar_522d00e2.pdf"
  },
  "3cbffab9d7981da6662d474aaa056dcbd3c1701e": {
    "paperId": "3cbffab9d7981da6662d474aaa056dcbd3c1701e",
    "title": "Emergent analogical reasoning in large language models",
    "year": 2022,
    "authors": "Taylor W. Webb, K. Holyoak, Hongjing Lu",
    "abstract": "The recent advent of large language models has reinvigorated debate over whether human cognitive capacities might emerge in such generic models given sufficient training data. Of particular interest is the ability of these models to reason about novel problems zero-shot, without any direct training. In human cognition, this capacity is closely tied to an ability to reason by analogy. Here we performed a direct comparison between human reasoners and a large language model (the text-davinci-003 variant of Generative Pre-trained Transformer (GPT)-3) on a range of analogical tasks, including a non-visual matrix reasoning task based on the rule structure of Raven’s Standard Progressive Matrices. We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings; preliminary tests of GPT-4 indicated even better performance. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems. Webb et al. show that new artificial intelligence language models, such as Generative Pre-trained Transformer 3, are able to solve analogical reasoning problems at a human-like level of performance.",
    "citationCount": 407,
    "pdf_filename": "2022_Emergent_analogical_reasoning_in_large_l_3cbffab9.pdf"
  },
  "dc21d8ee24038e99ddfd0fe88b263e0eabc54337": {
    "paperId": "dc21d8ee24038e99ddfd0fe88b263e0eabc54337",
    "title": "Diffusion Models for Medical Anomaly Detection",
    "year": 2022,
    "authors": "Julia Wolleb, Florentin Bieder, Robin Sandkühler, P. Cattin",
    "abstract": "In medical applications, weakly supervised anomaly detection methods are of great interest, as only image-level annotations are required for training. Current anomaly detection methods mainly rely on generative adversarial networks or autoencoder models. Those models are often complicated to train or have difficulties to preserve fine details in the image. We present a novel weakly supervised anomaly detection method based on denoising diffusion implicit models. We combine the deterministic iterative noising and denoising scheme with classifier guidance for image-to-image translation between diseased and healthy subjects. Our method generates very detailed anomaly maps without the need for a complex training procedure. We evaluate our method on the BRATS2020 dataset for brain tumor detection and the CheXpert dataset for detecting pleural effusions.",
    "citationCount": 349,
    "pdf_filename": "2022_Diffusion_Models_for_Medical_Anomaly_Det_dc21d8ee.pdf"
  },
  "2e6654520d8831f1721d4ec2dd1089b5d27f460f": {
    "paperId": "2e6654520d8831f1721d4ec2dd1089b5d27f460f",
    "title": "Self-Supervised Learning for Recommender Systems: A Survey",
    "year": 2022,
    "authors": "Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Jundong Li",
    "abstract": "In recent years, neural architecture-based recommender systems have achieved tremendous success, but they still fall short of expectation when dealing with highly sparse data. Self-supervised learning (SSL), as an emerging technique for learning from unlabeled data, has attracted considerable attention as a potential solution to this issue. This survey paper presents a systematic and timely review of research efforts on self-supervised recommendation (SSR). Specifically, we propose an exclusive definition of SSR, on top of which we develop a comprehensive taxonomy to divide existing SSR methods into four categories: contrastive, generative, predictive, and hybrid. For each category, we elucidate its concept and formulation, the involved methods, as well as its pros and cons. Furthermore, to facilitate empirical comparison, we release an open-source library SELFRec (https://github.com/Coder-Yu/SELFRec), which incorporates a wide range of SSR models and benchmark datasets. Through rigorous experiments using this library, we derive and report some significant findings regarding the selection of self-supervised signals for enhancing recommendation. Finally, we shed light on the limitations in the current research and outline the future research directions.",
    "citationCount": 365,
    "pdf_filename": "2022_Self_Supervised_Learning_for_Recommender_2e665452.pdf"
  },
  "8941e477b2f39eb92712f04400412da60d349ec1": {
    "paperId": "8941e477b2f39eb92712f04400412da60d349ec1",
    "title": "CLIP-Mesh: Generating textured meshes from text using pretrained image-text models",
    "year": 2022,
    "authors": "N. Khalid, Tianhao Xie, Eugene Belilovsky, T. Popa",
    "abstract": "We present a technique for zero-shot generation of a 3D model using only a target text prompt. Without any 3D supervision our method deforms the control shape of a limit subdivided surface along with its texture map and normal map to obtain a 3D asset that corresponds to the input text prompt and can be easily deployed into games or modeling applications. We rely only on a pre-trained CLIP model that compares the input text prompt with differentiably rendered images of our 3D model. While previous works have focused on stylization or required training of generative models we perform optimization on mesh parameters directly to generate shape, texture or both. To constrain the optimization to produce plausible meshes and textures we introduce a number of techniques using image augmentations and the use of a pretrained prior that generates CLIP image embeddings given a text embedding.",
    "citationCount": 335,
    "pdf_filename": "2022_CLIP_Mesh__Generating_textured_meshes_fr_8941e477.pdf"
  },
  "805748eec6be59ae0cd92a48400a902b3b7ed8e6": {
    "paperId": "805748eec6be59ae0cd92a48400a902b3b7ed8e6",
    "title": "Flexible Diffusion Modeling of Long Videos",
    "year": 2022,
    "authors": "William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian Weilbach, Frank Wood",
    "abstract": "We present a framework for video modeling based on denoising diffusion probabilistic models that produces long-duration video completions in a variety of realistic environments. We introduce a generative model that can at test-time sample any arbitrary subset of video frames conditioned on any other subset and present an architecture adapted for this purpose. Doing so allows us to efficiently compare and optimize a variety of schedules for the order in which frames in a long video are sampled and use selective sparse and long-range conditioning on previously sampled frames. We demonstrate improved video modeling over prior work on a number of datasets and sample temporally coherent videos over 25 minutes in length. We additionally release a new video modeling dataset and semantically meaningful metrics based on videos generated in the CARLA autonomous driving simulator.",
    "citationCount": 341,
    "pdf_filename": "2022_Flexible_Diffusion_Modeling_of_Long_Vide_805748ee.pdf"
  },
  "e3d8680daee504a581a0ff745d31b9e186eb357f": {
    "paperId": "e3d8680daee504a581a0ff745d31b9e186eb357f",
    "title": "Survey on Synthetic Data Generation, Evaluation Methods and GANs",
    "year": 2022,
    "authors": "Á. Figueira, Bruno Vaz",
    "abstract": "Synthetic data consists of artificially generated data. When data are scarce, or of poor quality, synthetic data can be used, for example, to improve the performance of machine learning models. Generative adversarial networks (GANs) are a state-of-the-art deep generative models that can generate novel synthetic samples that follow the underlying data distribution of the original dataset. Reviews on synthetic data generation and on GANs have already been written. However, none in the relevant literature, to the best of our knowledge, has explicitly combined these two topics. This survey aims to fill this gap and provide useful material to new researchers in this field. That is, we aim to provide a survey that combines synthetic data generation and GANs, and that can act as a good and strong starting point for new researchers in the field, so that they have a general overview of the key contributions and useful references. We have conducted a review of the state-of-the-art by querying four major databases: Web of Sciences (WoS), Scopus, IEEE Xplore, and ACM Digital Library. This allowed us to gain insights into the most relevant authors, the most relevant scientific journals in the area, the most cited papers, the most significant research areas, the most important institutions, and the most relevant GAN architectures. GANs were thoroughly reviewed, as well as their most common training problems, their most important breakthroughs, and a focus on GAN architectures for tabular data. Further, the main algorithms for generating synthetic data, their applications and our thoughts on these methods are also expressed. Finally, we reviewed the main techniques for evaluating the quality of synthetic data (especially tabular data) and provided a schematic overview of the information presented in this paper.",
    "citationCount": 326,
    "pdf_filename": "2022_Survey_on_Synthetic_Data_Generation__Eva_e3d8680d.pdf"
  },
  "1641774b55a471a23eb31b722ee05c2e032fec7a": {
    "paperId": "1641774b55a471a23eb31b722ee05c2e032fec7a",
    "title": "Diffusion Probabilistic Modeling for Video Generation",
    "year": 2022,
    "authors": "Ruihan Yang, Prakhar Srivastava, S. Mandt",
    "abstract": "Denoising diffusion probabilistic models are a promising new class of generative models that mark a milestone in high-quality image generation. This paper showcases their ability to sequentially generate video, surpassing prior methods in perceptual and probabilistic forecasting metrics. We propose an autoregressive, end-to-end optimized video diffusion model inspired by recent advances in neural video compression. The model successively generates future frames by correcting a deterministic next-frame prediction using a stochastic residual generated by an inverse diffusion process. We compare this approach against six baselines on four datasets involving natural and simulation-based videos. We find significant improvements in terms of perceptual quality and probabilistic frame forecasting ability for all datasets.",
    "citationCount": 304,
    "pdf_filename": "2022_Diffusion_Probabilistic_Modeling_for_Vid_1641774b.pdf"
  },
  "3ac52f3e6f185ef61bd35b74ae8a5c2bde4d1997": {
    "paperId": "3ac52f3e6f185ef61bd35b74ae8a5c2bde4d1997",
    "title": "Shifting machine learning for healthcare from development to deployment and from models to data",
    "year": 2022,
    "authors": "Angela Zhang, L. Xing, James Zou, Joseph C. Wu",
    "abstract": "In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance. This Review discusses the use of deep generative models, federated learning and transformer models to address challenges in the deployment of machine learning for healthcare.",
    "citationCount": 300,
    "pdf_filename": "2022_Shifting_machine_learning_for_healthcare_3ac52f3e.pdf"
  },
  "5432b77bfb1dced97c5b1fc684b0fa7d0d84c424": {
    "paperId": "5432b77bfb1dced97c5b1fc684b0fa7d0d84c424",
    "title": "Large Language Models in Finance: A Survey",
    "year": 2023,
    "authors": "Yinheng Li, Shaofei Wang, Han Ding, Hang Chen",
    "abstract": "Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.",
    "citationCount": 327,
    "pdf_filename": "2023_Large_Language_Models_in_Finance__A_Surv_5432b77b.pdf"
  },
  "ac27dd71af3ee93e1129482ceececbae7dd0d0e8": {
    "paperId": "ac27dd71af3ee93e1129482ceececbae7dd0d0e8",
    "title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation",
    "year": 2023,
    "authors": "Yangsibo Huang, Samyak Gupta, Mengzhou Xia, Kai Li, Danqi Chen",
    "abstract": "The rapid progress in open-source large language models (LLMs) is significantly advancing AI development. Extensive efforts have been made before model release to align their behavior with human values, with the primary goal of ensuring their helpfulness and harmlessness. However, even carefully aligned models can be manipulated maliciously, leading to unintended behaviors, known as\"jailbreaks\". These jailbreaks are typically triggered by specific text inputs, often referred to as adversarial prompts. In this work, we propose the generation exploitation attack, an extremely simple approach that disrupts model alignment by only manipulating variations of decoding methods. By exploiting different generation strategies, including varying decoding hyper-parameters and sampling methods, we increase the misalignment rate from 0% to more than 95% across 11 language models including LLaMA2, Vicuna, Falcon, and MPT families, outperforming state-of-the-art attacks with $30\\times$ lower computational cost. Finally, we propose an effective alignment method that explores diverse generation strategies, which can reasonably reduce the misalignment rate under our attack. Altogether, our study underscores a major failure in current safety evaluation and alignment procedures for open-source LLMs, strongly advocating for more comprehensive red teaming and better alignment before releasing such models. Our code is available at https://github.com/Princeton-SysML/Jailbreak_LLM.",
    "citationCount": 388,
    "pdf_filename": "2023_Catastrophic_Jailbreak_of_Open_source_LL_ac27dd71.pdf"
  },
  "8b5eab31e1c5689312fff3181a75bfbf5c13e51c": {
    "paperId": "8b5eab31e1c5689312fff3181a75bfbf5c13e51c",
    "title": "Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks",
    "year": 2022,
    "authors": "Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, Aniruddha Kembhavi",
    "abstract": "We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression, to natural language processing tasks such as question answering and paraphrasing. Developing a single unified model for such a large variety of tasks poses unique challenges due to the heterogeneous inputs and outputs pertaining to each task, including RGB images, per-pixel maps, binary masks, bounding boxes, and language. We achieve this unification by homogenizing every supported input and output into a sequence of discrete vocabulary tokens. This common representation across all tasks allows us to train a single transformer-based architecture, jointly on over 90 diverse datasets in the vision and language fields. Unified-IO is the first model capable of performing all 7 tasks on the GRIT benchmark and produces strong results across 16 diverse benchmarks like NYUv2-Depth, ImageNet, VQA2.0, OK-VQA, Swig, VizWizGround, BoolQ, and SciTail, with no task-specific fine-tuning. Code and demos for Unified-IO are available at: https://unified-io.allenai.org.",
    "citationCount": 466,
    "pdf_filename": "2022_Unified_IO__A_Unified_Model_for_Vision___8b5eab31.pdf"
  },
  "a35f1315e91513ff0bec0c488fe175214fd9636c": {
    "paperId": "a35f1315e91513ff0bec0c488fe175214fd9636c",
    "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
    "year": 2023,
    "authors": "Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei",
    "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an indispensable and important component, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have achieved significant advancements in enhancing recommender systems, these DNN-based methods still exhibit some limitations, such as inferior capabilities to effectively capture textual side information about users and items, difficulties in generalization to various recommendation scenarios, and reasoning on their predictions, etc. Meanwhile, the development of Large Language Models (LLMs), such as ChatGPT and GPT-4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization capabilities and reasoning skills. As a result, recent studies have actively attempted to harness the power of LLMs to enhance recommender systems. Given the rapid evolution of this research direction in recommender systems, there is a pressing need for a systematic overview that summarizes existing LLM-empowered recommender systems. Therefore, in this survey, we comprehensively review LLM-empowered recommender systems from various perspectives including pre-training, fine-tuning, and prompting paradigms. More specifically, we first introduce the representative methods to learn user and item representations, leveraging LLMs as feature encoders. Then, we systematically review the emerging advanced techniques of LLMs for enhancing recommender systems from three paradigms, namely pre-training, fine-tuning, and prompting. Finally, we comprehensively discuss the promising future directions in this emerging field.",
    "citationCount": 422,
    "pdf_filename": "2023_Recommender_Systems_in_the_Era_of_Large__a35f1315.pdf"
  },
  "12c6be503e4e5b7c9cb1810152d4364f26628a8d": {
    "paperId": "12c6be503e4e5b7c9cb1810152d4364f26628a8d",
    "title": "Data-centric Artificial Intelligence: A Survey",
    "year": 2023,
    "authors": "D. Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang",
    "abstract": "Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI.",
    "citationCount": 306,
    "pdf_filename": "2023_Data_centric_Artificial_Intelligence__A__12c6be50.pdf"
  },
  "5272acad9e4201e93dabe3fd99bd7ead9b1a544d": {
    "paperId": "5272acad9e4201e93dabe3fd99bd7ead9b1a544d",
    "title": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
    "year": 2024,
    "authors": "S. Tonmoy, S. M. M. Zaman, Vinija Jain, Anku Rani, Vipula Rawte",
    "abstract": "As Large Language Models (LLMs) continue to advance in their ability to write human-like text, a key challenge remains around their tendency to hallucinate generating content that appears factual but is ungrounded. This issue of hallucination is arguably the biggest hindrance to safely deploying these powerful LLMs into real-world production systems that impact people's lives. The journey toward widespread adoption of LLMs in practical settings heavily relies on addressing and mitigating hallucinations. Unlike traditional AI systems focused on limited tasks, LLMs have been exposed to vast amounts of online text data during training. While this allows them to display impressive language fluency, it also means they are capable of extrapolating information from the biases in training data, misinterpreting ambiguous prompts, or modifying the information to align superficially with the input. This becomes hugely alarming when we rely on language generation capabilities for sensitive applications, such as summarizing medical records, financial analysis reports, etc. This paper presents a comprehensive survey of over 32 techniques developed to mitigate hallucination in LLMs. Notable among these are Retrieval Augmented Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023), CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we introduce a detailed taxonomy categorizing these methods based on various parameters, such as dataset utilization, common tasks, feedback mechanisms, and retriever types. This classification helps distinguish the diverse approaches specifically designed to tackle hallucination issues in LLMs. Additionally, we analyze the challenges and limitations inherent in these techniques, providing a solid foundation for future research in addressing hallucinations and related phenomena within the realm of LLMs.",
    "citationCount": 322,
    "pdf_filename": "2024_A_Comprehensive_Survey_of_Hallucination__5272acad.pdf"
  },
  "5c128102d50d7ed96784ece1eb25533bb4ff3078": {
    "paperId": "5c128102d50d7ed96784ece1eb25533bb4ff3078",
    "title": "Drawbacks of Artificial Intelligence and Their Potential Solutions in the Healthcare Sector",
    "year": 2023,
    "authors": "Bangul Khan, Hajira Fatima, Ayatullah Qureshi, Surinder Kumar, Abdul Hanan",
    "abstract": "Artificial intelligence (AI) has the potential to make substantial progress toward the goal of making healthcare more personalized, predictive, preventative, and interactive. We believe AI will continue its present path and ultimately become a mature and effective tool for the healthcare sector. Besides this AI-based systems raise concerns regarding data security and privacy. Because health records are important and vulnerable, hackers often target them during data breaches. The absence of standard guidelines for the moral use of AI and ML in healthcare has only served to worsen the situation. There is debate about how far artificial intelligence (AI) may be utilized ethically in healthcare settings since there are no universal guidelines for its use. Therefore, maintaining the confidentiality of medical records is crucial. This study enlightens the possible drawbacks of AI in the implementation of healthcare sector and their solutions to overcome these situations. Graphical Abstract",
    "citationCount": 309,
    "pdf_filename": "2023_Drawbacks_of_Artificial_Intelligence_and_5c128102.pdf"
  },
  "2d93d27fb07fc43bb1e430c37f802586bc9aaf00": {
    "paperId": "2d93d27fb07fc43bb1e430c37f802586bc9aaf00",
    "title": "Trustworthy Artificial Intelligence: A Review",
    "year": 2022,
    "authors": "Davinder Kaur, Suleyman Uslu, Kaley J. Rittichier, A. Durresi",
    "abstract": "Artificial intelligence (AI) and algorithmic decision making are having a profound impact on our daily lives. These systems are vastly used in different high-stakes applications like healthcare, business, government, education, and justice, moving us toward a more algorithmic society. However, despite so many advantages of these systems, they sometimes directly or indirectly cause harm to the users and society. Therefore, it has become essential to make these systems safe, reliable, and trustworthy. Several requirements, such as fairness, explainability, accountability, reliability, and acceptance, have been proposed in this direction to make these systems trustworthy. This survey analyzes all of these different requirements through the lens of the literature. It provides an overview of different approaches that can help mitigate AI risks and increase trust and acceptance of the systems by utilizing the users and society. It also discusses existing strategies for validating and verifying these systems and the current standardization efforts for trustworthy AI. Finally, we present a holistic view of the recent advancements in trustworthy AI to help the interested researchers grasp the crucial facets of the topic efficiently and offer possible future research directions.",
    "citationCount": 486,
    "pdf_filename": "2022_Trustworthy_Artificial_Intelligence__A_R_2d93d27f.pdf"
  },
  "fb9a88ac3c4795e3fcf5de926516c59463b42e67": {
    "paperId": "fb9a88ac3c4795e3fcf5de926516c59463b42e67",
    "title": "Grounded Copilot: How Programmers Interact with Code-Generating Models",
    "year": 2022,
    "authors": "Shraddha Barke, M. James, N. Polikarpova",
    "abstract": "Powered by recent advances in code-generating models, AI assistants like Github Copilot promise to change the face of programming forever. But what is this new face of programming? We present the first grounded theory analysis of how programmers interact with Copilot, based on observing 20 participants—with a range of prior experience using the assistant—as they solve diverse programming tasks across four languages. Our main finding is that interactions with programming assistants are bimodal: in acceleration mode, the programmer knows what to do next and uses Copilot to get there faster; in exploration mode, the programmer is unsure how to proceed and uses Copilot to explore their options. Based on our theory, we provide recommendations for improving the usability of future AI programming assistants.",
    "citationCount": 420,
    "pdf_filename": "2022_Grounded_Copilot__How_Programmers_Intera_fb9a88ac.pdf"
  },
  "f3a6115e5fb2237df938976e005468f0b18da797": {
    "paperId": "f3a6115e5fb2237df938976e005468f0b18da797",
    "title": "The Stack: 3 TB of permissively licensed source code",
    "year": 2022,
    "authors": "Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou",
    "abstract": "Large Language Models (LLMs) play an ever-increasing role in the field of Artificial Intelligence (AI)--not only for natural language processing but also for code understanding and generation. To stimulate open and responsible research on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting of permissively licensed source code in 30 programming languages. We describe how we collect the full dataset, construct a permissively licensed subset, present a data governance plan, discuss limitations, and show promising results on text2code benchmarks by training 350M-parameter decoders on different Python subsets. We find that (1) near-deduplicating the data significantly boosts performance across all experiments, and (2) it is possible to match previously reported HumanEval and MBPP performance using only permissively licensed data. We make the dataset available at https://hf.co/BigCode, provide a tool called\"Am I in The Stack\"(https://hf.co/spaces/bigcode/in-the-stack) for developers to search The Stack for copies of their code, and provide a process for code to be removed from the dataset by following the instructions at https://www.bigcode-project.org/docs/about/the-stack/.",
    "citationCount": 389,
    "pdf_filename": "2022_The_Stack__3_TB_of_permissively_licensed_f3a6115e.pdf"
  },
  "e89ed6bb1864558e3889f5f2fb8931643c633479": {
    "paperId": "e89ed6bb1864558e3889f5f2fb8931643c633479",
    "title": "Human-level play in the game of Diplomacy by combining language models with strategic reasoning",
    "year": 2022,
    "authors": "A. Bakhtin, Noam Brown, Emily Dinan, Gabriele Farina, Colin Flaherty",
    "abstract": "Despite much progress in training artificial intelligence (AI) systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge. We introduce Cicero, the first AI agent to achieve human-level performance in Diplomacy, a strategy game involving both cooperation and competition that emphasizes natural language negotiation and tactical coordination between seven players. Cicero integrates a language model with planning and reinforcement learning algorithms by inferring players’ beliefs and intentions from its conversations and generating dialogue in pursuit of its plans. Across 40 games of an anonymous online Diplomacy league, Cicero achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game. Description AI masters Diplomacy The game Diplomacy has been a major challenge for artificial intelligence (AI). Unlike other competitive games that AI has recently mastered, such as chess, Go, and poker, Diplomacy cannot be solved purely through self-play; it requires the development of an agent to understand other players’ motivations and perspectives and to use natural language to negotiate complex shared plans. The Meta Fundamental AI Research Diplomacy Team (FAIR) et al. developed an agent that is able to play the full natural language form of the game and demonstrates performance well above the human average in an online Diplomacy league. The present work has far-reaching implications for the development of cooperative AI and language models for communication with people, even when interactions involve a mixture of aligned and competing interests. —YS Artificial intelligence demonstrates human-level performance in the strategic board game Diplomacy.",
    "citationCount": 449,
    "pdf_filename": "2022_Human_level_play_in_the_game_of_Diplomac_e89ed6bb.pdf"
  },
  "767098d2e324258fec0d33148eec44f7955b56ce": {
    "paperId": "767098d2e324258fec0d33148eec44f7955b56ce",
    "title": "Measuring user competence in using artificial intelligence: validity and reliability of artificial intelligence literacy scale",
    "year": 2022,
    "authors": "Bingcheng Wang, P. Rau, Tianyi Yuan",
    "abstract": "ABSTRACT As artificial intelligence (AI) became a part of daily life, it has become important to determine user competence in using AI technology. Here, we propose the concept of AI literacy and develop a quantitative scale for obtaining accurate data regarding the AI literacy of ordinary users. We first identified the primary core constructs of AI literacy, including awareness, use, evaluation, and ethics. Next, we generated 65 items to capture these four constructs; only 31 items were retained after a three-step content validation process. Then, we conducted a survey, and collected two samples of data. By reducing the number of items using the first sample and performing reliability and validity tests on the second sample, we obtained a 12-item instrument for the quantitative measurement of AI literacy. The results confirmed that the proposed four-construct model is an adequate representation of AI literacy. Further, AI literacy is significantly related to digital literacy, attitude towards robots, and users’ daily usage of AI. This study will not only aid researchers in understanding how user competence in using AI technology affects human–AI interactions but will also help designers develop AI applications that are aligned with the AI literacy levels of the target users.",
    "citationCount": 328,
    "pdf_filename": "2022_Measuring_user_competence_in_using_artif_767098d2.pdf"
  },
  "b36acdfc67612d707c95d1ed282672d3ca262be7": {
    "paperId": "b36acdfc67612d707c95d1ed282672d3ca262be7",
    "title": "Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers",
    "year": 2022,
    "authors": "C. Gao, F. Howard, N. Markov, E. Dyer, S. Ramesh",
    "abstract": "Background Large language models such as ChatGPT can produce increasingly realistic text, with unknown information on the accuracy and integrity of using these models in scientific writing. Methods We gathered ten research abstracts from five high impact factor medical journals (n=50) and asked ChatGPT to generate research abstracts based on their titles and journals. We evaluated the abstracts using an artificial intelligence (AI) output detector, plagiarism detector, and had blinded human reviewers try to distinguish whether abstracts were original or generated. Results All ChatGPT-generated abstracts were written clearly but only 8% correctly followed the specific journal’s formatting requirements. Most generated abstracts were detected using the AI output detector, with scores (higher meaning more likely to be generated) of median [interquartile range] of 99.98% [12.73, 99.98] compared with very low probability of AI-generated output in the original abstracts of 0.02% [0.02, 0.09]. The AUROC of the AI output detector was 0.94. Generated abstracts scored very high on originality using the plagiarism detector (100% [100, 100] originality). Generated abstracts had a similar patient cohort size as original abstracts, though the exact numbers were fabricated. When given a mixture of original and general abstracts, blinded human reviewers correctly identified 68% of generated abstracts as being generated by ChatGPT, but incorrectly identified 14% of original abstracts as being generated. Reviewers indicated that it was surprisingly difficult to differentiate between the two, but that the generated abstracts were vaguer and had a formulaic feel to the writing. Conclusion ChatGPT writes believable scientific abstracts, though with completely generated data. These are original without any plagiarism detected but are often identifiable using an AI output detector and skeptical human reviewers. Abstract evaluation for journals and medical conferences must adapt policy and practice to maintain rigorous scientific standards; we suggest inclusion of AI output detectors in the editorial process and clear disclosure if these technologies are used. The boundaries of ethical and acceptable use of large language models to help scientific writing remain to be determined.",
    "citationCount": 339,
    "pdf_filename": "2022_Comparing_scientific_abstracts_generated_b36acdfc.pdf"
  },
  "157530e815652b7e864a9f7885977c7ae8214b6f": {
    "paperId": "157530e815652b7e864a9f7885977c7ae8214b6f",
    "title": "ResViT: Residual Vision Transformers for Multimodal Medical Image Synthesis",
    "year": 2021,
    "authors": "Onat Dalmaz, Mahmut Yurt, Tolga Cukur",
    "abstract": "Generative adversarial models with convolutional neural network (CNN) backbones have recently been established as state-of-the-art in numerous medical image synthesis tasks. However, CNNs are designed to perform local processing with compact filters, and this inductive bias compromises learning of contextual features. Here, we propose a novel generative adversarial approach for medical image synthesis, ResViT, that leverages the contextual sensitivity of vision transformers along with the precision of convolution operators and realism of adversarial learning. ResViT’s generator employs a central bottleneck comprising novel aggregated residual transformer (ART) blocks that synergistically combine residual convolutional and transformer modules. Residual connections in ART blocks promote diversity in captured representations, while a channel compression module distills task-relevant information. A weight sharing strategy is introduced among ART blocks to mitigate computational burden. A unified implementation is introduced to avoid the need to rebuild separate synthesis models for varying source-target modality configurations. Comprehensive demonstrations are performed for synthesizing missing sequences in multi-contrast MRI, and CT images from MRI. Our results indicate superiority of ResViT against competing CNN- and transformer-based methods in terms of qualitative observations and quantitative metrics.",
    "citationCount": 446,
    "pdf_filename": "2021_ResViT__Residual_Vision_Transformers_for_157530e8.pdf"
  },
  "48f9a48aa5b1230b05a443d2d531e6441a541686": {
    "paperId": "48f9a48aa5b1230b05a443d2d531e6441a541686",
    "title": "The MVTec Anomaly Detection Dataset: A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection",
    "year": 2021,
    "authors": "Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, C. Steger",
    "abstract": "The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the field of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec anomaly detection dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth annotations for all anomalies. We conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pretrained convolutional neural networks, as well as classical computer vision methods. We highlight the advantages and disadvantages of multiple performance metrics as well as threshold estimation techniques. This benchmark indicates that methods that leverage descriptors of pretrained networks outperform all other approaches and deep-learning-based generative models show considerable room for improvement.",
    "citationCount": 432,
    "pdf_filename": "2021_The_MVTec_Anomaly_Detection_Dataset__A_C_48f9a48a.pdf"
  },
  "457573d719fd38ae133f516274c7cecd28916639": {
    "paperId": "457573d719fd38ae133f516274c7cecd28916639",
    "title": "Prototype Augmentation and Self-Supervision for Incremental Learning",
    "year": 2021,
    "authors": "Fei Zhu, Xu-Yao Zhang, Chuan Wang, Fei Yin, Cheng-Lin Liu",
    "abstract": "Despite the impressive performance in many individual tasks, deep neural networks suffer from catastrophic forgetting when learning new tasks incrementally. Recently, various incremental learning methods have been proposed, and some approaches achieved acceptable performance relying on stored data or complex generative models. However, storing data from previous tasks is limited by memory or privacy issues, and generative models are usually unstable and inefficient in training. In this paper, we propose a simple non-exemplar based method named PASS, to address the catastrophic forgetting problem in incremental learning. On the one hand, we propose to memorize one class-representative prototype for each old class and adopt prototype augmentation (protoAug) in the deep feature space to maintain the decision boundary of previous tasks. On the other hand, we employ self-supervised learning (SSL) to learn more generalizable and transferable features for other tasks, which demonstrates the effectiveness of SSL in incremental learning. Experimental results on benchmark datasets show that our approach significantly outperforms non-exemplar based methods, and achieves comparable performance compared to exemplar based approaches.",
    "citationCount": 434,
    "pdf_filename": "2021_Prototype_Augmentation_and_Self_Supervis_457573d7.pdf"
  },
  "df5f3ffe15207eb6ae2f00f3ccc818625b9bfbe7": {
    "paperId": "df5f3ffe15207eb6ae2f00f3ccc818625b9bfbe7",
    "title": "Artificial Intelligence and Jobs: Evidence from Online Vacancies",
    "year": 2022,
    "authors": "D. Acemoglu, David Autor, J. Hazell, P. Restrepo",
    "abstract": "We study the impact of artificial intelligence (AI) on labor markets using establishment-level data on the near universe of online vacancies in the United States from 2010 onward. There is rapid growth in AI-related vacancies over 2010–18 that is driven by establishments whose workers engage in tasks compatible with AI’s current capabilities. As these AI-exposed establishments adopt AI, they simultaneously reduce hiring in non-AI positions and change the skill requirements of remaining postings. While visible at the establishment level, the aggregate impacts of AI-labor substitution on employment and wage growth in more exposed occupations and industries is currently too small to be detectable.",
    "citationCount": 391,
    "pdf_filename": "2022_Artificial_Intelligence_and_Jobs__Eviden_df5f3ffe.pdf"
  },
  "cb4b91a6a7103410c1bcde9df69ab641c2e79a10": {
    "paperId": "cb4b91a6a7103410c1bcde9df69ab641c2e79a10",
    "title": "Latent Video Diffusion Models for High-Fidelity Long Video Generation",
    "year": 2022,
    "authors": "Yin-Yin He, Tianyu Yang, Yong Zhang, Ying Shan, Qifeng Chen",
    "abstract": "AI-generated content has attracted lots of attention recently, but photo-realistic video synthesis is still challenging. Although many attempts using GANs and autoregressive models have been made in this area, the visual quality and length of generated videos are far from satisfactory. Diffusion models have shown remarkable results recently but require significant computational resources. To address this, we introduce lightweight video diffusion models by leveraging a low-dimensional 3D latent space, significantly outperforming previous pixel-space video diffusion models under a limited computational budget. In addition, we propose hierarchical diffusion in the latent space such that longer videos with more than one thousand frames can be produced. To further overcome the performance degradation issue for long video generation, we propose conditional latent perturbation and unconditional guidance that effectively mitigate the accumulated errors during the extension of video length. Extensive experiments on small domain datasets of different categories suggest that our framework generates more realistic and longer videos than previous strong baselines. We additionally provide an extension to large-scale text-to-video generation to demonstrate the superiority of our work. Our code and models will be made publicly available.",
    "citationCount": 330,
    "pdf_filename": "2022_Latent_Video_Diffusion_Models_for_High_F_cb4b91a6.pdf"
  },
  "facca3eff019a509ac88b0ce4b8cb60341f22d78": {
    "paperId": "facca3eff019a509ac88b0ce4b8cb60341f22d78",
    "title": "Artificial intelligence – challenges and opportunities for international HRM: a review and research agenda",
    "year": 2022,
    "authors": "P. Budhwar, A. Malik, M. T. Thedushika, De Silva, Praveena Thevisuthan",
    "abstract": "Abstract Artificial intelligence (AI) and other AI-based applications are being integrated into firms’ human resource management (HRM) approaches for managing people in domestic and international organisations. The last decade has seen a growth in AI-based applications proliferating the HRM function, triggering an exciting new stream of research on topics such as the social presence of AI and robotics, effects of AI adoption on individual and business level outcomes, and evaluating AI-enabled HRM practices. Adopting these technologies has resulted in how work is organised in local and international firms, noting opportunities for employees and firms’ resource utilisation, decision-making, and problem-solving. However, despite a growing interest in scholarship, research on AI-based technologies for HRM is limited and fragmented. Further research is needed that analyses the role of AI-assisted applications in HRM functions and human-AI interactions in large multinational enterprises diffusing such innovations. In response to these combined issues—the fragmented nature of research and limited extant literature, we present a systematic review on the theme of this special issue and offer a nuanced understating of what is known, yet to be known, and future research directions to frame a future research agenda for international HRM. We develop a conceptual framework that integrates research on AI applications in HRM and offers a cohesive base for future research endeavours. We also develop a set of testable propositions that serve as directions for future research.",
    "citationCount": 362,
    "pdf_filename": "2022_Artificial_intelligence___challenges_and_facca3ef.pdf"
  },
  "59027b574cd02905cbdcb1fd8feefb878cc49c8d": {
    "paperId": "59027b574cd02905cbdcb1fd8feefb878cc49c8d",
    "title": "A Survey of Machine Unlearning",
    "year": 2022,
    "authors": "T. Nguyen, T. Huynh, Phi-Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin",
    "abstract": "Today, computer systems hold large amounts of personal data. Yet while such an abundance of data allows breakthroughs in AI, and especially machine learning, its existence can be a threat to user privacy, and it can weaken the bonds of trust between humans and AI. Recent regulations now require that, on request, private information about a user must be removed both from computer systems and from machine learning models—this legislation is more colloquially called “the right to be forgotten.” While removing data from back-end databases should be straightforward, it is not sufficient in the AI context as machine learning models often “remember” the old data. Contemporary adversarial attacks on trained models have proven that we can learn whether an instance or an attribute belonged to the training data. This phenomenon calls for a new paradigm, namely machine unlearning, to make machine learning models forget about particular data. It turns out that recent works on machine unlearning have not been able to completely solve the problem due to the lack of common frameworks and resources. Therefore, this article aspires to present a comprehensive examination of machine unlearning’s concepts, designs, methods, and applications. Specifically, as a category collection of cutting-edge studies, the intention behind this article is to serve as a comprehensive resource for researchers and practitioners seeking an introduction to machine unlearning and its formulations, design criteria, removal requests, algorithms, and applications. In addition, we aim to highlight the key findings, current trends, and new research areas that have not yet featured the use of machine unlearning but could benefit greatly from it. We hope that this survey serves as a valuable resource for machine learning researchers and those seeking to innovate privacy technologies. Our resources are publicly available at https://github.com/tamlhp/awesome-machine-unlearning.",
    "citationCount": 301,
    "pdf_filename": "2022_A_Survey_of_Machine_Unlearning_59027b57.pdf"
  },
  "cdfe9580f63070f311151444f9df32818cc858bf": {
    "paperId": "cdfe9580f63070f311151444f9df32818cc858bf",
    "title": "An Empirical Evaluation of GitHub Copilot's Code Suggestions",
    "year": 2022,
    "authors": "N. Nguyen, Sarah Nadi",
    "abstract": "GitHub and OpenAI recently launched Copilot, an “AI pair programmer” that utilizes the power of Natural Language Processing, Static Analysis, Code Synthesis, and Artificial Intelligence. Given a natural language description of the target functionality, Copilot can generate corresponding code in several programming languages. In this paper, we perform an empirical study to evaluate the correctness and understandability of Copilot's suggested code. We use 33 LeetCode questions to create queries for Copilot in four different programming languages. We evaluate the correctness of the corresponding 132 Copilot solutions by running LeetCode's provided tests, and evaluate understandability using SonarQube's cyclomatic complexity and cognitive complexity metrics. We find that Copilot's Java suggestions have the highest correctness score (57%) while JavaScript is the lowest (27%). Overall, Copilot's suggestions have low complexity with no notable differences between the programming languages. We also find some potential Copilot shortcomings, such as generating code that can be further simplified and code that relies on undefined helper methods.",
    "citationCount": 323,
    "pdf_filename": "2022_An_Empirical_Evaluation_of_GitHub_Copilo_cdfe9580.pdf"
  },
  "652032fbb744da4f279e8f30eef2323155878ac4": {
    "paperId": "652032fbb744da4f279e8f30eef2323155878ac4",
    "title": "Cross-Modal Contrastive Learning for Text-to-Image Generation",
    "year": 2021,
    "authors": "Han Zhang, Jing Yu Koh, Jason Baldridge, Honglak Lee, Yinfei Yang",
    "abstract": "The output of text-to-image synthesis systems should be coherent, clear, photo-realistic scenes with high semantic fidelity to their conditioned text descriptions. Our Cross-Modal Contrastive Generative Adversarial Network (XMC-GAN) addresses this challenge by maximizing the mutual information between image and text. It does this via multiple contrastive losses which capture inter-modality and intra-modality correspondences. XMC-GAN uses an attentional self-modulation generator, which enforces strong text-image correspondence, and a contrastive discriminator, which acts as a critic as well as a feature encoder for contrastive learning. The quality of XMC-GAN’s output is a major step up from previous models, as we show on three challenging datasets. On MS-COCO, not only does XMC-GAN improve state-of-the-art FID from 24.70 to 9.33, but– more importantly–people prefer XMC-GAN by 77.3% for image quality and 74.1% for image-text alignment, compared to three other recent models. XMC-GAN also generalizes to the challenging Localized Narratives dataset (which has longer, more detailed descriptions), improving state-of-the-art FID from 48.70 to 14.12. Lastly, we train and evaluate XMC-GAN on the challenging Open Images data, establishing a strong benchmark FID score of 26.91.",
    "citationCount": 412,
    "pdf_filename": "2021_Cross_Modal_Contrastive_Learning_for_Tex_652032fb.pdf"
  },
  "26f3ee78b1ff4041e7a8e9ecffc95a9185a17caa": {
    "paperId": "26f3ee78b1ff4041e7a8e9ecffc95a9185a17caa",
    "title": "GAN Prior Embedded Network for Blind Face Restoration in the Wild",
    "year": 2021,
    "authors": "T. Yang, Peiran Ren, Xuansong Xie, Lei Zhang",
    "abstract": "Blind face restoration (BFR) from severely degraded face images in the wild is a very challenging problem. Due to the high illness of the problem and the complex unknown degradation, directly training a deep neural network (DNN) usually cannot lead to acceptable results. Existing generative adversarial network (GAN) based methods can produce better results but tend to generate over-smoothed restorations. In this work, we propose a new method by first learning a GAN for high-quality face image generation and embedding it into a U-shaped DNN as a prior decoder, then fine-tuning the GAN prior embedded DNN with a set of synthesized low-quality face images. The GAN blocks are designed to ensure that the latent code and noise input to the GAN can be respectively generated from the deep and shallow features of the DNN, controlling the global face structure, local face details and background of the reconstructed image. The proposed GAN prior embedded network (GPEN) is easy-to-implement, and it can generate visually photo-realistic results. Our experiments demonstrated that the proposed GPEN achieves significantly superior results to state-of-the-art BFR methods both quantitatively and qualitatively, especially for the restoration of severely degraded face images in the wild. The source code and models can be found at https://github.com/yangxy/GPEN.",
    "citationCount": 328,
    "pdf_filename": "2021_GAN_Prior_Embedded_Network_for_Blind_Fac_26f3ee78.pdf"
  },
  "783f918cfe7107167a4d842ebaa9c8a9e20673bb": {
    "paperId": "783f918cfe7107167a4d842ebaa9c8a9e20673bb",
    "title": "Guidelines and quality criteria for artificial intelligence-based prediction models in healthcare: a scoping review",
    "year": 2022,
    "authors": "A. D. de Hond, A. Leeuwenberg, L. Hooft, Ilse M. J. Kant, Steven W. J. Nijman",
    "abstract": "While the opportunities of ML and AI in healthcare are promising, the growth of complex data-driven prediction models requires careful quality and applicability assessment before they are applied and disseminated in daily practice. This scoping review aimed to identify actionable guidance for those closely involved in AI-based prediction model (AIPM) development, evaluation and implementation including software engineers, data scientists, and healthcare professionals and to identify potential gaps in this guidance. We performed a scoping review of the relevant literature providing guidance or quality criteria regarding the development, evaluation, and implementation of AIPMs using a comprehensive multi-stage screening strategy. PubMed, Web of Science, and the ACM Digital Library were searched, and AI experts were consulted. Topics were extracted from the identified literature and summarized across the six phases at the core of this review: (1) data preparation, (2) AIPM development, (3) AIPM validation, (4) software development, (5) AIPM impact assessment, and (6) AIPM implementation into daily healthcare practice. From 2683 unique hits, 72 relevant guidance documents were identified. Substantial guidance was found for data preparation, AIPM development and AIPM validation (phases 1–3), while later phases clearly have received less attention (software development, impact assessment and implementation) in the scientific literature. The six phases of the AIPM development, evaluation and implementation cycle provide a framework for responsible introduction of AI-based prediction models in healthcare. Additional domain and technology specific research may be necessary and more practical experience with implementing AIPMs is needed to support further guidance.",
    "citationCount": 314,
    "pdf_filename": "2022_Guidelines_and_quality_criteria_for_arti_783f918c.pdf"
  },
  "3592f77e5fa3f4cd860a747ea8ef7fa627bea3f2": {
    "paperId": "3592f77e5fa3f4cd860a747ea8ef7fa627bea3f2",
    "title": "Edge Computing with Artificial Intelligence: A Machine Learning Perspective",
    "year": 2022,
    "authors": "H. Hua, Yutong Li, Tonghe Wang, Nanqing Dong, Wei Li",
    "abstract": "Recent years have witnessed the widespread popularity of Internet of things (IoT). By providing sufficient data for model training and inference, IoT has promoted the development of artificial intelligence (AI) to a great extent. Under this background and trend, the traditional cloud computing model may nevertheless encounter many problems in independently tackling the massive data generated by IoT and meeting corresponding practical needs. In response, a new computing model called edge computing (EC) has drawn extensive attention from both industry and academia. With the continuous deepening of the research on EC, however, scholars have found that traditional (non-AI) methods have their limitations in enhancing the performance of EC. Seeing the successful application of AI in various fields, EC researchers start to set their sights on AI, especially from a perspective of machine learning, a branch of AI that has gained increased popularity in the past decades. In this article, we first explain the formal definition of EC and the reasons why EC has become a favorable computing model. Then, we discuss the problems of interest in EC. We summarize the traditional solutions and hightlight their limitations. By explaining the research results of using AI to optimize EC and applying AI to other fields under the EC architecture, this article can serve as a guide to explore new research ideas in these two aspects while enjoying the mutually beneficial relationship between AI and EC.",
    "citationCount": 331,
    "pdf_filename": "2022_Edge_Computing_with_Artificial_Intellige_3592f77e.pdf"
  },
  "429018881ad753f0d5be21fdad6c036c44566005": {
    "paperId": "429018881ad753f0d5be21fdad6c036c44566005",
    "title": "Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review",
    "year": 2022,
    "authors": "L. Celi, J. Cellini, Marie Charpignon, E. Dee, Franck Dernoncourt",
    "abstract": "Background While artificial intelligence (AI) offers possibilities of advanced clinical prediction and decision-making in healthcare, models trained on relatively homogeneous datasets, and populations poorly-representative of underlying diversity, limits generalisability and risks biased AI-based decisions. Here, we describe the landscape of AI in clinical medicine to delineate population and data-source disparities. Methods We performed a scoping review of clinical papers published in PubMed in 2019 using AI techniques. We assessed differences in dataset country source, clinical specialty, and author nationality, sex, and expertise. A manually tagged subsample of PubMed articles was used to train a model, leveraging transfer-learning techniques (building upon an existing BioBERT model) to predict eligibility for inclusion (original, human, clinical AI literature). Of all eligible articles, database country source and clinical specialty were manually labelled. A BioBERT-based model predicted first/last author expertise. Author nationality was determined using corresponding affiliated institution information using Entrez Direct. And first/last author sex was evaluated using the Gendarize.io API. Results Our search yielded 30,576 articles, of which 7,314 (23.9%) were eligible for further analysis. Most databases came from the US (40.8%) and China (13.7%). Radiology was the most represented clinical specialty (40.4%), followed by pathology (9.1%). Authors were primarily from either China (24.0%) or the US (18.4%). First and last authors were predominately data experts (i.e., statisticians) (59.6% and 53.9% respectively) rather than clinicians. And the majority of first/last authors were male (74.1%). Interpretation U.S. and Chinese datasets and authors were disproportionately overrepresented in clinical AI, and almost all of the top 10 databases and author nationalities were from high income countries (HICs). AI techniques were most commonly employed for image-rich specialties, and authors were predominantly male, with non-clinical backgrounds. Development of technological infrastructure in data-poor regions, and diligence in external validation and model re-calibration prior to clinical implementation in the short-term, are crucial in ensuring clinical AI is meaningful for broader populations, and to avoid perpetuating global health inequity.",
    "citationCount": 311,
    "pdf_filename": "2022_Sources_of_bias_in_artificial_intelligen_42901888.pdf"
  },
  "78e3106101bbacdf6601a92eb39026c15f443861": {
    "paperId": "78e3106101bbacdf6601a92eb39026c15f443861",
    "title": "Artificial Intelligence for Remote Sensing Data Analysis: A review of challenges and opportunities",
    "year": 2022,
    "authors": "Lefei Zhang, Liangpei Zhang",
    "abstract": "Artificial intelligence (AI) plays a growing role in remote sensing (RS). Applications of AI, particularly machine learning algorithms, range from initial image processing to high-level data understanding and knowledge discovery. AI techniques have emerged as a powerful strategy for analyzing RS data and led to remarkable breakthroughs in all RS fields. Given this period of breathtaking evolution, this work aims to provide a comprehensive review of the recent achievements of AI algorithms and applications in RS data analysis. The review includes more than 270 research papers, covering the following major aspects of AI innovation for RS: machine learning, computational intelligence, AI explicability, data mining, natural language processing (NLP), and AI security. We conclude this review by identifying promising directions for future research.",
    "citationCount": 369,
    "pdf_filename": "2022_Artificial_Intelligence_for_Remote_Sensi_78e31061.pdf"
  },
  "96ba3947d48f5d6866556aa043ebbeaaf20e7759": {
    "paperId": "96ba3947d48f5d6866556aa043ebbeaaf20e7759",
    "title": "Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction",
    "year": 2021,
    "authors": "Hyungjin Chung, Byeongsu Sim, Jong-Chul Ye",
    "abstract": "Diffusion models have recently attained significant interest within the community owing to their strong performance as generative models. Furthermore, its application to inverse problems have demonstrated state-of-the-art performance. Unfortunately, diffusion models have a critical downside - they are inherently slow to sample from, needing few thousand steps of iteration to generate images from pure Gaussian noise. In this work, we show that starting from Gaussian noise is unnecessary. Instead, starting from a single forward diffusion with better initialization significantly reduces the number of sampling steps in the reverse conditional diffusion. This phenomenon is formally explained by the contraction theory of the stochastic difference equations like our conditional diffusion strategy - the alternating applications of reverse diffusion followed by a non-expansive data consistency step. The new sampling strategy, dubbed Come-Closer-Diffuse-Faster (CCDF), also reveals a new insight on how the existing feed-forward neural network approaches for inverse problems can be synergistically combined with the diffusion models. Experimental results with super-resolution, image inpainting, and compressed sensing MRI demonstrate that our method can achieve state-of-the-art reconstruction performance at significantly reduced sampling steps.",
    "citationCount": 413,
    "pdf_filename": "2021_Come_Closer_Diffuse_Faster__Accelerating_96ba3947.pdf"
  },
  "e137c4fcdd7be545f1001d5f590538387493f7f1": {
    "paperId": "e137c4fcdd7be545f1001d5f590538387493f7f1",
    "title": "HuMoR: 3D Human Motion Model for Robust Pose Estimation",
    "year": 2021,
    "authors": "Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar",
    "abstract": "We introduce HuMoR: a 3D Human Motion Model for Robust Estimation of temporal pose and shape. Though substantial progress has been made in estimating 3D human motion and shape from dynamic observations, recovering plausible pose sequences in the presence of noise and occlusions remains a challenge. For this purpose, we propose an expressive generative model in the form of a conditional variational autoencoder, which learns a distribution of the change in pose at each step of a motion sequence. Furthermore, we introduce a flexible optimization-based approach that leverages HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Through extensive evaluations, we demonstrate that our model generalizes to diverse motions and body shapes after training on a large motion capture dataset, and enables motion reconstruction from multiple input modalities including 3D keypoints and RGB(-D) videos. See the project page at geometry.stanford.edu/projects/humor.",
    "citationCount": 361,
    "pdf_filename": "2021_HuMoR__3D_Human_Motion_Model_for_Robust__e137c4fc.pdf"
  },
  "44c0446bb53e951cca8df07af91f1dea96045aea": {
    "paperId": "44c0446bb53e951cca8df07af91f1dea96045aea",
    "title": "ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement",
    "year": 2021,
    "authors": "Yuval Alaluf, Or Patashnik, D. Cohen-Or",
    "abstract": "Recently, the power of unconditional image synthesis has significantly advanced through the use of Generative Adversarial Networks (GANs). The task of inverting an image into its corresponding latent code of the trained GAN is of utmost importance as it allows for the manipulation of real images, leveraging the rich semantics learned by the network. Recognizing the limitations of current inversion approaches, in this work we present a novel inversion scheme that extends current encoder-based inversion methods by introducing an iterative refinement mechanism. Instead of directly predicting the latent code of a given real image using a single pass, the encoder is tasked with predicting a residual with respect to the current estimate of the inverted latent code in a self-correcting manner. Our residual-based encoder, named ReStyle, attains improved accuracy compared to current state-of-the-art encoder-based methods with a negligible increase in inference time. We analyze the behavior of ReStyle to gain valuable insights into its iterative nature. We then evaluate the performance of our residual encoder and analyze its robustness compared to optimization-based inversion and state-of-the-art encoders. Code is available via our project page: https: //yuval-alaluf.github.io/restyle-encoder/",
    "citationCount": 363,
    "pdf_filename": "2021_ReStyle__A_Residual_Based_StyleGAN_Encod_44c0446b.pdf"
  },
  "6e8f35c6d54acb14109c9b792a62609eac8a7b5e": {
    "paperId": "6e8f35c6d54acb14109c9b792a62609eac8a7b5e",
    "title": "TransGAN: Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up",
    "year": 2021,
    "authors": "Yifan Jiang, Shiyu Chang, Zhangyang Wang",
    "abstract": "The recent explosive interest on transformers has suggested their potential to become powerful\"universal\"models for computer vision tasks, such as classification, detection, and segmentation. While those attempts mainly study the discriminative models, we explore transformers on some more notoriously difficult vision tasks, e.g., generative adversarial networks (GANs). Our goal is to conduct the first pilot study in building a GAN completely free of convolutions, using only pure transformer-based architectures. Our vanilla GAN architecture, dubbed TransGAN, consists of a memory-friendly transformer-based generator that progressively increases feature resolution, and correspondingly a multi-scale discriminator to capture simultaneously semantic contexts and low-level textures. On top of them, we introduce the new module of grid self-attention for alleviating the memory bottleneck further, in order to scale up TransGAN to high-resolution generation. We also develop a unique training recipe including a series of techniques that can mitigate the training instability issues of TransGAN, such as data augmentation, modified normalization, and relative position encoding. Our best architecture achieves highly competitive performance compared to current state-of-the-art GANs using convolutional backbones. Specifically, TransGAN sets new state-of-the-art inception score of 10.43 and FID of 18.28 on STL-10, outperforming StyleGAN-V2. When it comes to higher-resolution (e.g. 256 x 256) generation tasks, such as on CelebA-HQ and LSUN-Church, TransGAN continues to produce diverse visual examples with high fidelity and impressive texture details. In addition, we dive deep into the transformer-based generation models to understand how their behaviors differ from convolutional ones, by visualizing training dynamics. The code is available at https://github.com/VITA-Group/TransGAN.",
    "citationCount": 452,
    "pdf_filename": "2021_TransGAN__Two_Pure_Transformers_Can_Make_6e8f35c6.pdf"
  },
  "e19ca3c11fd45dfc9bc6e43ddf9b03b6c798e66d": {
    "paperId": "e19ca3c11fd45dfc9bc6e43ddf9b03b6c798e66d",
    "title": "Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding",
    "year": 2021,
    "authors": "S. Tonekaboni, D. Eytan, A. Goldenberg",
    "abstract": "Time series are often complex and rich in information but sparsely labeled and therefore challenging to model. In this paper, we propose a self-supervised framework for learning generalizable representations for non-stationary time series. Our approach, called Temporal Neighborhood Coding (TNC), takes advantage of the local smoothness of a signal's generative process to define neighborhoods in time with stationary properties. Using a debiased contrastive objective, our framework learns time series representations by ensuring that in the encoding space, the distribution of signals from within a neighborhood is distinguishable from the distribution of non-neighboring signals. Our motivation stems from the medical field, where the ability to model the dynamic nature of time series data is especially valuable for identifying, tracking, and predicting the underlying patients' latent states in settings where labeling data is practically impossible. We compare our method to recently developed unsupervised representation learning approaches and demonstrate superior performance on clustering and classification tasks for multiple datasets.",
    "citationCount": 348,
    "pdf_filename": "2021_Unsupervised_Representation_Learning_for_e19ca3c1.pdf"
  },
  "20b04a687d7c0b50dd5ec2466f6535bb7719f322": {
    "paperId": "20b04a687d7c0b50dd5ec2466f6535bb7719f322",
    "title": "Artificial Intelligence‐Enabled Sensing Technologies in the 5G/Internet of Things Era: From Virtual Reality/Augmented Reality to the Digital Twin",
    "year": 2022,
    "authors": "Zixuan Zhang, Feng Wen, Zhongda Sun, Xinge Guo, Tianyiyi He",
    "abstract": "With the development of 5G and Internet of Things (IoT), the era of big data‐driven product design is booming. In addition, artificial intelligence (AI) is also emerging and evolving by recent breakthroughs in computing power and software architectures. In this regard, the digital twin, analyzing various sensor data with the help of AI algorithms, has become a cutting‐edge technology that connects the physical and virtual worlds, in which the various sensors are highly desirable to collect environmental information. However, although existing sensor technologies, including cameras, microphones, inertial measurement units, etc., are widely used as sensing elements for various applications, high‐power consumption and battery replacement of them is still a problem. Triboelectric nanogenerators (TENGs) as self‐powered sensors supply a feasible platform for realizing self‐sustainable and low‐power systems. Herein, the recent progress on TENG‐based intelligent systems, that is, wearable electronics, robot‐related systems, and smart homes, followed by prospective future development enabled by sensor fusion technology, is focused on. Finally, how to apply artificial intelligence to the design of intelligent sensor systems for the 5G and IoT era is discussed.",
    "citationCount": 303,
    "pdf_filename": "2022_Artificial_Intelligence_Enabled_Sensing__20b04a68.pdf"
  },
  "362cc80481b288874af0428107ab31e955dcf09f": {
    "paperId": "362cc80481b288874af0428107ab31e955dcf09f",
    "title": "Offline Reinforcement Learning with Fisher Divergence Critic Regularization",
    "year": 2021,
    "authors": "Ilya Kostrikov, Jonathan Tompson, R. Fergus, Ofir Nachum",
    "abstract": "Many modern approaches to offline Reinforcement Learning (RL) utilize behavior regularization, typically augmenting a model-free actor critic algorithm with a penalty measuring divergence of the policy from the offline data. In this work, we propose an alternative approach to encouraging the learned policy to stay close to the data, namely parameterizing the critic as the log-behavior-policy, which generated the offline data, plus a state-action value offset term, which can be learned using a neural network. Behavior regularization then corresponds to an appropriate regularizer on the offset term. We propose using a gradient penalty regularizer for the offset term and demonstrate its equivalence to Fisher divergence regularization, suggesting connections to the score matching and generative energy-based model literature. We thus term our resulting algorithm Fisher-BRC (Behavior Regularized Critic). On standard offline RL benchmarks, Fisher-BRC achieves both improved performance and faster convergence over existing state-of-the-art methods.",
    "citationCount": 335,
    "pdf_filename": "2021_Offline_Reinforcement_Learning_with_Fish_362cc804.pdf"
  },
  "5b00442bd7e12ac1c614127f1f6429c8df3747bc": {
    "paperId": "5b00442bd7e12ac1c614127f1f6429c8df3747bc",
    "title": "Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style",
    "year": 2021,
    "authors": "Julius von Kügelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, B. Scholkopf",
    "abstract": "Self-supervised representation learning has shown remarkable success in a number of domains. A common practice is to perform data augmentation via hand-crafted transformations intended to leave the semantics of the data invariant. We seek to understand the empirical success of this approach from a theoretical perspective. We formulate the augmentation process as a latent variable model by postulating a partition of the latent representation into a content component, which is assumed invariant to augmentation, and a style component, which is allowed to change. Unlike prior work on disentanglement and independent component analysis, we allow for both nontrivial statistical and causal dependencies in the latent space. We study the identifiability of the latent representation based on pairs of views of the observations and prove sufficient conditions that allow us to identify the invariant content partition up to an invertible mapping in both generative and discriminative settings. We find numerical simulations with dependent latent variables are consistent with our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional, visually complex images with rich causal dependencies, which we use to study the effect of data augmentations performed in practice.",
    "citationCount": 348,
    "pdf_filename": "2021_Self_Supervised_Learning_with_Data_Augme_5b00442b.pdf"
  },
  "9c8d46b59e871e18d8d2e1ec1aa9b96d2f3d7342": {
    "paperId": "9c8d46b59e871e18d8d2e1ec1aa9b96d2f3d7342",
    "title": "Improving Robustness using Generated Data",
    "year": 2021,
    "authors": "Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, D. A. Calian",
    "abstract": "Recent work argues that robust training requires substantially larger datasets than those required for standard classification. On CIFAR-10 and CIFAR-100, this translates into a sizable robust-accuracy gap between models trained solely on data from the original training set and those trained with additional data extracted from the\"80 Million Tiny Images\"dataset (TI-80M). In this paper, we explore how generative models trained solely on the original training set can be leveraged to artificially increase the size of the original training set and improve adversarial robustness to $\\ell_p$ norm-bounded perturbations. We identify the sufficient conditions under which incorporating additional generated data can improve robustness, and demonstrate that it is possible to significantly reduce the robust-accuracy gap to models trained with additional real data. Surprisingly, we even show that even the addition of non-realistic random data (generated by Gaussian sampling) can improve robustness. We evaluate our approach on CIFAR-10, CIFAR-100, SVHN and TinyImageNet against $\\ell_\\infty$ and $\\ell_2$ norm-bounded perturbations of size $\\epsilon = 8/255$ and $\\epsilon = 128/255$, respectively. We show large absolute improvements in robust accuracy compared to previous state-of-the-art methods. Against $\\ell_\\infty$ norm-bounded perturbations of size $\\epsilon = 8/255$, our models achieve 66.10% and 33.49% robust accuracy on CIFAR-10 and CIFAR-100, respectively (improving upon the state-of-the-art by +8.96% and +3.29%). Against $\\ell_2$ norm-bounded perturbations of size $\\epsilon = 128/255$, our model achieves 78.31% on CIFAR-10 (+3.81%). These results beat most prior works that use external data.",
    "citationCount": 340,
    "pdf_filename": "2021_Improving_Robustness_using_Generated_Dat_9c8d46b5.pdf"
  },
  "fe92f3f7ceec008118842d42b578dc25bcba63f9": {
    "paperId": "fe92f3f7ceec008118842d42b578dc25bcba63f9",
    "title": "DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism",
    "year": 2021,
    "authors": "Jinglin Liu, Chengxi Li, Yi Ren, Feiyang Chen, Zhou Zhao",
    "abstract": "Singing voice synthesis (SVS) systems are built to synthesize high-quality and expressive singing voice, in which the acoustic model generates the acoustic features (e.g., mel-spectrogram) given a music score. Previous singing acoustic models adopt a simple loss (e.g., L1 and L2) or generative adversarial network (GAN) to reconstruct the acoustic features, while they suffer from over-smoothing and unstable training issues respectively, which hinder the naturalness of synthesized singing. \nIn this work, we propose DiffSinger, an acoustic model for SVS based on the diffusion probabilistic model. DiffSinger is a parameterized Markov chain that iteratively converts the noise into mel-spectrogram conditioned on the music score. By implicitly optimizing variational bound, DiffSinger can be stably trained and generate realistic outputs. \nTo further improve the voice quality and speed up inference, we introduce a shallow diffusion mechanism to make better use of the prior knowledge learned by the simple loss. Specifically, DiffSinger starts generation at a shallow step smaller than the total number of diffusion steps, according to the intersection of the diffusion trajectories of the ground-truth mel-spectrogram and the one predicted by a simple mel-spectrogram decoder. Besides, we propose boundary prediction methods to locate the intersection and determine the shallow step adaptively.\nThe evaluations conducted on a Chinese singing dataset demonstrate that DiffSinger outperforms state-of-the-art SVS work. Extensional experiments also prove the generalization of our methods on text-to-speech task (DiffSpeech). Audio samples: https://diffsinger.github.io. Codes: https://github.com/MoonInTheRiver/DiffSinger.",
    "citationCount": 318,
    "pdf_filename": "2021_DiffSinger__Singing_Voice_Synthesis_via__fe92f3f7.pdf"
  },
  "03a718819cdd3fcc102db640330037ff46431d67": {
    "paperId": "03a718819cdd3fcc102db640330037ff46431d67",
    "title": "Diffusion Models for Implicit Image Segmentation Ensembles",
    "year": 2021,
    "authors": "Julia Wolleb, Robin Sandkühler, Florentin Bieder, P. Valmaggia, P. Cattin",
    "abstract": "Diffusion models have shown impressive performance for generative modelling of images. In this paper, we present a novel semantic segmentation method based on diffusion models. By modifying the training and sampling scheme, we show that diffusion models can perform lesion segmentation of medical images. To generate an image specific segmentation, we train the model on the ground truth segmentation, and use the image as a prior during training and in every step during the sampling process. With the given stochastic sampling process, we can generate a distribution of segmentation masks. This property allows us to compute pixel-wise uncertainty maps of the segmentation, and allows an implicit ensemble of segmentations that increases the segmentation performance. We evaluate our method on the BRATS2020 dataset for brain tumor segmentation. Compared to state-of-the-art segmentation models, our approach yields good segmentation results and, additionally, detailed uncertainty maps.",
    "citationCount": 347,
    "pdf_filename": "2021_Diffusion_Models_for_Implicit_Image_Segm_03a71881.pdf"
  },
  "e8f1c51c4e881345c0588bec8aa8bc6d9164a535": {
    "paperId": "e8f1c51c4e881345c0588bec8aa8bc6d9164a535",
    "title": "Deepfakes generation and detection: state-of-the-art, open challenges, countermeasures, and way forward",
    "year": 2021,
    "authors": "Momina Masood, M. Nawaz, K. Malik, A. Javed, Aun Irtaza",
    "abstract": "Easy access to audio-visual content on social media, combined with the availability of modern tools such as Tensorflow or Keras, and open-source trained models, along with economical computing infrastructure, and the rapid evolution of deep-learning (DL) methods have heralded a new and frightening trend. Particularly, the advent of easily available and ready to use Generative Adversarial Networks (GANs), have made it possible to generate deepfakes media partially or completely fabricated with the intent to deceive to disseminate disinformation and revenge porn, to perpetrate financial frauds and other hoaxes, and to disrupt government functioning. Existing surveys have mainly focused on the detection of deepfake images and videos; this paper provides a comprehensive review and detailed analysis of existing tools and machine learning (ML) based approaches for deepfake generation, and the methodologies used to detect such manipulations in both audio and video. For each category of deepfake, we discuss information related to manipulation approaches, current public datasets, and key standards for the evaluation of the performance of deepfake detection techniques, along with their results. Additionally, we also discuss open challenges and enumerate future directions to guide researchers on issues which need to be considered in order to improve the domains of both deepfake generation and detection. This work is expected to assist readers in understanding how deepfakes are created and detected, along with their current limitations and where future research may lead.",
    "citationCount": 392,
    "pdf_filename": "2021_Deepfakes_generation_and_detection__stat_e8f1c51c.pdf"
  },
  "77805d75199e7b9e580b4827f56a069ba0ddd13f": {
    "paperId": "77805d75199e7b9e580b4827f56a069ba0ddd13f",
    "title": "MolGPT: Molecular Generation Using a Transformer-Decoder Model",
    "year": 2021,
    "authors": "Viraj Bagal, Rishal Aggarwal, P. K. Vinod, U. Priyakumar",
    "abstract": "Application of deep learning techniques for de novo generation of molecules, termed as inverse molecular design, has been gaining enormous traction in drug design. The representation of molecules in SMILES notation as a string of characters enables the usage of state of the art models in natural language processing, such as Transformers, for molecular design in general. Inspired by generative pre-training (GPT) models that have been shown to be successful in generating meaningful text, we train a transformer-decoder on the next token prediction task using masked self-attention for the generation of druglike molecules in this study. We show that our model, MolGPT, performs on par with other previously proposed modern machine learning frameworks for molecular generation in terms of generating valid, unique, and novel molecules. Furthermore, we demonstrate that the model can be trained conditionally to control multiple properties of the generated molecules. We also show that the model can be used to generate molecules with desired scaffolds as well as desired molecular properties by conditioning the generation on scaffold SMILES strings of desired scaffolds and property values. Using saliency maps, we highlight the interpretability of the generative process of the model.",
    "citationCount": 391,
    "pdf_filename": "2021_MolGPT__Molecular_Generation_Using_a_Tra_77805d75.pdf"
  },
  "f0c27af6c330d5c3b0a8eb376a69ce92c85badd7": {
    "paperId": "f0c27af6c330d5c3b0a8eb376a69ce92c85badd7",
    "title": "A Comprehensive Survey on Community Detection With Deep Learning",
    "year": 2021,
    "authors": "Xing Su, Shan Xue, Fanzhen Liu, Jia Wu, Jian Yang",
    "abstract": "Detecting a community in a network is a matter of discerning the distinct features and connections of a group of members that are different from those in other communities. The ability to do this is of great significance in network analysis. However, beyond the classic spectral clustering and statistical inference methods, there have been significant developments with deep learning techniques for community detection in recent years—particularly when it comes to handling high-dimensional network data. Hence, a comprehensive review of the latest progress in community detection through deep learning is timely. To frame the survey, we have devised a new taxonomy covering different state-of-the-art methods, including deep learning models based on deep neural networks (DNNs), deep nonnegative matrix factorization, and deep sparse filtering. The main category, i.e., DNNs, is further divided into convolutional networks, graph attention networks, generative adversarial networks, and autoencoders. The popular benchmark datasets, evaluation metrics, and open-source implementations to address experimentation settings are also summarized. This is followed by a discussion on the practical applications of community detection in various domains. The survey concludes with suggestions of challenging topics that would make for fruitful future research directions in this fast-growing deep learning field.",
    "citationCount": 394,
    "pdf_filename": "2021_A_Comprehensive_Survey_on_Community_Dete_f0c27af6.pdf"
  },
  "973c01a6458928a1b3797daf13298969f03c0a1f": {
    "paperId": "973c01a6458928a1b3797daf13298969f03c0a1f",
    "title": "Understanding the role of individual units in a deep neural network",
    "year": 2020,
    "authors": "David Bau, Jun-Yan Zhu, Hendrik Strobelt, Àgata Lapedriza, Bolei Zhou",
    "abstract": "Deep neural networks excel at finding hierarchical representations that solve complex tasks over large datasets. How can we humans understand these learned representations? In this work, we present network dissection, an analytic framework to systematically identify the semantics of individual hidden units within image classification and image generation networks. First, we analyze a convolutional neural network (CNN) trained on scene classification and discover units that match a diverse set of object concepts. We find evidence that the network has learned many object classes that play crucial roles in classifying scene classes. Second, we use a similar analytic method to analyze a generative adversarial network (GAN) model trained to generate scenes. By analyzing changes made when small sets of units are activated or deactivated, we find that objects can be added and removed from the output scenes while adapting to the context. Finally, we apply our analytic framework to understanding adversarial attacks and to semantic image editing.",
    "citationCount": 494,
    "pdf_filename": "2020_Understanding_the_role_of_individual_uni_973c01a6.pdf"
  },
  "e0b2735a02153872b780432ce4af81cdf7902ab1": {
    "paperId": "e0b2735a02153872b780432ce4af81cdf7902ab1",
    "title": "Environmental influences on the pace of brain development",
    "year": 2021,
    "authors": "Ursula A. Tooley, D. Bassett, A. Mackey",
    "abstract": "Childhood socio-economic status (SES), a measure of the availability of material and social resources, is one of the strongest predictors of lifelong well-being. Here we review evidence that experiences associated with childhood SES affect not only the outcome but also the pace of brain development. We argue that higher childhood SES is associated with protracted structural brain development and a prolonged trajectory of functional network segregation, ultimately leading to more efficient cortical networks in adulthood. We hypothesize that greater exposure to chronic stress accelerates brain maturation, whereas greater access to novel positive experiences decelerates maturation. We discuss the impact of variation in the pace of brain development on plasticity and learning. We provide a generative theoretical framework to catalyse future basic science and translational research on environmental influences on brain development. Evidence suggests that socio-economic status can affect not only the outcome of structural and functional development of the brain but also its rate. Tooley, Bassett and Mackey review this evidence and suggest that the valence and frequency of early experiences interact to influence brain development.",
    "citationCount": 348,
    "pdf_filename": "2021_Environmental_influences_on_the_pace_of__e0b2735a.pdf"
  },
  "1c83f3f9789df43bf937ae2618721e2da83dcc06": {
    "paperId": "1c83f3f9789df43bf937ae2618721e2da83dcc06",
    "title": "From Show to Tell: A Survey on Deep Learning-Based Image Captioning",
    "year": 2021,
    "authors": "Matteo Stefanini, Marcella Cornia, L. Baraldi, Silvia Cascianelli, G. Fiameni",
    "abstract": "Connecting Vision and Language plays an essential role in Generative Intelligence. For this reason, large research efforts have been devoted to image captioning, i.e. describing images with syntactically and semantically meaningful sentences. Starting from 2015 the task has generally been addressed with pipelines composed of a visual encoder and a language model for text generation. During these years, both components have evolved considerably through the exploitation of object regions, attributes, the introduction of multi-modal connections, fully-attentive approaches, and BERT-like early-fusion strategies. However, regardless of the impressive results, research in image captioning has not reached a conclusive answer yet. This work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics. In this respect, we quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies. Moreover, many variants of the problem and its open challenges are discussed. The final goal of this work is to serve as a tool for understanding the existing literature and highlighting the future directions for a research area where Computer Vision and Natural Language Processing can find an optimal synergy.",
    "citationCount": 339,
    "pdf_filename": "2021_From_Show_to_Tell__A_Survey_on_Deep_Lear_1c83f3f9.pdf"
  },
  "f19db28a8fdcdc2eaa44c777c40714e2622bf0ff": {
    "paperId": "f19db28a8fdcdc2eaa44c777c40714e2622bf0ff",
    "title": "DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding",
    "year": 2024,
    "authors": "Zhiyu Wu, Xiaokang Chen, Zizheng Pan, Xingchao Liu, Wen Liu",
    "abstract": "We present DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL, through two key major upgrades. For the vision component, we incorporate a dynamic tiling vision encoding strategy designed for processing high-resolution images with different aspect ratios. For the language component, we leverage DeepSeekMoE models with the Multi-head Latent Attention mechanism, which compresses Key-Value cache into latent vectors, to enable efficient inference and high throughput. Trained on an improved vision-language dataset, DeepSeek-VL2 demonstrates superior capabilities across various tasks, including but not limited to visual question answering, optical character recognition, document/table/chart understanding, and visual grounding. Our model series is composed of three variants: DeepSeek-VL2-Tiny, DeepSeek-VL2-Small and DeepSeek-VL2, with 1.0B, 2.8B and 4.5B activated parameters respectively. DeepSeek-VL2 achieves competitive or state-of-the-art performance with similar or fewer activated parameters compared to existing open-source dense and MoE-based models. Codes and pre-trained models are publicly accessible at https://github.com/deepseek-ai/DeepSeek-VL2.",
    "citationCount": 369,
    "pdf_filename": "2024_DeepSeek_VL2__Mixture_of_Experts_Vision__f19db28a.pdf"
  },
  "468aa95cfdf66da9fc3dc6a1b9042a52a6ec99c6": {
    "paperId": "468aa95cfdf66da9fc3dc6a1b9042a52a6ec99c6",
    "title": "DDSP: Differentiable Digital Signal Processing",
    "year": 2020,
    "authors": "Jesse Engel, Lamtharn Hantrakul, Chenjie Gu, Adam Roberts",
    "abstract": "Most generative models of audio directly generate samples in one of two domains: time or frequency. While sufficient to express any signal, these representations are inefficient, as they do not utilize existing knowledge of how sound is generated and perceived. A third approach (vocoders/synthesizers) successfully incorporates strong domain knowledge of signal processing and perception, but has been less actively researched due to limited expressivity and difficulty integrating with modern auto-differentiation-based machine learning methods. In this paper, we introduce the Differentiable Digital Signal Processing (DDSP) library, which enables direct integration of classic signal processing elements with deep learning methods. Focusing on audio synthesis, we achieve high-fidelity generation without the need for large autoregressive models or adversarial losses, demonstrating that DDSP enables utilizing strong inductive biases without losing the expressive power of neural networks. Further, we show that combining interpretable modules permits manipulation of each separate model component, with applications such as independent control of pitch and loudness, realistic extrapolation to pitches not seen during training, blind dereverberation of room acoustics, transfer of extracted room acoustics to new environments, and transformation of timbre between disparate sources. In short, DDSP enables an interpretable and modular approach to generative modeling, without sacrificing the benefits of deep learning. The library will be made available upon paper acceptance and we encourage further contributions from the community and domain experts.",
    "citationCount": 427,
    "pdf_filename": "2020_DDSP__Differentiable_Digital_Signal_Proc_468aa95c.pdf"
  },
  "3e577c9bdc82cb7fed337a74f90bbc4505fdfb69": {
    "paperId": "3e577c9bdc82cb7fed337a74f90bbc4505fdfb69",
    "title": "Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images",
    "year": 2020,
    "authors": "R. Child",
    "abstract": "We present a hierarchical VAE that, for the first time, outperforms the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that VAEs can actually implement autoregressive models, and other, more efficient generative models, if made sufficiently deep. Despite this, autoregressive models have traditionally outperformed VAEs. We test if insufficient depth explains the performance gap by by scaling a VAE to greater stochastic depth than previously explored and evaluating it on CIFAR-10, ImageNet, and FFHQ. We find that, in comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. We visualize the generative process and show the VAEs learn efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.",
    "citationCount": 380,
    "pdf_filename": "2020_Very_Deep_VAEs_Generalize_Autoregressive_3e577c9b.pdf"
  },
  "8f5065abd7600eb48a3e576e7f13943d5bc67dab": {
    "paperId": "8f5065abd7600eb48a3e576e7f13943d5bc67dab",
    "title": "Digital transformation",
    "year": 2020,
    "authors": "Jörn Kleinert",
    "abstract": "The introductory chapter to the book The Data Imperative examines how technological advances together with a new managerial mindset are driving digital transformation. While early business information systems were often self-contained and designed to solve specific problems, contemporary systems are highly interconnected and integrated. Corporations can use data flows to coordinate diverse processes and activities across organizational and geographic boundaries. The chapter explains how digital transformation involves a systematic shift from predominant reliance on human knowledge and skills to digital data flows and smart algorithms. Artificial intelligence techniques, such as generative adversarial networks and advanced natural language processing, and 5G wireless technologies create new opportunities to replace human routines with algorithmic processing. Data will continue to break down organizational silos, enable deeper collaboration across company boundaries, and speed up the development of new services.",
    "citationCount": 448,
    "pdf_filename": "2020_Digital_transformation_8f5065ab.pdf"
  },
  "f139e31818ef1bc7d2728018c3899637ea02a7b7": {
    "paperId": "f139e31818ef1bc7d2728018c3899637ea02a7b7",
    "title": "Photonic matrix multiplication lights up photonic accelerator and beyond",
    "year": 2022,
    "authors": "Hailong Zhou, Jianji Dong, Junwei Cheng, Wenchan Dong, Chaoran Huang",
    "abstract": "Matrix computation, as a fundamental building block of information processing in science and technology, contributes most of the computational overheads in modern signal processing and artificial intelligence algorithms. Photonic accelerators are designed to accelerate specific categories of computing in the optical domain, especially matrix multiplication, to address the growing demand for computing resources and capacity. Photonic matrix multiplication has much potential to expand the domain of telecommunication, and artificial intelligence benefiting from its superior performance. Recent research in photonic matrix multiplication has flourished and may provide opportunities to develop applications that are unachievable at present by conventional electronic processors. In this review, we first introduce the methods of photonic matrix multiplication, mainly including the plane light conversion method, Mach–Zehnder interferometer method and wavelength division multiplexing method. We also summarize the developmental milestones of photonic matrix multiplication and the related applications. Then, we review their detailed advances in applications to optical signal processing and artificial neural networks in recent years. Finally, we comment on the challenges and perspectives of photonic matrix multiplication and photonic acceleration. This review summarizes the advances of photonic accelerators from the viewpoint of photonic matrix multiplication, providing a guidance for all-optical or optoelectronic-hybrid AI hardware chip system.",
    "citationCount": 385,
    "pdf_filename": "2022_Photonic_matrix_multiplication_lights_up_f139e318.pdf"
  },
  "87c45a908537ffe1d2ab71a5d609bd7b4efa4fe1": {
    "paperId": "87c45a908537ffe1d2ab71a5d609bd7b4efa4fe1",
    "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language",
    "year": 2020,
    "authors": "Oyvind Tafjord, Bhavana Dalvi, Peter Clark",
    "abstract": "Transformers have been shown to emulate logical deduction over natural language theories (logical rules expressed in natural language), reliably assigning true/false labels to candidate implications. However, their ability to generate implications of a theory has not yet been demonstrated, and methods for reconstructing proofs of answers are imperfect. In this work we show that a generative model, called ProofWriter, can reliably generate both implications of a theory and the natural language proof(s) that support them. In particular, iterating a 1-step implication generator results in proofs that are highly reliable, and represent actual model decisions (rather than post-hoc rationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's proofs exceed previous methods by +9% absolute, and in a way that generalizes to proof depths unseen in training and on out-of-domain problems. We also show that generative techniques can perform a type of abduction with high precision: Given a theory and an unprovable conclusion, identify a missing fact that allows the conclusion to be proved, along with a proof. These results significantly improve the viability of neural methods for systematically reasoning over natural language.",
    "citationCount": 355,
    "pdf_filename": "2020_ProofWriter__Generating_Implications__Pr_87c45a90.pdf"
  },
  "7f91c91c817ee1488f70264ecc22cee0f6908260": {
    "paperId": "7f91c91c817ee1488f70264ecc22cee0f6908260",
    "title": "Swapping Autoencoder for Deep Image Manipulation",
    "year": 2020,
    "authors": "Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, Eli Shechtman",
    "abstract": "Deep generative models have become increasingly effective at producing realistic images from randomly sampled seeds, but using such models for controllable manipulation of existing images remains challenging. We propose the Swapping Autoencoder, a deep model designed specifically for image manipulation, rather than random sampling. The key idea is to encode an image with two independent components and enforce that any swapped combination maps to a realistic image. In particular, we encourage the components to represent structure and texture, by enforcing one component to encode co-occurrent patch statistics across different parts of an image. As our method is trained with an encoder, finding the latent codes for a new input image becomes trivial, rather than cumbersome. As a result, it can be used to manipulate real input images in various ways, including texture swapping, local and global editing, and latent code vector arithmetic. Experiments on multiple datasets show that our model produces better results and is substantially more efficient compared to recent generative models.",
    "citationCount": 358,
    "pdf_filename": "2020_Swapping_Autoencoder_for_Deep_Image_Mani_7f91c91c.pdf"
  },
  "985c4c6b6dd50ebb9871792d5e8d47a5161f87de": {
    "paperId": "985c4c6b6dd50ebb9871792d5e8d47a5161f87de",
    "title": "Global Texture Enhancement for Fake Face Detection in the Wild",
    "year": 2020,
    "authors": "Zhengzhe Liu, Xiaojuan Qi, Jiaya Jia, Philip H. S. Torr",
    "abstract": "Generative Adversarial Networks (GANs) can generate realistic fake face images that can easily fool human beings. On the contrary, a common Convolutional Neural Network(CNN) discriminator can achieve more than99.9%accuracyin discerning fake/real images. In this paper, we conduct an empirical study on fake/real faces, and have two important observations: firstly, the texture of fake faces is substantially different from real ones; secondly, global texture statistics are more robust to image editing and transferable to fake faces from different GANs and datasets. Motivated by the above observations, we propose a new architecture coined as Gram-Net, which leverages global image texture representations for robust fake image detection. Experimental results on several datasets demonstrate that our Gram-Netoutperforms existing approaches. Especially, our Gram-Netis more robust to image editings, e.g. down-sampling, JPEGcompression, blur, and noise. More importantly, our Gram-Net generalizes significantly better in detecting fake faces from GAN models not seen in the training phase and can perform decently in detecting fake natural images",
    "citationCount": 366,
    "pdf_filename": "2020_Global_Texture_Enhancement_for_Fake_Face_985c4c6b.pdf"
  },
  "611b5f9f868c9e820d2c4cd8e8a9bb4274eb3a8f": {
    "paperId": "611b5f9f868c9e820d2c4cd8e8a9bb4274eb3a8f",
    "title": "Universal Source-Free Domain Adaptation",
    "year": 2020,
    "authors": "Jogendra Nath Kundu, Naveen Venkat, V. RahulM., R. Venkatesh Babu",
    "abstract": "There is a strong incentive to develop versatile learning techniques that can transfer the knowledge of class-separability from a labeled source domain to an unlabeled target domain in the presence of a domain-shift. Existing domain adaptation (DA) approaches are not equipped for practical DA scenarios as a result of their reliance on the knowledge of source-target label-set relationship (e.g. Closed-set, Open-set or Partial DA). Furthermore, almost all prior unsupervised DA works require coexistence of source and target samples even during deployment, making them unsuitable for real-time adaptation. Devoid of such impractical assumptions, we propose a novel two-stage learning process. 1) In the Procurement stage, we aim to equip the model for future source-free deployment, assuming no prior knowledge of the upcoming category-gap and domain-shift. To achieve this, we enhance the model’s ability to reject out-of-source distribution samples by leveraging the available source data, in a novel generative classifier framework. 2) In the Deployment stage, the goal is to design a unified adaptation algorithm capable of operating across a wide range of category-gaps, with no access to the previously seen source samples. To this end, in contrast to the usage of complex adversarial training regimes, we define a simple yet effective source-free adaptation objective by utilizing a novel instance-level weighting mechanism, named as Source Similarity Metric (SSM). A thorough evaluation shows the practical usability of the proposed learning framework with superior DA performance even over state-of-the-art source-dependent approaches.",
    "citationCount": 376,
    "pdf_filename": "2020_Universal_Source_Free_Domain_Adaptation_611b5f9f.pdf"
  },
  "97095b4f5d38f5b8c0d966f84ad2bfc501644a78": {
    "paperId": "97095b4f5d38f5b8c0d966f84ad2bfc501644a78",
    "title": "Advancing Theory with Review Articles",
    "year": 2020,
    "authors": "Corinne Post, R. Sarala, Caroline Gatrell, J. Prescott",
    "abstract": "Reviewing a body of work presents unique opportunities for making a theoretical contribution. Review articles can make readers think theoretically differently about a given field or phenomenon. Yet, review articles that advance theory have been historically under‐represented in Journal of Management Studies. Accordingly, the purpose of this editorial is to propose a multi‐faceted approach for fashioning theoretical contributions in review articles, which we hope will inspire more authors to develop and submit innovative, original, and high‐quality theory‐building review articles. We argue that advancing theory with review articles requires an integrative and generative approach. We propose a non‐exhaustive set of avenues for developing theory with a review article: exposing emerging perspectives, analysing assumptions, clarifying constructs, establishing boundary conditions, testing new theory, theorizing with systems theory, and theorizing with mechanisms. As a journal, Journal of Management Studies is a journal of ideas – new ideas; ideas drawn from reflections on extant theory and ideas with potential to change the way we understand and interpret theory. With this in mind, we think that advancing theory with review articles is an untapped source of new ideas.",
    "citationCount": 406,
    "pdf_filename": "2020_Advancing_Theory_with_Review_Articles_97095b4f.pdf"
  },
  "c9287de07ff689cfaf700a5b1999f7fbb2707275": {
    "paperId": "c9287de07ff689cfaf700a5b1999f7fbb2707275",
    "title": "Structure-Preserving Super Resolution With Gradient Guidance",
    "year": 2020,
    "authors": "Cheng Ma, Yongming Rao, Yean Cheng, Ce Chen, Jiwen Lu",
    "abstract": "Structures matter in single image super resolution (SISR). Recent studies benefiting from generative adversarial network (GAN) have promoted the development of SISR by recovering photo-realistic images. However, there are always undesired structural distortions in the recovered images. In this paper, we propose a structure-preserving super resolution method to alleviate the above issue while maintaining the merits of GAN-based methods to generate perceptual-pleasant details. Specifically, we exploit gradient maps of images to guide the recovery in two aspects. On the one hand, we restore high-resolution gradient maps by a gradient branch to provide additional structure priors for the SR process. On the other hand, we propose a gradient loss which imposes a second-order restriction on the super-resolved images. Along with the previous image-space loss functions, the gradient-space objectives help generative networks concentrate more on geometric structures. Moreover, our method is model-agnostic, which can be potentially used for off-the-shelf SR networks. Experimental results show that we achieve the best PI and LPIPS performance and meanwhile comparable PSNR and SSIM compared with state-of-the-art perceptual-driven SR methods. Visual results demonstrate our superiority in restoring structures while generating natural SR images.",
    "citationCount": 353,
    "pdf_filename": "2020_Structure_Preserving_Super_Resolution_Wi_c9287de0.pdf"
  },
  "06b676b052b17cf32b6033f40dcf8a37a0700f95": {
    "paperId": "06b676b052b17cf32b6033f40dcf8a37a0700f95",
    "title": "Deep neural networks for the evaluation and design of photonic devices",
    "year": 2020,
    "authors": "Jiaqi Jiang, Ming-Keh Chen, Jonathan A. Fan",
    "abstract": "The data-science revolution is poised to transform the way photonic systems are simulated and designed. Photonic systems are, in many ways, an ideal substrate for machine learning: the objective of much of computational electromagnetics is the capture of nonlinear relationships in high-dimensional spaces, which is the core strength of neural networks. Additionally, the mainstream availability of Maxwell solvers makes the training and evaluation of neural networks broadly accessible and tailorable to specific problems. In this Review, we show how deep neural networks, configured as discriminative networks, can learn from training sets and operate as high-speed surrogate electromagnetic solvers. We also examine how deep generative networks can learn geometric features in device distributions and even be configured to serve as robust global optimizers. Fundamental data-science concepts framed within the context of photonics are also discussed, including the network-training process, delineation of different network classes and architectures, and dimensionality reduction. Neural networks can capture nonlinear relationships in high-dimensional spaces and are powerful tools for photonic-system modelling. This Review discusses how deep neural networks can serve as surrogate electromagnetic solvers, inverse modelling tools and global device optimizers.",
    "citationCount": 455,
    "pdf_filename": "2020_Deep_neural_networks_for_the_evaluation__06b676b0.pdf"
  },
  "7f1637319a9ecf74f8afdeac4baaa6bb48fd7eb2": {
    "paperId": "7f1637319a9ecf74f8afdeac4baaa6bb48fd7eb2",
    "title": "MoFlow: An Invertible Flow Model for Generating Molecular Graphs",
    "year": 2020,
    "authors": "Chengxi Zang, Fei Wang",
    "abstract": "Generating molecular graphs with desired chemical properties driven by deep graph generative models provides a very promising way to accelerate drug discovery process. Such graph generative models usually consist of two steps: learning latent representations and generation of molecular graphs. However, to generate novel and chemically-valid molecular graphs from latent representations is very challenging because of the chemical constraints and combinatorial complexity of molecular graphs. In this paper, we propose MoFlow, a flow-based graph generative model to learn invertible mappings between molecular graphs and their latent representations. To generate molecular graphs, our MoFlow first generates bonds (edges) through a Glow based model, then generates atoms (nodes) given bonds by a novel graph conditional flow, and finally assembles them into a chemically valid molecular graph with a posthoc validity correction. Our MoFlow has merits including exact and tractable likelihood training, efficient one-pass embedding and generation, chemical validity guarantees, 100% reconstruction of training data, and good generalization ability. We validate our model by four tasks: molecular graph generation and reconstruction, visualization of the continuous latent space, property optimization, and constrained property optimization. Our MoFlow achieves state-of-the-art performance, which implies its potential efficiency and effectiveness to explore large chemical space for drug discovery.",
    "citationCount": 329,
    "pdf_filename": "2020_MoFlow__An_Invertible_Flow_Model_for_Gen_7f163731.pdf"
  },
  "a4375125ee9900d1a5f090f433d5348601cb9989": {
    "paperId": "a4375125ee9900d1a5f090f433d5348601cb9989",
    "title": "How to train your neural ODE",
    "year": 2020,
    "authors": "Chris Finlay, J. Jacobsen, L. Nurbekyan, Adam M. Oberman",
    "abstract": "Training neural ODEs on large datasets has not been tractable due to the necessity of allowing the adaptive numerical ODE solver to refine its step size to very small values. In practice this leads to dynamics equivalent to many hundreds or even thousands of layers. In this paper, we overcome this apparent difficulty by introducing a theoretically-grounded combination of both optimal transport and stability regularizations which encourage neural ODEs to prefer simpler dynamics out of all the dynamics that solve a problem well. Simpler dynamics lead to faster convergence and to fewer discretizations of the solver, considerably decreasing wall-clock time without loss in performance. Our approach allows us to train neural ODE based generative models to the same performance as the unregularized dynamics in just over a day on one GPU, whereas unregularized dynamics can take up to 4-6 days of training time on multiple GPUs. This brings neural ODEs significantly closer to practical relevance in large-scale applications.",
    "citationCount": 324,
    "pdf_filename": "2020_How_to_train_your_neural_ODE_a4375125.pdf"
  },
  "d2599ccb2401198b5e6e1d867c7d0f22b5055f5e": {
    "paperId": "d2599ccb2401198b5e6e1d867c7d0f22b5055f5e",
    "title": "CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models",
    "year": 2020,
    "authors": "Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao",
    "abstract": "Learning disentanglement aims at finding a low dimensional representation which consists of multiple explanatory and generative factors of the observational data. The framework of variational autoencoder (VAE) is commonly used to disentangle independent factors from observations. However, in real scenarios, factors with semantics are not necessarily independent. Instead, there might be an underlying causal structure which renders these factors dependent. We thus propose a new VAE based framework named CausalVAE, which includes a Causal Layer to transform independent exogenous factors into causal endogenous ones that correspond to causally related concepts in data. We further analyze the model identifiabitily, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments are conducted on various datasets, including synthetic and real word benchmark CelebA. Results show that the causal representations learned by CausalVAE are semantically interpretable, and their causal relationship as a Directed Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we demonstrate that the proposed CausalVAE model is able to generate counterfactual data through \"do-operation\" to the causal factors.",
    "citationCount": 328,
    "pdf_filename": "2020_CausalVAE__Disentangled_Representation_L_d2599ccb.pdf"
  },
  "7561f28a9d063c3275a3b416fe09da1d645e5ede": {
    "paperId": "7561f28a9d063c3275a3b416fe09da1d645e5ede",
    "title": "Generation and evaluation of synthetic patient data",
    "year": 2020,
    "authors": "André R. Gonçalves, P. Ray, Braden C. Soper, Jennifer L. Stevens, Linda Coyle",
    "abstract": "Background Machine learning (ML) has made a significant impact in medicine and cancer research; however, its impact in these areas has been undeniably slower and more limited than in other application domains. A major reason for this has been the lack of availability of patient data to the broader ML research community, in large part due to patient privacy protection concerns. High-quality, realistic, synthetic datasets can be leveraged to accelerate methodological developments in medicine. By and large, medical data is high dimensional and often categorical. These characteristics pose multiple modeling challenges. Methods In this paper, we evaluate three classes of synthetic data generation approaches; probabilistic models, classification-based imputation models, and generative adversarial neural networks. Metrics for evaluating the quality of the generated synthetic datasets are presented and discussed. Results While the results and discussions are broadly applicable to medical data, for demonstration purposes we generate synthetic datasets for cancer based on the publicly available cancer registry data from the Surveillance Epidemiology and End Results (SEER) program. Specifically, our cohort consists of breast, respiratory, and non-solid cancer cases diagnosed between 2010 and 2015, which includes over 360,000 individual cases. Conclusions We discuss the trade-offs of the different methods and metrics, providing guidance on considerations for the generation and usage of medical synthetic data.",
    "citationCount": 319,
    "pdf_filename": "2020_Generation_and_evaluation_of_synthetic_p_7561f28a.pdf"
  },
  "07499a8835abe0c362815b12d530b9c03a7a63b3": {
    "paperId": "07499a8835abe0c362815b12d530b9c03a7a63b3",
    "title": "Learning to Do Qualitative Data Analysis: A Starting Point",
    "year": 2020,
    "authors": "J. Lester, Yonjoo Cho, Chad R. Lochmiller",
    "abstract": "Given the vast and diverse qualitative analytic landscape, what might be a generative starting point for researchers who desire to learn how to produce quality qualitative analyses? This question is particularly relevant to researchers new to the field and practice of qualitative research and instructors and mentors who regularly introduce students to qualitative research practices. In this article, we seek to offer what we view as a useful starting point for learning how to do qualitative analysis. We begin by discussing briefly the general landscape of qualitative research methodologies and methods. To contextualize our suggestions, we review the qualitative analytic practices commonly used within human resource development (HRD). Following this, we describe thematic analysis in more detail, including why we believe it is a particularly useful analytic approach to consider when first learning about qualitative analysis. We share seven common practices or important considerations for carrying out a thematic analysis and conclude by highlighting key considerations for assuring quality when conducting a thematic analysis.",
    "citationCount": 391,
    "pdf_filename": "2020_Learning_to_Do_Qualitative_Data_Analysis_07499a88.pdf"
  },
  "c0a1b887aefcec5570d4894c8eac054ddd0f06d1": {
    "paperId": "c0a1b887aefcec5570d4894c8eac054ddd0f06d1",
    "title": "Entanglement Induced Barren Plateaus",
    "year": 2020,
    "authors": "Carlos Ortiz Marrero, M. Kieferová, N. Wiebe",
    "abstract": "We argue that an excess in entanglement between the visible and hidden units in a Quantum Neural Network can hinder learning. In particular, we show that quantum neural networks that satisfy a volume-law in the entanglement entropy will give rise to models not suitable for learning with high probability. Using arguments from quantum thermodynamics, we then show that this volume law is typical and that there exists a barren plateau in the optimization landscape due to entanglement. More precisely, we show that for any bounded objective function on the visible layers, the Lipshitz constants of the expectation value of that objective function will scale inversely with the dimension of the hidden-subsystem with high probability. We show how this can cause both gradient descent and gradient-free methods to fail. We note that similar problems can happen with quantum Boltzmann machines, although stronger assumptions on the coupling between the hidden/visible subspaces are necessary. We highlight how pretraining such generative models may provide a way to navigate these barren plateaus.",
    "citationCount": 317,
    "pdf_filename": "2020_Entanglement_Induced_Barren_Plateaus_c0a1b887.pdf"
  },
  "f030656c4441093852ca0ad0d533b156a7c8a884": {
    "paperId": "f030656c4441093852ca0ad0d533b156a7c8a884",
    "title": "FedHome: Cloud-Edge Based Personalized Federated Learning for In-Home Health Monitoring",
    "year": 2020,
    "authors": "Qiong Wu, Xu Chen, Zhi Zhou, Junshan Zhang",
    "abstract": "In-home health monitoring has attracted great attention for the ageing population worldwide. With the abundant user health data accessed by Internet of Things (IoT) devices and recent development in machine learning, smart healthcare has seen many successful stories. However, existing approaches for in-home health monitoring do not pay sufficient attention to user data privacy and thus are far from being ready for large-scale practical deployment. In this paper, we propose FedHome, a novel cloud-edge based federated learning framework for in-home health monitoring, which learns a shared global model in the cloud from multiple homes at the network edges and achieves data privacy protection by keeping user data locally. To cope with the imbalanced and non-IID distribution inherent in user’s monitoring data, we design a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user’s personal data. Besides, GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. Extensive experiments based on realistic human activity recognition data traces corroborate that FedHome significantly outperforms existing widely-adopted methods.",
    "citationCount": 341,
    "pdf_filename": "2020_FedHome__Cloud_Edge_Based_Personalized_F_f030656c.pdf"
  },
  "3571241861333dee845c9970dbd0d1e68a32fe71": {
    "paperId": "3571241861333dee845c9970dbd0d1e68a32fe71",
    "title": "Data augmentation for deep-learning-based electroencephalography",
    "year": 2020,
    "authors": "Elnaz Lashgari, Dehua Liang, U. Maoz",
    "abstract": "BACKGROUND\nData augmentation (DA) has recently been demonstrated to achieve considerable performance gains for deep learning (DL)-increased accuracy and stability and reduced overfitting. Some electroencephalography (EEG) tasks suffer from low samples-to-features ratio, severely reducing DL effectiveness. DA with DL thus holds transformative promise for EEG processing, possibly like DL revolutionized computer vision, etc. NEW METHOD: We review trends and approaches to DA for DL in EEG to address: Which DA approaches exist and are common for which EEG tasks? What input features are used? And, what kind of accuracy gain can be expected?\n\n\nRESULTS\nDA for DL on EEG begun 5 years ago and is steadily used more. We grouped DA techniques (noise addition, generative adversarial networks, sliding windows, sampling, Fourier transform, recombination of segmentation, and others) and EEG tasks (into seizure detection, sleep stages, motor imagery, mental workload, emotion recognition, motor tasks, and visual tasks). DA efficacy across techniques varied considerably. Noise addition and sliding windows provided the highest accuracy boost; mental workload most benefitted from DA. Sliding window, noise addition, and sampling methods most common for seizure detection, mental workload, and sleep stages, respectively.\n\n\nCOMPARING WITH EXISTING METHODS\nPercent of decoding accuracy explained by DA beyond unaugmented accuracy varied between 8% for recombination of segmentation and 36% for noise addition and from 14% for motor imagery to 56% for mental workload-29% on average.\n\n\nCONCLUSIONS\nDA increasingly used and considerably improved DL decoding accuracy on EEG. Additional publications-if adhering to our reporting guidelines-will facilitate more detailed analysis.",
    "citationCount": 309,
    "pdf_filename": "2020_Data_augmentation_for_deep_learning_base_35712418.pdf"
  },
  "3c6067c120790b142e9b581bfc82ca02db2ce095": {
    "paperId": "3c6067c120790b142e9b581bfc82ca02db2ce095",
    "title": "Artificial intelligence-driven innovation for enhancing supply chain resilience and performance under the effect of supply chain dynamism: an empirical investigation",
    "year": 2021,
    "authors": "Amine Belhadi, Venkatesh Mani, Sachin S. Kamble, S. Khan, Surabhi Verma",
    "abstract": "Supply chain resilience (SCRes) and performance have become increasingly important in the wake of the recent supply chain disruptions caused by subsequent pandemics and crisis. Besides, the context of digitalization, integration, and globalization of the supply chain has raised an increasing awareness of advanced information processing techniques such as Artificial Intelligence (AI) in building SCRes and improving supply chain performance (SCP). The present study investigates the direct and indirect effects of AI, SCRes, and SCP under a context of dynamism and uncertainty of the supply chain. In doing so, we have conceptualized the use of AI in the supply chain on the organizational information processing theory (OIPT). The developed framework was evaluated using a structural equation modeling (SEM) approach. Survey data was collected from 279 firms representing different sizes, operating in various sectors, and countries. Our findings suggest that while AI has a direct impact on SCP in the short-term, it is recommended to exploit its information processing capabilities to build SCRes for long-lasting SCP. This study is among the first to provide empirical evidence on maximizing the benefits of AI capabilities to generate sustained SCP. The study could be further extended using a longitudinal investigation to explore more facets of the phenomenon.",
    "citationCount": 470,
    "pdf_filename": "2021_Artificial_intelligence_driven_innovatio_3c6067c1.pdf"
  },
  "3c0293f7ddb627cd913ec6510fec7df63dd7ed61": {
    "paperId": "3c0293f7ddb627cd913ec6510fec7df63dd7ed61",
    "title": "Artificial Intelligence Augmentation of Radiologist Performance in Distinguishing COVID-19 from Pneumonia of Other Origin at Chest CT",
    "year": 2021,
    "authors": "H. Bai, Robin Wang, Z. Xiong, B. Hsieh, Ken Chang",
    "abstract": "Background Coronavirus disease 2019 (COVID-19) and pneumonia of other diseases share similar CT characteristics, which contributes to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system for differentiating COVID-19 and other pneumonia at chest CT and assessing radiologist performance without and with AI assistance. Materials and Methods A total of 521 patients with positive reverse transcription polymerase chain reaction results for COVID-19 and abnormal chest CT findings were retrospectively identified from 10 hospitals from January 2020 to April 2020. A total of 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia at chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by a two-layer fully connected neural network to pool slices together. The final cohort of 1186 patients (132 583 CT slices) was divided into training, validation, and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance in separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results The final model achieved a test accuracy of 96% (95% confidence interval [CI]: 90%, 98%), a sensitivity of 95% (95% CI: 83%, 100%), and a specificity of 96% (95% CI: 88%, 99%) with area under the receiver operating characteristic curve of 0.95 and area under the precision-recall curve of 0.90. On independent testing, this model achieved an accuracy of 87% (95% CI: 82%, 90%), a sensitivity of 89% (95% CI: 81%, 94%), and a specificity of 86% (95% CI: 80%, 90%) with area under the receiver operating characteristic curve of 0.90 and area under the precision-recall curve of 0.87. Assisted by the probabilities of the model, the radiologists achieved a higher average test accuracy (90% vs 85%, &#916; = 5, P < .001), sensitivity (88% vs 79%, &#916; = 9, P < .001), and specificity (91% vs 88%, &#916; = 3, P = .001). Conclusion Artificial intelligence assistance improved radiologists' performance in distinguishing coronavirus disease 2019 pneumonia from non-coronavirus disease 2019 pneumonia at chest CT. © RSNA, 2020 Online supplemental material is available for this article.",
    "citationCount": 301,
    "pdf_filename": "2021_Artificial_Intelligence_Augmentation_of__3c0293f7.pdf"
  },
  "9bbb61d9bcfa1a2b63efbdb8a521af8c8a2e94ec": {
    "paperId": "9bbb61d9bcfa1a2b63efbdb8a521af8c8a2e94ec",
    "title": "End-to-end privacy preserving deep learning on multi-institutional medical imaging",
    "year": 2021,
    "authors": "Georgios Kaissis, Alexander Ziller, Jonathan Passerat-Palmbach, T. Ryffel, Dmitrii Usynin",
    "abstract": "Using large, multi-national datasets for high-performance medical imaging AI systems requires innovation in privacy-preserving machine learning so models can train on sensitive data without requiring data transfer. Here we present PriMIA (Privacy-preserving Medical Image Analysis), a free, open-source software framework for differentially private, securely aggregated federated learning and encrypted inference on medical imaging data. We test PriMIA using a real-life case study in which an expert-level deep convolutional neural network classifies paediatric chest X-rays; the resulting model’s classification performance is on par with locally, non-securely trained models. We theoretically and empirically evaluate our framework’s performance and privacy guarantees, and demonstrate that the protections provided prevent the reconstruction of usable data by a gradient-based model inversion attack. Finally, we successfully employ the trained model in an end-to-end encrypted remote inference scenario using secure multi-party computation to prevent the disclosure of the data and the model. Gaining access to medical data to train AI applications can present problems due to patient privacy or proprietary interests. A way forward can be privacy-preserving federated learning schemes. Kaissis, Ziller and colleagues demonstrate here their open source framework for privacy-preserving medical image analysis in a remote inference scenario.",
    "citationCount": 385,
    "pdf_filename": "2021_End_to_end_privacy_preserving_deep_learn_9bbb61d9.pdf"
  },
  "19923458a40496d4fe1259662a0e2deea4465957": {
    "paperId": "19923458a40496d4fe1259662a0e2deea4465957",
    "title": "Current Challenges and Future Opportunities for XAI in Machine Learning-Based Clinical Decision Support Systems: A Systematic Review",
    "year": 2021,
    "authors": "A. Antoniadi, Yuhan Du, Yasmine Guendouz, Lan Wei, Claudia Mazo",
    "abstract": "Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs.",
    "citationCount": 456,
    "pdf_filename": "2021_Current_Challenges_and_Future_Opportunit_19923458.pdf"
  },
  "209fadc6f7fdbb92404ef69d2ee01df8e475d692": {
    "paperId": "209fadc6f7fdbb92404ef69d2ee01df8e475d692",
    "title": "Rainbow Memory: Continual Learning with a Memory of Diverse Samples",
    "year": 2021,
    "authors": "Jihwan Bang, Heesu Kim, Y. Yoo, Jung-Woo Ha, Jonghyun Choi",
    "abstract": "Continual learning is a realistic learning scenario for AI models. Prevalent scenario of continual learning, however, assumes disjoint sets of classes as tasks and is less realistic rather artificial. Instead, we focus on ‘blurry’ task boundary; where tasks shares classes and is more realistic and practical. To address such task, we argue the importance of diversity of samples in an episodic memory. To enhance the sample diversity in the memory, we propose a novel memory management strategy based on per-sample classification uncertainty and data augmentation, named Rainbow Memory (RM). With extensive empirical validations on MNIST, CIFAR10, CIFAR100, and ImageNet datasets, we show that the proposed method significantly improves the accuracy in blurry continual learning setups, outperforming state of the arts by large margins despite its simplicity. Code and data splits will be available in https://github.com/clovaai/rainbow-memory.",
    "citationCount": 413,
    "pdf_filename": "2021_Rainbow_Memory__Continual_Learning_with__209fadc6.pdf"
  },
  "0f4f35880697674efcb6ebf6b14f099bd8e7f920": {
    "paperId": "0f4f35880697674efcb6ebf6b14f099bd8e7f920",
    "title": "Viral infection and transmission in a large, well-traced outbreak caused by the SARS-CoV-2 Delta variant",
    "year": 2021,
    "authors": "Baisheng Li, A. Deng, Kui-biao Li, Yao Hu, Zhencui Li",
    "abstract": "The SARS-CoV-2 Delta variant has spread rapidly worldwide. To provide data on its virological profile, we here report the first local transmission of Delta in mainland China. All 167 infections could be traced back to the first index case. Daily sequential PCR testing of quarantined individuals indicated that the viral loads of Delta infections, when they first become PCR-positive, were on average ~1000 times greater compared to lineage A/B infections during the first epidemic wave in China in early 2020, suggesting potentially faster viral replication and greater infectiousness of Delta during early infection. The estimated transmission bottleneck size of the Delta variant was generally narrow, with 1-3 virions in 29 donor-recipient transmission pairs. However, the transmission of minor iSNVs resulted in at least 3 of the 34 substitutions that were identified in the outbreak, highlighting the contribution of intra-host variants to population-level viral diversity during rapid spread. The SARS-CoV-2 Delta variant has spread rapidly worldwide. Here, the authors characterise a single chain of transmission of Delta in China, and find evidence that it is more infectious and replicates faster during early infection compared to early pandemic lineages.",
    "citationCount": 459,
    "pdf_filename": "2021_Viral_infection_and_transmission_in_a_la_0f4f3588.pdf"
  },
  "15ababe7cfd45041daa05efd97d5193d06693123": {
    "paperId": "15ababe7cfd45041daa05efd97d5193d06693123",
    "title": "A comparison between VGG16, VGG19 and ResNet50 architecture frameworks for Image Classification",
    "year": 2021,
    "authors": "Sheldon Mascarenhas, Mukul l Agarwal",
    "abstract": "Artificial Intelligence advancements have come a long way over the past twenty years. Rapid developments in AI have given birth to a trending topic called machine learning. Machine learning enables us to use algorithms and programming techniques to extract, understand and train data. Machine learning led to the creation of a concept called deep learning which uses algorithms to create an artificial neural network and use it to develop and learn, based on which it makes intuitive decisions by itself. Image classification is a task where we classify the images into sets of different categories, which when performed using deep learning increases business productivity by saving time and manpower. In this paper, we intend to determine which model of the architecture of the Convoluted Neural Network (CNN) can be used to solve a real-life problem of product classification to help optimize pricing comparison. We have compared the VGG16, VGG19, and ResNet50 architectures based on their accuracy while all three of these models solve the same image classification problem. We have concluded that the ResNet50 is the best architecture based on the comparison. These models have provided accuracies of 0.9667, 0.9707, and 0.9733 for VGG16, VGG19, and ResNet50 at epoch 20. The data provided is a real-life data set, sourced from a regional retailer.",
    "citationCount": 377,
    "pdf_filename": "2021_A_comparison_between_VGG16__VGG19_and_Re_15ababe7.pdf"
  },
  "54ca116f1e9a45768a3a2c47a4608ff34adefa0c": {
    "paperId": "54ca116f1e9a45768a3a2c47a4608ff34adefa0c",
    "title": "Therapeutics Data Commons: Machine Learning Datasets and Tasks for Drug Discovery and Development",
    "year": 2021,
    "authors": "Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf H. Roohani",
    "abstract": "Therapeutics machine learning is an emerging field with incredible opportunities for innovatiaon and impact. However, advancement in this field requires formulation of meaningful learning tasks and careful curation of datasets. Here, we introduce Therapeutics Data Commons (TDC), the first unifying platform to systematically access and evaluate machine learning across the entire range of therapeutics. To date, TDC includes 66 AI-ready datasets spread across 22 learning tasks and spanning the discovery and development of safe and effective medicines. TDC also provides an ecosystem of tools and community resources, including 33 data functions and types of meaningful data splits, 23 strategies for systematic model evaluation, 17 molecule generation oracles, and 29 public leaderboards. All resources are integrated and accessible via an open Python library. We carry out extensive experiments on selected datasets, demonstrating that even the strongest algorithms fall short of solving key therapeutics challenges, including real dataset distributional shifts, multi-scale modeling of heterogeneous data, and robust generalization to novel data points. We envision that TDC can facilitate algorithmic and scientific advances and considerably accelerate machine-learning model development, validation and transition into biomedical and clinical implementation. TDC is an open-science initiative available at https://tdcommons.ai.",
    "citationCount": 350,
    "pdf_filename": "2021_Therapeutics_Data_Commons__Machine_Learn_54ca116f.pdf"
  },
  "8f566001453bc6be0a935bf69ffd90d9db3af32b": {
    "paperId": "8f566001453bc6be0a935bf69ffd90d9db3af32b",
    "title": "Towards Causal Representation Learning",
    "year": 2021,
    "authors": "B. Scholkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner",
    "abstract": "The two fields of machine learning and graphical causality arose and developed separately. However, there is now cross-pollination and increasing interest in both fields to benefit from the advances of the other. In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.",
    "citationCount": 338,
    "pdf_filename": "2021_Towards_Causal_Representation_Learning_8f566001.pdf"
  },
  "e58f278d8f30f1d48f0b0f3d1a4f944ce9ca7797": {
    "paperId": "e58f278d8f30f1d48f0b0f3d1a4f944ce9ca7797",
    "title": "Security and Privacy for 6G: A Survey on Prospective Technologies and Challenges",
    "year": 2021,
    "authors": "V. Nguyen, Po-Ching Lin, Bo-Chao Cheng, Ren-Hung Hwang, Ying-Dar Lin",
    "abstract": "Sixth-generation (6G) mobile networks will have to cope with diverse threats on a space-air-ground integrated network environment, novel technologies, and an accessible user information explosion. However, for now, security and privacy issues for 6G remain largely in concept. This survey provides a systematic overview of security and privacy issues based on prospective technologies for 6G in the physical, connection, and service layers, as well as through lessons learned from the failures of existing security architectures and state-of-the-art defenses. Two key lessons learned are as follows. First, other than inheriting vulnerabilities from the previous generations, 6G has new threat vectors from new radio technologies, such as the exposed location of radio stripes in ultra-massive MIMO systems at Terahertz bands and attacks against pervasive intelligence. Second, physical layer protection, deep network slicing, quantum-safe communications, artificial intelligence (AI) security, platform-agnostic security, real-time adaptive security, and novel data protection mechanisms such as distributed ledgers and differential privacy are the top promising techniques to mitigate the attack magnitude and personal data breaches substantially.",
    "citationCount": 343,
    "pdf_filename": "2021_Security_and_Privacy_for_6G__A_Survey_on_e58f278d.pdf"
  },
  "fc0b46a0f3720e6c29c1a913aaa3de4a0699f713": {
    "paperId": "fc0b46a0f3720e6c29c1a913aaa3de4a0699f713",
    "title": "PathVQA: 30000+ Questions for Medical Visual Question Answering",
    "year": 2020,
    "authors": "Xuehai He, Yichen Zhang, Luntian Mou, E. Xing, Pengtao Xie",
    "abstract": "Is it possible to develop an \"AI Pathologist\" to pass the board-certified examination of the American Board of Pathology? To achieve this goal, the first step is to create a visual question answering (VQA) dataset where the AI agent is presented with a pathology image together with a question and is asked to give the correct answer. Our work makes the first attempt to build such a dataset. Different from creating general-domain VQA datasets where the images are widely accessible and there are many crowdsourcing workers available and capable of generating question-answer pairs, developing a medical VQA dataset is much more challenging. First, due to privacy concerns, pathology images are usually not publicly available. Second, only well-trained pathologists can understand pathology images, but they barely have time to help create datasets for AI research. To address these challenges, we resort to pathology textbooks and online digital libraries. We develop a semi-automated pipeline to extract pathology images and captions from textbooks and generate question-answer pairs from captions using natural language processing. We collect 32,799 open-ended questions from 4,998 pathology images where each question is manually checked to ensure correctness. To our best knowledge, this is the first dataset for pathology VQA. Our dataset will be released publicly to promote research in medical VQA.",
    "citationCount": 368,
    "pdf_filename": "2020_PathVQA__30000__Questions_for_Medical_Vi_fc0b46a0.pdf"
  },
  "8b165eba2d0b9308682fdc4d775c00d1d3907a59": {
    "paperId": "8b165eba2d0b9308682fdc4d775c00d1d3907a59",
    "title": "Demystifying the Draft EU Artificial Intelligence Act — Analysing the good, the bad, and the unclear elements of the proposed approach",
    "year": 2021,
    "authors": "Michael Veale, Frederik J. Zuiderveen Borgesius",
    "abstract": "In April 2021, the European Commission proposed a Regulation on Artificial Intelligence, known as the AI Act. We present an overview of the Act and analyse its implications, drawing on scholarship ranging from the study of contemporary AI practices to the structure of EU product safety regimes over the last four decades. Aspects of the AI Act, such as different rules for different risk-levels of AI, make sense. But we also find that some provisions of the draft AI Act have surprising legal implications, whilst others may be largely ineffective at achieving their stated goals. Several overarching aspects, including the enforcement regime and the effect of maximum harmonisation on the space for AI policy more generally, engender significant concern. These issues should be addressed as a priority in the legislative process.",
    "citationCount": 435,
    "pdf_filename": "2021_Demystifying_the_Draft_EU_Artificial_Int_8b165eba.pdf"
  },
  "04c902a91806288af4c7646e95cc2c94d9f15d97": {
    "paperId": "04c902a91806288af4c7646e95cc2c94d9f15d97",
    "title": "Recommendation of the Council on Artificial Intelligence (OECD)",
    "year": 2020,
    "authors": "K. Yeung",
    "abstract": "On May 22, 2019, the Organisation for Economic Co-operation and Development (OECD) Ministerial Council Meeting adopted the Recommendation on Artificial Intelligence, signed by all 36 OECD member countries and non-member countries Argentina, Brazil, Columbia, Costa Rica, Peru, and Romania. Its aim is to foster innovation and trust in artificial intelligence (AI) by promoting the “responsible stewardship of trustworthy AI.”",
    "citationCount": 492,
    "pdf_filename": "2020_Recommendation_of_the_Council_on_Artific_04c902a9.pdf"
  },
  "65772de56676a6a437c8abaeccef34224f62ee13": {
    "paperId": "65772de56676a6a437c8abaeccef34224f62ee13",
    "title": "To Trust or to Think",
    "year": 2021,
    "authors": "Zana Buçinca, M. Malaya, Krzysztof Z Gajos",
    "abstract": "People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI's suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.",
    "citationCount": 410,
    "pdf_filename": "2021_To_Trust_or_to_Think_65772de5.pdf"
  },
  "8684506a5c7e208d36ffde509aad3a21abc04c04": {
    "paperId": "8684506a5c7e208d36ffde509aad3a21abc04c04",
    "title": "Digital pathology and artificial intelligence in translational medicine and clinical practice",
    "year": 2021,
    "authors": "V. Baxi, R. Edwards, M. Montalto, Saurabh Saha",
    "abstract": "Traditional pathology approaches have played an integral role in the delivery of diagnosis, semi-quantitative or qualitative assessment of protein expression, and classification of disease. Technological advances and the increased focus on precision medicine have recently paved the way for the development of digital pathology-based approaches for quantitative pathologic assessments, namely whole slide imaging and artificial intelligence (AI)–based solutions, allowing us to explore and extract information beyond human visual perception. Within the field of immuno-oncology, the application of such methodologies in drug development and translational research have created invaluable opportunities for deciphering complex pathophysiology and the discovery of novel biomarkers and drug targets. With an increasing number of treatment options available for any given disease, practitioners face the growing challenge of selecting the most appropriate treatment for each patient. The ever-increasing utilization of AI-based approaches substantially expands our understanding of the tumor microenvironment, with digital approaches to patient stratification and selection for diagnostic assays supporting the identification of the optimal treatment regimen based on patient profiles. This review provides an overview of the opportunities and limitations around implementing AI-based methods in biomarker discovery and patient selection and discusses how advances in digital pathology and AI should be considered in the current landscape of translational medicine, touching on challenges this technology may face if adopted in clinical settings. The traditional role of pathologists in delivering accurate diagnoses or assessing biomarkers for companion diagnostics may be enhanced in precision, reproducibility, and scale by AI-powered analysis tools.",
    "citationCount": 419,
    "pdf_filename": "2021_Digital_pathology_and_artificial_intelli_8684506a.pdf"
  },
  "870da55ec826bcfeae42ca0f72e06be3660ebcea": {
    "paperId": "870da55ec826bcfeae42ca0f72e06be3660ebcea",
    "title": "Machine-Learning-Based Disease Diagnosis: A Comprehensive Review",
    "year": 2021,
    "authors": "M. Ahsan, Z. Siddique",
    "abstract": "Globally, there is a substantial unmet need to diagnose various diseases effectively. The complexity of the different disease mechanisms and underlying symptoms of the patient population presents massive challenges in developing the early diagnosis tool and effective treatment. Machine learning (ML), an area of artificial intelligence (AI), enables researchers, physicians, and patients to solve some of these issues. Based on relevant research, this review explains how machine learning (ML) is being used to help in the early identification of numerous diseases. Initially, a bibliometric analysis of the publication is carried out using data from the Scopus and Web of Science (WOS) databases. The bibliometric study of 1216 publications was undertaken to determine the most prolific authors, nations, organizations, and most cited articles. The review then summarizes the most recent trends and approaches in machine-learning-based disease diagnosis (MLBDD), considering the following factors: algorithm, disease types, data type, application, and evaluation metrics. Finally, in this paper, we highlight key results and provides insight into future trends and opportunities in the MLBDD area.",
    "citationCount": 408,
    "pdf_filename": "2021_Machine_Learning_Based_Disease_Diagnosis_870da55e.pdf"
  },
  "cce1f4f0ffce089ce623f6d132b75fb139302b0f": {
    "paperId": "cce1f4f0ffce089ce623f6d132b75fb139302b0f",
    "title": "Artificial Intelligence in Cancer Research and Precision Medicine.",
    "year": 2021,
    "authors": "B. Bhinder, Coryandar Gilvary, Neel S. Madhukar, O. Elemento",
    "abstract": "Artificial intelligence (AI) is rapidly reshaping cancer research and personalized clinical care. Availability of high-dimensionality datasets coupled with advances in high-performance computing, as well as innovative deep learning architectures, has led to an explosion of AI use in various aspects of oncology research. These applications range from detection and classification of cancer, to molecular characterization of tumors and their microenvironment, to drug discovery and repurposing, to predicting treatment outcomes for patients. As these advances start penetrating the clinic, we foresee a shifting paradigm in cancer care becoming strongly driven by AI. SIGNIFICANCE: AI has the potential to dramatically affect nearly all aspects of oncology-from enhancing diagnosis to personalizing treatment and discovering novel anticancer drugs. Here, we review the recent enormous progress in the application of AI to oncology, highlight limitations and pitfalls, and chart a path for adoption of AI in the cancer clinic.",
    "citationCount": 438,
    "pdf_filename": "2021_Artificial_Intelligence_in_Cancer_Resear_cce1f4f0.pdf"
  },
  "363165e6781dc79829d9e775a4bece3d9639ced6": {
    "paperId": "363165e6781dc79829d9e775a4bece3d9639ced6",
    "title": "Human- versus Artificial Intelligence",
    "year": 2021,
    "authors": "J. Korteling, G. V. D. Boer-Visschedijk, R. Blankendaal, R. Boonekamp, A. Eikelboom",
    "abstract": "AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.",
    "citationCount": 367,
    "pdf_filename": "2021_Human__versus_Artificial_Intelligence_363165e6.pdf"
  },
  "9198d6ab8ad1c6f1527a7d4adf06809848bf23c7": {
    "paperId": "9198d6ab8ad1c6f1527a7d4adf06809848bf23c7",
    "title": "Challenges and Future Directions of Big Data and Artificial Intelligence in Education",
    "year": 2020,
    "authors": "Hui Luan, P. Géczy, H. Lai, J. Gobert, Stephen J. H. Yang",
    "abstract": "We discuss the new challenges and directions facing the use of big data and artificial intelligence (AI) in education research, policy-making, and industry. In recent years, applications of big data and AI in education have made significant headways. This highlights a novel trend in leading-edge educational research. The convenience and embeddedness of data collection within educational technologies, paired with computational techniques have made the analyses of big data a reality. We are moving beyond proof-of-concept demonstrations and applications of techniques, and are beginning to see substantial adoption in many areas of education. The key research trends in the domains of big data and AI are associated with assessment, individualized learning, and precision education. Model-driven data analytics approaches will grow quickly to guide the development, interpretation, and validation of the algorithms. However, conclusions from educational analytics should, of course, be applied with caution. At the education policy level, the government should be devoted to supporting lifelong learning, offering teacher education programs, and protecting personal data. With regard to the education industry, reciprocal and mutually beneficial relationships should be developed in order to enhance academia-industry collaboration. Furthermore, it is important to make sure that technologies are guided by relevant theoretical frameworks and are empirically tested. Lastly, in this paper we advocate an in-depth dialog between supporters of “cold” technology and “warm” humanity so that it can lead to greater understanding among teachers and students about how technology, and specifically, the big data explosion and AI revolution can bring new opportunities (and challenges) that can be best leveraged for pedagogical practices and learning.",
    "citationCount": 401,
    "pdf_filename": "2020_Challenges_and_Future_Directions_of_Big__9198d6ab.pdf"
  },
  "9d9cd469279655f8efc2c0c95e55295036c8ab12": {
    "paperId": "9d9cd469279655f8efc2c0c95e55295036c8ab12",
    "title": "Governance of artificial intelligence",
    "year": 2021,
    "authors": "Araz Taeihagh",
    "abstract": "ABSTRACT The rapid developments in Artificial Intelligence (AI) and the intensification in the adoption of AI in domains such as autonomous vehicles, lethal weapon systems, robotics and alike pose serious challenges to governments as they must manage the scale and speed of socio-technical transitions occurring. While there is considerable literature emerging on various aspects of AI, governance of AI is a significantly underdeveloped area. The new applications of AI offer opportunities for increasing economic efficiency and quality of life, but they also generate unexpected and unintended consequences and pose new forms of risks that need to be addressed. To enhance the benefits from AI while minimising the adverse risks, governments worldwide need to understand better the scope and depth of the risks posed and develop regulatory and governance processes and structures to address these challenges. This introductory article unpacks AI and describes why the Governance of AI should be gaining far more attention given the myriad of challenges it presents. It then summarises the special issue articles and highlights their key contributions. This special issue introduces the multifaceted challenges of governance of AI, including emerging governance approaches to AI, policy capacity building, exploring legal and regulatory challenges of AI and Robotics, and outstanding issues and gaps that need attention. The special issue showcases the state-of-the-art in the governance of AI, aiming to enable researchers and practitioners to appreciate the challenges and complexities of AI governance and highlight future avenues for exploration.",
    "citationCount": 311,
    "pdf_filename": "2021_Governance_of_artificial_intelligence_9d9cd469.pdf"
  },
  "82e4cfd74d8d390bbb63625d724ffc6eb752bed4": {
    "paperId": "82e4cfd74d8d390bbb63625d724ffc6eb752bed4",
    "title": "Artificial intelligence for supply chain resilience: learning from Covid-19",
    "year": 2021,
    "authors": "S. Modgil, R. Singh, C. Hannibal",
    "abstract": "PurposeMany supply chains have faced disruption during Covid-19. Artificial intelligence (AI) is one mechanism that can be used to improve supply chain resilience by developing business continuity capabilities. This study examines how firms employ AI and consider the opportunities for AI to enhance supply chain resilience by developing visibility, risk, sourcing and distribution capabilities.Design/methodology/approachThe authors have gathered rich data by conducting semistructured interviews with 35 experts from the e-commerce supply chain. The authors have adopted a systematic approach of coding using open, axial and selective methods to map and identify the themes that represent the critical elements of AI-enabled supply chain resilience.FindingsThe results of the study highlight the emergence of five critical areas where AI can contribute to enhanced supply chain resilience; (1) transparency, (2) ensuring last-mile delivery, (3) offering personalized solutions to both upstream and downstream supply chain stakeholders, (4) minimizing the impact of disruption and (5) facilitating an agile procurement strategy.Research limitations/implicationsThe study offers interesting implications for bridging the theory–practice gap by drawing on contemporary empirical data to demonstrate how enhancing dynamic capabilities via AI technologies further strengthens supply chain resilience. The study also offers suggestions for utilizing the findings and proposes a framework to strengthen supply chain resilience through AI.Originality/valueThe study presents the dynamic capabilities for supply chain resilience through the employment of AI. AI can contribute to readying supply chains to reduce their risk of disruption through enhanced resilience.",
    "citationCount": 322,
    "pdf_filename": "2021_Artificial_intelligence_for_supply_chain_82e4cfd7.pdf"
  },
  "13c37c5419da09a2fd303e6dac3ebf8077e72ae7": {
    "paperId": "13c37c5419da09a2fd303e6dac3ebf8077e72ae7",
    "title": "The impact of 5G on the evolution of intelligent automation and industry digitization",
    "year": 2021,
    "authors": "M. Attaran",
    "abstract": "The mobile industry is developing and preparing to deploy the fifth-generation (5G) networks. The evolving 5G networks are becoming more readily available as a significant driver of the growth of IoT and other intelligent automation applications. 5G’s lightning-fast connection and low-latency are needed for advances in intelligent automation—the Internet of Things (IoT), Artificial Intelligence (AI), driverless cars, digital reality, blockchain, and future breakthroughs we haven’t even thought of yet. The advent of 5G is more than just a generational step; it opens a new world of possibilities for every tech industry. The purpose of this paper is to do a literature review and explore how 5G can enable or streamline intelligent automation in different industries. This paper reviews the evolution and development of various generations of mobile wireless technology underscores the importance of 5G revolutionary networks, reviews its key enabling technologies, examines its trends and challenges, explores its applications in different manufacturing industries, and highlights its role in shaping the age of unlimited connectivity, intelligent automation, and industry digitization.",
    "citationCount": 348,
    "pdf_filename": "2021_The_impact_of_5G_on_the_evolution_of_int_13c37c54.pdf"
  },
  "34602875dc6c40f8060d517669b80bbed5538da5": {
    "paperId": "34602875dc6c40f8060d517669b80bbed5538da5",
    "title": "The promise of artificial intelligence: a review of the opportunities and challenges of artificial intelligence in healthcare.",
    "year": 2021,
    "authors": "Y. Y. Aung, D. C. Wong, D. Ting",
    "abstract": "INTRODUCTION\nArtificial intelligence (AI) and machine learning (ML) are rapidly evolving fields in various sectors, including healthcare. This article reviews AI's present applications in healthcare, including its benefits, limitations and future scope.\n\n\nSOURCES OF DATA\nA review of the English literature was conducted with search terms 'AI' or 'ML' or 'deep learning' and 'healthcare' or 'medicine' using PubMED and Google Scholar from 2000-2021.\n\n\nAREAS OF AGREEMENT\nAI could transform physician workflow and patient care through its applications, from assisting physicians and replacing administrative tasks to augmenting medical knowledge.\n\n\nAREAS OF CONTROVERSY\nFrom challenges training ML systems to unclear accountability, AI's implementation is difficult and incremental at best. Physicians also lack understanding of what AI implementation could represent.\n\n\nGROWING POINTS\nAI can ultimately prove beneficial in healthcare, but requires meticulous governance similar to the governance of physician conduct.\n\n\nAREAS TIMELY FOR DEVELOPING RESEARCH\nRegulatory guidelines are needed on how to safely implement and assess AI technology, alongside further research into the specific capabilities and limitations of its medical use.",
    "citationCount": 306,
    "pdf_filename": "2021_The_promise_of_artificial_intelligence___34602875.pdf"
  },
  "25b5a8eaa34abfeb737a63bc27388ca66e1a4a71": {
    "paperId": "25b5a8eaa34abfeb737a63bc27388ca66e1a4a71",
    "title": "Artificial intelligence in operations management and supply chain management: an exploratory case study",
    "year": 2021,
    "authors": "P. Helo, Yuqiuge Hao",
    "abstract": "Abstract With the development and evolution of information technology, competition has become more and more intensive on a global scale. Many companies have forecast that the future of operation and supply chain management (SCM) may change dramatically, from planning, scheduling, optimisation, to transportation, with the presence of artificial intelligence (AI). People will be more and more interested in machine learning, AI, and other intelligent technologies, in terms of SCM. Within this context, this particular research study provides an overview of the concept of AI and SCM. It then focuses on timely and critical analysis of AI-driven supply chain research and applications. In this exploratory research, the emerging AI-based business models of different case companies are analysed. Their relevant AI solutions and related values to companies are also evaluated. As a result, this research identifies several areas of value creation for the application of AI in the supply chain. It also proposes an approach to designing business models for AI supply chain applications.",
    "citationCount": 300,
    "pdf_filename": "2021_Artificial_intelligence_in_operations_ma_25b5a8ea.pdf"
  },
  "9e12539d92088001e08b1e903c490127c479de4c": {
    "paperId": "9e12539d92088001e08b1e903c490127c479de4c",
    "title": "Transformers as Soft Reasoners over Language",
    "year": 2020,
    "authors": "Peter Clark, Oyvind Tafjord, Kyle Richardson",
    "abstract": "Beginning with McCarthy's Advice Taker (1959), AI has pursued the goal of providing a system with explicit, general knowledge and having the system reason over that knowledge. However, expressing the knowledge in a formal (logical or probabilistic) representation has been a major obstacle to this research. This paper investigates a modern approach to this problem where the facts and rules are provided as natural language sentences, thus bypassing a formal representation. We train transformers to reason (or emulate reasoning) over these sentences using synthetically generated data. Our models, that we call RuleTakers, provide the first empirical demonstration that this kind of soft reasoning over language is learnable, can achieve high (99%) accuracy, and generalizes to test data requiring substantially deeper chaining than seen during training (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as limited \"soft theorem provers\" operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering.",
    "citationCount": 412,
    "pdf_filename": "2020_Transformers_as_Soft_Reasoners_over_Lang_9e12539d.pdf"
  },
  "e32a2519b59d62cff6cb8136ee242dc3754ed57b": {
    "paperId": "e32a2519b59d62cff6cb8136ee242dc3754ed57b",
    "title": "Second opinion needed: communicating uncertainty in medical machine learning",
    "year": 2021,
    "authors": "Benjamin Kompa, Jasper Snoek, A. Beam",
    "abstract": "There is great excitement that medical artificial intelligence (AI) based on machine learning (ML) can be used to improve decision making at the patient level in a variety of healthcare settings. However, the quantification and communication of uncertainty for individual predictions is often neglected even though uncertainty estimates could lead to more principled decision-making and enable machine learning models to automatically or semi-automatically abstain on samples for which there is high uncertainty. In this article, we provide an overview of different approaches to uncertainty quantification and abstention for machine learning and highlight how these techniques could improve the safety and reliability of current ML systems being used in healthcare settings. Effective quantification and communication of uncertainty could help to engender trust with healthcare workers, while providing safeguards against known failure modes of current machine learning approaches. As machine learning becomes further integrated into healthcare environments, the ability to say “I’m not sure” or “I don’t know” when uncertain is a necessary capability to enable safe clinical deployment.",
    "citationCount": 347,
    "pdf_filename": "2021_Second_opinion_needed__communicating_unc_e32a2519.pdf"
  },
  "783dead4fd1aa29ee019a2f324e859a6b3dcb332": {
    "paperId": "783dead4fd1aa29ee019a2f324e859a6b3dcb332",
    "title": "Artificial Intelligence for Student Assessment: A Systematic Review",
    "year": 2021,
    "authors": "Víctor González-Calatayud, Paz Prendes-Espinosa, Rosabel Roig-Vila",
    "abstract": "Artificial Intelligence (AI) is being implemented in more and more fields, including education. The main uses of AI in education are related to tutoring and assessment. This paper analyzes the use of AI for student assessment based on a systematic review. For this purpose, a search was carried out in two databases: Scopus and Web of Science. A total of 454 papers were found and, after analyzing them according to the PRISMA Statement, a total of 22 papers were selected. It is clear from the studies analyzed that, in most of them, the pedagogy underlying the educational action is not reflected. Similarly, formative evaluation seems to be the main use of AI. Another of the main functionalities of AI in assessment is for the automatic grading of students. Several studies analyze the differences between the use of AI and its non-use. We discuss the results and conclude the need for teacher training and further research to understand the possibilities of AI in educational assessment, mainly in other educational levels than higher education. Moreover, it is necessary to increase the wealth of research which focuses on educational aspects more than technical development around AI.",
    "citationCount": 302,
    "pdf_filename": "2021_Artificial_Intelligence_for_Student_Asse_783dead4.pdf"
  },
  "00cb69a9f280317d1c59ac5827551ee9b10642b8": {
    "paperId": "00cb69a9f280317d1c59ac5827551ee9b10642b8",
    "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought",
    "year": 2023,
    "authors": "Yao Mu, Qinglong Zhang, Mengkang Hu, Wen Wang, Mingyu Ding",
    "abstract": "Embodied AI is a crucial frontier in robotics, capable of planning and executing action sequences for robots to accomplish long-horizon tasks in physical environments. In this work, we introduce EmbodiedGPT, an end-to-end multi-modal foundation model for embodied AI, empowering embodied agents with multi-modal understanding and execution capabilities. To achieve this, we have made the following efforts: (i) We craft a large-scale embodied planning dataset, termed EgoCOT. The dataset consists of carefully selected videos from the Ego4D dataset, along with corresponding high-quality language instructions. Specifically, we generate a sequence of sub-goals with the\"Chain of Thoughts\"mode for effective embodied planning. (ii) We introduce an efficient training approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We introduce a paradigm for extracting task-related features from LLM-generated planning queries to form a closed loop between high-level planning and low-level control. Extensive experiments show the effectiveness of EmbodiedGPT on embodied tasks, including embodied planning, embodied control, visual captioning, and visual question answering. Notably, EmbodiedGPT significantly enhances the success rate of the embodied control task by extracting more effective features. It has achieved a remarkable 1.6 times increase in success rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.",
    "citationCount": 335,
    "pdf_filename": "2023_EmbodiedGPT__Vision_Language_Pre_Trainin_00cb69a9.pdf"
  },
  "8448010d9adad18bf36070c012770a10ecb21c76": {
    "paperId": "8448010d9adad18bf36070c012770a10ecb21c76",
    "title": "Privacy and Robustness in Federated Learning: Attacks and Defenses",
    "year": 2020,
    "authors": "L. Lyu, Han Yu, Xingjun Ma, Lichao Sun, Jun Zhao",
    "abstract": "As data are increasingly being stored in different silos and societies becoming more aware of data privacy issues, the traditional centralized training of artificial intelligence (AI) models is facing efficiency and privacy challenges. Recently, federated learning (FL) has emerged as an alternative solution and continues to thrive in this new reality. Existing FL protocol designs have been shown to be vulnerable to adversaries within or outside of the system, compromising data privacy and system robustness. Besides training powerful global models, it is of paramount importance to design FL systems that have privacy guarantees and are resistant to different types of adversaries. In this article, we conduct a comprehensive survey on privacy and robustness in FL over the past five years. Through a concise introduction to the concept of FL and a unique taxonomy covering: 1) threat models; 2) privacy attacks and defenses; and 3) poisoning attacks and defenses, we provide an accessible review of this important topic. We highlight the intuitions, key techniques, and fundamental assumptions adopted by various attacks and defenses. Finally, we discuss promising future research directions toward robust and privacy-preserving FL, and their interplays with the multidisciplinary goals of FL.",
    "citationCount": 458,
    "pdf_filename": "2020_Privacy_and_Robustness_in_Federated_Lear_8448010d.pdf"
  },
  "a0d18dddaa995b126ad373e33767b9b881d16b2f": {
    "paperId": "a0d18dddaa995b126ad373e33767b9b881d16b2f",
    "title": "An Introductory Review of Deep Learning for Prediction Models With Big Data",
    "year": 2020,
    "authors": "F. Emmert-Streib, Zhenyi Yang, Han Feng, S. Tripathi, M. Dehmer",
    "abstract": "Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly—in an almost Lego-like manner—to build new application-specific network architectures. Hence, a basic understanding of these network architectures is important to be prepared for future developments in AI.",
    "citationCount": 456,
    "pdf_filename": "2020_An_Introductory_Review_of_Deep_Learning__a0d18ddd.pdf"
  },
  "f938a29f108fe901ba4bc9162bbece909e8940f1": {
    "paperId": "f938a29f108fe901ba4bc9162bbece909e8940f1",
    "title": "Future Intelligent and Secure Vehicular Network Toward 6G: Machine-Learning Approaches",
    "year": 2020,
    "authors": "Fengxiao Tang, Y. Kawamoto, N. Kato, Jiajia Liu",
    "abstract": "As a powerful tool, the vehicular network has been built to connect human communication and transportation around the world for many years to come. However, with the rapid growth of vehicles, the vehicular network becomes heterogeneous, dynamic, and large scaled, which makes it difficult to meet the strict requirements, such as ultralow latency, high reliability, high security, and massive connections of the next-generation (6G) network. Recently, machine learning (ML) has emerged as a powerful artificial intelligence (AI) technique to make both the vehicle and wireless communication highly efficient and adaptable. Naturally, employing ML into vehicular communication and network becomes a hot topic and is being widely studied in both academia and industry, paving the way for the future intelligentization in 6G vehicular networks. In this article, we provide a survey on various ML techniques applied to communication, networking, and security parts in vehicular networks and envision the ways of enabling AI toward a future 6G vehicular network, including the evolution of intelligent radio (IR), network intelligentization, and self-learning with proactive exploration.",
    "citationCount": 468,
    "pdf_filename": "2020_Future_Intelligent_and_Secure_Vehicular__f938a29f.pdf"
  },
  "93e353567bbc7525306a14b6219973d34b084c4e": {
    "paperId": "93e353567bbc7525306a14b6219973d34b084c4e",
    "title": "Artificial intelligence in radiology: 100 commercially available products and their scientific evidence",
    "year": 2021,
    "authors": "K. V. van Leeuwen, S. Schalekamp, Matthieu Rutten, B. van Ginneken, M. de Rooij",
    "abstract": "Map the current landscape of commercially available artificial intelligence (AI) software for radiology and review the availability of their scientific evidence. We created an online overview of CE-marked AI software products for clinical radiology based on vendor-supplied product specifications (www.aiforradiology.com). Characteristics such as modality, subspeciality, main task, regulatory information, deployment, and pricing model were retrieved. We conducted an extensive literature search on the available scientific evidence of these products. Articles were classified according to a hierarchical model of efficacy. The overview included 100 CE-marked AI products from 54 different vendors. For 64/100 products, there was no peer-reviewed evidence of its efficacy. We observed a large heterogeneity in deployment methods, pricing models, and regulatory classes. The evidence of the remaining 36/100 products comprised 237 papers that predominantly (65%) focused on diagnostic accuracy (efficacy level 2). From the 100 products, 18 had evidence that regarded level 3 or higher, validating the (potential) impact on diagnostic thinking, patient outcome, or costs. Half of the available evidence (116/237) were independent and not (co-)funded or (co-)authored by the vendor. Even though the commercial supply of AI software in radiology already holds 100 CE-marked products, we conclude that the sector is still in its infancy. For 64/100 products, peer-reviewed evidence on its efficacy is lacking. Only 18/100 AI products have demonstrated (potential) clinical impact. • Artificial intelligence in radiology is still in its infancy even though already 100 CE-marked AI products are commercially available. • Only 36 out of 100 products have peer-reviewed evidence of which most studies demonstrate lower levels of efficacy. • There is a wide variety in deployment strategies, pricing models, and CE marking class of AI products for radiology.",
    "citationCount": 323,
    "pdf_filename": "2021_Artificial_intelligence_in_radiology__10_93e35356.pdf"
  },
  "971ee735f8f259b220d35a252ee20f74b82c6371": {
    "paperId": "971ee735f8f259b220d35a252ee20f74b82c6371",
    "title": "COVID-19 Artificial Intelligence Diagnosis Using Only Cough Recordings",
    "year": 2020,
    "authors": "Jordi Laguarta, F. Hueto, B. Subirana",
    "abstract": "Goal: We hypothesized that COVID-19 subjects, especially including asymptomatics, could be accurately discriminated only from a forced-cough cell phone recording using Artificial Intelligence. To train our MIT Open Voice model we built a data collection pipeline of COVID-19 cough recordings through our website (opensigma.mit.edu) between April and May 2020 and created the largest audio COVID-19 cough balanced dataset reported to date with 5,320 subjects. Methods: We developed an AI speech processing framework that leverages acoustic biomarker feature extractors to pre-screen for COVID-19 from cough recordings, and provide a personalized patient saliency map to longitudinally monitor patients in real-time, non-invasively, and at essentially zero variable cost. Cough recordings are transformed with Mel Frequency Cepstral Coefficient and inputted into a Convolutional Neural Network (CNN) based architecture made up of one Poisson biomarker layer and 3 pre-trained ResNet50's in parallel, outputting a binary pre-screening diagnostic. Our CNN-based models have been trained on 4256 subjects and tested on the remaining 1064 subjects of our dataset. Transfer learning was used to learn biomarker features on larger datasets, previously successfully tested in our Lab on Alzheimer's, which significantly improves the COVID-19 discrimination accuracy of our architecture. Results: When validated with subjects diagnosed using an official test, the model achieves COVID-19 sensitivity of 98.5% with a specificity of 94.2% (AUC: 0.97). For asymptomatic subjects it achieves sensitivity of 100% with a specificity of 83.2%. Conclusions: AI techniques can produce a free, non-invasive, real-time, any-time, instantly distributable, large-scale COVID-19 asymptomatic screening tool to augment current approaches in containing the spread of COVID-19. Practical use cases could be for daily screening of students, workers, and public as schools, jobs, and transport reopen, or for pool testing to quickly alert of outbreaks in groups. General speech biomarkers may exist that cover several disease categories, as we demonstrated using the same ones for COVID-19 and Alzheimer's.",
    "citationCount": 431,
    "pdf_filename": "2020_COVID_19_Artificial_Intelligence_Diagnos_971ee735.pdf"
  },
  "dd47dd54dfe333e49805ede37d4e7a060241b3ba": {
    "paperId": "dd47dd54dfe333e49805ede37d4e7a060241b3ba",
    "title": "Conversational Agents in Health Care: Scoping Review and Conceptual Analysis",
    "year": 2020,
    "authors": "Lorainne Tudor Car, D. Dhinagaran, B. M. Kyaw, T. Kowatsch, Shafiq R. Joty",
    "abstract": "Background Conversational agents, also known as chatbots, are computer programs designed to simulate human text or verbal conversations. They are increasingly used in a range of fields, including health care. By enabling better accessibility, personalization, and efficiency, conversational agents have the potential to improve patient care. Objective This study aimed to review the current applications, gaps, and challenges in the literature on conversational agents in health care and provide recommendations for their future research, design, and application. Methods We performed a scoping review. A broad literature search was performed in MEDLINE (Medical Literature Analysis and Retrieval System Online; Ovid), EMBASE (Excerpta Medica database; Ovid), PubMed, Scopus, and Cochrane Central with the search terms “conversational agents,” “conversational AI,” “chatbots,” and associated synonyms. We also searched the gray literature using sources such as the OCLC (Online Computer Library Center) WorldCat database and ResearchGate in April 2019. Reference lists of relevant articles were checked for further articles. Screening and data extraction were performed in parallel by 2 reviewers. The included evidence was analyzed narratively by employing the principles of thematic analysis. Results The literature search yielded 47 study reports (45 articles and 2 ongoing clinical trials) that matched the inclusion criteria. The identified conversational agents were largely delivered via smartphone apps (n=23) and used free text only as the main input (n=19) and output (n=30) modality. Case studies describing chatbot development (n=18) were the most prevalent, and only 11 randomized controlled trials were identified. The 3 most commonly reported conversational agent applications in the literature were treatment and monitoring, health care service support, and patient education. Conclusions The literature on conversational agents in health care is largely descriptive and aimed at treatment and monitoring and health service support. It mostly reports on text-based, artificial intelligence–driven, and smartphone app–delivered conversational agents. There is an urgent need for a robust evaluation of diverse health care conversational agents’ formats, focusing on their acceptability, safety, and effectiveness.",
    "citationCount": 375,
    "pdf_filename": "2020_Conversational_Agents_in_Health_Care__Sc_dd47dd54.pdf"
  },
  "6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291": {
    "paperId": "6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291",
    "title": "Advancing Biosensors with Machine Learning.",
    "year": 2020,
    "authors": "Feiyun Cui, Yun Yue, Yi Zhang, Ziming Zhang, H. S. Zhou",
    "abstract": "Chemometrics play a critical role in biosensors-based detection, analysis, and diagnosis. Nowadays, as a branch of artificial intelligence (AI), machine learning (ML) have achieved impressive advances. However, novel advanced ML methods, especially deep learning, which is famous for image analysis, facial recognition, and speech recognition, has remained relatively elusive to the biosensor community. Herein, how ML can be beneficial to biosensors is systematically discussed. The advantages and drawbacks of most popular ML algorithms are summarized on the basis of sensing data analysis. Specially, deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN) are emphasized. Diverse ML-assisted electrochemical biosensors, wearable electronics, SERS and other spectra-based biosensors, fluorescence biosensors and colorimetric biosensors are comprehensively discussed. Furthermore, biosensor networks and multibiosensor data fusion are introduced. This review will nicely bridge ML with biosensors, and greatly expand chemometrics for detection, analysis, and diagnosis.",
    "citationCount": 483,
    "pdf_filename": "2020_Advancing_Biosensors_with_Machine_Learni_6f803c17.pdf"
  },
  "2ced2ac19a88439b52e519d2e6ce44cccf08e191": {
    "paperId": "2ced2ac19a88439b52e519d2e6ce44cccf08e191",
    "title": "Motif-based Graph Self-Supervised Learning for Molecular Property Prediction",
    "year": 2021,
    "authors": "Zaixin Zhang, Qi Liu, Hao Wang, Chengqiang Lu, Chee-Kong Lee",
    "abstract": "Predicting molecular properties with data-driven methods has drawn much attention in recent years. Particularly, Graph Neural Networks (GNNs) have demonstrated remarkable success in various molecular generation and prediction tasks. In cases where labeled data is scarce, GNNs can be pre-trained on unlabeled molecular data to first learn the general semantic and structural information before being fine-tuned for specific tasks. However, most existing self-supervised pre-training frameworks for GNNs only focus on node-level or graph-level tasks. These approaches cannot capture the rich information in subgraphs or graph motifs. For example, functional groups (frequently-occurred subgraphs in molecular graphs) often carry indicative information about the molecular properties. To bridge this gap, we propose Motif-based Graph Self-supervised Learning (MGSSL) by introducing a novel self-supervised motif generation framework for GNNs. First, for motif extraction from molecular graphs, we design a molecule fragmentation method that leverages a retrosynthesis-based algorithm BRICS and additional rules for controlling the size of motif vocabulary. Second, we design a general motif-based generative pre-training framework in which GNNs are asked to make topological and label predictions. This generative framework can be implemented in two different ways, i.e., breadth-first or depth-first. Finally, to take the multi-scale information in molecular graphs into consideration, we introduce a multi-level self-supervised pre-training. Extensive experiments on various downstream benchmark tasks show that our methods outperform all state-of-the-art baselines.",
    "citationCount": 310,
    "pdf_filename": "2021_Motif_based_Graph_Self_Supervised_Learni_2ced2ac1.pdf"
  },
  "60f484f0769a2916fb6706160990a134f6b4ca0b": {
    "paperId": "60f484f0769a2916fb6706160990a134f6b4ca0b",
    "title": "A review on deep learning in medical image analysis",
    "year": 2021,
    "authors": "S. Suganyadevi, V. Seethalakshmi, K. Balasamy",
    "abstract": "Ongoing improvements in AI, particularly concerning deep learning techniques, are assisting to identify, classify, and quantify patterns in clinical images. Deep learning is the quickest developing field in artificial intelligence and is effectively utilized lately in numerous areas, including medication. A brief outline is given on studies carried out on the region of application: neuro, brain, retinal, pneumonic, computerized pathology, bosom, heart, breast, bone, stomach, and musculoskeletal. For information exploration, knowledge deployment, and knowledge-based prediction, deep learning networks can be successfully applied to big data. In the field of medical image processing methods and analysis, fundamental information and state-of-the-art approaches with deep learning are presented in this paper. The primary goals of this paper are to present research on medical image processing as well as to define and implement the key guidelines that are identified and addressed.",
    "citationCount": 310,
    "pdf_filename": "2021_A_review_on_deep_learning_in_medical_ima_60f484f0.pdf"
  },
  "bbdd3e510522698f250afe5b2c40e9729a429a3e": {
    "paperId": "bbdd3e510522698f250afe5b2c40e9729a429a3e",
    "title": "Network pharmacology: towards the artificial intelligence-based precision traditional Chinese medicine",
    "year": 2023,
    "authors": "Peng Zhang, Di Zhang, Wuai Zhou, Lan Wang, Boyang Wang",
    "abstract": "Abstract Network pharmacology (NP) provides a new methodological perspective for understanding traditional medicine from a holistic perspective, giving rise to frontiers such as traditional Chinese medicine network pharmacology (TCM-NP). With the development of artificial intelligence (AI) technology, it is key for NP to develop network-based AI methods to reveal the treatment mechanism of complex diseases from massive omics data. In this review, focusing on the TCM-NP, we summarize involved AI methods into three categories: network relationship mining, network target positioning and network target navigating, and present the typical application of TCM-NP in uncovering biological basis and clinical value of Cold/Hot syndromes. Collectively, our review provides researchers with an innovative overview of the methodological progress of NP and its application in TCM from the AI perspective.",
    "citationCount": 366,
    "pdf_filename": "2023_Network_pharmacology__towards_the_artifi_bbdd3e51.pdf"
  },
  "170c97c7215f42edfb20c2248f954879e91ef86e": {
    "paperId": "170c97c7215f42edfb20c2248f954879e91ef86e",
    "title": "Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models",
    "year": 2023,
    "authors": "Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang",
    "abstract": "Large language models (LLMs) have achieved remarkable progress in solving various natural language processing tasks due to emergent reasoning abilities. However, LLMs have inherent limitations as they are incapable of accessing up-to-date information (stored on the Web or in task-specific knowledge bases), using external tools, and performing precise mathematical and logical reasoning. In this paper, we present Chameleon, an AI system that mitigates these limitations by augmenting LLMs with plug-and-play modules for compositional reasoning. Chameleon synthesizes programs by composing various tools (e.g., LLMs, off-the-shelf vision models, web search engines, Python functions, and heuristic-based modules) for accomplishing complex reasoning tasks. At the heart of Chameleon is an LLM-based planner that assembles a sequence of tools to execute to generate the final response. We showcase the effectiveness of Chameleon on two multi-modal knowledge-intensive reasoning tasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54% overall accuracy on ScienceQA, improving the best published few-shot result by 11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%, lifting the state of the art to 98.78%. Our analysis also shows that the GPT-4-powered planner exhibits more consistent and rational tool selection via inferring potential constraints from instructions, compared to a ChatGPT-powered planner. The project is available at https://chameleon-llm.github.io.",
    "citationCount": 403,
    "pdf_filename": "2023_Chameleon__Plug_and_Play_Compositional_R_170c97c7.pdf"
  },
  "f7dda3cd6a26f514f367f2280fe6844f5e5c8a2f": {
    "paperId": "f7dda3cd6a26f514f367f2280fe6844f5e5c8a2f",
    "title": "Bias in artificial intelligence algorithms and recommendations for mitigation",
    "year": 2023,
    "authors": "L. Nazer, Razan Zatarah, Shai Waldrip, J. Ke, M. Moukheiber",
    "abstract": "The adoption of artificial intelligence (AI) algorithms is rapidly increasing in healthcare. Such algorithms may be shaped by various factors such as social determinants of health that can influence health outcomes. While AI algorithms have been proposed as a tool to expand the reach of quality healthcare to underserved communities and improve health equity, recent literature has raised concerns about the propagation of biases and healthcare disparities through implementation of these algorithms. Thus, it is critical to understand the sources of bias inherent in AI-based algorithms. This review aims to highlight the potential sources of bias within each step of developing AI algorithms in healthcare, starting from framing the problem, data collection, preprocessing, development, and validation, as well as their full implementation. For each of these steps, we also discuss strategies to mitigate the bias and disparities. A checklist was developed with recommendations for reducing bias during the development and implementation stages. It is important for developers and users of AI-based algorithms to keep these important considerations in mind to advance health equity for all populations.",
    "citationCount": 325,
    "pdf_filename": "2023_Bias_in_artificial_intelligence_algorith_f7dda3cd.pdf"
  },
  "43289edd2df09327fdff374d0fda6fd7b100ad43": {
    "paperId": "43289edd2df09327fdff374d0fda6fd7b100ad43",
    "title": "Progress in wearable electronics/photonics—Moving toward the era of artificial intelligence and internet of things",
    "year": 2020,
    "authors": "Qiongfeng Shi, B. Dong, Tianyiyi He, Zhongda Sun, Jianxiong Zhu",
    "abstract": "The past few years have witnessed the significant impacts of wearable electronics/photonics on various aspects of our daily life, for example, healthcare monitoring and treatment, ambient monitoring, soft robotics, prosthetics, flexible display, communication, human-machine interactions, and so on. According to the development in recent years, the next-generation wearable electronics and photonics are advancing rapidly toward the era of artificial intelligence (AI)",
    "citationCount": 490,
    "pdf_filename": "2020_Progress_in_wearable_electronics_photoni_43289edd.pdf"
  },
  "27cd5a3eb55d2df2a4c06e96247b79f215516a67": {
    "paperId": "27cd5a3eb55d2df2a4c06e96247b79f215516a67",
    "title": "Algorithmic Fairness",
    "year": 2020,
    "authors": "Dana Pessach, E. Shmueli",
    "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence (AI) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop AI algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision-making may be inherently prone to unfairness, even when there is no intention for it. This paper presents an overview of the main concepts of identifying, measuring and improving algorithmic fairness when using AI algorithms. The paper begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, towards a better understanding of which mechanisms should be used in different scenarios. The paper then describes the most commonly used fairness-related datasets in this field. Finally, the paper ends by reviewing several emerging research sub-fields of algorithmic fairness.",
    "citationCount": 414,
    "pdf_filename": "2020_Algorithmic_Fairness_27cd5a3e.pdf"
  },
  "b4582b3400b3f3475fa364ce9dd3d175d8e62e90": {
    "paperId": "b4582b3400b3f3475fa364ce9dd3d175d8e62e90",
    "title": "Omicron variant showed lower neutralizing sensitivity than other SARS-CoV-2 variants to immune sera elicited by vaccines after boost",
    "year": 2021,
    "authors": "Jingwen Ai, Haocheng Zhang, Yi Zhang, Ke Lin, Yanliang Zhang",
    "abstract": "ABSTRACT The emerging new VOC B.1.1.529 (Omicron) variant has raised serious concerns due to multiple mutations, reported significant immune escape, and unprecedented rapid spreading speed. Currently, studies describing the neutralization ability of different homologous and heterologous booster vaccination against Omicron are still lacking. In this study, we explored the immunogenicity of COVID-19 breakthrough patients, BBIBP-CorV homologous booster group and BBIBP-CorV/ZF2001 heterologous booster group against SARS-CoV-2 pseudotypes corresponding to the prototype, Beta, Delta, and the emergent Omicron variant. Notably, at 14 days post two-dose inactivated vaccines, pVNT titre increased to 67.4 GMTs against prototype, 8.85 against Beta and 35.07 against Delta, while neutralization activity against Omicron was below the lower limit of quantitation in 80% of the samples. At day 14 post BBIBP-CorV homologous booster vaccination, GMTs of pVNT significantly increased to 285.6, 215.7, 250.8, 48.73 against prototype, Beta, Delta, and Omicron, while at day 14 post ZF2001 heterologous booster vaccination, GMTs of pVNT significantly increased to 1436.00, 789.6, 1501.00, 95.86, respectively. Post booster vaccination, 100% samples showed positive neutralization activity against Omicron, albeit illustrated a significant reduction (5.86- to 14.98-fold) of pVNT against Omicron compared to prototype at 14 days after the homologous or heterologous vaccine boosters. Overall, our study demonstrates that vaccine-induced immune protection might more likely be escaped by Omicron compared to prototypes and other VOCs. After two doses of inactivated whole-virion vaccines as the “priming” shot, a third heterologous protein subunit vaccine and a homologous inactivated vaccine booster could improve neutralization against Omicron.",
    "citationCount": 328,
    "pdf_filename": "2021_Omicron_variant_showed_lower_neutralizin_b4582b34.pdf"
  },
  "15e323f54df13a2386d8fc462ba755190ab16c5d": {
    "paperId": "15e323f54df13a2386d8fc462ba755190ab16c5d",
    "title": "Immunogenicity of COVID-19 mRNA Vaccines in Pregnant and Lactating Women.",
    "year": 2021,
    "authors": "Ai-ris Y. Collier, K. McMahan, Jingyou Yu, Lisa H. Tostanoski, R. Aguayo",
    "abstract": "Importance\nPregnant women are at increased risk of morbidity and mortality from COVID-19 but have been excluded from the phase 3 COVID-19 vaccine trials. Data on vaccine safety and immunogenicity in these populations are therefore limited.\n\n\nObjective\nTo evaluate the immunogenicity of COVID-19 messenger RNA (mRNA) vaccines in pregnant and lactating women, including against emerging SARS-CoV-2 variants of concern.\n\n\nDesign, Setting, and Participants\nAn exploratory, descriptive, prospective cohort study enrolled 103 women who received a COVID-19 vaccine from December 2020 through March 2021 and 28 women who had confirmed SARS-CoV-2 infection from April 2020 through March 2021 (the last follow-up date was March 26, 2021). This study enrolled 30 pregnant, 16 lactating, and 57 neither pregnant nor lactating women who received either the mRNA-1273 (Moderna) or BNT162b2 (Pfizer-BioNTech) COVID-19 vaccines and 22 pregnant and 6 nonpregnant unvaccinated women with SARS-CoV-2 infection.\n\n\nMain Outcomes and Measures\nSARS-CoV-2 receptor binding domain binding, neutralizing, and functional nonneutralizing antibody responses from pregnant, lactating, and nonpregnant women were assessed following vaccination. Spike-specific T-cell responses were evaluated using IFN-γ enzyme-linked immunospot and multiparameter intracellular cytokine-staining assays. Humoral and cellular immune responses were determined against the original SARS-CoV-2 USA-WA1/2020 strain as well as against the B.1.1.7 and B.1.351 variants.\n\n\nResults\nThis study enrolled 103 women aged 18 to 45 years (66% non-Hispanic White) who received a COVID-19 mRNA vaccine. After the second vaccine dose, fever was reported in 4 pregnant women (14%; SD, 6%), 7 lactating women (44%; SD, 12%), and 27 nonpregnant women (52%; SD, 7%). Binding, neutralizing, and functional nonneutralizing antibody responses as well as CD4 and CD8 T-cell responses were present in pregnant, lactating, and nonpregnant women following vaccination. Binding and neutralizing antibodies were also observed in infant cord blood and breast milk. Binding and neutralizing antibody titers against the SARS-CoV-2 B.1.1.7 and B.1.351 variants of concern were reduced, but T-cell responses were preserved against viral variants.\n\n\nConclusion and Relevance\nIn this exploratory analysis of a convenience sample, receipt of a COVID-19 mRNA vaccine was immunogenic in pregnant women, and vaccine-elicited antibodies were transported to infant cord blood and breast milk. Pregnant and nonpregnant women who were vaccinated developed cross-reactive antibody responses and T-cell responses against SARS-CoV-2 variants of concern.",
    "citationCount": 331,
    "pdf_filename": "2021_Immunogenicity_of_COVID_19_mRNA_Vaccines_15e323f5.pdf"
  },
  "ea155231e5cda1ba8093c06cbd60c837fb5cef71": {
    "paperId": "ea155231e5cda1ba8093c06cbd60c837fb5cef71",
    "title": "Researchers' perspectives on Industry 4.0: multi-disciplinary analysis and opportunities for operations management",
    "year": 2020,
    "authors": "D. Ivanov, Christopher S. Tang, A. Dolgui, D. Battini, Ajay Das",
    "abstract": "ABSTRACT While Industry 4.0 has been trending in practice and research, operations management studies in this area remain nascent. Our intent is to understand the current state of research in Industry 4.0 in different disciplines and deduce insights and opportunities for future research in operations management. In this paper, we provide a focused analysis to examine the state-of-the-art research in Industry 4.0. To learn about researchers’ perspectives about Industry 4.0, we conducted a large-scale, cross-disciplinary and global survey on Industry 4.0 topics among researchers in industrial engineering, operations management, operations research, control and data science at the 9th IFAC MIM 2019 Conference in Berlin in August 2019. By using our survey findings and literature analysis, we build structural and conceptual frameworks to understand the current state of knowledge and to propose future research opportunities for operations management scholars. Glossary of Abbreviations AGV: Automated guided vehicle; AI: Artificial intelligence; APS: Advanced planning system: a wide variety of software tools and techniques, with many applications in manufacturing and logistics (including the service sector); BDA: Big data analytics; CAS: Complex adaptive system: a system composed of many interacting parts that evolve and adapt over time; CIM: Computer integrated manufacturing; CPFR: Collaborative planning, forecasting and replenishment; CPS: Cyber-physical system: a seamless integration of computation and physical components; DAMCLS: Decision analysis, modelling, control and learning systems; ERP: Enterprise resource planning; FMS: Flexible manufacturing system; I4.0: Industry 4.0; IFAC: International Federation of Automatic Control: a federation is concerned with the impact of control technology on society; IME: Industrial and mechanical engineering; IoT: Internet-of-Things; IT: Information technology; M2M: Machine-to-machine; MAS: Multi-agent system: a loosely coupled network of software agents that interact to solve problems that are beyond the individual capacities or knowledge of each problem solver; OR: Operations research; RFID: Radio frequency identification: a technology that uses electromagnetic fields to automatically identify and track tags attached to objects; RMS: Reconfigurable manufacturing system: a manufacturing system that can change and evolve rapidly in order to adjust its productivity capacity and functionality; OM: Operations management; T&T: Track and trace system; VCA: VOS viewer co-occurrence analysis: a software tool for visualising bibliometric networks; VMI: Vendor-managed inventory.",
    "citationCount": 348,
    "pdf_filename": "2020_Researchers__perspectives_on_Industry_4__ea155231.pdf"
  },
  "9b529fe170823f95509585d5aa39fa01a43558fd": {
    "paperId": "9b529fe170823f95509585d5aa39fa01a43558fd",
    "title": "How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence",
    "year": 2020,
    "authors": "Haoxiang Zhong, Chaojun Xiao, Cunchao Tu, T. Zhang, Zhiyuan Liu",
    "abstract": "Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rule-based and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we introduce the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an in-depth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github.com/thunlp/CLAIM.",
    "citationCount": 356,
    "pdf_filename": "2020_How_Does_NLP_Benefit_Legal_System__A_Sum_9b529fe1.pdf"
  },
  "2bd20336dd0b024eff47fd4b1bfd8d57b3553794": {
    "paperId": "2bd20336dd0b024eff47fd4b1bfd8d57b3553794",
    "title": "Artificial intelligence applications in the development of autonomous vehicles: a survey",
    "year": 2020,
    "authors": "Yifang Ma, Zhenyu Wang, Hong Yang, Lin Yang",
    "abstract": "The advancement of artificial intelligence ( AI ) has truly stimulated the development and deployment of autonomous vehicles ( AVs ) in the transportation industry. Fueled by big data from various sensing devices and advanced computing resources, AI has become an essential component of AVs for perceiving the surrounding environment and making appropriate decision in motion. To achieve goal of full automation ( i.e., self-driving ( , it is important to know how AI works in AV systems. Existing research have made great efforts in investigating different aspects of applying AI in AV development. However, few studies have offered the research community a thorough examination of current practices in implementing AI in AVs. Thus, this paper aims to shorten the gap by providing a comprehensive survey of key studies in this research avenue. Specifically, it intends to analyze their use of AIs in supporting the primary applications in AVs: 1) perception; 2) localization and mapping; and 3) decision making. It investigates the current practices to understand how AI can be used and what are the challenges and issues associated with their implementation. Based on the exploration of current practices and technology advances, this paper further provides insights into potential opportunities regarding the use of AI in conjunction with other emerging technologies: 1) high definition maps, big data, and high performance computing; 2) augmented reality( AR ) / virtual reality ( VR ) enhanced simulation platform; and 3) 5G communication for connected AVs. This paper is expected to offer a quick reference for researchers interested in understanding the use of AI in AV research.",
    "citationCount": 432,
    "pdf_filename": "2020_Artificial_intelligence_applications_in__2bd20336.pdf"
  },
  "7e38476342ce1fcc8ef0dcd23686539395961769": {
    "paperId": "7e38476342ce1fcc8ef0dcd23686539395961769",
    "title": "Inductive biases for deep learning of higher-level cognition",
    "year": 2020,
    "authors": "Anirudh Goyal, Yoshua Bengio",
    "abstract": "A fascinating hypothesis is that human and animal intelligence could be explained by a few principles (rather than an encyclopaedic list of heuristics). If that hypothesis was correct, we could more easily both understand our own intelligence and build intelligent machines. Just like in physics, the principles themselves would not be sufficient to predict the behaviour of complex systems like brains, and substantial computation might be needed to simulate human-like intelligence. This hypothesis would suggest that studying the kind of inductive biases that humans and animals exploit could help both clarify these principles and provide inspiration for AI research and neuroscience theories. Deep learning already exploits several key inductive biases, and this work considers a larger list, focusing on those which concern mostly higher-level and sequential conscious processing. The objective of clarifying these particular principles is that they could potentially help us build AI systems benefiting from humans’ abilities in terms of flexible out-of-distribution and systematic generalization, which is currently an area where a large gap exists between state-of-the-art machine learning and human intelligence.",
    "citationCount": 411,
    "pdf_filename": "2020_Inductive_biases_for_deep_learning_of_hi_7e384763.pdf"
  },
  "f1321f2df5bc686d3adfba8eae06a6c12cb88ef8": {
    "paperId": "f1321f2df5bc686d3adfba8eae06a6c12cb88ef8",
    "title": "Explainable Deep Learning: A Field Guide for the Uninitiated",
    "year": 2020,
    "authors": "Ning Xie, Gabrielle Ras, M. Gerven, Derek Doran",
    "abstract": "Deep neural networks (DNNs) are an indispensable machine learning tool despite the difficulty of diagnosing what aspects of a model’s input drive its decisions. In countless real-world domains, from legislation and law enforcement to healthcare, such diagnosis is essential to ensure that DNN decisions are driven by aspects appropriate in the context of its use. The development of methods and studies enabling the explanation of a DNN’s decisions has thus blossomed into an active and broad area of research. The field’s complexity is exacerbated by competing definitions of what it means “to explain” the actions of a DNN and to evaluate an approach’s “ability to explain”. This article offers a field guide to explore the space of explainable deep learning for those in the AI/ML field who are uninitiated. The field guide: i) Introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning, ii) discusses the evaluations for model explanations, iii) places explainability in the context of other related deep learning research areas, and iv) discusses user-oriented explanation design and future directions. We hope the guide is seen as a starting point for those embarking on this research field.",
    "citationCount": 414,
    "pdf_filename": "2020_Explainable_Deep_Learning__A_Field_Guide_f1321f2d.pdf"
  },
  "451539c0d0f5f5785ff58d09ca5e67a5f129f9de": {
    "paperId": "451539c0d0f5f5785ff58d09ca5e67a5f129f9de",
    "title": "A Survey on Multimodal Large Language Models for Autonomous Driving",
    "year": 2023,
    "authors": "Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou",
    "abstract": "With the emergence of Large Language Models (LLMs) and Vision Foundation Models (VFMs), multimodal AI systems benefiting from large models have the potential to equally perceive the real world, make decisions, and control tools as humans. In recent months, LLMs have shown widespread attention in autonomous driving and map systems. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors to apply in LLM driving systems. In this paper, we present a systematic investigation in this field. We first introduce the background of Multimodal Large Language Models (MLLMs), the multimodal models development using LLMs, and the history of autonomous driving. Then, we overview existing MLLM tools for driving, transportation, and map systems together with existing datasets and benchmarks. Moreover, we summarized the works in The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which is the first workshop of its kind regarding LLMs in autonomous driving. To further promote the development of this field, we also discuss several important problems regarding using MLLMs in autonomous driving systems that need to be solved by both academia and industry.",
    "citationCount": 415,
    "pdf_filename": "2023_A_Survey_on_Multimodal_Large_Language_Mo_451539c0.pdf"
  },
  "19db2d61f20a6c439cc79f28ef4c9e4bf26cd20e": {
    "paperId": "19db2d61f20a6c439cc79f28ef4c9e4bf26cd20e",
    "title": "Preference Ranking Optimization for Human Alignment",
    "year": 2023,
    "authors": "Feifan Song, Yu Bowen, Minghao Li, Haiyang Yu, Fei Huang",
    "abstract": "Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secure AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment. However, it encompasses two main drawbacks: (1) RLHF exhibits complexity, instability, and sensitivity to hyperparameters in contrast to SFT. (2) Despite massive trial-and-error, multiple sampling is reduced to pair-wise contrast, thus lacking contrasts from a macro perspective. In this paper, we propose Preference Ranking Optimization (PRO) as an efficient SFT algorithm to directly fine-tune LLMs for human alignment. PRO extends the pair-wise contrast to accommodate preference rankings of any length. By iteratively contrasting candidates, PRO instructs the LLM to prioritize the best response while progressively ranking the rest responses. In this manner, PRO effectively transforms human alignment into aligning the probability ranking of n responses generated by LLM with the preference ranking of humans towards these responses. Experiments have shown that PRO outperforms baseline algorithms, achieving comparable results to ChatGPT and human responses through automatic-based, reward-based, GPT-4, and human evaluations.",
    "citationCount": 324,
    "pdf_filename": "2023_Preference_Ranking_Optimization_for_Huma_19db2d61.pdf"
  },
  "4f4e0e251f191e81652c262a75491d034ac82f89": {
    "paperId": "4f4e0e251f191e81652c262a75491d034ac82f89",
    "title": "Recent Advances in Nanozymes: From Matters to Bioapplications",
    "year": 2021,
    "authors": "Yongjian Ai, Ze‐nan Hu, Xiao‐Tian Liang, Hong‐bin Sun, Hongbo Xin",
    "abstract": "The manufacture of bionic materials to simulate the natural counterparts has attracted extensive attention. As one of the subcategories of biomimetic materials, the development of artificial enzyme is intensive pursuing. As a kind of artificial enzyme, nanozymes are dedicated to solve the limitations of natural enzymes. In recent years, attributed to the explosive development of nanotechnology, biotechnology, catalysis science, computational design and theory calculation, research on nanozymes has made great progress. To highlight these achievements and help researchers to understand the current investigation status of nanozyme, the state‐of‐the‐art development in nanozymes from fabrication materials to bioapplications are summarized. First different raw materials are summarized, including metal‐based, metal‐free, metal‐organic frameworks‐based, and some other novel matters, which are applied to fabricate nanozymes. The different types of enzymes‐like catalytic activities of nanozymes are briefly discussed. Subsequently, the wide applications of nanozymes such as anti‐oxidation, curing diseases, anti‐bacteria, biosensing, and bioimaging are discussed. Finally, the current challenges faced by nanozymes are outlined and the future directions for advancing nanozyme research are outlooked. The authors hope this review can inspire research in the fields of nanotechnology, chemistry, biology, materials science, and theoretical computing, and can contribute to the development of nanozymes.",
    "citationCount": 340,
    "pdf_filename": "2021_Recent_Advances_in_Nanozymes__From_Matte_4f4e0e25.pdf"
  },
  "4a8692d75d9bb1bbc2b84cddc52521d6a03461d4": {
    "paperId": "4a8692d75d9bb1bbc2b84cddc52521d6a03461d4",
    "title": "On the Interpretability of Artificial Intelligence in Radiology: Challenges and Opportunities.",
    "year": 2020,
    "authors": "M. Reyes, Raphael Meier, Sérgio Pereira, Carlos A. Silva, F. Dahlweid",
    "abstract": "As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI \"interpretable\" have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists' opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice. Supplemental material is available for this article. © RSNA, 2020 See also the commentary by Gastounioti and Kontos in this issue.",
    "citationCount": 370,
    "pdf_filename": "2020_On_the_Interpretability_of_Artificial_In_4a8692d7.pdf"
  },
  "e6000a578a4ec3ef9260abbac7099b4090a16d32": {
    "paperId": "e6000a578a4ec3ef9260abbac7099b4090a16d32",
    "title": "Artificial Intelligence in Advanced Manufacturing: Current Status and Future Outlook",
    "year": 2020,
    "authors": "J. Arinez, Q. Chang, R. Gao, Chengyi Xu, Jianjing Zhang",
    "abstract": "\n Today’s manufacturing systems are becoming increasingly complex, dynamic, and connected. The factory operations face challenges of highly nonlinear and stochastic activity due to the countless uncertainties and interdependencies that exist. Recent developments in artificial intelligence (AI), especially Machine Learning (ML) have shown great potential to transform the manufacturing domain through advanced analytics tools for processing the vast amounts of manufacturing data generated, known as Big Data. The focus of this paper is threefold: (1) review the state-of-the-art applications of AI to representative manufacturing problems, (2) provide a systematic view for analyzing data and process dependencies at multiple levels that AI must comprehend, and (3) identify challenges and opportunities to not only further leverage AI for manufacturing, but also influence the future development of AI to better meet the needs of manufacturing. To satisfy these objectives, the paper adopts the hierarchical organization widely practiced in manufacturing plants in examining the interdependencies from the overall system level to the more detailed granular level of incoming material process streams. In doing so, the paper considers a wide range of topics from throughput and quality, supervisory control in human–robotic collaboration, process monitoring, diagnosis, and prognosis, finally to advances in materials engineering to achieve desired material property in process modeling and control.",
    "citationCount": 374,
    "pdf_filename": "2020_Artificial_Intelligence_in_Advanced_Manu_e6000a57.pdf"
  },
  "8bc617c9139648d7a92991d70c671230bac7b2e2": {
    "paperId": "8bc617c9139648d7a92991d70c671230bac7b2e2",
    "title": "AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head",
    "year": 2023,
    "authors": "Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving 16 AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Code can be found in https://github.com/AIGC-Audio/AudioGPT",
    "citationCount": 317,
    "pdf_filename": "2023_AudioGPT__Understanding_and_Generating_S_8bc617c9.pdf"
  },
  "684f4cba51f717953ccef410094eb159fea58f33": {
    "paperId": "684f4cba51f717953ccef410094eb159fea58f33",
    "title": "Bridging the Gap Between Ethics and Practice",
    "year": 2020,
    "authors": "B. Shneiderman",
    "abstract": "This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, non-governmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society.",
    "citationCount": 356,
    "pdf_filename": "2020_Bridging_the_Gap_Between_Ethics_and_Prac_684f4cba.pdf"
  },
  "1a59ca238c64e4bae304240d7df787cf0345d50e": {
    "paperId": "1a59ca238c64e4bae304240d7df787cf0345d50e",
    "title": "Artificial Intelligence Forecasting of Covid-19 in China",
    "year": 2020,
    "authors": "Zixin Hu, Qiyang Ge, Shudi Li, Li Jin, M. Xiong",
    "abstract": "BACKGROUND An alternative to epidemiological models for transmission dynamics of Covid-19 in China, we propose the artificial intelligence (AI)-inspired methods for real-time forecasting of Covid-19 to estimate the size, lengths and ending time of Covid-19 across China. METHODS We developed a modified stacked auto-encoder for modeling the transmission dynamics of the epidemics. We applied this model to real-time forecasting the confirmed cases of Covid-19 across China. The data were collected from January 11 to February 27, 2020 by WHO. We used the latent variables in the auto-encoder and clustering algorithms to group the provinces/cities for investigating the transmission structure. RESULTS We forecasted curves of cumulative confirmed cases of Covid-19 across China from Jan 20, 2020 to April 20, 2020. Using the multiple-step forecasting, the estimated average errors of 6-step, 7-step, 8-step, 9-step and 10-step forecasting were 1.64%, 2.27%, 2.14%, 2.08%, 0.73%, respectively. We predicted that the time points of the provinces/cities entering the plateau of the forecasted transmission dynamic curves varied, ranging from Jan 21 to April 19, 2020. The 34 provinces/cities were grouped into 9 clusters. CONCLUSIONS The accuracy of the AI-based methods for forecasting the trajectory of Covid-19 was high. We predicted that the epidemics of Covid-19 will be over by the middle of April. If the data are reliable and there are no second transmissions, we can accurately forecast the transmission dynamics of the Covid-19 across the provinces/cities in China. The AI-inspired methods are a powerful tool for helping public health planning and policymaking.",
    "citationCount": 335,
    "pdf_filename": "2020_Artificial_Intelligence_Forecasting_of_C_1a59ca23.pdf"
  },
  "04258349cf59b55b4b5a65882b5da2dd992a2344": {
    "paperId": "04258349cf59b55b4b5a65882b5da2dd992a2344",
    "title": "Development and evaluation of an artificial intelligence system for COVID-19 diagnosis",
    "year": 2020,
    "authors": "Cheng Jin, Weixiang Chen, Yukun Cao, Zhanwei Xu, Zimeng Tan",
    "abstract": "Early detection of COVID-19 based on chest CT enables timely treatment of patients and helps control the spread of the disease. We proposed an artificial intelligence (AI) system for rapid COVID-19 detection and performed extensive statistical analysis of CTs of COVID-19 based on the AI system. We developed and evaluated our system on a large dataset with more than 10 thousand CT volumes from COVID-19, influenza-A/B, non-viral community acquired pneumonia (CAP) and non-pneumonia subjects. In such a difficult multi-class diagnosis task, our deep convolutional neural network-based system is able to achieve an area under the receiver operating characteristic curve (AUC) of 97.81% for multi-way classification on test cohort of 3,199 scans, AUC of 92.99% and 93.25% on two publicly available datasets, CC-CCII and MosMedData respectively. In a reader study involving five radiologists, the AI system outperforms all of radiologists in more challenging tasks at a speed of two orders of magnitude above them. Diagnosis performance of chest x-ray (CXR) is compared to that of CT. Detailed interpretation of deep network is also performed to relate system outputs with CT presentations. The code is available at https://github.com/ChenWWWeixiang/diagnosis_covid19. In some contexts, rapid detection of COVID-19 from CT scans can be crucial for optimal patient management. Here, the authors present a Deep Learning system for this task with multi-center data, human reader comparison and age stratified results.",
    "citationCount": 323,
    "pdf_filename": "2020_Development_and_evaluation_of_an_artific_04258349.pdf"
  },
  "2bbc7e46425d8dabb2c2ebbf28dbbb0462d3b5e3": {
    "paperId": "2bbc7e46425d8dabb2c2ebbf28dbbb0462d3b5e3",
    "title": "Artificial Intelligence in Health Care: Bibliometric Analysis",
    "year": 2020,
    "authors": "Yuqi Guo, Zhichao Hao, Shichong Zhao, Jiaqi Gong, Fan Yang",
    "abstract": "Background As a critical driving power to promote health care, the health care–related artificial intelligence (AI) literature is growing rapidly. Objective The purpose of this analysis is to provide a dynamic and longitudinal bibliometric analysis of health care–related AI publications. Methods The Web of Science (Clarivate PLC) was searched to retrieve all existing and highly cited AI-related health care research papers published in English up to December 2019. Based on bibliometric indicators, a search strategy was developed to screen the title for eligibility, using the abstract and full text where needed. The growth rate of publications, characteristics of research activities, publication patterns, and research hotspot tendencies were computed using the HistCite software. Results The search identified 5235 hits, of which 1473 publications were included in the analyses. Publication output increased an average of 17.02% per year since 1995, but the growth rate of research papers significantly increased to 45.15% from 2014 to 2019. The major health problems studied in AI research are cancer, depression, Alzheimer disease, heart failure, and diabetes. Artificial neural networks, support vector machines, and convolutional neural networks have the highest impact on health care. Nucleosides, convolutional neural networks, and tumor markers have remained research hotspots through 2019. Conclusions This analysis provides a comprehensive overview of the AI-related research conducted in the field of health care, which helps researchers, policy makers, and practitioners better understand the development of health care–related AI research and possible practice implications. Future AI research should be dedicated to filling in the gaps between AI health care research and clinical applications.",
    "citationCount": 329,
    "pdf_filename": "2020_Artificial_Intelligence_in_Health_Care___2bbc7e46.pdf"
  },
  "03d7cd2475ba417fbc0d5f6b7255f8aa14eb227a": {
    "paperId": "03d7cd2475ba417fbc0d5f6b7255f8aa14eb227a",
    "title": "Towards Transparency by Design for Artificial Intelligence",
    "year": 2020,
    "authors": "Heike Felzmann, E. Fosch-Villaronga, C. Lutz, Aurelia Tamó-Larrieux",
    "abstract": "In this article, we develop the concept of Transparency by Design that serves as practical guidance in helping promote the beneficial functions of transparency while mitigating its challenges in automated-decision making (ADM) environments. With the rise of artificial intelligence (AI) and the ability of AI systems to make automated and self-learned decisions, a call for transparency of how such systems reach decisions has echoed within academic and policy circles. The term transparency, however, relates to multiple concepts, fulfills many functions, and holds different promises that struggle to be realized in concrete applications. Indeed, the complexity of transparency for ADM shows tension between transparency as a normative ideal and its translation to practical application. To address this tension, we first conduct a review of transparency, analyzing its challenges and limitations concerning automated decision-making practices. We then look at the lessons learned from the development of Privacy by Design, as a basis for developing the Transparency by Design principles. Finally, we propose a set of nine principles to cover relevant contextual, technical, informational, and stakeholder-sensitive considerations. Transparency by Design is a model that helps organizations design transparent AI systems, by integrating these principles in a step-by-step manner and as an ex-ante value, not as an afterthought.",
    "citationCount": 342,
    "pdf_filename": "2020_Towards_Transparency_by_Design_for_Artif_03d7cd24.pdf"
  },
  "59c9cdd553d48d574f637336aae2bc6b9b1a47e6": {
    "paperId": "59c9cdd553d48d574f637336aae2bc6b9b1a47e6",
    "title": "The Chinese approach to artificial intelligence: an analysis of policy, ethics, and regulation",
    "year": 2020,
    "authors": "Huw Roberts, Josh Cowls, J. Morley, M. Taddeo, Vincent Wang",
    "abstract": "In July 2017, China’s State Council released the country’s strategy for developing artificial intelligence (AI), entitled ‘New Generation Artificial Intelligence Development Plan’ (新一代人工智能发展规划). This strategy outlined China’s aims to become the world leader in AI by 2030, to monetise AI into a trillion-yuan (ca. 150 billion dollars) industry, and to emerge as the driving force in defining ethical norms and standards for AI. Several reports have analysed specific aspects of China’s AI policies or have assessed the country’s technical capabilities. Instead, in this article, we focus on the socio-political background and policy debates that are shaping China’s AI strategy. In particular, we analyse the main strategic areas in which China is investing in AI and the concurrent ethical debates that are delimiting its use. By focusing on the policy backdrop, we seek to provide a more comprehensive and critical understanding of China’s AI policy by bringing together debates and analyses of a wide array of policy documents.",
    "citationCount": 333,
    "pdf_filename": "2020_The_Chinese_approach_to_artificial_intel_59c9cdd5.pdf"
  },
  "753d9bb1ffb825cb014568764a16fdaef70ca6e0": {
    "paperId": "753d9bb1ffb825cb014568764a16fdaef70ca6e0",
    "title": "Application of Artificial Intelligence in Dentistry",
    "year": 2020,
    "authors": "T. Shan, F. R. Tay, L.S. Gu",
    "abstract": "Artificial intelligence (AI) is a technology that utilizes machines to mimic intelligent human behavior. To appreciate human-technology interaction in the clinical setting, augmented intelligence has been proposed as a cognitive extension of AI in health care, emphasizing its assistive and supplementary role to medical professionals. While truly autonomous medical robotic systems are still beyond reach, the virtual component of AI, known as software-type algorithms, is the main component used in dentistry. Because of their powerful capabilities in data analysis, these virtual algorithms are expected to improve the accuracy and efficacy of dental diagnosis, provide visualized anatomic guidance for treatment, simulate and evaluate prospective results, and project the occurrence and prognosis of oral diseases. Potential obstacles in contemporary algorithms that prevent routine implementation of AI include the lack of data curation, sharing, and readability; the inability to illustrate the inner decision-making process; the insufficient power of classical computing; and the neglect of ethical principles in the design of AI frameworks. It is necessary to maintain a proactive attitude toward AI to ensure its affirmative development and promote human-technology rapport to revolutionize dental practice. The present review outlines the progress and potential dental applications of AI in medical-aided diagnosis, treatment, and disease prediction and discusses their data limitations, interpretability, computing power, and ethical considerations, as well as their impact on dentists, with the objective of creating a backdrop for future research in this rapidly expanding arena.",
    "citationCount": 331,
    "pdf_filename": "2020_Application_of_Artificial_Intelligence_i_753d9bb1.pdf"
  },
  "0b9e5e206890d1cbb77aa89c1e077cfa3e0d87bb": {
    "paperId": "0b9e5e206890d1cbb77aa89c1e077cfa3e0d87bb",
    "title": "Artificial intelligence in recommender systems",
    "year": 2020,
    "authors": "Qian Zhang, Jie Lu, Yaochu Jin",
    "abstract": "Recommender systems provide personalized service support to users by learning their previous behaviors and predicting their current preferences for particular products. Artificial intelligence (AI), particularly computational intelligence and machine learning methods and algorithms, has been naturally applied in the development of recommender systems to improve prediction accuracy and solve data sparsity and cold start problems. This position paper systematically discusses the basic methodologies and prevailing techniques in recommender systems and how AI can effectively improve the technological development and application of recommender systems. The paper not only reviews cutting-edge theoretical and practical contributions, but also identifies current research issues and indicates new research directions. It carefully surveys various issues related to recommender systems that use AI, and also reviews the improvements made to these systems through the use of such AI approaches as fuzzy techniques, transfer learning, genetic algorithms, evolutionary algorithms, neural networks and deep learning, and active learning. The observations in this paper will directly support researchers and professionals to better understand current developments and new directions in the field of recommender systems using AI.",
    "citationCount": 327,
    "pdf_filename": "2020_Artificial_intelligence_in_recommender_s_0b9e5e20.pdf"
  },
  "e84152309429cae1a12ffc208f4ba971c6710761": {
    "paperId": "e84152309429cae1a12ffc208f4ba971c6710761",
    "title": "Emerging role of deep learning‐based artificial intelligence in tumor pathology",
    "year": 2020,
    "authors": "Yahui Jiang, Meng Yang, Shuhao Wang, Xiangchun Li, Yan Sun",
    "abstract": "The development of digital pathology and progression of state‐of‐the‐art algorithms for computer vision have led to increasing interest in the use of artificial intelligence (AI), especially deep learning (DL)‐based AI, in tumor pathology. The DL‐based algorithms have been developed to conduct all kinds of work involved in tumor pathology, including tumor diagnosis, subtyping, grading, staging, and prognostic prediction, as well as the identification of pathological features, biomarkers and genetic changes. The applications of AI in pathology not only contribute to improve diagnostic accuracy and objectivity but also reduce the workload of pathologists and subsequently enable them to spend additional time on high‐level decision‐making tasks. In addition, AI is useful for pathologists to meet the requirements of precision oncology. However, there are still some challenges relating to the implementation of AI, including the issues of algorithm validation and interpretability, computing systems, the unbelieving attitude of pathologists, clinicians and patients, as well as regulators and reimbursements. Herein, we present an overview on how AI‐based approaches could be integrated into the workflow of pathologists and discuss the challenges and perspectives of the implementation of AI in tumor pathology.",
    "citationCount": 340,
    "pdf_filename": "2020_Emerging_role_of_deep_learning_based_art_e8415230.pdf"
  },
  "9cb1693f84cd608986afeedb2aa0eb47cf865996": {
    "paperId": "9cb1693f84cd608986afeedb2aa0eb47cf865996",
    "title": "Error Metrics and Performance Fitness Indicators for Artificial Intelligence and Machine Learning in Engineering and Sciences",
    "year": 2020,
    "authors": "M. Z. Naser, A. Alavi",
    "abstract": "Artificial intelligence (AI) and Machine learning (ML) train machines to achieve a high level of cognition and perform human-like analysis. Both AI and ML seemingly fit into our daily lives as well as complex and interdisciplinary fields. With the rise of commercial, open-source, and user-catered AI/ML tools, a key question often arises whenever AI/ML is applied to explore a phenomenon or a scenario: what constitutes a good AI/ML model? Keeping in mind that a proper answer to this question depends on various factors, this work presumes that a goodmodel optimally performs and best describes the phenomenon on hand . From this perspective, identifying proper assessment metrics to evaluate the performance of AI/ML models is not only necessary but is also warranted. As such, this paper examines 78 of the most commonly-used performance fitness and error metrics for regression and classification algorithms, with emphasis on engineering and sciences applications.",
    "citationCount": 341,
    "pdf_filename": "2020_Error_Metrics_and_Performance_Fitness_In_9cb1693f.pdf"
  },
  "65e9e1e5629a61d61c26c99442518652abfef00a": {
    "paperId": "65e9e1e5629a61d61c26c99442518652abfef00a",
    "title": "Lung adenocarcinoma promotion by air pollutants",
    "year": 2023,
    "authors": "William Hill, E. Lim, C. Weeden, Claudia Lee, M. Augustine",
    "abstract": "A complete understanding of how exposure to environmental substances promotes cancer formation is lacking. More than 70 years ago, tumorigenesis was proposed to occur in a two-step process: an initiating step that induces mutations in healthy cells, followed by a promoter step that triggers cancer development^ 1 . Here we propose that environmental particulate matter measuring ≤2.5 μm (PM_2.5), known to be associated with lung cancer risk, promotes lung cancer by acting on cells that harbour pre-existing oncogenic mutations in healthy lung tissue. Focusing on EGFR-driven lung cancer, which is more common in never-smokers or light smokers, we found a significant association between PM_2.5 levels and the incidence of lung cancer for 32,957 EGFR-driven lung cancer cases in four within-country cohorts. Functional mouse models revealed that air pollutants cause an influx of macrophages into the lung and release of interleukin-1β. This process results in a progenitor-like cell state within EGFR mutant lung alveolar type II epithelial cells that fuels tumorigenesis. Ultradeep mutational profiling of histologically normal lung tissue from 295 individuals across 3 clinical cohorts revealed oncogenic EGFR and KRAS driver mutations in 18% and 53% of healthy tissue samples, respectively. These findings collectively support a tumour-promoting role for  PM_2.5 air pollutants  and provide impetus for public health policy initiatives to address air pollution to reduce disease burden. Combination of epidemiology, preclinical models and ultradeep DNA profiling of clinical cohorts unpicks the inflammatory mechanism by which air pollution promotes lung cancer",
    "citationCount": 485,
    "pdf_filename": "2023_Lung_adenocarcinoma_promotion_by_air_pol_65e9e1e5.pdf"
  },
  "16691c78b5948b5dd6b4efe42870f47460662c02": {
    "paperId": "16691c78b5948b5dd6b4efe42870f47460662c02",
    "title": "Ten Challenges in Advancing Machine Learning Technologies toward 6G",
    "year": 2020,
    "authors": "N. Kato, Bomin Mao, Fengxiao Tang, Y. Kawamoto, Jiajia Liu",
    "abstract": "As the 5G standard is being completed, academia and industry have begun to consider a more developed cellular communication technique, 6G, which is expected to achieve high data rates up to 1 Tb/s and broad frequency bands of 100 GHz to 3 THz. Besides the significant upgrade of the key communication metrics, Artificial Intelligence (AI) has been envisioned by many researchers as the most important feature of 6G, since the state-of-the-art machine learning technique has been adopted as the top solution in many extremely complex scenarios. Network intelligentization will be the new trend to address the challenges of exponentially increasing number of connected heterogeneous devices. However, compared with the application of machine learning in other fields, such as computer games, current research on intelligent networking still has a long way to go to realize the automatically- configured cellular communication systems. Various problems in terms of communication system, machine learning architectures, and computation efficiency should be addressed for the full use of this technique in 6G. In this paper, we analyze machine learning techniques and introduce 10 most critical challenges in advancing the intelligent 6G system.",
    "citationCount": 326,
    "pdf_filename": "2020_Ten_Challenges_in_Advancing_Machine_Lear_16691c78.pdf"
  },
  "7385eaf066ba20d7529b883a55156b455147b26f": {
    "paperId": "7385eaf066ba20d7529b883a55156b455147b26f",
    "title": "Six Human-Centered Artificial Intelligence Grand Challenges",
    "year": 2023,
    "authors": "Ozlem Ozmen Garibay, Brent D. Winslow, S. Andolina, M. Antona, Anja Bodenschatz",
    "abstract": "Abstract Widespread adoption of artificial intelligence (AI) technologies is substantially affecting the human condition in ways that are not yet well understood. Negative unintended consequences abound including the perpetuation and exacerbation of societal inequalities and divisions via algorithmic decision making. We present six grand challenges for the scientific community to create AI technologies that are human-centered, that is, ethical, fair, and enhance the human condition. These grand challenges are the result of an international collaboration across academia, industry and government and represent the consensus views of a group of 26 experts in the field of human-centered artificial intelligence (HCAI). In essence, these challenges advocate for a human-centered approach to AI that (1) is centered in human well-being, (2) is designed responsibly, (3) respects privacy, (4) follows human-centered design principles, (5) is subject to appropriate governance and oversight, and (6) interacts with individuals while respecting human’s cognitive capacities. We hope that these challenges and their associated research directions serve as a call for action to conduct research and development in AI that serves as a force multiplier towards more fair, equitable and sustainable societies.",
    "citationCount": 307,
    "pdf_filename": "2023_Six_Human_Centered_Artificial_Intelligen_7385eaf0.pdf"
  },
  "1c6fbf5c76aee77b539dc3f50991d7ac6c8356e8": {
    "paperId": "1c6fbf5c76aee77b539dc3f50991d7ac6c8356e8",
    "title": "Motion Planning for Autonomous Driving: The State of the Art and Future Perspectives",
    "year": 2023,
    "authors": "Siyu Teng, Xuemin Hu, Peng Deng, Bai Li, Yuchen Li",
    "abstract": "Intelligent vehicles (IVs) have gained worldwide attention due to their increased convenience, safety advantages, and potential commercial value. Despite predictions of commercial deployment by 2025, implementation remains limited to small-scale validation, with precise tracking controllers and motion planners being essential prerequisites for IVs. This article reviews state-of-the-art motion planning methods for IVs, including pipeline planning and end-to-end planning methods. The study examines the selection, expansion, and optimization operations in a pipeline method, while it investigates training approaches and validation scenarios for driving tasks in end-to-end methods. Experimental platforms are reviewed to assist readers in choosing suitable training and validation strategies. A side-by-side comparison of the methods is provided to highlight their strengths and limitations, aiding system-level design choices. Current challenges and future perspectives are also discussed in this survey.",
    "citationCount": 464,
    "pdf_filename": "2023_Motion_Planning_for_Autonomous_Driving___1c6fbf5c.pdf"
  },
  "8d2650784b6491fd2b9e73bb212aae229cea01ea": {
    "paperId": "8d2650784b6491fd2b9e73bb212aae229cea01ea",
    "title": "Artificial Intelligence and Machine Learning Applications in Smart Production: Progress, Trends, and Directions",
    "year": 2020,
    "authors": "R. Cioffi, Marta Travaglioni, G. Piscitelli, A. Petrillo, F. De Felice",
    "abstract": "Adaptation and innovation are extremely important to the manufacturing industry. This development should lead to sustainable manufacturing using new technologies. To promote sustainability, smart production requires global perspectives of smart production application technology. In this regard, thanks to intensive research efforts in the field of artificial intelligence (AI), a number of AI-based techniques, such as machine learning, have already been established in the industry to achieve sustainable manufacturing. Thus, the aim of the present research was to analyze, systematically, the scientific literature relating to the application of artificial intelligence and machine learning (ML) in industry. In fact, with the introduction of the Industry 4.0, artificial intelligence and machine learning are considered the driving force of smart factory revolution. The purpose of this review was to classify the literature, including publication year, authors, scientific sector, country, institution, and keywords. The analysis was done using the Web of Science and SCOPUS database. Furthermore, UCINET and NVivo 12 software were used to complete them. A literature review on ML and AI empirical studies published in the last century was carried out to highlight the evolution of the topic before and after Industry 4.0 introduction, from 1999 to now. Eighty-two articles were reviewed and classified. A first interesting result is the greater number of works published by the USA and the increasing interest after the birth of Industry 4.0.",
    "citationCount": 304,
    "pdf_filename": "2020_Artificial_Intelligence_and_Machine_Lear_8d265078.pdf"
  },
  "8e404c468452a0d76576f974159170e6c2480c6b": {
    "paperId": "8e404c468452a0d76576f974159170e6c2480c6b",
    "title": "Artificial intelligence vs COVID-19: limitations, constraints and pitfalls",
    "year": 2020,
    "authors": "W. Naudé",
    "abstract": "This paper provides an early evaluation of Artificial Intelligence (AI) against COVID-19. The main areas where AI can contribute to the fight against COVID-19 are discussed. It is concluded that AI has not yet been impactful against COVID-19. Its use is hampered by a lack of data, and by too much data. Overcoming these constraints will require a careful balance between data privacy and public health, and rigorous human-AI interaction. It is unlikely that these will be addressed in time to be of much help during the present pandemic. In the meantime, extensive gathering of diagnostic data on who is infectious will be essential to save lives, train AI, and limit economic damages.",
    "citationCount": 304,
    "pdf_filename": "2020_Artificial_intelligence_vs_COVID_19__lim_8e404c46.pdf"
  },
  "d5318a4ebb4160743e3af568b310ebc5aaebc09e": {
    "paperId": "d5318a4ebb4160743e3af568b310ebc5aaebc09e",
    "title": "Federated learning for 6G communications: Challenges, methods, and future directions",
    "year": 2020,
    "authors": "Yi Liu, Xingliang Yuan, Zehui Xiong, Jiawen Kang, Xiaofei Wang",
    "abstract": "As the 5G communication networks are being widely deployed worldwide, both industry and academia have started to move beyond 5G and explore 6G communications. It is generally believed that 6G will be established on ubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning (ML) solutions in heterogeneous and massive-scale networks. However, traditional ML techniques require centralized data collection and processing by a central server, which is becoming a bottleneck of large-scale implementation in daily life due to significantly increasing privacy concerns. Federated learning, as an emerging distributed AI approach with privacy preservation nature, is particularly attractive for various wireless applications, especially being treated as one of the vital solutions to achieve ubiquitous AI in 6G. In this article, we first introduce the integration of 6G and federated learning and provide potential federated learning applications for 6G. We then describe key technical challenges, the corresponding federated learning methods, and open problems for future research on federated learning in the context of 6G communications.",
    "citationCount": 305,
    "pdf_filename": "2020_Federated_learning_for_6G_communications_d5318a4e.pdf"
  },
  "e49a05b8c45411a5e33c6e4ea74bbac6433c42e2": {
    "paperId": "e49a05b8c45411a5e33c6e4ea74bbac6433c42e2",
    "title": "The Role of Imaging in the Detection and Management of COVID-19: A Review",
    "year": 2020,
    "authors": "D. Dong, Zhenchao Tang, Shuo Wang, Hui Hui, Lixin Gong",
    "abstract": "Coronavirus disease 2019 (COVID-19) caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is spreading rapidly around the world, resulting in a massive death toll. Lung infection or pneumonia is the common complication of COVID-19, and imaging techniques, especially computed tomography (CT), have played an important role in diagnosis and treatment assessment of the disease. Herein, we review the imaging characteristics and computing models that have been applied for the management of COVID-19. CT, positron emission tomography - CT (PET/CT), lung ultrasound, and magnetic resonance imaging (MRI) have been used for detection, treatment, and follow-up. The quantitative analysis of imaging data using artificial intelligence (AI) is also explored. Our findings indicate that typical imaging characteristics and their changes can play crucial roles in the detection and management of COVID-19. In addition, AI or other quantitative image analysis methods are urgently needed to maximize the value of imaging in the management of COVID-19.",
    "citationCount": 312,
    "pdf_filename": "2020_The_Role_of_Imaging_in_the_Detection_and_e49a05b8.pdf"
  },
  "95718d6f1900a299c9b540cb77f0687f4eb0d4b6": {
    "paperId": "95718d6f1900a299c9b540cb77f0687f4eb0d4b6",
    "title": "A Survey on Beyond 5G Network With the Advent of 6G: Architecture and Emerging Technologies",
    "year": 2020,
    "authors": "Anutusha Dogra, R. Jha, Shubha Jain",
    "abstract": "Nowadays, 5G is in its initial phase of commercialization. The 5G network will revolutionize the existing wireless network with its enhanced capabilities and novel features. 5G New Radio (5G NR), referred to as the global standardization of 5G, is presently under the $3^{\\mathrm {rd}}$ Generation Partnership Project (3GPP) and can be operable over the wide range of frequency bands from less than 6GHz to mmWave (100GHz). 3GPP mainly focuses on the three major use cases of 5G NR that are comprised of Ultra-Reliable and Low Latency Communication (uRLLC), Massive Machine Type Communication (mMTC), Enhanced Mobile Broadband (eMBB). For meeting the targets of 5G NR, multiple features like scalable numerology, flexible spectrum, forward compatibility, and ultra-lean design are added as compared to the LTE systems. This paper presents a brief overview of the added features and key performance indicators of 5G NR. The issues related to the adaptation of higher modulation schemes and inter-RAT handover synchronization are well addressed in this paper. With the consideration of these challenges, a next-generation wireless communication architecture is proposed. The architecture acts as the platform for migration towards beyond 5G/6G networks. Along with this, various technologies and applications of 6G networks are also overviewed in this paper. 6G network will incorporate Artificial intelligence (AI) based services, edge computing, quantum computing, optical wireless communication, hybrid access, and tactile services. For enabling these diverse services, a virtualized network slicing based architecture of 6G is proposed. Various ongoing projects on 6G and its technologies are also listed in this paper.",
    "citationCount": 352,
    "pdf_filename": "2020_A_Survey_on_Beyond_5G_Network_With_the_A_95718d6f.pdf"
  },
  "551a32d6bb196127b75d256e8547b81ef67a7ad3": {
    "paperId": "551a32d6bb196127b75d256e8547b81ef67a7ad3",
    "title": "Artificial intelligence for diagnosis and Gleason grading of prostate cancer: the PANDA challenge",
    "year": 2022,
    "authors": "W. Bulten, K. Kartasalo, Po-Hsuan Cameron Chen, P. Ström, H. Pinckaers",
    "abstract": "Artificial intelligence (AI) has shown promise for diagnosing prostate cancer in biopsies. However, results have been limited to individual studies, lacking validation in multinational settings. Competitions have been shown to be accelerators for medical imaging innovations, but their impact is hindered by lack of reproducibility and independent validation. With this in mind, we organized the PANDA challenge—the largest histopathology competition to date, joined by 1,290 developers—to catalyze development of reproducible AI algorithms for Gleason grading using 10,616 digitized prostate biopsies. We validated that a diverse set of submitted algorithms reached pathologist-level performance on independent cross-continental cohorts, fully blinded to the algorithm developers. On United States and European external validation sets, the algorithms achieved agreements of 0.862 (quadratically weighted κ, 95% confidence interval (CI), 0.840–0.884) and 0.868 (95% CI, 0.835–0.900) with expert uropathologists. Successful generalization across different patient populations, laboratories and reference standards, achieved by a variety of algorithmic approaches, warrants evaluating AI-based Gleason grading in prospective clinical trials. Through a community-driven competition, the PANDA challenge provides a curated diverse dataset and a catalog of models for prostate cancer pathology, and represents a blueprint for evaluating AI algorithms in digital pathology.",
    "citationCount": 471,
    "pdf_filename": "2022_Artificial_intelligence_for_diagnosis_an_551a32d6.pdf"
  },
  "12601dd02aa624c4c676f42c8f7b034fa3457e37": {
    "paperId": "12601dd02aa624c4c676f42c8f7b034fa3457e37",
    "title": "SSAST: Self-Supervised Audio Spectrogram Transformer",
    "year": 2021,
    "authors": "Yuan Gong, Cheng-I Lai, Yu-An Chung, James R. Glass",
    "abstract": "Recently, neural networks based purely on self-attention, such as the Vision Transformer (ViT), have been shown to outperform deep learning models constructed with convolutional neural networks (CNNs) on various vision tasks, thus extending the success of Transformers, which were originally developed for language processing, to the vision domain. A recent study showed that a similar methodology can also be applied to the audio domain. Specifically, the Audio Spectrogram Transformer (AST) achieves state-of-the-art results on various audio classification benchmarks. However, pure Transformer models tend to require more training data compared to CNNs, and the success of the AST relies on supervised pretraining that requires a large amount of labeled data and a complex training pipeline, thus limiting the practical usage of AST. This paper focuses on audio and speech classification, and aims to reduce the need for large amounts of labeled data for the AST by leveraging self-supervised learning using unlabeled data. Specifically, we propose to pretrain the AST model with joint discriminative and generative masked spectrogram patch modeling (MSPM) using unlabeled audio from AudioSet and Librispeech. We evaluate our pretrained models on both audio and speech classification tasks including audio event classification, keyword spotting, emotion recognition, and speaker identification. The proposed self-supervised framework significantly boosts AST performance on all tasks, with an average improvement of 60.9%, leading to similar or even better results than a supervised pretrained AST. To the best of our knowledge, it is the first patch-based self-supervised learning framework in the audio and speech domain, and also the first self-supervised learning framework for AST.",
    "citationCount": 343,
    "pdf_filename": "2021_SSAST__Self_Supervised_Audio_Spectrogram_12601dd0.pdf"
  },
  "b17d3549814927b678c562737e51f190716c826b": {
    "paperId": "b17d3549814927b678c562737e51f190716c826b",
    "title": "Etiological and epidemiological features of acute respiratory infections in China",
    "year": 2021,
    "authors": "Zhong-jie Li, Haiyang Zhang, L. Ren, Q. Lu, X. Ren",
    "abstract": "Nationwide prospective surveillance of all-age patients with acute respiratory infections was conducted in China between 2009‒2019. Here we report the etiological and epidemiological features of the 231,107 eligible patients enrolled in this analysis. Children <5 years old and school-age children have the highest viral positivity rate (46.9%) and bacterial positivity rate (30.9%). Influenza virus, respiratory syncytial virus and human rhinovirus are the three leading viral pathogens with proportions of 28.5%, 16.8% and 16.7%, and Streptococcus pneumoniae, Mycoplasma pneumoniae and Klebsiella pneumoniae are the three leading bacterial pathogens (29.9%, 18.6% and 15.8%). Negative interactions between viruses and positive interactions between viral and bacterial pathogens are common. A Join-Point analysis reveals the age-specific positivity rate and how this varied for individual pathogens. These data indicate that differential priorities for diagnosis, prevention and control should be highlighted in terms of acute respiratory tract infection patients’ demography, geographic locations and season of illness in China. China operates a national surveillance program for acute respiratory infections and sampled over 200,000 patients between 2009–2019. Here, the authors present results from this program and describe patterns by age, pathogen type, presence of pneumonia, and season.",
    "citationCount": 353,
    "pdf_filename": "2021_Etiological_and_epidemiological_features_b17d3549.pdf"
  },
  "1d3900c44eb9840205927dcfbde2d370a574c0b9": {
    "paperId": "1d3900c44eb9840205927dcfbde2d370a574c0b9",
    "title": "Wireless Image Transmission Using Deep Source Channel Coding With Attention Modules",
    "year": 2020,
    "authors": "Jia-lin Xu, B. Ai, Wei Chen, Ang Yang, Peng Sun",
    "abstract": "Recent research on joint source channel coding (JSCC) for wireless communications has achieved great success owing to the employment of deep learning (DL). However, the existing work on DL based JSCC usually trains the designed network to operate under a specific signal-to-noise ratio (SNR) regime, without taking into account that the SNR level during the deployment stage may differ from that during the training stage. A number of networks are required to cover the scenario with a broad range of SNRs, which is computational inefficiency (in the training stage) and requires large storage. To overcome these drawbacks our paper proposes a novel method called Attention DL based JSCC (ADJSCC) that can successfully operate with different SNR levels during transmission. This design is inspired by the resource assignment strategy in traditional JSCC, which dynamically adjusts the compression ratio in source coding and the channel coding rate according to the channel SNR. This is achieved by resorting to attention mechanisms because these are able to allocate computing resources to more critical tasks. Instead of applying the resource allocation strategy in traditional JSCC, the ADJSCC uses the channel-wise soft attention to scaling features according to SNR conditions. We compare the ADJSCC method with the state-of-the-art DL based JSCC method through extensive experiments to demonstrate its adaptability, robustness and versatility. Compared with the existing methods, the proposed method takes less storage and is more robust in the presence of channel mismatch.",
    "citationCount": 334,
    "pdf_filename": "2020_Wireless_Image_Transmission_Using_Deep_S_1d3900c4.pdf"
  },
  "129c66d240883c735dbb08c8f025a6573328827b": {
    "paperId": "129c66d240883c735dbb08c8f025a6573328827b",
    "title": "The Clinician and Dataset Shift in Artificial Intelligence.",
    "year": 2021,
    "authors": "S. G. Finlayson, Adarsh Subbaswamy, Karandeep Singh, John Bowers, Annabel Kupke",
    "abstract": "To the Editor: Artificial intelligence (AI) systems are now regularly being used in medical settings,1 although regulatory oversight is inconsistent and undeveloped.2,3 Safe deployment of clinical AI requires informed clinician-users, who are generally responsible for identifying and reporting emerging problems. Clinicians may also serve as administrators in governing the use of clinical AI. A natural question follows: are clinicians adequately prepared to identify circumstances in which AI systems fail to perform their intended function reliably? A major driver of AI system malfunction is known as “dataset shift.”4,5 Most clinical AI systems today use machine learning, algorithms that leverage statistical methods to learn key patterns from clinical data. Dataset shift occurs when a machine-learning system underperforms because of a mismatch between the data set with which it was developed and the data on which it is deployed.4 For example, the University of Michigan Hospital implemented the widely used sepsis-alerting model developed by Epic Systems; in April 2020, the model had to be deactivated because of spurious alerting owing to changes in patients’ demographic characteristics associated with the coronavirus disease 2019 pandemic. This was a case in which dataset shift fundamentally altered the relationship between fevers and bacterial sepsis, leading the hospital’s clinical AI governing committee (which one of the authors of this letter chairs) to decommission its use. This is an extreme example; many causes of dataset shift are more subtle. In Table 1, we present common causes of dataset shift, which we group into changes in technology (e.g., software vendors), changes in population and setting (e.g., new demographics), and changes in behavior (e.g., new reimbursement incentives); the list is not meant to be exhaustive. Successful recognition and mitigation of dataset shift require both vigilant clinicians and sound technical oversight through AI governance teams.4,5 When using an AI system, clinicians should note misalignment between the predictions of the model and their own clinical judgment, as in the sepsis example above. Clinicians who use AI systems must frequently consider whether relevant aspects of their own clinical practice are atypical or have recently changed. For their part, AI governance teams must be sure that it is easy for clinicians to report concerns about the function of AI systems and provide feedback so that the clinician who is reporting will understand that the registered concern has been noted and, if appropriate, actions to mitigate the concern have been taken. Teams must also establish AI monitoring and updating protocols that integrate technical solu-",
    "citationCount": 456,
    "pdf_filename": "2021_The_Clinician_and_Dataset_Shift_in_Artif_129c66d2.pdf"
  },
  "4899dffeca9285ecd47fad26a7790ab9998d56e6": {
    "paperId": "4899dffeca9285ecd47fad26a7790ab9998d56e6",
    "title": "Deep Learning for Safe Autonomous Driving: Current Challenges and Future Directions",
    "year": 2020,
    "authors": "Khan Muhammad, Amin Ullah, Jaime Lloret, J. Ser, V. Albuquerque",
    "abstract": "Advances in information and signal processing technologies have a significant impact on autonomous driving (AD), improving driving safety while minimizing the efforts of human drivers with the help of advanced artificial intelligence (AI) techniques. Recently, deep learning (DL) approaches have solved several real-world problems of complex nature. However, their strengths in terms of control processes for AD have not been deeply investigated and highlighted yet. This survey highlights the power of DL architectures in terms of reliability and efficient real-time performance and overviews state-of-the-art strategies for safe AD, with their major achievements and limitations. Furthermore, it covers major embodiments of DL along the AD pipeline including measurement, analysis, and execution, with a focus on road, lane, vehicle, pedestrian, drowsiness detection, collision avoidance, and traffic sign detection through sensing and vision-based DL methods. In addition, we discuss on the performance of several reviewed methods by using different evaluation metrics, with critics on their pros and cons. Finally, this survey highlights the current issues of safe DL-based AD with a prospect of recommendations for future research, rounding up a reference material for newcomers and researchers willing to join this vibrant area of Intelligent Transportation Systems.",
    "citationCount": 493,
    "pdf_filename": "2020_Deep_Learning_for_Safe_Autonomous_Drivin_4899dffe.pdf"
  },
  "a8e0effdc54ec0dbc412694c9f8f711af2f59bde": {
    "paperId": "a8e0effdc54ec0dbc412694c9f8f711af2f59bde",
    "title": "Manipulating spin polarization of titanium dioxide for efficient photocatalysis",
    "year": 2020,
    "authors": "Lun Pan, Minhua Ai, Chenyu Huang, Li Yin, Xiang Liu",
    "abstract": "Photocatalysis has been regarded as a promising strategy for hydrogen production and high-value-added chemicals synthesis, in which the activity of photocatalyst depends significantly on their electronic structures, however the effect of electron spin polarization has been rarely considered. Here we report a controllable method to manipulate its electron spin polarization by tuning the concentration of Ti vacancies. The characterizations confirm the emergence of spatial spin polarization among Ti-defected TiO2, which promotes the efficiency of charge separation and surface reaction via the parallel alignment of electron spin orientation. Specifically, Ti0.936O2, possessing intensive spin polarization, performs 20-fold increased photocatalytic hydrogen evolution and 8-fold increased phenol photodegradation rates, compared with stoichiometric TiO2. Notably, we further observed the positive effect of external magnetic fields on photocatalytic activity of spin-polarized TiO2, attributed to the enhanced electron-spin parallel alignment. This work may create the opportunity for tailoring the spin-dependent electronic structures in metal oxides. Photocatalyst activity depends significantly on the material’s electronic structures. Here, authors manipulate the electron spin polarization of TiO2 by tuning the concentration of Ti vacancies and show improved photocatalytic activities.",
    "citationCount": 358,
    "pdf_filename": "2020_Manipulating_spin_polarization_of_titani_a8e0effd.pdf"
  },
  "ae12ffb64c61762e58eab6e15c31827f6d859b90": {
    "paperId": "ae12ffb64c61762e58eab6e15c31827f6d859b90",
    "title": "A detailed map of Higgs boson interactions by the ATLAS experiment ten years after the discovery",
    "year": 2022,
    "authors": "G. B. D. C. K. S. H. A. H. H. Y. A. C. B. S. B. L. C. Aad Abbott Abbott Abeling Abidi Aboulhorma Abramow, G. Aad, B. Abbott, D. Abbott, K. Abeling",
    "abstract": "The standard model of particle physics1–4 describes the known fundamental particles and forces that make up our Universe, with the exception of gravity. One of the central features of the standard model is a field that permeates all of space and interacts with fundamental particles5–9. The quantum excitation of this field, known as the Higgs field, manifests itself as the Higgs boson, the only fundamental particle with no spin. In 2012, a particle with properties consistent with the Higgs boson of the standard model was observed by the ATLAS and CMS experiments at the Large Hadron Collider at CERN10,11. Since then, more than 30 times as many Higgs bosons have been recorded by the ATLAS experiment, enabling much more precise measurements and new tests of the theory. Here, on the basis of this larger dataset, we combine an unprecedented number of production and decay processes of the Higgs boson to scrutinize its interactions with elementary particles. Interactions with gluons, photons, and W and Z bosons—the carriers of the strong, electromagnetic and weak forces—are studied in detail. Interactions with three third-generation matter particles (bottom (b) and top (t) quarks, and tau leptons (τ)) are well measured and indications of interactions with a second-generation particle (muons, μ) are emerging. These tests reveal that the Higgs boson discovered ten years ago is remarkably consistent with the predictions of the theory and provide stringent constraints on many models of new phenomena beyond the standard model. Ten years after the discovery of the Higgs boson, the ATLAS experiment at CERN probes its kinematic properties with a significantly larger dataset from 2015–2018 and provides further insights on its interaction with other known particles.",
    "citationCount": 458,
    "pdf_filename": "2022_A_detailed_map_of_Higgs_boson_interactio_ae12ffb6.pdf"
  },
  "8adc96980d6872880c8d3ace746049027c5125e5": {
    "paperId": "8adc96980d6872880c8d3ace746049027c5125e5",
    "title": "Exploring Opportunities and Challenges of Artificial Intelligence and Machine Learning in Higher Education Institutions",
    "year": 2021,
    "authors": "Valentin Kuleto, Milena P. Ilić, Mihail-Alexandru Dumangiu, M. Ranković, Oliva M. D. Martins",
    "abstract": "The way people travel, organise their time, and acquire information has changed due to information technologies. Artificial intelligence (AI) and machine learning (ML) are mechanisms that evolved from data management and developing processes. Incorporating these mechanisms into business is a trend many different industries, including education, have identified as game-changers. As a result, education platforms and applications are more closely aligned with learners’ needs and knowledge, making the educational process more efficient. Therefore, AI and ML have great potential in e-learning and higher education institutions (HEI). Thus, the article aims to determine its potential and use areas in higher education based on secondary research and document analysis (literature review), content analysis, and primary research (survey). As referent points for this research, multiple academic, scientific, and commercial sources were used to obtain a broader picture of the research subject. Furthermore, the survey was implemented among students in the Republic of Serbia, with 103 respondents to generate data and information on how much knowledge of AI and ML is held by the student population, mainly to understand both opportunities and challenges involved in AI and ML in HEI. The study addresses critical issues, like common knowledge and stance of research bases regarding AI and ML in HEI; best practices regarding usage of AI and ML in HEI; students’ knowledge of AI and ML; and students’ attitudes regarding AI and ML opportunities and challenges in HEI. In statistical considerations, aiming to evaluate if the indicators were considered reflexive and, in this case, belong to the same theoretical dimension, the Correlation Matrix was presented, followed by the Composite Reliability. Finally, the results were evaluated by regression analysis. The results indicated that AI and ML are essential technologies that enhance learning, primarily through students’ skills, collaborative learning in HEI, and an accessible research environment.",
    "citationCount": 356,
    "pdf_filename": "2021_Exploring_Opportunities_and_Challenges_o_8adc9698.pdf"
  },
  "831490668e6d389d530c988d3969c4f79cf7027e": {
    "paperId": "831490668e6d389d530c988d3969c4f79cf7027e",
    "title": "An Overall Understanding of Sodium Storage Behaviors in Hard Carbons by an “Adsorption‐Intercalation/Filling” Hybrid Mechanism",
    "year": 2022,
    "authors": "Xiaoyan Chen, Jiyu Tian, Peng Li, Youlong Fang, Yongjin Fang",
    "abstract": "Hard carbon has the potential to serve as a high‐capacity anode material for sodium‐ion batteries (SIBs), however, its Na+ storage mechanism, particularly on the low potential plateau, remains controversial. To overcome this issue, two types of hard carbons with different microstructures are employed and the relationship between the microstructures and Na+ storage behaviors is evaluated. By the combination of operando X‐ray diffraction, ex situ Raman spectroscopy, NMR, and theoretical calculation, it is found that the sodium storage capacities of the hard carbons in the low potential plateau region contain the concurrent contributions from both interlayer intercalation and micropores filling, and the ratio of the two contributors greatly depends on the microstructure of hard carbon materials. Moreover, an electrochemical pointer (potential inflection point at the end of the discharge curve) is found to distinguish the dominance of interlayer intercalation and the micropores filling processes of sodium ions in the low potential plateau region. Based on this new finding, a microstructure‐dependent mechanism (“adsorption‐intercalation/filling” hybrid mechanism) is proposed to achieve an overall understanding of the sodium storage behaviors in different hard carbon materials, which may provide deep insight into the rational design of hard carbon structures as high‐performance anode materials for advanced SIBs.",
    "citationCount": 362,
    "pdf_filename": "2022_An_Overall_Understanding_of_Sodium_Stora_83149066.pdf"
  },
  "ff6914cef1a774d8fa4a1d84639ccf983265136d": {
    "paperId": "ff6914cef1a774d8fa4a1d84639ccf983265136d",
    "title": "Attitudes and perceptions of UK medical students towards artificial intelligence and radiology: a multicentre survey",
    "year": 2020,
    "authors": "C. Sit, R. Srinivasan, A. Amlani, K. Muthuswamy, A. Azam",
    "abstract": "Objectives To explore the attitudes of United Kingdom (UK) medical students regarding artificial intelligence (AI), their understanding, and career intention towards radiology. We also examine the state of education relating to AI amongst this cohort. Methods UK medical students were invited to complete an anonymous electronic survey consisting of Likert and dichotomous questions. Results Four hundred eighty-four responses were received from 19 UK medical schools. Eighty-eight percent of students believed that AI will play an important role in healthcare, and 49% reported they were less likely to consider a career in radiology due to AI. Eighty-nine percent of students believed that teaching in AI would be beneficial for their careers, and 78% agreed that students should receive training in AI as part of their medical degree. Only 45 students received any teaching on AI; none of the students received such teaching as part of their compulsory curriculum. Statistically, students that did receive teaching in AI were more likely to consider radiology ( p  = 0.01) and rated more positively to the questions relating to the perceived competence in the post-graduation use of AI ( p  = 0.01–0.04); despite this, a large proportion of students in the taught group reported a lack of confidence and understanding required for the critical use of healthcare AI tools. Conclusions UK medical students understand the importance of AI and are keen to engage. Medical school training on AI should be expanded and improved. Realistic use cases and limitations of AI must be presented to students so they will not feel discouraged from pursuing radiology.",
    "citationCount": 338,
    "pdf_filename": "2020_Attitudes_and_perceptions_of_UK_medical__ff6914ce.pdf"
  },
  "4d666a751c577303e777a8da56b765dc1571a58e": {
    "paperId": "4d666a751c577303e777a8da56b765dc1571a58e",
    "title": "Preparing Workplaces for Digital Transformation: An Integrative Review and Framework of Multi-Level Factors",
    "year": 2021,
    "authors": "Brigid Trenerry, Samuel Chng, Yang Wang, Zainal Shah Suhaila, S. S. Lim",
    "abstract": "The rapid advancement of new digital technologies, such as smart technology, artificial intelligence (AI) and automation, robotics, cloud computing, and the Internet of Things (IoT), is fundamentally changing the nature of work and increasing concerns about the future of jobs and organizations. To keep pace with rapid disruption, companies need to update and transform business models to remain competitive. Meanwhile, the growth of advanced technologies is changing the types of skills and competencies needed in the workplace and demanded a shift in mindset among individuals, teams and organizations. The recent COVID-19 pandemic has accelerated digitalization trends, while heightening the importance of employee resilience and well-being in adapting to widespread job and technological disruption. Although digital transformation is a new and urgent imperative, there is a long trajectory of rigorous research that can readily be applied to grasp these emerging trends. Recent studies and reviews of digital transformation have primarily focused on the business and strategic levels, with only modest integration of employee-related factors. Our review article seeks to fill these critical gaps by identifying and consolidating key factors important for an organization’s overarching digital transformation. We reviewed studies across multiple disciplines and integrated the findings into a multi-level framework. At the individual level, we propose five overarching factors related to effective digital transformation among employees: technology adoption; perceptions and attitudes toward technological change; skills and training; workplace resilience and adaptability, and work-related wellbeing. At the group-level, we identified three factors necessary for digital transformation: team communication and collaboration; workplace relationships and team identification, and team adaptability and resilience. Finally, at the organizational-level, we proposed three factors for digital transformation: leadership; human resources, and organizational culture/climate. Our review of the literature confirms that multi-level factors are important when planning for and embarking on digital transformation, thereby providing a framework for future research and practice.",
    "citationCount": 353,
    "pdf_filename": "2021_Preparing_Workplaces_for_Digital_Transfo_4d666a75.pdf"
  },
  "703eaf607de6872b13225e053a4e15ad90440a8e": {
    "paperId": "703eaf607de6872b13225e053a4e15ad90440a8e",
    "title": "Towards an Artificial Intelligence Framework for Data-Driven Prediction of Coronavirus Clinical Severity",
    "year": 2020,
    "authors": "Xiangao Jiang, M. Coffee, Anasse Bari, Junzhang Wang, Xinyue Jiang",
    "abstract": "The virus SARS-CoV2, which causes coronavirus disease (COVID-19) has become a pandemic and has spread to every inhabited continent Given the increasing caseload, there is an urgent need to augment clinical skills in order to identify from among the many mild cases the few that will progress to critical illness We present a first step towards building an artificial intelligence (AI) framework, with predictive analytics (PA) capabilities applied to real patient data, to provide rapid clinical decision-making support COVID-19 has presented a pressing need as a) clinicians are still developing clinical acumen to this novel disease and b) resource limitations in a surging pandemic require difficult resource allocation decisions The objectives of this research are: (1) to algorithmically identify the combinations of clinical characteristics of COVID-19 that predict outcomes, and (2) to develop a tool with AI capabilities that will predict patients at risk for more severe illness on initial presentation The predictive models learn from historical data to help predict who will develop acute respiratory distress syndrome (ARDS), a severe outcome in COVID-19 Our results, based on data from two hospitals in Wenzhou, Zhejiang, China, identified features on initial presentation with COVID-19 that were most predictive of later development of ARDS A mildly elevated alanine aminotransferase (ALT) (a liver enzyme), the presence of myalgias (body aches), and an elevated hemoglobin (red blood cells), in this order, are the clinical features, on presentation, that are the most predictive The predictive models that learned from historical data of patients from these two hospitals achieved 70% to 80% accuracy in predicting severe cases",
    "citationCount": 383,
    "pdf_filename": "2020_Towards_an_Artificial_Intelligence_Frame_703eaf60.pdf"
  },
  "081d0df96fdd03b36a56ca9dad02157af9ffdd0f": {
    "paperId": "081d0df96fdd03b36a56ca9dad02157af9ffdd0f",
    "title": "Trends in Disease Severity and Health Care Utilization During the Early Omicron Variant Period Compared with Previous SARS-CoV-2 High Transmission Periods — United States, December 2020–January 2022",
    "year": 2022,
    "authors": "A. Iuliano, J. Brunkard, T. Boehmer, Elisha E Peterson, S. Adjei",
    "abstract": "The B.1.1.529 (Omicron) variant of SARS-CoV-2, the virus that causes COVID-19, was first clinically identified in the United States on December 1, 2021, and spread rapidly. By late December, it became the predominant strain, and by January 15, 2022, it represented 99.5% of sequenced specimens in the United States* (1). The Omicron variant has been shown to be more transmissible and less virulent than previously circulating variants (2,3). To better understand the severity of disease and health care utilization associated with the emergence of the Omicron variant in the United States, CDC examined data from three surveillance systems and a large health care database to assess multiple indicators across three high-COVID-19 transmission periods: December 1, 2020-February 28, 2021 (winter 2020-21); July 15-October 31, 2021 (SARS-CoV-2 B.1.617.2 [Delta] predominance); and December 19, 2021-January 15, 2022 (Omicron predominance). The highest daily 7-day moving average to date of cases (798,976 daily cases during January 9-15, 2022), emergency department (ED) visits (48,238), and admissions (21,586) were reported during the Omicron period, however, the highest daily 7-day moving average of deaths (1,854) was lower than during previous periods. During the Omicron period, a maximum of 20.6% of staffed inpatient beds were in use for COVID-19 patients, 3.4 and 7.2 percentage points higher than during the winter 2020-21 and Delta periods, respectively. However, intensive care unit (ICU) bed use did not increase to the same degree: 30.4% of staffed ICU beds were in use for COVID-19 patients during the Omicron period, 0.5 percentage points lower than during the winter 2020-21 period and 1.2 percentage points higher than during the Delta period. The ratio of peak ED visits to cases (event-to-case ratios) (87 per 1,000 cases), hospital admissions (27 per 1,000 cases), and deaths (nine per 1,000 cases [lagged by 3 weeks]) during the Omicron period were lower than those observed during the winter 2020-21 (92, 68, and 16 respectively) and Delta (167, 78, and 13, respectively) periods. Further, among hospitalized COVID-19 patients from 199 U.S. hospitals, the mean length of stay and percentages who were admitted to an ICU, received invasive mechanical ventilation (IMV), and died while in the hospital were lower during the Omicron period than during previous periods. COVID-19 disease severity appears to be lower during the Omicron period than during previous periods of high transmission, likely related to higher vaccination coverage,† which reduces disease severity (4), lower virulence of the Omicron variant (3,5,6), and infection-acquired immunity (3,7). Although disease severity appears lower with the Omicron variant, the high volume of ED visits and hospitalizations can strain local health care systems in the United States, and the average daily number of deaths remains substantial.§ This underscores the importance of national emergency preparedness, specifically, hospital surge capacity and the ability to adequately staff local health care systems. In addition, being up to date on vaccination and following other recommended prevention strategies are critical to preventing infections, severe illness, or death from COVID-19.",
    "citationCount": 397,
    "pdf_filename": "2022_Trends_in_Disease_Severity_and_Health_Ca_081d0df9.pdf"
  },
  "0fd6bdf5003c76b9b144bab1b326f9e3e7c16f22": {
    "paperId": "0fd6bdf5003c76b9b144bab1b326f9e3e7c16f22",
    "title": "Transmission dynamics of 2019 novel coronavirus (2019-nCoV)",
    "year": 2020,
    "authors": "Tao Liu, Jianxiong Hu, Min Kang, Lifeng Lin, Haojie Zhong",
    "abstract": "Background Since December 29, 2019, pneumonia infection with 2019-nCoV has rapidly spread out from Wuhan, Hubei Province, China to most others provinces and other counties. However, the transmission dynamics of 2019-nCoV remain unclear. Methods Data of confirmed 2019-nCoV cases before January 23, 2020 were collected from medical records, epidemiological investigations or official websites. Data of severe acute respiratory syndrome (SARS) cases in Guangdong Province during 2002-2003 were obtained from Guangdong Provincial Center for Disease Control and Prevention (GDCDC). Exponential Growth (EG) and maximum likelihood estimation (ML) were applied to estimate the reproductive number (R) of 2019-nCoV and SARS. Findings As of January 23, 2020, a total of 830 confirmed 2019-nCoV cases were identified across China, and 9 cases were reported overseas. The average incubation duration of 2019-nCoV infection was 4.8days. The average period from onset of symptoms to isolation of 2019-nCoV and SARS cases were 2.9 and 4.2 days, respectively. The R values of 2019-nCoV were 2.90 (95%CI: 2.32-3.63) and 2.92 (95%CI: 2.28-3.67) estimated using EG and ML respectively, while the corresponding R values of SARS-CoV were 1.77 (95%CI: 1.37-2.27) and 1.85 (95%CI: 1.32-2.49). We observe a decreasing trend of the period from onset to isolation and R values of both 2019-nCoV and SARS-CoV. Interpretation The 2019-nCoV may have a higher pandemic risk than SARS broken out in 2003. The implemented public-health efforts have significantly decreased the pandemic risk of 2019-nCoV. However, more rigorous control and prevention strategies and measures to contain its further spread. Funding National Key Research and Development Program of China, Science and Technology Program of Guangdong Province, and Guangzhou Science and technology Plan Project.",
    "citationCount": 456,
    "pdf_filename": "2020_Transmission_dynamics_of_2019_novel_coro_0fd6bdf5.pdf"
  },
  "ed2bcfa4536eee4ed23d26e45e0d2a9af573567b": {
    "paperId": "ed2bcfa4536eee4ed23d26e45e0d2a9af573567b",
    "title": "Deep-Reinforcement-Learning-Based Autonomous Voltage Control for Power Grid Operations",
    "year": 2020,
    "authors": "Jiajun Duan, Di Shi, R. Diao, Haifeng Li, Zhiwei Wang",
    "abstract": "In this letter, a novel autonomous control framework “Grid Mind” is proposed for the secure operation of power grids based on cutting-edge artificial intelligence (AI) technologies. The proposed platform provides a data-driven, model-free and closed-loop control agent trained using deep reinforcement learning (DRL) algorithms by interacting with massive simulations and/or real environment of a power grid. The proposed agent learns from scratch to master the power grid voltage control problem purely from data. It can make autonomous voltage control (AVC) strategies to support grid operators in making effective and timely control actions, according to the current system conditions detected by real-time measurements from supervisory control and data acquisition (SCADA) or phasor measurement units (PMUs). Two state-of-the-art DRL algorithms, namely deep Q-network (DQN) and deep deterministic policy gradient (DDPG), are proposed to formulate the AVC problem with performance compared. Case studies on a realistic 200-bus test system demonstrate the effectiveness and promising performance of the proposed framework.",
    "citationCount": 327,
    "pdf_filename": "2020_Deep_Reinforcement_Learning_Based_Autono_ed2bcfa4.pdf"
  },
  "4b89b8238b695b5163ad8a54a2fdf1b429df1cba": {
    "paperId": "4b89b8238b695b5163ad8a54a2fdf1b429df1cba",
    "title": "Artificial Intelligence Applied to Battery Research: Hype or Reality?",
    "year": 2021,
    "authors": "Teo Lombardo, M. Duquesnoy, Hassna El-Bouysidy, Fabian Årén, Alfonso Gallo-Bueno",
    "abstract": "This is a critical review of artificial intelligence/machine learning (AI/ML) methods applied to battery research. It aims at providing a comprehensive, authoritative, and critical, yet easily understandable, review of general interest to the battery community. It addresses the concepts, approaches, tools, outcomes, and challenges of using AI/ML as an accelerator for the design and optimization of the next generation of batteries—a current hot topic. It intends to create both accessibility of these tools to the chemistry and electrochemical energy sciences communities and completeness in terms of the different battery R&D aspects covered.",
    "citationCount": 327,
    "pdf_filename": "2021_Artificial_Intelligence_Applied_to_Batte_4b89b823.pdf"
  },
  "aa64d955454464ef5d921cc9df6682ff4921b2e3": {
    "paperId": "aa64d955454464ef5d921cc9df6682ff4921b2e3",
    "title": "Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare",
    "year": 2020,
    "authors": "D. Cirillo, S. Catuara-Solarz, Czuee Morey, E. Guney, L. Subirats",
    "abstract": "Precision Medicine implies a deep understanding of inter-individual differences in health and disease that are due to genetic and environmental factors. To acquire such understanding there is a need for the implementation of different types of technologies based on artificial intelligence (AI) that enable the identification of biomedically relevant patterns, facilitating progress towards individually tailored preventative and therapeutic interventions. Despite the significant scientific advances achieved so far, most of the currently used biomedical AI technologies do not account for bias detection. Furthermore, the design of the majority of algorithms ignore the sex and gender dimension and its contribution to health and disease differences among individuals. Failure in accounting for these differences will generate sub-optimal results and produce mistakes as well as discriminatory outcomes. In this review we examine the current sex and gender gaps in a subset of biomedical technologies used in relation to Precision Medicine. In addition, we provide recommendations to optimize their utilization to improve the global health and disease landscape and decrease inequalities.",
    "citationCount": 363,
    "pdf_filename": "2020_Sex_and_gender_differences_and_biases_in_aa64d955.pdf"
  },
  "063b91a32968b7e1410d4b390b763a2379d17797": {
    "paperId": "063b91a32968b7e1410d4b390b763a2379d17797",
    "title": "Key residues of the receptor binding motif in the spike protein of SARS-CoV-2 that interact with ACE2 and neutralizing antibodies",
    "year": 2020,
    "authors": "C. Yi, Xiaoyu Sun, Jing Ye, Longfei Ding, Meiqin Liu",
    "abstract": "Coronavirus disease 2019 (COVID-19), caused by the novel human coronavirus SARS-CoV-2, is currently a major threat to public health worldwide. The viral spike protein binds the host receptor angiotensin-converting enzyme 2 (ACE2) via the receptor-binding domain (RBD), and thus is believed to be a major target to block viral entry. Both SARS-CoV-2 and SARS-CoV share this mechanism. Here we functionally analyzed the key amino acid residues located within receptor binding motif of RBD that may interact with human ACE2 and available neutralizing antibodies. The in vivo experiments showed that immunization with either the SARS-CoV RBD or SARS-CoV-2 RBD was able to induce strong clade-specific neutralizing antibodies in mice; however, the cross-neutralizing activity was much weaker, indicating that there are distinct antigenic features in the RBDs of the two viruses. This finding was confirmed with the available neutralizing monoclonal antibodies against SARS-CoV or SARS-CoV-2. It is worth noting that a newly developed SARS-CoV-2 human antibody, HA001, was able to neutralize SARS-CoV-2, but failed to recognize SARS-CoV. Moreover, the potential epitope residues of HA001 were identified as A475 and F486 in the SARS-CoV-2 RBD, representing new binding sites for neutralizing antibodies. Overall, our study has revealed the presence of different key epitopes between SARS-CoV and SARS-CoV-2, which indicates the necessity to develop new prophylactic vaccine and antibody drugs for specific control of the COVID-19 pandemic although the available agents obtained from the SARS-CoV study are unneglectable.",
    "citationCount": 450,
    "pdf_filename": "2020_Key_residues_of_the_receptor_binding_mot_063b91a3.pdf"
  },
  "96bfe3b2f29eb79dd496ccdf78532e85fe8fbcb7": {
    "paperId": "96bfe3b2f29eb79dd496ccdf78532e85fe8fbcb7",
    "title": "Serial Quantitative Chest CT Assessment of COVID-19: A Deep Learning Approach",
    "year": 2020,
    "authors": "Lu Huang, R. Han, T. Ai, Pengxin Yu, Han Kang",
    "abstract": "Purpose To quantitatively evaluate lung burden changes in patients with coronavirus disease 2019 (COVID-19) by using serial CT scan by an automated deep learning method. Materials and Methods Patients with COVID-19, who underwent chest CT between January 1 and February 3, 2020, were retrospectively evaluated. The patients were divided into mild, moderate, severe, and critical types, according to their baseline clinical, laboratory, and CT findings. CT lung opacification percentages of the whole lung and five lobes were automatically quantified by a commercial deep learning software and compared with those at follow-up CT scans. Longitudinal changes of the CT quantitative parameter were also compared among the four clinical types. Results A total of 126 patients with COVID-19 (mean age, 52 years ± 15 [standard deviation]; 53.2% males) were evaluated, including six mild, 94 moderate, 20 severe, and six critical cases. CT-derived opacification percentage was significantly different among clinical groups at baseline, gradually progressing from mild to critical type (all P < .01). Overall, the whole-lung opacification percentage significantly increased from baseline CT to first follow-up CT (median [interquartile range]: 3.6% [0.5%, 12.1%] vs 8.7% [2.7%, 21.2%]; P < .01). No significant progression of the opacification percentages was noted from the first follow-up to second follow-up CT (8.7% [2.7%, 21.2%] vs 6.0% [1.9%, 24.3%]; P = .655). Conclusion The quantification of lung opacification in COVID-19 measured at chest CT by using a commercially available deep learning–based tool was significantly different among groups with different clinical severity. This approach could potentially eliminate the subjectivity in the initial assessment and follow-up of pulmonary findings in COVID-19. Supplemental material is available for this article. © RSNA, 2020",
    "citationCount": 377,
    "pdf_filename": "2020_Serial_Quantitative_Chest_CT_Assessment__96bfe3b2.pdf"
  },
  "dcb93a5e9818ca0681788bfaae2c290bcb2c4ac8": {
    "paperId": "dcb93a5e9818ca0681788bfaae2c290bcb2c4ac8",
    "title": "Gold Nanorods: The Most Versatile Plasmonic Nanoparticles.",
    "year": 2021,
    "authors": "Jiapeng Zheng, Xizhe Cheng, Han Zhang, Xiaopeng Bai, Ruoqi Ai",
    "abstract": "Gold nanorods (NRs), pseudo-one-dimensional rod-shaped nanoparticles (NPs), have become one of the burgeoning materials in the recent years due to their anisotropic shape and adjustable plasmonic properties. With the continuous improvement in synthetic methods, a variety of materials have been attached around Au NRs to achieve unexpected or improved plasmonic properties and explore state-of-the-art technologies. In this review, we comprehensively summarize the latest progress on Au NRs, the most versatile anisotropic plasmonic NPs. We present a representative overview of the advances in the synthetic strategies and outline an extensive catalogue of Au-NR-based heterostructures with tailored architectures and special functionalities. The bottom-up assembly of Au NRs into preprogrammed metastructures is then discussed, as well as the design principles. We also provide a systematic elucidation of the different plasmonic properties associated with the Au-NR-based structures, followed by a discussion of the promising applications of Au NRs in various fields. We finally discuss the future research directions and challenges of Au NRs.",
    "citationCount": 433,
    "pdf_filename": "2021_Gold_Nanorods__The_Most_Versatile_Plasmo_dcb93a5e.pdf"
  },
  "835f68a9c9fa75a22fd2eefdabb124fd34b53618": {
    "paperId": "835f68a9c9fa75a22fd2eefdabb124fd34b53618",
    "title": "Assessment of Maternal and Neonatal SARS-CoV-2 Viral Load, Transplacental Antibody Transfer, and Placental Pathology in Pregnancies During the COVID-19 Pandemic",
    "year": 2020,
    "authors": "A. Edlow, Jonathan Z. Li, Ai-ris Y. Collier, C. Atyeo, K. James",
    "abstract": "Key Points Question What key biological characteristics of maternal severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection and placental function and pathology have implications for vertical transmission and neonatal protection? Findings In this prospective cohort study including 127 pregnancies, there was no maternal viremia, placental infection, or vertical transmission of SARS-CoV-2. Compromised transplacental transfer of anti–SARS-CoV-2 antibodies with robust transfer of influenza-specific immunity and nonoverlapping placental expression of SARS-CoV-2 receptors angiotensin-converting enzyme 2 and transmembrane serine protease 2 were noted. Meaning These findings suggest that, although low rates of maternal viremia and patterns of placental SARS-CoV-2 receptor distribution may underlie the rarity of vertical transmission, reduced transplacental transfer of anti–SARS-CoV-2 antibodies may leave neonates at risk for infection.",
    "citationCount": 352,
    "pdf_filename": "2020_Assessment_of_Maternal_and_Neonatal_SARS_835f68a9.pdf"
  },
  "b608db98d844908dab02c09f07030071841edc46": {
    "paperId": "b608db98d844908dab02c09f07030071841edc46",
    "title": "Effect of Endovascular Treatment Alone vs Intravenous Alteplase Plus Endovascular Treatment on Functional Independence in Patients With Acute Ischemic Stroke: The DEVT Randomized Clinical Trial.",
    "year": 2021,
    "authors": "W. Zi, Zhongming Qiu, Fengli Li, Hongfei Sang, Deping Wu",
    "abstract": "Importance\nFor patients with large vessel occlusion strokes, it is unknown whether endovascular treatment alone compared with intravenous thrombolysis plus endovascular treatment (standard treatment) can achieve similar functional outcomes.\n\n\nObjective\nTo investigate whether endovascular thrombectomy alone is noninferior to intravenous alteplase followed by endovascular thrombectomy for achieving functional independence at 90 days among patients with large vessel occlusion stroke.\n\n\nDesign, Setting, and Participants\nMulticenter, randomized, noninferiority trial conducted at 33 stroke centers in China. Patients (n = 234) were 18 years or older with proximal anterior circulation intracranial occlusion strokes within 4.5 hours from symptoms onset and eligible for intravenous thrombolysis. Enrollment took place from May 20, 2018, to May 2, 2020. Patients were enrolled and followed up for 90 days (final follow-up was July 22, 2020).\n\n\nInterventions\nA total of 116 patients were randomized to the endovascular thrombectomy alone group and 118 patients to combined intravenous thrombolysis and endovascular thrombectomy group.\n\n\nMain Outcomes and Measures\nThe primary end point was the proportion of patients achieving functional independence at 90 days (defined as score 0-2 on the modified Rankin Scale; range, 0 [no symptoms] to 6 [death]). The noninferiority margin was -10%. Safety outcomes included the incidence of symptomatic intracerebral hemorrhage within 48 hours and 90-day mortality.\n\n\nResults\nThe trial was stopped early because of efficacy when 234 of a planned 970 patients had undergone randomization. All 234 patients who were randomized (mean age, 68 years; 102 women [43.6%]) completed the trial. At the 90-day follow-up, 63 patients (54.3%) in the endovascular thrombectomy alone group vs 55 (46.6%) in the combined treatment group achieved functional independence at the 90-day follow-up (difference, 7.7%, 1-sided 97.5% CI, -5.1% to ∞)P for noninferiority = .003). No significant between-group differences were detected in symptomatic intracerebral hemorrhage (6.1% vs 6.8%; difference, -0.8%; 95% CI, -7.1% to 5.6%) and 90-day mortality (17.2% vs 17.8%; difference, -0.5%; 95% CI, -10.3% to 9.2%).\n\n\nConclusions and Relevance\nAmong patients with ischemic stroke due to proximal anterior circulation occlusion within 4.5 hours from onset, endovascular treatment alone, compared with intravenous alteplase plus endovascular treatment, met the prespecified statistical threshold for noninferiority for the outcome of 90-day functional independence. These findings should be interpreted in the context of the clinical acceptability of the selected noninferiority threshold.\n\n\nTrial Registration\nChinese Clinical Trial Registry: ChiCTR-IOR-17013568.",
    "citationCount": 435,
    "pdf_filename": "2021_Effect_of_Endovascular_Treatment_Alone_v_b608db98.pdf"
  },
  "0704e6aa96836df49eb7d587eb74ba244262c7d2": {
    "paperId": "0704e6aa96836df49eb7d587eb74ba244262c7d2",
    "title": "Active Site Engineering in Porous Electrocatalysts",
    "year": 2020,
    "authors": "Hui Chen, Xiao Liang, Yipu Liu, X. Ai, Tewodros Asefa",
    "abstract": "Electrocatalysis is at the center of many sustainable energy conversion technologies that are being developed to reduce the dependence on fossil fuels. The past decade has witnessed significant progresses in the exploitation of advanced electrocatalysts for diverse electrochemical reactions involved in electrolyzers and fuel cells, such as the hydrogen evolution reaction (HER), the oxygen reduction reaction (ORR), the CO2 reduction reaction (CO2RR), the nitrogen reduction reaction (NRR), and the oxygen evolution reaction (OER). Herein, the recent research advances made in porous electrocatalysts for these five important reactions are reviewed. In the discussions, an attempt is made to highlight the advantages of porous electrocatalysts in multiobjective optimization of surface active sites including not only their density and accessibility but also their intrinsic activity. First, the current knowledge about electrocatalytic active sites is briefly summarized. Then, the electrocatalytic mechanisms of the five above‐mentioned reactions (HER, ORR, CO2RR, NRR, and OER), the current challenges faced by these reactions, and the recent efforts to meet these challenges using porous electrocatalysts are examined. Finally, the future research directions on porous electrocatalysts including synthetic strategies leading to these materials, insights into their active sites, and the standardized tests and the performance requirements involved are discussed.",
    "citationCount": 406,
    "pdf_filename": "2020_Active_Site_Engineering_in_Porous_Electr_0704e6aa.pdf"
  },
  "2950b480a1df0d884506b66c5a1353cbbd150712": {
    "paperId": "2950b480a1df0d884506b66c5a1353cbbd150712",
    "title": "Pulmonary function and radiological features 4 months after COVID-19: first results from the national prospective observational Swiss COVID-19 lung study",
    "year": 2021,
    "authors": "S. Guler, L. Ebner, Catherine Aubry-Beigelman, P. Bridevaux, M. Brutsche",
    "abstract": "Background The infectious coronavirus disease 2019 (COVID-19) pandemic is an ongoing global healthcare challenge. Up to one-third of hospitalised patients develop severe pulmonary complications and acute respiratory distress syndrome. Pulmonary outcomes following COVID-19 are unknown. Methods The Swiss COVID-19 lung study is a multicentre prospective cohort investigating pulmonary sequelae of COVID-19. We report on initial follow-up 4 months after mild/moderate or severe/critical COVID-19 according to the World Health Organization severity classification. Results 113 COVID-19 survivors were included (mild/moderate n=47, severe/critical n=66). We confirmed several comorbidities as risk factors for severe/critical disease. Severe/critical disease was associated with impaired pulmonary function, i.e. diffusing capacity of the lung for carbon monoxide (DLCO) % predicted, reduced 6-min walk distance (6MWD) and exercise-induced oxygen desaturation. After adjustment for potential confounding by age, sex and body mass index (BMI), patients after severe/critical COVID-19 had a DLCO 20.9% pred (95% CI 12.4–29.4% pred, p=0.01) lower at follow-up. DLCO % pred was the strongest independent factor associated with previous severe/critical disease when age, sex, BMI, 6MWD and minimal peripheral oxygen saturation at exercise were included in the multivariable model (adjusted odds ratio per 10% predicted 0.59, 95% CI 0. 37–0.87; p=0.01). Mosaic hypoattenuation on chest computed tomography at follow-up was significantly associated with previous severe/critical COVID-19 including adjustment for age and sex (adjusted OR 11.7, 95% CI 1.7–239; p=0.03). Conclusions 4 months after severe acute respiratory syndrome coronavirus 2 infection, severe/critical COVID-19 was associated with significant functional and radiological abnormalities, potentially due to small-airway and lung parenchymal disease. A systematic follow-up for survivors needs to be evaluated to optimise care for patients recovering from COVID-19. COVID-19 pulmonary sequelae are unknown. The Swiss COVID-19 lung study reports on initial follow-up findings. Severe or critical COVID-19 was associated with significant functional impairment and radiological abnormalities after 4 months. https://bit.ly/34sNVvi",
    "citationCount": 357,
    "pdf_filename": "2021_Pulmonary_function_and_radiological_feat_2950b480.pdf"
  },
  "ea05c9025b4ac95dd1dc3bf86ea0394198170b0c": {
    "paperId": "ea05c9025b4ac95dd1dc3bf86ea0394198170b0c",
    "title": "IoT for Smart Cities: Machine Learning Approaches in Smart Healthcare - A Review",
    "year": 2021,
    "authors": "Taher M. Ghazal, M Zahid Hasan, M. Alshurideh, Haitham M. Alzoubi, Munir Ahmad",
    "abstract": "Smart city is a collective term for technologies and concepts that are directed toward making cities efficient, technologically more advanced, greener and more socially inclusive. These concepts include technical, economic and social innovations. This term has been tossed around by various actors in politics, business, administration and urban planning since the 2000s to establish tech-based changes and innovations in urban areas. The idea of the smart city is used in conjunction with the utilization of digital technologies and at the same time represents a reaction to the economic, social and political challenges that post-industrial societies are confronted with at the start of the new millennium. The key focus is on dealing with challenges faced by urban society, such as environmental pollution, demographic change, population growth, healthcare, the financial crisis or scarcity of resources. In a broader sense, the term also includes non-technical innovations that make urban life more sustainable. So far, the idea of using IoT-based sensor networks for healthcare applications is a promising one with the potential of minimizing inefficiencies in the existing infrastructure. A machine learning approach is key to successful implementation of the IoT-powered wireless sensor networks for this purpose since there is large amount of data to be handled intelligently. Throughout this paper, it will be discussed in detail how AI-powered IoT and WSNs are applied in the healthcare sector. This research will be a baseline study for understanding the role of the IoT in smart cities, in particular in the healthcare sector, for future research works.",
    "citationCount": 414,
    "pdf_filename": "2021_IoT_for_Smart_Cities__Machine_Learning_A_ea05c902.pdf"
  },
  "486877c60b3b1854c7a10767f6a4116901d010fc": {
    "paperId": "486877c60b3b1854c7a10767f6a4116901d010fc",
    "title": "Performance of the ATLAS muon triggers in Run 2",
    "year": 2020,
    "authors": "G. Aad, B. Abbott, D. Abbott, A. A. Abud, K. Abeling",
    "abstract": "The performance of the ATLAS muon trigger system is evaluated with proton-proton ($pp$) and heavy-ion (HI) collision data collected in Run 2 during 2015-2018 at the Large Hadron Collider. It is primarily evaluated using events containing a pair of muons from the decay of $Z$ bosons to cover the intermediate momentum range between 25 GeV and 100 GeV. Overall, the efficiency of the single-muon triggers is about 68 % in the barrel region and 85% in the endcap region. The $p_{\\text{T}}$ range for efficiency determination is extended by using muons from decays of $J/\\psi$ mesons, $W$ bosons, and top quarks. The performance in HI collision data is measured and shows good agreement with the results obtained in $pp$ collisions. The muon trigger shows uniform and stable performance in good agreement with the prediction of a detailed simulation. Dedicated multi-muon triggers with kinematic selections provide the backbone to beauty, quarkonia, and low-mass physics studies. The design, evolution and performance of these triggers are discussed in detail.",
    "citationCount": 322,
    "pdf_filename": "2020_Performance_of_the_ATLAS_muon_triggers_i_486877c6.pdf"
  },
  "0cfdd655100055f234fd23ebecd915504b8e00e3": {
    "paperId": "0cfdd655100055f234fd23ebecd915504b8e00e3",
    "title": "Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System",
    "year": 2023,
    "authors": "Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang",
    "abstract": "Large language models (LLMs) have demonstrated their significant potential to be applied for addressing various application tasks. However, traditional recommender systems continue to face great challenges such as poor interactivity and explainability, which actually also hinder their broad deployment in real-world systems. To address these limitations, this paper proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender System) that innovatively augments LLMs for building conversational recommender systems by converting user profiles and historical interactions into prompts. Chat-Rec is demonstrated to be effective in learning user preferences and establishing connections between users and products through in-context learning, which also makes the recommendation process more interactive and explainable. What's more, within the Chat-Rec framework, user's preferences can transfer to different products for cross-domain recommendations, and prompt-based injection of information into LLMs can also handle the cold-start scenarios with new items. In our experiments, Chat-Rec effectively improve the results of top-k recommendations and performs better in zero-shot rating prediction task. Chat-Rec offers a novel approach to improving recommender systems and presents new practical scenarios for the implementation of AIGC (AI generated content) in recommender system studies.",
    "citationCount": 383,
    "pdf_filename": "2023_Chat_REC__Towards_Interactive_and_Explai_0cfdd655.pdf"
  },
  "6c2e438068e101d31af55add9f6ac6cac7159bc8": {
    "paperId": "6c2e438068e101d31af55add9f6ac6cac7159bc8",
    "title": "Practical and ethical challenges of large language models in education: A systematic scoping review",
    "year": 2023,
    "authors": "Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martínez Maldonado",
    "abstract": "Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs‐based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer‐reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state‐of‐the‐art models (eg, GPT‐3/4), embracing the initiative of open‐sourcing models/systems, and adopting a human‐centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.\nWhat is currently known about this topic\n\nGenerating and analysing text‐based content are time‐consuming and laborious tasks.\nLarge language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.\nLarge language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.\nWhat this paper adds\n\nA comprehensive list of different educational tasks that could potentially benefit from LLMs‐based innovations through automation.\nA structured assessment of the practicality and ethicality of existing LLMs‐based innovations from seven important aspects using established frameworks.\nThree recommendations that could potentially support future studies to develop LLMs‐based innovations that are practical and ethical to implement in authentic educational contexts.\nImplications for practice and/or policy\n\nUpdating existing innovations with state‐of‐the‐art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.\nThe reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.\nAdopting a human‐centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.\n\n",
    "citationCount": 452,
    "pdf_filename": "2023_Practical_and_ethical_challenges_of_larg_6c2e4380.pdf"
  },
  "281a7a99c16ce8f53bfbfb7aeb460dbd28648d28": {
    "paperId": "281a7a99c16ce8f53bfbfb7aeb460dbd28648d28",
    "title": "Toxicity in ChatGPT: Analyzing Persona-assigned Language Models",
    "year": 2023,
    "authors": "A. Deshpande, Vishvak Murahari, Tanmay Rajpurohit, A. Kalyan, Karthik Narasimhan",
    "abstract": "Large language models (LLMs) have shown incredible capabilities and transcended the natural language processing (NLP) community, with adoption throughout many services like healthcare, therapy, education, and customer service. Since users include people with critical information needs like students or patients engaging with chatbots, the safety of these systems is of prime importance. Therefore, a clear understanding of the capabilities and limitations of LLMs is necessary. To this end, we systematically evaluate toxicity in over half a million generations of ChatGPT, a popular dialogue-based LLM. We find that setting the system parameter of ChatGPT by assigning it a persona, say that of the boxer Muhammad Ali, significantly increases the toxicity of generations. Depending on the persona assigned to ChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. This may be potentially defamatory to the persona and harmful to an unsuspecting user. Furthermore, we find concerning patterns where specific entities (e.g., certain races) are targeted more than others (3x more) irrespective of the assigned persona, that reflect inherent discriminatory biases in the model. We hope that our findings inspire the broader AI community to rethink the efficacy of current safety guardrails and develop better techniques that lead to robust, safe, and trustworthy AI systems.",
    "citationCount": 442,
    "pdf_filename": "2023_Toxicity_in_ChatGPT__Analyzing_Persona_a_281a7a99.pdf"
  },
  "8822357efe500caded16e603d21239be3a39547c": {
    "paperId": "8822357efe500caded16e603d21239be3a39547c",
    "title": "ChatGPT: The End of Online Exam Integrity?",
    "year": 2022,
    "authors": "Teo Sušnjak",
    "abstract": "This study addresses the significant challenge posed by the use of Large Language Models (LLMs) such as ChatGPT on the integrity of online examinations, focusing on how these models can undermine academic honesty by demonstrating their latent and advanced reasoning capabilities. An iterative self-reflective strategy was developed for invoking critical thinking and higher-order reasoning in LLMs when responding to complex multimodal exam questions involving both visual and textual data. The proposed strategy was demonstrated and evaluated on real exam questions by subject experts and the performance of ChatGPT (GPT-4) with vision was estimated on an additional dataset of 600 text descriptions of multimodal exam questions. The results indicate that the proposed self-reflective strategy can invoke latent multi-hop reasoning capabilities within LLMs, effectively steering them towards correct answers by integrating critical thinking from each modality into the final response. Meanwhile, ChatGPT demonstrated considerable proficiency in being able to answer multimodal exam questions across 12 subjects. These findings challenge prior assertions about the limitations of LLMs in multimodal reasoning and emphasise the need for robust online exam security measures such as advanced proctoring systems and more sophisticated multimodal exam questions to mitigate potential academic misconduct enabled by AI technologies.",
    "citationCount": 470,
    "pdf_filename": "2022_ChatGPT__The_End_of_Online_Exam_Integrit_8822357e.pdf"
  },
  "49584dc597366e0e991827d1d7496863a3ab327a": {
    "paperId": "49584dc597366e0e991827d1d7496863a3ab327a",
    "title": "Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and Research Challenges",
    "year": 2022,
    "authors": "Michele Polese, Leonardo Bonati, Salvatore D’oro, S. Basagni, T. Melodia",
    "abstract": "The Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance specifications are poised to revolutionize the telecom ecosystem. O-RAN promotes virtualized RANs where disaggregated components are connected via open interfaces and optimized by intelligent controllers. The result is a new paradigm for the RAN design, deployment, and operations: O-RAN networks can be built with multi-vendor, interoperable components, and can be programmatically optimized through a centralized abstraction layer and data-driven closed-loop control. Therefore, understanding O-RAN, its architecture, its interfaces, and workflows is key for researchers and practitioners in the wireless community. In this article, we present the first detailed tutorial on O-RAN. We also discuss the main research challenges and review early research results. We provide a deep dive of the O-RAN specifications, describing its architecture, design principles, and the O-RAN interfaces. We then describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to effectively control and manage 3GPP-defined RANs. Based on this, we discuss innovations and challenges of O-RAN networks, including the Artificial Intelligence (AI) and Machine Learning (ML) workflows that the architecture and interfaces enable, security, and standardization issues. Finally, we review experimental research platforms that can be used to design and test O-RAN networks, along with recent research results, and we outline future directions for O-RAN development.",
    "citationCount": 451,
    "pdf_filename": "2022_Understanding_O_RAN__Architecture__Inter_49584dc5.pdf"
  },
  "29acc890e521f7a6415666ab9eb3432c49b4587a": {
    "paperId": "29acc890e521f7a6415666ab9eb3432c49b4587a",
    "title": "Self-critiquing models for assisting human evaluators",
    "year": 2022,
    "authors": "W. Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Ouyang Long",
    "abstract": "We fine-tune large language models to write natural language critiques (natural language critical comments) using behavioral cloning. On a topic-based summarization task, critiques written by our models help humans find flaws in summaries that they would have otherwise missed. Our models help find naturally occurring flaws in both model and human written summaries, and intentional flaws in summaries written by humans to be deliberately misleading. We study scaling properties of critiquing with both topic-based summarization and synthetic tasks. Larger models write more helpful critiques, and on most tasks, are better at self-critiquing, despite having harder-to-critique outputs. Larger models can also integrate their own selfcritiques as feedback, refining their own summaries into better ones. Finally, we motivate and introduce a framework for comparing critiquing ability to generation and discrimination ability. Our measurements suggest that even large models may still have relevant knowledge they cannot or do not articulate as critiques. These results are a proof of concept for using AI-assisted human feedback to scale the supervision of machine learning systems to tasks that are difficult for humans to evaluate directly. We release our training datasets, as well as samples from our critique assistance experiments.",
    "citationCount": 352,
    "pdf_filename": "2022_Self_critiquing_models_for_assisting_hum_29acc890.pdf"
  },
  "dcd32548d72640637c447e42ef4d7d468c95f177": {
    "paperId": "dcd32548d72640637c447e42ef4d7d468c95f177",
    "title": "A Normalized Gaussian Wasserstein Distance for Tiny Object Detection",
    "year": 2021,
    "authors": "Jinwang Wang, Chang Xu, Wen Yang, Lei Yu",
    "abstract": "Detecting tiny objects is a very challenging problem since a tiny object only contains a few pixels in size. We demonstrate that state-of-the-art detectors do not produce satisfactory results on tiny objects due to the lack of appearance information. Our key observation is that Intersection over Union (IoU) based metrics such as IoU itself and its extensions are very sensitive to the location deviation of the tiny objects, and drastically deteriorate the detection performance when used in anchor-based detectors. To alleviate this, we propose a new evaluation metric using Wasserstein distance for tiny object detection. Specifically, we first model the bounding boxes as 2D Gaussian distributions and then propose a new metric dubbed Normalized Wasserstein Distance (NWD) to compute the similarity between them by their corresponding Gaussian distributions. The proposed NWD metric can be easily embedded into the assignment, non-maximum suppression, and loss function of any anchor-based detector to replace the commonly used IoU metric. We evaluate our metric on a new dataset for tiny object detection (AI-TOD) in which the average object size is much smaller than existing object detection datasets. Extensive experiments show that, when equipped with NWD metric, our approach yields performance that is 6.7 AP points higher than a standard fine-tuning baseline, and 6.0 AP points higher than state-of-the-art competitors. Codes are available at: https://github.com/jwwangchn/NWD.",
    "citationCount": 454,
    "pdf_filename": "2021_A_Normalized_Gaussian_Wasserstein_Distan_dcd32548.pdf"
  },
  "4fd13f5ff417fcdd44f530006c7391c5d88877dd": {
    "paperId": "4fd13f5ff417fcdd44f530006c7391c5d88877dd",
    "title": "Intelligent Systems for Engineers and Scientists",
    "year": 2021,
    "authors": "A. Hopgood",
    "abstract": "INTRODUCTION Intelligent Systems Knowledge-Based Systems The Knowledge Base Deduction, Abduction, and Induction The Inference Engine Declarative and Procedural Programming Expert Systems Knowledge Acquisition Search Computational Intelligence Integration with other Software RULE-BASED SYSTEMS Rules and Facts A Rule-Based System for Boiler Control Rule Examination and Rule Firing Maintaining Consistency The Closed-World Assumption Use of Variables within Rules Forward-Chaining Conflict Resolution Backward-Chaining A Hybrid Strategy Explanation Facilities DEALING WITH UNCERTAINTY Sources of Uncertainty Bayesian Updating Certainty Theory Fuzzy Logic Other Techniques OBJECT-ORIENTED SYSTEMS Objects and Frames An Illustrative Example Introducing OOP Data Abstraction Inheritance Encapsulation Unified Modeling Language (UML) Dynamic (or late) Binding Message Passing and Function Calls Type Checking Further Aspects of OOP Frame-Based Systems INTELLIGENT AGENTS Characteristics of an Intelligent Agent Agents and Objects Agent Architectures Multiagent Systems SYMBOLIC LEARNING Introduction Learning by Induction Case-Based Reasoning OPTIMIZATION ALGORITHMS Optimization The Search Space Searching the Search Space Hill-Climbing and Gradient Descent Algorithms Simulated Annealing Genetic Algorithms NEURAL NETWORKS Introduction Neural Network Applications Nodes and Interconnections Single and Multilayer Perceptrons The Hopfield Network MAXNET The Hamming Network Adaptive Resonance Theory (ART) Networks Kohonen Self-Organizing Networks Radial Basis Function Networks HYBRID SYSTEMS Convergence of Techniques Blackboard Systems Genetic-Fuzzy Systems Neuro-Fuzzy Systems Genetic Neural Systems Clarifying and Verifying Neural Networks Learning Classifier Systems TOOLS AND LANGUAGES A Range of Intelligent Systems Tools Expert System Shells Toolkits and Libraries Artificial Intelligence Languages Lisp Prolog Comparison of AI Languages SYSTEMS FOR INTERPRETATION AND DIAGNOSIS Introduction Deduction and Abduction for Diagnosis Depth of Knowledge Model-Based Reasoning Case Study: A Blackboard System for Interpreting Ultrasonic Images SYSTEMS FOR DESIGN AND SELECTION The Design Process Design as a Search Problem Computer Aided Design The Product Design Specification (PDS) Conceptual Design Constraint Propagation and Truth Maintenance Case Study: The Design of a Lightweight Beam Design as a Selection Exercise Failure Mode and Effects Analysis (FMEA) SYSTEMS FOR PLANNING Introduction Classical Planning Systems STRIPS Considering the Side Effects of Actions Hierarchical Planning Postponement of Commitment Job-Shop Scheduling Constraint-Based Analysis Replanning and Reactive Planning SYSTEMS FOR CONTROL Introduction Low-Level Control Requirements of High-Level (Supervisory) Control Blackboard Maintenance Time-Constrained Reasoning Fuzzy Control The BOXES Controller Neural Network Controllers Statistical Process Control (SPC) CONCLUDING REMARKS Benefits Information Trends INDEX",
    "citationCount": 382,
    "pdf_filename": "2021_Intelligent_Systems_for_Engineers_and_Sc_4fd13f5f.pdf"
  },
  "0808f356856bf8db3f5f24645dadc8e169fd14d2": {
    "paperId": "0808f356856bf8db3f5f24645dadc8e169fd14d2",
    "title": "GRAB: A Dataset of Whole-Body Human Grasping of Objects",
    "year": 2020,
    "authors": "Omid Taheri, N. Ghorbani, Michael J. Black, Dimitrios Tzionas",
    "abstract": "Training computers to understand, model, and synthesize human grasping requires a rich dataset containing complex 3D object shapes, detailed contact information, hand pose and shape, and the 3D body motion over time. While \"grasping\" is commonly thought of as a single hand stably lifting an object, we capture the motion of the entire body and adopt the generalized notion of \"whole-body grasps\". Thus, we collect a new dataset, called GRAB (GRasping Actions with Bodies), of whole-body grasps, containing full 3D shape and pose sequences of 10 subjects interacting with 51 everyday objects of varying shape and size. Given MoCap markers, we fit the full 3D body shape and pose, including the articulated face and hands, as well as the 3D object pose. This gives detailed 3D meshes over time, from which we compute contact between the body and object. This is a unique dataset, that goes well beyond existing ones for modeling and understanding how humans grasp and manipulate objects, how their full body is involved, and how interaction varies with the task. We illustrate the practical value of GRAB with an example application; we train GrabNet, a conditional generative network, to predict 3D hand grasps for unseen 3D object shapes. The dataset and code are available for research purposes at this https URL.",
    "citationCount": 452,
    "pdf_filename": "2020_GRAB__A_Dataset_of_Whole_Body_Human_Gras_0808f356.pdf"
  },
  "267f1de5ff863ab03f8c48c7ac3df1d422de7c3b": {
    "paperId": "267f1de5ff863ab03f8c48c7ac3df1d422de7c3b",
    "title": "Multimodal datasets: misogyny, pornography, and malignant stereotypes",
    "year": 2021,
    "authors": "Abeba Birhane, Vinay Uday Prabhu, Emmanuel Kahembwe",
    "abstract": "We have now entered the era of trillion parameter machine learning models trained on billion-sized datasets scraped from the internet. The rise of these gargantuan datasets has given rise to formidable bodies of critical work that has called for caution while generating these large datasets. These address concerns surrounding the dubious curation practices used to generate these datasets, the sordid quality of alt-text data available on the world wide web, the problematic content of the CommonCrawl dataset often used as a source for training large language models, and the entrenched biases in large-scale visio-linguistic models (such as OpenAI's CLIP model) trained on opaque datasets (WebImageText). In the backdrop of these specific calls of caution, we examine the recently released LAION-400M dataset, which is a CLIP-filtered dataset of Image-Alt-text pairs parsed from the Common-Crawl dataset. We found that the dataset contains, troublesome and explicit images and text pairs of rape, pornography, malign stereotypes, racist and ethnic slurs, and other extremely problematic content. We outline numerous implications, concerns and downstream harms regarding the current state of large scale datasets while raising open questions for various stakeholders including the AI community, regulators, policy makers and data subjects.",
    "citationCount": 428,
    "pdf_filename": "2021_Multimodal_datasets__misogyny__pornograp_267f1de5.pdf"
  },
  "80d3f14c95a1c187b5ba17b3a326a611874a3996": {
    "paperId": "80d3f14c95a1c187b5ba17b3a326a611874a3996",
    "title": "Computational bioacoustics with deep learning: a review and roadmap",
    "year": 2021,
    "authors": "D. Stowell",
    "abstract": "Animal vocalisations and natural soundscapes are fascinating objects of study, and contain valuable evidence about animal behaviours, populations and ecosystems. They are studied in bioacoustics and ecoacoustics, with signal processing and analysis an important component. Computational bioacoustics has accelerated in recent decades due to the growth of affordable digital sound recording devices, and to huge progress in informatics such as big data, signal processing and machine learning. Methods are inherited from the wider field of deep learning, including speech and image processing. However, the tasks, demands and data characteristics are often different from those addressed in speech or music analysis. There remain unsolved problems, and tasks for which evidence is surely present in many acoustic signals, but not yet realised. In this paper I perform a review of the state of the art in deep learning for computational bioacoustics, aiming to clarify key concepts and identify and analyse knowledge gaps. Based on this, I offer a subjective but principled roadmap for computational bioacoustics with deep learning: topics that the community should aim to address, in order to make the most of future developments in AI and informatics, and to use audio data in answering zoological and ecological questions.",
    "citationCount": 327,
    "pdf_filename": "2021_Computational_bioacoustics_with_deep_lea_80d3f14c.pdf"
  },
  "31d20462d35059502ffeb13e1afbba11a81c7d41": {
    "paperId": "31d20462d35059502ffeb13e1afbba11a81c7d41",
    "title": "SMIL: Multimodal Learning with Severely Missing Modality",
    "year": 2021,
    "authors": "Mengmeng Ma, Jian Ren, Long Zhao, S. Tulyakov, Cathy Wu",
    "abstract": "A common assumption in multimodal learning is the completeness of training data, i.e., full modalities are available in all training examples. Although there exists research endeavor in developing novel methods to tackle the incompleteness of testing data, e.g., modalities are partially missing in testing examples, few of them can handle incomplete training modalities. The problem becomes even more challenging if considering the case of severely missing, e.g., ninety percent of training examples may have incomplete modalities. For the first time in the literature, this paper formally studies multimodal learning with missing modality in terms of flexibility (missing modalities in training, testing, or both) and efficiency (most training data have incomplete modality). Technically, we propose a new method named SMIL that leverages Bayesian meta-learning in uniformly achieving both objectives. To validate our idea, we conduct a series of experiments on three popular benchmarks: MM-IMDb, CMU-MOSI, and avMNIST. The results prove the state-of-the-art performance of SMIL over existing methods and generative baselines including autoencoders and generative adversarial networks.",
    "citationCount": 334,
    "pdf_filename": "2021_SMIL__Multimodal_Learning_with_Severely__31d20462.pdf"
  },
  "fda2a8b03fb15a2d8b5c5aeb01d1c0b27f0b006b": {
    "paperId": "fda2a8b03fb15a2d8b5c5aeb01d1c0b27f0b006b",
    "title": "Top2Vec: Distributed Representations of Topics",
    "year": 2020,
    "authors": "D. Angelov",
    "abstract": "Topic modeling is used for discovering latent semantic structure, usually referred to as topics, in a large collection of documents. The most widely used methods are Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis. Despite their popularity they have several weaknesses. In order to achieve optimal results they often require the number of topics to be known, custom stop-word lists, stemming, and lemmatization. Additionally these methods rely on bag-of-words representation of documents which ignore the ordering and semantics of words. Distributed representations of documents and words have gained popularity due to their ability to capture semantics of words and documents. We present $\\texttt{top2vec}$, which leverages joint document and word semantic embedding to find $\\textit{topic vectors}$. This model does not require stop-word lists, stemming or lemmatization, and it automatically finds the number of topics. The resulting topic vectors are jointly embedded with the document and word vectors with distance between them representing semantic similarity. Our experiments demonstrate that $\\texttt{top2vec}$ finds topics which are significantly more informative and representative of the corpus trained on than probabilistic generative models.",
    "citationCount": 424,
    "pdf_filename": "2020_Top2Vec__Distributed_Representations_of__fda2a8b0.pdf"
  },
  "63b90ba84e6c881166085bf2e838a7fc84428904": {
    "paperId": "63b90ba84e6c881166085bf2e838a7fc84428904",
    "title": "Industrial Artificial Intelligence in Industry 4.0 - Systematic Review, Challenges and Outlook",
    "year": 2020,
    "authors": "Ricardo Silva Peres, Xiaodong Jia, J. Lee, K. Sun, A. Colombo",
    "abstract": "The advent of the Industry 4.0 initiative has made it so that manufacturing environments are becoming more and more dynamic, connected but also inherently more complex, with additional inter-dependencies, uncertainties and large volumes of data being generated. Recent advances in Industrial Artificial Intelligence have showcased the potential of this technology to assist manufacturers in tackling the challenges associated with this digital transformation of Cyber-Physical Systems, through its data-driven predictive analytics and capacity to assist decision-making in highly complex, non-linear and often multistage environments. However, the industrial adoption of such solutions is still relatively low beyond the experimental pilot stage, as real environments provide unique and difficult challenges for which organizations are still unprepared. The aim of this paper is thus two-fold. First, a systematic review of current Industrial Artificial Intelligence literature is presented, focusing on its application in real manufacturing environments to identify the main enabling technologies and core design principles. Then, a set of key challenges and opportunities to be addressed by future research efforts are formulated along with a conceptual framework to bridge the gap between research in this field and the manufacturing industry, with the goal of promoting industrial adoption through a successful transition towards a digitized and data-driven company-wide culture. This paper is among the first to provide a clear definition and holistic view of Industrial Artificial Intelligence in the Industry 4.0 landscape, identifying and analysing its fundamental building blocks and ongoing trends. Its findings are expected to assist and empower researchers and manufacturers alike to better understand the requirements and steps necessary for a successful transition into Industry 4.0 supported by AI, as well as the challenges that may arise during this process.",
    "citationCount": 358,
    "pdf_filename": "2020_Industrial_Artificial_Intelligence_in_In_63b90ba8.pdf"
  },
  "36f5c81e0e92057f73c136e8553119ab9e4ea613": {
    "paperId": "36f5c81e0e92057f73c136e8553119ab9e4ea613",
    "title": "VinDr-CXR: An open dataset of chest X-rays with radiologist’s annotations",
    "year": 2020,
    "authors": "H. Nguyen, K. Lam, Linh T. Le, Hieu Pham, Dat Q. Tran",
    "abstract": "Most of the existing chest X-ray datasets include labels from a list of findings without specifying their locations on the radiographs. This limits the development of machine learning algorithms for the detection and localization of chest abnormalities. In this work, we describe a dataset of more than 100,000 chest X-ray scans that were retrospectively collected from two major hospitals in Vietnam. Out of this raw data, we release 18,000 images that were manually annotated by a total of 17 experienced radiologists with 22 local labels of rectangles surrounding abnormalities and 6 global labels of suspected diseases. The released dataset is divided into a training set of 15,000 and a test set of 3,000. Each scan in the training set was independently labeled by 3 radiologists, while each scan in the test set was labeled by the consensus of 5 radiologists. We designed and built a labeling platform for DICOM images to facilitate these annotation procedures. All images are made publicly available in DICOM format along with the labels of both the training set and the test set. Measurement(s) diseases and abnormal findings from chest X-ray scans Technology Type(s) AI is used to detect diseases and abnormal findings Sample Characteristic - Location Vietnam Measurement(s) diseases and abnormal findings from chest X-ray scans Technology Type(s) AI is used to detect diseases and abnormal findings Sample Characteristic - Location Vietnam",
    "citationCount": 401,
    "pdf_filename": "2020_VinDr_CXR__An_open_dataset_of_chest_X_ra_36f5c81e.pdf"
  },
  "37e35e2257e927f9d77cb7e94936d76c70883409": {
    "paperId": "37e35e2257e927f9d77cb7e94936d76c70883409",
    "title": "Survey on Network Slicing for Internet of Things Realization in 5G Networks",
    "year": 2021,
    "authors": "Shalitha Wijethilaka, Madhusanka Liyanage",
    "abstract": "Internet of Things (IoT) is an emerging technology that makes people’s lives smart by conquering a plethora of diverse application and service areas. In near future, the fifth-generation (5G) wireless networks provide the connectivity for this IoT ecosystem. It has been carefully designed to facilitate the exponential growth in the IoT field. Network slicing is one of the key technologies in the 5G architecture that has the ability to divide the physical network into multiple logical networks (i.e., slices) with different network characteristics. Therefore, network slicing is also a key enabler of realisation of IoT in 5G. Network slicing can satisfy the various networking demands by heterogeneous IoT applications via dedicated slices. In this survey, we present a comprehensive analysis of the exploitation of network slicing in IoT realisation. We discuss network slicing utilisation in different IoT application scenarios, along with the technical challenges that can be solved via network slicing. Furthermore, integration challenges and open research problems related to the network slicing in the IoT realisation are also discussed in this paper. Finally, we discuss the role of other emerging technologies and concepts, such as blockchain and Artificial Intelligence/Machine Learning (AI/ML) in network slicing and IoT integration.",
    "citationCount": 319,
    "pdf_filename": "2021_Survey_on_Network_Slicing_for_Internet_o_37e35e22.pdf"
  },
  "685b27cf6dc891da649af035507b7b43b3b4b0b9": {
    "paperId": "685b27cf6dc891da649af035507b7b43b3b4b0b9",
    "title": "Dynamic Backdoor Attacks Against Machine Learning Models",
    "year": 2020,
    "authors": "A. Salem, Rui Wen, M. Backes, Shiqing Ma, Yang Zhang",
    "abstract": "Machine learning (ML) has made tremendous progress during the past decade and is being adopted in various critical real-world applications. However, recent research has shown that ML models are vulnerable to multiple security and privacy attacks. In particular, backdoor attacks against ML models have recently raised a lot of awareness. A successful backdoor attack can cause severe consequences, such as allowing an adversary to bypass critical authentication systems. Current backdooring techniques rely on adding static triggers (with fixed patterns and locations) on ML model inputs which are prone to detection by the current backdoor detection mechanisms. In this paper, we propose the first class of dynamic backdooring techniques against deep neural networks (DNN), namely Random Backdoor, Backdoor Generating Network (BaN), and conditional Backdoor Generating Network (c-BaN). Triggers generated by our techniques can have random patterns and locations, which reduce the efficacy of the current backdoor detection mechanisms. In particular, BaN and c-BaN based on a novel generative network are the first two schemes that algorithmically generate triggers. Moreover, c-BaN is the first conditional backdooring technique that given a target label, it can generate a target-specific trigger. Both BaN and c-BaN are essentially a general framework which renders the adversary the flexibility for further customizing backdoor attacks. We extensively evaluate our techniques on three benchmark datasets: MNIST, CelebA, and CIFAR-10. Our techniques achieve almost perfect attack performance on back-doored data with a negligible utility loss. We further show that our techniques can bypass current state-of-the-art defense mechanisms against backdoor attacks, including ABS, Februus, MNTD, Neural Cleanse, and STRIP.",
    "citationCount": 302,
    "pdf_filename": "2020_Dynamic_Backdoor_Attacks_Against_Machine_685b27cf.pdf"
  },
  "9f6034d02bf0766c021489bfe498488b0fd5eff5": {
    "paperId": "9f6034d02bf0766c021489bfe498488b0fd5eff5",
    "title": "Mapping the Landscape of Artificial Intelligence Applications against COVID-19",
    "year": 2020,
    "authors": "Joseph Aylett-Bullock, A. Luccioni, K. H. Pham, C. Lam, M. Luengo-Oroz",
    "abstract": "\n \n \nCOVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a pandemic by the World Health Organization, which has reported over 18 million confirmed cases as of August 5, 2020. In this review, we present an overview of recent studies using Machine Learning and, more broadly, Artificial Intelligence, to tackle many aspects of the COVID19 crisis. We have identified applications that address challenges posed by COVID-19 at different scales, including: molecular, by identifying new or existing drugs for treatment; clinical, by supporting diagnosis and evaluating prognosis based on medical imaging and non-invasive measures; and societal, by tracking both the epidemic and the accompanying infodemic using multiple data sources. We also review datasets, tools, and resources needed to facilitate Artificial Intelligence research, and discuss strategic considerations related to the operational implementation of multidisciplinary partnerships and open science. We highlight the need for international cooperation to maximize the potential of AI in this and future pandemics. \n \n \n",
    "citationCount": 414,
    "pdf_filename": "2020_Mapping_the_Landscape_of_Artificial_Inte_9f6034d0.pdf"
  },
  "3b09a37c82d96afe0634c604664263bd50c141e0": {
    "paperId": "3b09a37c82d96afe0634c604664263bd50c141e0",
    "title": "GUIDANCE FOR GENERATIVE AI IN EDUCATION AND RESEARCH\" FOR TEACHERS",
    "year": 2024,
    "authors": "S. Boonlue",
    "abstract": "From the book title is \"Guidance for Generative AI in Education and Research\" for teachers, or this book serves as part of the guidelines for using Generative AI (GenAI) in the fields of education and research. This book was written by W. Holmes and F. Miao in 2023. This book addresses the rapid emergence of publicly available Generative AI tools, with the release of new versions outpacing the establishment of national regulatory frameworks. The lack of national regulations on GenAI in most countries raises concerns about user data privacy and leaves educational institutions unprotected and largely unprepared to scrutinize these tools. UNESCO has issued the first global guidelines on GenAI in education, aiming to support countries in taking immediate action, formulating long-term policies, and developing human capacity to ensure that people can effectively use AI and enhance their work with Generative AI.",
    "citationCount": 290,
    "pdf_filename": "2024_GUIDANCE_FOR_GENERATIVE_AI_IN_EDUCATION__3b09a37c.pdf"
  },
  "9e0e253a7f71f6702f40b083080232989c482464": {
    "paperId": "9e0e253a7f71f6702f40b083080232989c482464",
    "title": "Can Generative AI improve social science?",
    "year": 2024,
    "authors": "Christopher A Bail",
    "abstract": "Generative AI that can produce realistic text, images, and other human-like outputs is currently transforming many different industries. Yet it is not yet known how such tools might influence social science research. I argue Generative AI has the potential to improve survey research, online experiments, automated content analyses, agent-based models, and other techniques commonly used to study human behavior. In the second section of this article, I discuss the many limitations of Generative AI. I examine how bias in the data used to train these tools can negatively impact social science research—as well as a range of other challenges related to ethics, replication, environmental impact, and the proliferation of low-quality research. I conclude by arguing that social scientists can address many of these limitations by creating open-source infrastructure for research on human behavior. Such infrastructure is not only necessary to ensure broad access to high-quality research tools, I argue, but also because the progress of AI will require deeper understanding of the social forces that guide human behavior.",
    "citationCount": 248,
    "pdf_filename": "2024_Can_Generative_AI_improve_social_science_9e0e253a.pdf"
  },
  "25361e9582996220625a1823d931b4ed5f5558d3": {
    "paperId": "25361e9582996220625a1823d931b4ed5f5558d3",
    "title": "Generative AI in healthcare: an implementation science informed translational path on application, integration and governance",
    "year": 2024,
    "authors": "S. Reddy",
    "abstract": "Artificial intelligence (AI), particularly generative AI, has emerged as a transformative tool in healthcare, with the potential to revolutionize clinical decision-making and improve health outcomes. Generative AI, capable of generating new data such as text and images, holds promise in enhancing patient care, revolutionizing disease diagnosis and expanding treatment options. However, the utility and impact of generative AI in healthcare remain poorly understood, with concerns around ethical and medico-legal implications, integration into healthcare service delivery and workforce utilisation. Also, there is not a clear pathway to implement and integrate generative AI in healthcare delivery. This article aims to provide a comprehensive overview of the use of generative AI in healthcare, focusing on the utility of the technology in healthcare and its translational application highlighting the need for careful planning, execution and management of expectations in adopting generative AI in clinical medicine. Key considerations include factors such as data privacy, security and the irreplaceable role of clinicians’ expertise. Frameworks like the technology acceptance model (TAM) and the Non-Adoption, Abandonment, Scale-up, Spread and Sustainability (NASSS) model are considered to promote responsible integration. These frameworks allow anticipating and proactively addressing barriers to adoption, facilitating stakeholder participation and responsibly transitioning care systems to harness generative AI’s potential. Generative AI has the potential to transform healthcare through automated systems, enhanced clinical decision-making and democratization of expertise with diagnostic support tools providing timely, personalized suggestions. Generative AI applications across billing, diagnosis, treatment and research can also make healthcare delivery more efficient, equitable and effective. However, integration of generative AI necessitates meticulous change management and risk mitigation strategies. Technological capabilities alone cannot shift complex care ecosystems overnight; rather, structured adoption programs grounded in implementation science are imperative. It is strongly argued in this article that generative AI can usher in tremendous healthcare progress, if introduced responsibly. Strategic adoption based on implementation science, incremental deployment and balanced messaging around opportunities versus limitations helps promote safe, ethical generative AI integration. Extensive real-world piloting and iteration aligned to clinical priorities should drive development. With conscientious governance centred on human wellbeing over technological novelty, generative AI can enhance accessibility, affordability and quality of care. As these models continue advancing rapidly, ongoing reassessment and transparent communication around their strengths and weaknesses remain vital to restoring trust, realizing positive potential and, most importantly, improving patient outcomes.",
    "citationCount": 262,
    "pdf_filename": "2024_Generative_AI_in_healthcare__an_implemen_25361e95.pdf"
  },
  "15074299f9b3cfd1230f29fca3a26236dc8681b8": {
    "paperId": "15074299f9b3cfd1230f29fca3a26236dc8681b8",
    "title": "A multimodal generative AI copilot for human pathology",
    "year": 2024,
    "authors": "Ming Y. Lu, Bowen Chen, Drew F. K. Williamson, Richard J. Chen, Melissa Zhao",
    "abstract": "Computational pathology1,2 has witnessed considerable progress in the development of both task-specific predictive models and task-agnostic self-supervised vision encoders3,4. However, despite the explosive growth of generative artificial intelligence (AI), there have been few studies on building general-purpose multimodal AI assistants and copilots5 tailored to pathology. Here we present PathChat, a vision-language generalist AI assistant for human pathology. We built PathChat by adapting a foundational vision encoder for pathology, combining it with a pretrained large language model and fine-tuning the whole system on over 456,000 diverse visual-language instructions consisting of 999,202 question and answer turns. We compare PathChat with several multimodal vision-language AI assistants and GPT-4V, which powers the commercially available multimodal general-purpose AI assistant ChatGPT-4 (ref. 6). PathChat achieved state-of-the-art performance on multiple-choice diagnostic questions from cases with diverse tissue origins and disease models. Furthermore, using open-ended questions and human expert evaluation, we found that overall PathChat produced more accurate and pathologist-preferable responses to diverse queries related to pathology. As an interactive vision-language AI copilot that can flexibly handle both visual and natural language inputs, PathChat may potentially find impactful applications in pathology education, research and human-in-the-loop clinical decision-making. PathChat, a multimodal generative AI copilot for human pathology, has been trained on a large dataset of visual-language instructions to interactively assist users with diverse pathology tasks.",
    "citationCount": 292,
    "pdf_filename": "2024_A_multimodal_generative_AI_copilot_for_h_15074299.pdf"
  },
  "a00b966f5e335cb35f3e7537fad56f6b6f507478": {
    "paperId": "a00b966f5e335cb35f3e7537fad56f6b6f507478",
    "title": "Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students",
    "year": 2024,
    "authors": "Muhammad Abbas, Farooq Ahmed Jam, Tariq Iqbal Khan",
    "abstract": "While the discussion on generative artificial intelligence, such as ChatGPT, is making waves in academia and the popular press, there is a need for more insight into the use of ChatGPT among students and the potential harmful or beneficial consequences associated with its usage. Using samples from two studies, the current research examined the causes and consequences of ChatGPT usage among university students. Study 1 developed and validated an eight-item scale to measure ChatGPT usage by conducting a survey among university students (N = 165). Study 2 used a three-wave time-lagged design to collect data from university students (N = 494) to further validate the scale and test the study’s hypotheses. Study 2 also examined the effects of academic workload, academic time pressure, sensitivity to rewards, and sensitivity to quality on ChatGPT usage. Study 2 further examined the effects of ChatGPT usage on students’ levels of procrastination, memory loss, and academic performance. Study 1 provided evidence for the validity and reliability of the ChatGPT usage scale. Furthermore, study 2 revealed that when students faced higher academic workload and time pressure, they were more likely to use ChatGPT. In contrast, students who were sensitive to rewards were less likely to use ChatGPT. Not surprisingly, use of ChatGPT was likely to develop tendencies for procrastination and memory loss and dampen the students’ academic performance. Finally, academic workload, time pressure, and sensitivity to rewards had indirect effects on students’ outcomes through ChatGPT usage.",
    "citationCount": 293,
    "pdf_filename": "2024_Is_it_harmful_or_helpful__Examining_the__a00b966f.pdf"
  },
  "1c2fc6f6e9f22e109144e1dd01097b20fc86d530": {
    "paperId": "1c2fc6f6e9f22e109144e1dd01097b20fc86d530",
    "title": "The potential of generative AI for personalized persuasion at scale",
    "year": 2024,
    "authors": "S. C. Matz, J. D. Teeny, S. Vaid, H. Peters, G. M. Harari",
    "abstract": "Matching the language or content of a message to the psychological profile of its recipient (known as “personalized persuasion”) is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public.",
    "citationCount": 207,
    "pdf_filename": "2024_The_potential_of_generative_AI_for_perso_1c2fc6f6.pdf"
  },
  "7a5b44ea10a51708e18786595c8d70b18950da11": {
    "paperId": "7a5b44ea10a51708e18786595c8d70b18950da11",
    "title": "FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios",
    "year": 2023,
    "authors": "Ethan Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng",
    "abstract": "The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .",
    "citationCount": 258,
    "pdf_filename": "2023_FacTool__Factuality_Detection_in_Generat_7a5b44ea.pdf"
  },
  "ddf46191262aeff970d8c0106fb935f5e5690ce8": {
    "paperId": "ddf46191262aeff970d8c0106fb935f5e5690ce8",
    "title": "Generative AI enhances individual creativity but reduces the collective diversity of novel content",
    "year": 2023,
    "authors": "Anil R. Doshi, Oliver P. Hauser",
    "abstract": "Creativity is core to being human. Generative artificial intelligence (AI)—including powerful large language models (LLMs)—holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on generative AI ideas. We study the causal impact of generative AI ideas on the production of short stories in an online experiment where some writers obtained story ideas from an LLM. We find that access to generative AI ideas causes stories to be evaluated as more creative, better written, and more enjoyable, especially among less creative writers. However, generative AI–enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity at the risk of losing collective novelty. This dynamic resembles a social dilemma: With generative AI, writers are individually better off, but collectively a narrower scope of novel content is produced. Our results have implications for researchers, policy-makers, and practitioners interested in bolstering creativity.",
    "citationCount": 289,
    "pdf_filename": "2023_Generative_AI_enhances_individual_creati_ddf46191.pdf"
  },
  "2d42566eebc5704743ed4d69c2e752d7cb73a005": {
    "paperId": "2d42566eebc5704743ed4d69c2e752d7cb73a005",
    "title": "The Robots Are Here: Navigating the Generative AI Revolution in Computing Education",
    "year": 2023,
    "authors": "J. Prather, Paul Denny, Juho Leinonen, Brett A. Becker, Ibrahim Albluwi",
    "abstract": "Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving. There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.",
    "citationCount": 284,
    "pdf_filename": "2023_The_Robots_Are_Here__Navigating_the_Gene_2d42566e.pdf"
  },
  "16cabd6f8d93f77e175f217865d7b515d3612cc1": {
    "paperId": "16cabd6f8d93f77e175f217865d7b515d3612cc1",
    "title": "TPACK in the age of ChatGPT and Generative AI",
    "year": 2023,
    "authors": "Punya Mishra, Melissa Warr, Rezwana Islam",
    "abstract": "Abstract The educational impact of Generative AI (GenAI) technologies, such as ChatGPT, has received significant attention. We use the TPACK framework to discuss the types of knowledge teachers require to effectively use GenAI tools. We highlight the qualities of GenAI that make it like other digital technologies (they are protean, opaque, and unstable) as well as qualities that make it revolutionary (namely, they are generative and social). We describe how these traits affect specific knowledge domains (TK, TPK, TCK, XK, and TPACK) and explore implications for educators. Finally, we argue for a more expansive description of Contextual Knowledge (XK), going beyond the immediate context to include considerations of how GenAI will change individuals, society and, through that, the broader educational context.",
    "citationCount": 242,
    "pdf_filename": "2023_TPACK_in_the_age_of_ChatGPT_and_Generati_16cabd6f.pdf"
  },
  "c4d96dfef7b67ea371354b416d1e458aa65f8177": {
    "paperId": "c4d96dfef7b67ea371354b416d1e458aa65f8177",
    "title": "Is ChatGPT Leading Generative AI? What is Beyond Expectations?",
    "year": 2023,
    "authors": "Ömer Aydın, Enis Karaarslan",
    "abstract": "Generative AI has the potential to change the way we do things. The chatbot is one of the most popular implementation areas. Even though companies like Google and Meta had chatbots, ChatGPT became popular as it was made publicly available. Although ChatGPT is still in the early stages of its development, it attracted the attention of people and capital groups. It has taken the public interest; people from different fields, ages, and education levels started using ChatGPT. There have been many trials with ChatGPT. It is possible to see a lot of news and shares on the Internet. The study aims to shed light on what is happening in the literature and get an insight into the user expectations of ChatGPT and Generative AI. We also give information about the competitors of ChatGPT, such as Google’s Bard AI, Claude, Meta’s Wit.ai and Tencent’s HunyuanAide. We describe technical and structural fundamentals and try to shed light on who will win the race. We also shared information about the GPT4 version of OpenAI's ChatGPT. We share the early stage due diligence and current situation analysis for all these points. We examine preprint papers and published articles. We also included striking posts on the LinkedIn platform and a compilation of various blogs and news. We also made use of ChatGPT in editing the content of these resources of this study. We can get an insight into the people's interests through their questions submitted to ChatGPT. We can also understand the capabilities of GPT3, GPT4 and also predict further enhancements.",
    "citationCount": 235,
    "pdf_filename": "2023_Is_ChatGPT_Leading_Generative_AI__What_i_c4d96dfe.pdf"
  },
  "bb60d51630a649535ed3d1bcb445524fbae6cf0b": {
    "paperId": "bb60d51630a649535ed3d1bcb445524fbae6cf0b",
    "title": "Generative AI in Medicine and Healthcare: Promises, Opportunities and Challenges",
    "year": 2023,
    "authors": "Peng Zhang, M. Boulos",
    "abstract": "Generative AI (artificial intelligence) refers to algorithms and models, such as OpenAI’s ChatGPT, that can be prompted to generate various types of content. In this narrative review, we present a selection of representative examples of generative AI applications in medicine and healthcare. We then briefly discuss some associated issues, such as trust, veracity, clinical safety and reliability, privacy, copyrights, ownership, and opportunities, e.g., AI-driven conversational user interfaces for friendlier human-computer interaction. We conclude that generative AI will play an increasingly important role in medicine and healthcare as it further evolves and gets better tailored to the unique settings and requirements of the medical domain and as the laws, policies and regulatory frameworks surrounding its use start taking shape.",
    "citationCount": 228,
    "pdf_filename": "2023_Generative_AI_in_Medicine_and_Healthcare_bb60d516.pdf"
  },
  "bdd325fa62eef7e8ba04e3694dc13554e9e06344": {
    "paperId": "bdd325fa62eef7e8ba04e3694dc13554e9e06344",
    "title": "ChatGPT and Generative AI: Possibilities for Its Contribution to Lesson Planning, Critical Thinking and Openness in Teacher Education",
    "year": 2023,
    "authors": "G. van den Berg, Elize du Plessis",
    "abstract": "Although artificial intelligence (AI) has been part of our lives for some time, the launch of the Generative Pretrained Transformer (ChatGPT) has given it renewed attention. While most of these debates are about higher education in general, this article focuses on schoolteacher education and teacher training. This research aimed to determine the contribution of generative AI tools such as ChatGPT in lesson planning, critical thinking and openness in education. The research used a qualitative approach and document analysis following an interpretative paradigm. The findings reveal that generative language models such as ChatGPT can provide specific materials and support mechanisms, such as lesson plans, to schoolteachers and student teachers. It also showed that ChatGPT has levelled the playing field by opening access to lesson plans to all teachers. However, to unleash their full potential for education, it is crucial to approach these models with caution and critically evaluate their limitations and potential biases, understanding that they are tools to support teaching and learning and do not replace teachers. The study’s contribution lies in ChatGPT-generated lesson plans’ implications and the enhancement of critical thinking for teacher education, and it also underscores the need for further research to explore best practices for integrating ChatGPT in lesson planning.",
    "citationCount": 230,
    "pdf_filename": "2023_ChatGPT_and_Generative_AI__Possibilities_bdd325fa.pdf"
  },
  "f8e77bd3d573d0daee0744443c65c40e3b5dc10f": {
    "paperId": "f8e77bd3d573d0daee0744443c65c40e3b5dc10f",
    "title": "Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services",
    "year": 2023,
    "authors": "Minrui Xu, Hongyang Du, Dusist Niyato, Jiawen Kang, Zehui Xiong",
    "abstract": "Artificial Intelligence-Generated Content (AIGC) is an automated method for generating, manipulating, and modifying valuable and diverse data using AI algorithms creatively. This survey paper focuses on the deployment of AIGC applications, e.g., ChatGPT and Dall-E, at mobile edge networks, namely mobile AIGC networks, that provide personalized and customized AIGC services in real time while maintaining user privacy. We begin by introducing the background and fundamentals of generative models and the lifecycle of AIGC services at mobile AIGC networks, which includes data collection, training, fine-tuning, inference, and product management. We then discuss the collaborative cloud-edge-mobile infrastructure and technologies required to support AIGC services and enable users to access AIGC at mobile edge networks. Furthermore, we explore AIGC-driven creative applications and use cases for mobile AIGC networks. Additionally, we discuss the implementation, security, and privacy challenges of deploying mobile AIGC networks. Finally, we highlight some future research directions and open issues for the full realization of mobile AIGC networks.",
    "citationCount": 279,
    "pdf_filename": "2023_Unleashing_the_Power_of_Edge_Cloud_Gener_f8e77bd3.pdf"
  },
  "e3bbf0950ba0bc31ba991fdbfbd75b25ca3241ed": {
    "paperId": "e3bbf0950ba0bc31ba991fdbfbd75b25ca3241ed",
    "title": "Exploring the Potential Impact of Artificial Intelligence (AI) on International Students in Higher Education: Generative AI, Chatbots, Analytics, and International Student Success",
    "year": 2023,
    "authors": "Ting Wang, Brady D. Lund, A. Marengo, A. Pagano, Nishith Reddy Mannuru",
    "abstract": "International students face unique challenges in pursuing higher education in a foreign country. To address these challenges and enhance their academic experience, higher education institutions are increasingly exploring the use of artificial intelligence (AI) applications. This research essay aims to investigate the impact of AI on the education of international students. Instead of a traditional literature review, it employs a research approach to examine the potential applications of AI and discuss associated concerns. The research paper explores various AI applications, such as personalized learning experiences, adaptive testing, predictive analytics, and chatbots for learning and research. By analyzing the role of AI in education for international students, this research paper sheds light on how AI can improve learning efficiency and provide customized educational support. Additionally, it identifies significant risks and limitations, including privacy concerns, cultural differences, language proficiency, and ethical implications, which must be effectively addressed. The findings contribute to a better understanding of the potential impact of AI on international students’ educational experiences and offer insights into the integration of AI into educational administration and learning processes.",
    "citationCount": 262,
    "pdf_filename": "2023_Exploring_the_Potential_Impact_of_Artifi_e3bbf095.pdf"
  },
  "be2d38e0233ee2ef94eb05ecfe6f8bb5cf328a36": {
    "paperId": "be2d38e0233ee2ef94eb05ecfe6f8bb5cf328a36",
    "title": "Computing Education in the Era of Generative AI",
    "year": 2023,
    "authors": "Paul Denny, J. Prather, Brett A. Becker, James Finnie-Ansley, Arto Hellas",
    "abstract": "Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.",
    "citationCount": 225,
    "pdf_filename": "2023_Computing_Education_in_the_Era_of_Genera_be2d38e0.pdf"
  },
  "76ebf56d6ebb833d8c8c4124f7b2f15771a4997c": {
    "paperId": "76ebf56d6ebb833d8c8c4124f7b2f15771a4997c",
    "title": "Investigating Explainability of Generative AI for Code through Scenario-based Design",
    "year": 2022,
    "authors": "Jiao Sun, Q. Liao, Michael J. Muller, Mayank Agarwal, Stephanie Houde",
    "abstract": "What does it mean for a generative AI model to be explainable? The emergent discipline of explainable AI (XAI) has made great strides in helping people understand discriminative models. Less attention has been paid to generative models that produce artifacts, rather than decisions, as output. Meanwhile, generative AI (GenAI) technologies are maturing and being applied to application domains such as software engineering. Using scenario-based design and question-driven XAI design approaches, we explore users’ explainability needs for GenAI in three software engineering use cases: natural language to code, code translation, and code auto-completion. We conducted 9 workshops with 43 software engineers in which real examples from state-of-the-art generative AI models were used to elicit users’ explainability needs. Drawing from prior work, we also propose 4 types of XAI features for GenAI for code and gathered additional design ideas from participants. Our work explores explainability needs for GenAI for code and demonstrates how human-centered approaches can drive the technical development of XAI in novel domains.",
    "citationCount": 201,
    "pdf_filename": "2022_Investigating_Explainability_of_Generati_76ebf56d.pdf"
  },
  "c042a6a2e71b715aad8c6c672963aa5ef9bdae59": {
    "paperId": "c042a6a2e71b715aad8c6c672963aa5ef9bdae59",
    "title": "Not quite eye to A.I.: student and teacher perspectives on the use of generative artificial intelligence in the writing process",
    "year": 2023,
    "authors": "A. Barrett, Austin Pack",
    "abstract": "Generative artificial intelligence (GenAI) can be used to author academic texts at a similar level to what humans are capable of, causing concern about its misuse in education. Addressing the role of GenAI in teaching and learning has become an urgent task. This study reports the results of a survey comparing educators’ (n = 68) and university students’ (n = 158) perceptions on the appropriate use of GenAI in the writing process. The survey included representations of user prompts and output from ChatGPT, a GenAI chatbot, for each of six tasks of the writing process (brainstorming, outlining, writing, revising, feedback, and evaluating). Survey respondents were asked to differentiate between various uses of GenAI for these tasks, which were divided between student and teacher use. Results indicate minor disagreement between students and teachers on acceptable use of GenAI tools in the writing process, as well as classroom and institutional-level lack of preparedness for GenAI. These results imply the need for explicit guidelines and teacher professional development on the use of GenAI in educational contexts. This study can contribute to evidence-based guidelines on the integration of GenAI in teaching and learning.",
    "citationCount": 217,
    "pdf_filename": "2023_Not_quite_eye_to_A_I___student_and_teach_c042a6a2.pdf"
  },
  "b30ce57128b672945b3e24f98aee63b2b3881ee0": {
    "paperId": "b30ce57128b672945b3e24f98aee63b2b3881ee0",
    "title": "Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design",
    "year": 2024,
    "authors": "Andrew Campbell, Jason Yim, R. Barzilay, Tom Rainforth, T. Jaakkola",
    "abstract": "Combining discrete and continuous data is an important capability for generative models. We present Discrete Flow Models (DFMs), a new flow-based model of discrete data that provides the missing link in enabling flow-based generative models to be applied to multimodal continuous and discrete data problems. Our key insight is that the discrete equivalent of continuous space flow matching can be realized using Continuous Time Markov Chains. DFMs benefit from a simple derivation that includes discrete diffusion models as a specific instance while allowing improved performance over existing diffusion-based approaches. We utilize our DFMs method to build a multimodal flow-based modeling framework. We apply this capability to the task of protein co-design, wherein we learn a model for jointly generating protein structure and sequence. Our approach achieves state-of-the-art co-design performance while allowing the same multimodal model to be used for flexible generation of the sequence or structure.",
    "citationCount": 208,
    "pdf_filename": "2024_Generative_Flows_on_Discrete_State_Space_b30ce571.pdf"
  },
  "5549dc3ceff07561d9fb59610c0f78c71617901a": {
    "paperId": "5549dc3ceff07561d9fb59610c0f78c71617901a",
    "title": "Generative Diffusion Prior for Unified Image Restoration and Enhancement",
    "year": 2023,
    "authors": "Ben Fei, Zhaoyang Lyu, Liang Pan, Junzhe Zhang, Weidong Yang",
    "abstract": "Existing image restoration methods mostly leverage the posterior distribution of natural images. However, they often assume known degradation and also require supervised training, which restricts their adaptation to complex real applications. In this work, we propose the Generative Diffusion Prior (GDP) to effectively model the posterior distributions in an unsupervised sampling manner. GDP utilizes a pre-train denoising diffusion generative model (DDPM) for solving linear inverse, non-linear, or blind problems. Specifically, GDP systematically explores a protocol of conditional guidance, which is verified more practical than the commonly used guidance way. Furthermore, GDP is strength at optimizing the parameters of degradation model during the denoising process, achieving blind image restoration. Besides, we devise hierarchical guidance and patch-based methods, enabling the GDP to generate images of arbitrary resolutions. Experimentally, we demonstrate GDP's versatility on several image datasets for linear problems, such as super-resolution, deblurring, inpainting, and colorization, as well as non-linear and blind issues, such as low-light enhancement and HDR image recovery. GDP outperforms the current leading unsupervised methods on the diverse benchmarks in reconstruction quality and perceptual quality. Moreover, GDP also generalizes well for natural images or synthesized images with arbitrary sizes from various tasks out of the distribution of the ImageNet training set. The project page is available at https://generativediffusionprior.github.io/",
    "citationCount": 260,
    "pdf_filename": "2023_Generative_Diffusion_Prior_for_Unified_I_5549dc3c.pdf"
  },
  "77a5e08f361b6f91cac8a24b380a14c12bb93383": {
    "paperId": "77a5e08f361b6f91cac8a24b380a14c12bb93383",
    "title": "Novice-AI Music Co-Creation via AI-Steering Tools for Deep Generative Models",
    "year": 2020,
    "authors": "Ryan Louie, Andy Coenen, Cheng-Zhi Anna Huang, Michael Terry, Carrie J. Cai",
    "abstract": "While generative deep neural networks (DNNs) have demonstrated their capacity for creating novel musical compositions, less attention has been paid to the challenges and potential of co-creating with these musical AIs, especially for novices. In a needfinding study with a widely used, interactive musical AI, we found that the AI can overwhelm users with the amount of musical content it generates, and frustrate them with its non-deterministic output. To better match co-creation needs, we developed AI-steering tools, consisting of Voice Lanes that restrict content generation to particular voices; Example-Based Sliders to control the similarity of generated content to an existing example; Semantic Sliders to nudge music generation in high-level directions (happy/sad, conventional/surprising); and Multiple Alternatives of generated content to audition and choose from. In a summative study (N=21), we discovered the tools not only increased users' trust, control, comprehension, and sense of collaboration with the AI, but also contributed to a greater sense of self-efficacy and ownership of the composition relative to the AI.",
    "citationCount": 281,
    "pdf_filename": "2020_Novice_AI_Music_Co_Creation_via_AI_Steer_77a5e08f.pdf"
  },
  "262e5a2f7371b8cdaba06a24facc3aa3f7447516": {
    "paperId": "262e5a2f7371b8cdaba06a24facc3aa3f7447516",
    "title": "Generative Agent Simulations of 1,000 People",
    "year": 2024,
    "authors": "Joon Sung Park, Carolyn Q. Zou, Aaron Shaw, Benjamin Mako Hill, C. Cai",
    "abstract": "The promise of human behavioral simulation--general-purpose computational agents that replicate human behavior across domains--could enable broad applications in policymaking and social science. We present a novel agent architecture that simulates the attitudes and behaviors of 1,052 real individuals--applying large language models to qualitative interviews about their lives, then measuring how well these agents replicate the attitudes and behaviors of the individuals that they represent. The generative agents replicate participants' responses on the General Social Survey 85% as accurately as participants replicate their own answers two weeks later, and perform comparably in predicting personality traits and outcomes in experimental replications. Our architecture reduces accuracy biases across racial and ideological groups compared to agents given demographic descriptions. This work provides a foundation for new tools that can help investigate individual and collective behavior.",
    "citationCount": 221,
    "pdf_filename": "2024_Generative_Agent_Simulations_of_1_000_Pe_262e5a2f.pdf"
  },
  "441922f7ed3a91c5ef9fdac7025bc67012a88815": {
    "paperId": "441922f7ed3a91c5ef9fdac7025bc67012a88815",
    "title": "Generative artificial intelligence, human creativity, and art",
    "year": 2024,
    "authors": "Eric Zhou, Dokyun Lee",
    "abstract": "Abstract Recent artificial intelligence (AI) tools have demonstrated the ability to produce outputs traditionally considered creative. One such system is text-to-image generative AI (e.g. Midjourney, Stable Diffusion, DALL-E), which automates humans’ artistic execution to generate digital artworks. Utilizing a dataset of over 4 million artworks from more than 50,000 unique users, our research shows that over time, text-to-image AI significantly enhances human creative productivity by 25% and increases the value as measured by the likelihood of receiving a favorite per view by 50%. While peak artwork Content Novelty, defined as focal subject matter and relations, increases over time, average Content Novelty declines, suggesting an expanding but inefficient idea space. Additionally, there is a consistent reduction in both peak and average Visual Novelty, captured by pixel-level stylistic elements. Importantly, AI-assisted artists who can successfully explore more novel ideas, regardless of their prior originality, may produce artworks that their peers evaluate more favorably. Lastly, AI adoption decreased value capture (favorites earned) concentration among adopters. The results suggest that ideation and filtering are likely necessary skills in the text-to-image process, thus giving rise to “generative synesthesia”—the harmonious blending of human exploration and AI exploitation to discover new creative workflows.",
    "citationCount": 207,
    "pdf_filename": "2024_Generative_artificial_intelligence__huma_441922f7.pdf"
  },
  "858f0643110ccccb6a9103747f2169fecfb98668": {
    "paperId": "858f0643110ccccb6a9103747f2169fecfb98668",
    "title": "DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior",
    "year": 2023,
    "authors": "X. Lin, Jingwen He, Zi-Yuan Chen, Zhaoyang Lyu, Ben Fei",
    "abstract": "We present DiffBIR, a general restoration pipeline that could handle different blind image restoration tasks in a unified framework. DiffBIR decouples blind image restoration problem into two stages: 1) degradation removal: removing image-independent content; 2) information regeneration: generating the lost image content. Each stage is developed independently but they work seamlessly in a cascaded manner. In the first stage, we use restoration modules to remove degradations and obtain high-fidelity restored results. For the second stage, we propose IRControlNet that leverages the generative ability of latent diffusion models to generate realistic details. Specifically, IRControlNet is trained based on specially produced condition images without distracting noisy content for stable generation performance. Moreover, we design a region-adaptive restoration guidance that can modify the denoising process during inference without model re-training, allowing users to balance realness and fidelity through a tunable guidance scale. Extensive experiments have demonstrated DiffBIR's superiority over state-of-the-art approaches for blind image super-resolution, blind face restoration and blind image denoising tasks on both synthetic and real-world datasets. The code is available at https://github.com/XPixelGroup/DiffBIR.",
    "citationCount": 263,
    "pdf_filename": "2023_DiffBIR__Towards_Blind_Image_Restoration_858f0643.pdf"
  },
  "7f4ed88e626ae733bc95406c60087d903b6b41a4": {
    "paperId": "7f4ed88e626ae733bc95406c60087d903b6b41a4",
    "title": "Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review",
    "year": 2023,
    "authors": "C. Preiksaitis, Christian Rose",
    "abstract": "Background Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications. Objective This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration. Methods We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data. Results Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions. Conclusions The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.",
    "citationCount": 228,
    "pdf_filename": "2023_Opportunities__Challenges__and_Future_Di_7f4ed88e.pdf"
  },
  "df558a3daf22955fe42f4bbeb1415f6607b67567": {
    "paperId": "df558a3daf22955fe42f4bbeb1415f6607b67567",
    "title": "The GenAI is out of the bottle: generative artificial intelligence from a business model innovation perspective",
    "year": 2023,
    "authors": "Dominik K. Kanbach, Louisa Heiduk, Georg Blueher, Maximilian Schreiter, Alexander Lahmann",
    "abstract": "The introduction of ChatGPT in November 2022 by OpenAI has stimulated substantial discourse on the implementation of artificial intelligence (AI) in various domains such as academia, business, and society at large. Although AI has been utilized in numerous areas for several years, the emergence of generative AI (GAI) applications such as ChatGPT, Jasper, or DALL-E are considered a breakthrough for the acceleration of AI technology due to their ease of use, intuitive interface, and performance. With GAI, it is possible to create a variety of content such as texts, images, audio, code, and even videos. This creates a variety of implications for businesses requiring a deeper examination, including an influence on business model innovation (BMI). Therefore, this study provides a BMI perspective on GAI with two primary contributions: (1) The development of six comprehensive propositions outlining the impact of GAI on businesses, and (2) the discussion of three industry examples, specifically software engineering, healthcare, and financial services. This study employs a qualitative content analysis using a scoping review methodology, drawing from a wide-ranging sample of 513 data points. These include academic publications, company reports, and public information such as press releases, news articles, interviews, and podcasts. The study thus contributes to the growing academic discourse in management research concerning AI's potential impact and offers practical insights into how to utilize this technology to develop new or improve existing business models.",
    "citationCount": 272,
    "pdf_filename": "2023_The_GenAI_is_out_of_the_bottle__generati_df558a3d.pdf"
  },
  "ad022cd5da75637ac3e0a8f8cc4f0d394ba5ff7a": {
    "paperId": "ad022cd5da75637ac3e0a8f8cc4f0d394ba5ff7a",
    "title": "Self-Consuming Generative Models Go MAD",
    "year": 2023,
    "authors": "Sina Alemohammad, Josue Casco-Rodriguez, L. Luzi, Ahmed Imtiaz Humayun, Hossein Babaei",
    "abstract": "Seismic advances in generative AI algorithms have led to the temptation to use AI-synthesized data to train next-generation models. Repeating this process creates autophagous (“self-consuming”) loops whose properties are poorly understood. We conduct a thorough analysis using state-of-the-art generative image models of three autophagous loop families that differ in how they incorporate fixed or fresh real training data and whether previous generations' samples have been biased to trade off data quality versus diversity. Our primary conclusion across all scenarios is that without enough fresh real data in each generation of an autophagous loop, future generative models are doomed to have their quality (precision) or diversity (recall) progressively decrease. We term this condition Model Autophagy Disorder (MAD) and show that appreciable MADness arises in just a few generations.",
    "citationCount": 218,
    "pdf_filename": "2023_Self_Consuming_Generative_Models_Go_MAD_ad022cd5.pdf"
  },
  "fc819b599d6897fe1dc09961e201489e136558eb": {
    "paperId": "fc819b599d6897fe1dc09961e201489e136558eb",
    "title": "ChatGPT and Generative Artificial Intelligence for Medical Education: Potential Impact and Opportunity",
    "year": 2023,
    "authors": "C. Boscardin, Brian C. Gin, Polo Black Golde, K. Hauer",
    "abstract": "Abstract ChatGPT has ushered in a new era of artificial intelligence (AI) that already has significant consequences for many industries, including health care and education. Generative AI tools, such as ChatGPT, refer to AI that is designed to create or generate new content, such as text, images, or music, from their trained parameters. With free access online and an easy-to-use conversational interface, ChatGPT quickly accumulated more than 100 million users within the first few months of its launch. Recent headlines in the popular press have ignited concerns relevant to medical education over the possible implications of cheating and plagiarism in assessments as well as excitement over new opportunities for learning, assessment, and research. In this Scholarly Perspective, the authors offer insights and recommendations about generative AI for medical educators based on literature review, including the AI literacy framework. The authors provide a definition of generative AI, introduce an AI literacy framework and competencies, and offer considerations for potential impacts and opportunities to optimize integration of generative AI for admissions, learning, assessment, and medical education research to help medical educators navigate and start planning for this new environment. As generative AI tools continue to expand, educators need to increase their AI literacy through education and vigilance around new advances in the technology and serve as stewards of AI literacy to foster social responsibility and ethical awareness around the use of AI.",
    "citationCount": 214,
    "pdf_filename": "2023_ChatGPT_and_Generative_Artificial_Intell_fc819b59.pdf"
  },
  "c9ad9d69d7568110dd5527598a92c7f8b335eef4": {
    "paperId": "c9ad9d69d7568110dd5527598a92c7f8b335eef4",
    "title": "Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations",
    "year": 2023,
    "authors": "Josh A. Goldstein, Girish Sastry, Micah Musser, Renée DiResta, M. Gentzel",
    "abstract": "Generative language models have improved drastically, and can now produce realistic text outputs that are difficult to distinguish from human-written content. For malicious actors, these language models bring the promise of automating the creation of convincing and misleading text for use in influence operations. This report assesses how language models might change influence operations in the future, and what steps can be taken to mitigate this threat. We lay out possible changes to the actors, behaviors, and content of online influence operations, and provide a framework for stages of the language model-to-influence operations pipeline that mitigations could target (model construction, model access, content dissemination, and belief formation). While no reasonable mitigation can be expected to fully prevent the threat of AI-enabled influence operations, a combination of multiple mitigations may make an important difference.",
    "citationCount": 287,
    "pdf_filename": "2023_Generative_Language_Models_and_Automated_c9ad9d69.pdf"
  },
  "b026af1b2436fe064e02ca7a00b79713427bc3b2": {
    "paperId": "b026af1b2436fe064e02ca7a00b79713427bc3b2",
    "title": "Diagnostic Accuracy of Differential-Diagnosis Lists Generated by Generative Pretrained Transformer 3 Chatbot for Clinical Vignettes with Common Chief Complaints: A Pilot Study",
    "year": 2023,
    "authors": "Takanobu Hirosawa, Y. Harada, Masashi Yokose, Tetsu Sakamoto, Ren Kawamura",
    "abstract": "The diagnostic accuracy of differential diagnoses generated by artificial intelligence (AI) chatbots, including the generative pretrained transformer 3 (GPT-3) chatbot (ChatGPT-3) is unknown. This study evaluated the accuracy of differential-diagnosis lists generated by ChatGPT-3 for clinical vignettes with common chief complaints. General internal medicine physicians created clinical cases, correct diagnoses, and five differential diagnoses for ten common chief complaints. The rate of correct diagnosis by ChatGPT-3 within the ten differential-diagnosis lists was 28/30 (93.3%). The rate of correct diagnosis by physicians was still superior to that by ChatGPT-3 within the five differential-diagnosis lists (98.3% vs. 83.3%, p = 0.03). The rate of correct diagnosis by physicians was also superior to that by ChatGPT-3 in the top diagnosis (53.3% vs. 93.3%, p < 0.001). The rate of consistent differential diagnoses among physicians within the ten differential-diagnosis lists generated by ChatGPT-3 was 62/88 (70.5%). In summary, this study demonstrates the high diagnostic accuracy of differential-diagnosis lists generated by ChatGPT-3 for clinical cases with common chief complaints. This suggests that AI chatbots such as ChatGPT-3 can generate a well-differentiated diagnosis list for common chief complaints. However, the order of these lists can be improved in the future.",
    "citationCount": 260,
    "pdf_filename": "2023_Diagnostic_Accuracy_of_Differential_Diag_b026af1b.pdf"
  },
  "9f7e3f89ab59c9da5cc9c5323c96ce795dcb294a": {
    "paperId": "9f7e3f89ab59c9da5cc9c5323c96ce795dcb294a",
    "title": "Generative Artificial Intelligence: Implications and Considerations for Higher Education Practice",
    "year": 2023,
    "authors": "T. Farrelly, Nick Baker",
    "abstract": "Generative Artificial Intelligence (GAI) has emerged as a transformative force in higher education, offering both challenges and opportunities. This paper explores the multifaceted impact of GAI on academic work, with a focus on student life and, in particular, the implications for international students. While GAI, exemplified by models like ChatGPT, has the potential to revolutionize education, concerns about academic integrity have arisen, leading to debates on the use of AI detection tools. This essay highlights the difficulties in reliably detecting AI-generated content, raising concerns about potential false accusations against students. It also discusses biases within AI models, emphasizing the need for fairness and equity in AI-based assessments with a particular emphasis on the disproportionate impact of GAI on international students, who already face biases and discrimination. It also highlights the potential for AI to mitigate some of these challenges by providing language support and accessibility features. Finally, this essay acknowledges the disruptive potential of GAI in higher education and calls for a balanced approach that addresses both the challenges and opportunities it presents by emphasizing the importance of AI literacy and ethical considerations in adopting AI technologies to ensure equitable access and positive outcomes for all students. We offer a coda to Ng et al.’s AI competency framework, mapped to the Revised Bloom’s Taxonomy, through a lens of cultural competence with AI as a means of supporting educators to use these tools equitably in their teaching.",
    "citationCount": 215,
    "pdf_filename": "2023_Generative_Artificial_Intelligence__Impl_9f7e3f89.pdf"
  },
  "b50465f4c93714ce5df1b6e56dd1952080d019a8": {
    "paperId": "b50465f4c93714ce5df1b6e56dd1952080d019a8",
    "title": "Durably reducing conspiracy beliefs through dialogues with AI",
    "year": 2024,
    "authors": "Thomas H. Costello, Gordon Pennycook, David G. Rand",
    "abstract": "Conspiracy theory beliefs are notoriously persistent. Influential hypotheses propose that they fulfill important psychological needs, thus resisting counterevidence. Yet previous failures in correcting conspiracy beliefs may be due to counterevidence being insufficiently compelling and tailored. To evaluate this possibility, we leveraged developments in generative artificial intelligence and engaged 2190 conspiracy believers in personalized evidence-based dialogues with GPT-4 Turbo. The intervention reduced conspiracy belief by ~20%. The effect remained 2 months later, generalized across a wide range of conspiracy theories, and occurred even among participants with deeply entrenched beliefs. Although the dialogues focused on a single conspiracy, they nonetheless diminished belief in unrelated conspiracies and shifted conspiracy-related behavioral intentions. These findings suggest that many conspiracy theory believers can revise their views if presented with sufficiently compelling evidence. Editor’s summary Beliefs in conspiracies that a US election was stolen incited an attempted insurrection on 6 January 2021. Another conspiracy alleging that Germany’s COVID-19 restrictions were motivated by nefarious intentions sparked violent protests at Berlin’s Reichstag parliament building in August 2020. Amid growing threats to democracy, Costello et al. investigated whether dialogs with a generative artificial intelligence (AI) interface could convince people to abandon their conspiratorial beliefs (see the Perspective by Bago and Bonnefon). Human participants described a conspiracy theory that they subscribed to, and the AI then engaged in persuasive arguments with them that refuted their beliefs with evidence. The AI chatbot’s ability to sustain tailored counterarguments and personalized in-depth conversations reduced their beliefs in conspiracies for months, challenging research suggesting that such beliefs are impervious to change. This intervention illustrates how deploying AI may mitigate conflicts and serve society. —Ekeoma Uzogara INTRODUCTION Widespread belief in unsubstantiated conspiracy theories is a major source of public concern and a focus of scholarly research. Despite often being quite implausible, many such conspiracies are widely believed. Prominent psychological theories propose that many people want to adopt conspiracy theories (to satisfy underlying psychic “needs” or motivations), and thus, believers cannot be convinced to abandon these unfounded and implausible beliefs using facts and counterevidence. Here, we question this conventional wisdom and ask whether it may be possible to talk people out of the conspiratorial “rabbit hole” with sufficiently compelling evidence. RATIONALE We hypothesized that interventions based on factual, corrective information may seem ineffective simply because they lack sufficient depth and personalization. To test this hypothesis, we leveraged advancements in large language models (LLMs), a form of artificial intelligence (AI) that has access to vast amounts of information and the ability to generate bespoke arguments. LLMs can thereby directly refute particular evidence each individual cites as supporting their conspiratorial beliefs. To do so, we developed a pipeline for conducting behavioral science research using real-time, personalized interactions between research subjects and AI. Across two experiments, 2190 Americans articulated—in their own words—a conspiracy theory in which they believe, along with the evidence they think supports this theory. They then engaged in a three-round conversation with the LLM GPT-4 Turbo, which we prompted to respond to this specific evidence while trying to reduce participants’ belief in the conspiracy theory (or, as a control condition, to converse with the AI about an unrelated topic). RESULTS The treatment reduced participants’ belief in their chosen conspiracy theory by 20% on average. This effect persisted undiminished for at least 2 months; was consistently observed across a wide range of conspiracy theories, from classic conspiracies involving the assassination of John F. Kennedy, aliens, and the illuminati, to those pertaining to topical events such as COVID-19 and the 2020 US presidential election; and occurred even for participants whose conspiracy beliefs were deeply entrenched and important to their identities. Notably, the AI did not reduce belief in true conspiracies. Furthermore, when a professional fact-checker evaluated a sample of 128 claims made by the AI, 99.2% were true, 0.8% were misleading, and none were false. The debunking also spilled over to reduce beliefs in unrelated conspiracies, indicating a general decrease in conspiratorial worldview, and increased intentions to rebut other conspiracy believers. CONCLUSION Many people who strongly believe in seemingly fact-resistant conspiratorial beliefs can change their minds when presented with compelling evidence. From a theoretical perspective, this paints a surprisingly optimistic picture of human reasoning: Conspiratorial rabbit holes may indeed have an exit. Psychological needs and motivations do not inherently blind conspiracists to evidence—it simply takes the right evidence to reach them. Practically, by demonstrating the persuasive power of LLMs, our findings emphasize both the potential positive impacts of generative AI when deployed responsibly and the pressing importance of minimizing opportunities for this technology to be used irresponsibly. Dialogues with AI durably reduce conspiracy beliefs even among strong believers. (Left) Average belief in participant’s chosen conspiracy theory by condition (treatment, in which the AI attempted to refute the conspiracy theory, in red; control, in which the AI discussed an irrelevant topic, in blue) and time point for study 1. (Right) Change in belief in chosen conspiracy from before to after AI conversation, by condition and participant’s pretreatment belief in the conspiracy.",
    "citationCount": 212,
    "pdf_filename": "2024_Durably_reducing_conspiracy_beliefs_thro_b50465f4.pdf"
  },
  "cf923fb70bbad20c485cef355444a08096747f68": {
    "paperId": "cf923fb70bbad20c485cef355444a08096747f68",
    "title": "Generative Novel View Synthesis with 3D-Aware Diffusion Models",
    "year": 2023,
    "authors": "Eric Chan, Koki Nagano, Matthew A. Chan, Alexander W. Bergman, Jeong Joon Park",
    "abstract": "We present a diffusion-based model for 3D-aware generative novel view synthesis from as few as a single input image. Our model samples from the distribution of possible renderings consistent with the input and, even in the presence of ambiguity, is capable of rendering diverse and plausible novel views. To achieve this, our method makes use of existing 2D diffusion backbones but, crucially, incorporates geometry priors in the form of a 3D feature volume. This latent feature field captures the distribution over possible scene representations and improves our method’s ability to generate view-consistent novel renderings. In addition to generating novel views, our method has the ability to autoregressively synthesize 3D-consistent sequences. We demonstrate state-of-the-art results on synthetic renderings and room-scale scenes; we also show compelling results for challenging, real-world objects.",
    "citationCount": 289,
    "pdf_filename": "2023_Generative_Novel_View_Synthesis_with_3D__cf923fb7.pdf"
  },
  "b7a783e3897baed760fb91cd1289dd0e353377f5": {
    "paperId": "b7a783e3897baed760fb91cd1289dd0e353377f5",
    "title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling",
    "year": 2023,
    "authors": "Zhen Liu, Yao Feng, Michael J. Black, D. Nowrouzezahrai, L. Paull",
    "abstract": "We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectiveness of our model on multiple generative tasks.",
    "citationCount": 204,
    "pdf_filename": "2023_MeshDiffusion__Score_based_Generative_3D_b7a783e3.pdf"
  },
  "768ff532981f47a954d8bc6563a5b3e909cfbcad": {
    "paperId": "768ff532981f47a954d8bc6563a5b3e909cfbcad",
    "title": "Towards Generative Aspect-Based Sentiment Analysis",
    "year": 2021,
    "authors": "Wenxuan Zhang, Xin Li, Yang Deng, Lidong Bing, Wai Lam",
    "abstract": "Aspect-based sentiment analysis (ABSA) has received increasing attention recently. Most existing work tackles ABSA in a discriminative manner, designing various task-specific classification networks for the prediction. Despite their effectiveness, these methods ignore the rich label semantics in ABSA problems and require extensive task-specific designs. In this paper, we propose to tackle various ABSA tasks in a unified generative framework. Two types of paradigms, namely annotation-style and extraction-style modeling, are designed to enable the training process by formulating each ABSA task as a text generation problem. We conduct experiments on four ABSA tasks across multiple benchmark datasets where our proposed generative approach achieves new state-of-the-art results in almost all cases. This also validates the strong generality of the proposed framework which can be easily adapted to arbitrary ABSA task without additional task-specific model design.",
    "citationCount": 245,
    "pdf_filename": "2021_Towards_Generative_Aspect_Based_Sentimen_768ff532.pdf"
  },
  "70776ac43e2724e301e9f89877bbe4565d33e473": {
    "paperId": "70776ac43e2724e301e9f89877bbe4565d33e473",
    "title": "GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image",
    "year": 2023,
    "authors": "Mingjian Zhu, Hanting Chen, Qiang Yan, Xu Huang, Guanyu Lin",
    "abstract": "The extraordinary ability of generative models to generate photographic images has intensified concerns about the spread of disinformation, thereby leading to the demand for detectors capable of distinguishing between AI-generated fake images and real images. However, the lack of large datasets containing images from the most advanced image generators poses an obstacle to the development of such detectors. In this paper, we introduce the GenImage dataset, which has the following advantages: 1) Plenty of Images, including over one million pairs of AI-generated fake images and collected real images. 2) Rich Image Content, encompassing a broad range of image classes. 3) State-of-the-art Generators, synthesizing images with advanced diffusion models and GANs. The aforementioned advantages allow the detectors trained on GenImage to undergo a thorough evaluation and demonstrate strong applicability to diverse images. We conduct a comprehensive analysis of the dataset and propose two tasks for evaluating the detection method in resembling real-world scenarios. The cross-generator image classification task measures the performance of a detector trained on one generator when tested on the others. The degraded image classification task assesses the capability of the detectors in handling degraded images such as low-resolution, blurred, and compressed images. With the GenImage dataset, researchers can effectively expedite the development and evaluation of superior AI-generated image detectors in comparison to prevailing methodologies.",
    "citationCount": 231,
    "pdf_filename": "2023_GenImage__A_Million_Scale_Benchmark_for__70776ac4.pdf"
  },
  "c7c6d338e47b236edea76790d2997333f497319e": {
    "paperId": "c7c6d338e47b236edea76790d2997333f497319e",
    "title": "TaleBrush: Sketching Stories with Generative Pretrained Language Models",
    "year": 2022,
    "authors": "John Joon Young Chung, Wooseok Kim, Kang Min Yoo, Hwaran Lee, Eytan Adar",
    "abstract": "While advanced text generation algorithms (e.g., GPT-3) have enabled writers to co-create stories with an AI, guiding the narrative remains a challenge. Existing systems often leverage simple turn-taking between the writer and the AI in story development. However, writers remain unsupported in intuitively understanding the AI’s actions or steering the iterative generation. We introduce TaleBrush, a generative story ideation tool that uses line sketching interactions with a GPT-based language model for control and sensemaking of a protagonist’s fortune in co-created stories. Our empirical evaluation found our pipeline reliably controls story generation while maintaining the novelty of generated sentences. In a user study with 14 participants with diverse writing experiences, we found participants successfully leveraged sketching to iteratively explore and write stories according to their intentions about the character’s fortune while taking inspiration from generated stories. We conclude with a reflection on how sketching interactions can facilitate the iterative human-AI co-creation process.",
    "citationCount": 206,
    "pdf_filename": "2022_TaleBrush__Sketching_Stories_with_Genera_c7c6d338.pdf"
  },
  "cbf3bf8f541f5b446c59c8deacbcc18527768c75": {
    "paperId": "cbf3bf8f541f5b446c59c8deacbcc18527768c75",
    "title": "M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems",
    "year": 2022,
    "authors": "Zeyu Cui, Jianxin Ma, Chang Zhou, Jingren Zhou, Hongxia Yang",
    "abstract": "Industrial recommender systems have been growing increasingly complex, may involve \\emph{diverse domains} such as e-commerce products and user-generated contents, and can comprise \\emph{a myriad of tasks} such as retrieval, ranking, explanation generation, and even AI-assisted content production. The mainstream approach so far is to develop individual algorithms for each domain and each task. In this paper, we explore the possibility of developing a unified foundation model to support \\emph{open-ended domains and tasks} in an industrial recommender system, which may reduce the demand on downstream settings' data and can minimize the carbon footprint by avoiding training a separate model from scratch for every task. Deriving a unified foundation is challenging due to (i) the potentially unlimited set of downstream domains and tasks, and (ii) the real-world systems' emphasis on computational efficiency. We thus build our foundation upon M6, an existing large-scale industrial pretrained language model similar to GPT-3 and T5, and leverage M6's pretrained ability for sample-efficient downstream adaptation, by representing user behavior data as plain texts and converting the tasks to either language understanding or generation. To deal with a tight hardware budget, we propose an improved version of prompt tuning that outperforms fine-tuning with negligible 1\\% task-specific parameters, and employ techniques such as late interaction, early exiting, parameter sharing, and pruning to further reduce the inference time and the model size. We demonstrate the foundation model's versatility on a wide range of tasks such as retrieval, ranking, zero-shot recommendation, explanation generation, personalized content creation, and conversational recommendation, and manage to deploy it on both cloud servers and mobile devices.",
    "citationCount": 246,
    "pdf_filename": "2022_M6_Rec__Generative_Pretrained_Language_M_cbf3bf8f.pdf"
  },
  "af47d88093c3f32b299cfc93be4695a954406636": {
    "paperId": "af47d88093c3f32b299cfc93be4695a954406636",
    "title": "AI-generated feedback on writing: insights into efficacy and ENL student preference",
    "year": 2023,
    "authors": "Juan Escalante, Austin Pack, A. Barrett",
    "abstract": "The question of how generative AI tools, such as large language models and chatbots, can be leveraged ethically and effectively in education is ongoing. Given the critical role that writing plays in learning and assessment within educational institutions, it is of growing importance for educators to make thoughtful and informed decisions as to how and in what capacity generative AI tools should be leveraged to assist in the development of students’ writing skills. This paper reports on two longitudinal studies. Study 1 examined learning outcomes of 48 university English as a new language (ENL) learners in a six-week long repeated measures quasi experimental design where the experimental group received writing feedback generated from ChatGPT (GPT-4) and the control group received feedback from their human tutor. Study 2 analyzed the perceptions of a different group of 43 ENLs who received feedback from both ChatGPT and their tutor. Results of study 1 showed no difference in learning outcomes between the two groups. Study 2 results revealed a near even split in preference for AI-generated or human-generated feedback, with clear advantages to both forms of feedback apparent from the data. The main implication of these studies is that the use of AI-generated feedback can likely be incorporated into ENL essay evaluation without affecting learning outcomes, although we recommend a blended approach that utilizes the strengths of both forms of feedback. The main contribution of this paper is in addressing generative AI as an automatic essay evaluator while incorporating learner perspectives.",
    "citationCount": 266,
    "pdf_filename": "2023_AI_generated_feedback_on_writing__insigh_af47d880.pdf"
  },
  "7dbd3d51c453caf77cc1f9681f9b888095b97443": {
    "paperId": "7dbd3d51c453caf77cc1f9681f9b888095b97443",
    "title": "AI Art and its Impact on Artists",
    "year": 2023,
    "authors": "Harry H. Jiang, Lauren Brown, Jessica Cheng, Mehtab Khan, Abhishek Gupta",
    "abstract": "The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial “generative AI Art” products have entered the market, making generative AI an estimated $48B industry [125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.",
    "citationCount": 243,
    "pdf_filename": "2023_AI_Art_and_its_Impact_on_Artists_7dbd3d51.pdf"
  },
  "c889cdd52db3ec7a8f8270ce80e010d2725aede2": {
    "paperId": "c889cdd52db3ec7a8f8270ce80e010d2725aede2",
    "title": "Educational Design Principles of Using AI Chatbot That Supports Self-Regulated Learning in Education: Goal Setting, Feedback, and Personalization",
    "year": 2023,
    "authors": "Daniel H. Chang, M. P. Lin, Shiva Hajian, Quincy Q. Wang",
    "abstract": "The invention of ChatGPT and generative AI technologies presents educators with significant challenges, as concerns arise regarding students potentially exploiting these tools unethically, misrepresenting their work, or gaining academic merits without active participation in the learning process. To effectively navigate this shift, it is crucial to embrace AI as a contemporary educational trend and establish pedagogical principles for properly utilizing emerging technologies like ChatGPT to promote self-regulation. Rather than suppressing AI-driven tools, educators should foster collaborations among stakeholders, including educators, instructional designers, AI researchers, and developers. This paper proposes three key pedagogical principles for integrating AI chatbots in classrooms, informed by Zimmerman’s Self-Regulated Learning (SRL) framework and Judgment of Learning (JOL). We argue that the current conceptualization of AI chatbots in education is inadequate, so we advocate for the incorporation of goal setting (prompting), self-assessment and feedback, and personalization as three essential educational principles. First, we propose that teaching prompting is important for developing students’ SRL. Second, configuring reverse prompting in the AI chatbot’s capability will help to guide students’ SRL and monitoring for understanding. Third, developing a data-driven mechanism that enables an AI chatbot to provide learning analytics helps learners to reflect on learning and develop SRL strategies. By bringing in Zimmerman’s SRL framework with JOL, we aim to provide educators with guidelines for implementing AI in teaching and learning contexts, with a focus on promoting students’ self-regulation in higher education through AI-assisted pedagogy and instructional design.",
    "citationCount": 204,
    "pdf_filename": "2023_Educational_Design_Principles_of_Using_A_c889cdd5.pdf"
  },
  "9eb476cd15becf02163d6f3dab75d207eed52214": {
    "paperId": "9eb476cd15becf02163d6f3dab75d207eed52214",
    "title": "Power Hungry Processing: Watts Driving the Cost of AI Deployment?",
    "year": 2023,
    "authors": "Sasha Luccioni, Yacine Jernite, Emma Strubell",
    "abstract": "Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of “generality” comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and ‘general-purpose’ models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.",
    "citationCount": 288,
    "pdf_filename": "2023_Power_Hungry_Processing__Watts_Driving_t_9eb476cd.pdf"
  },
  "df901d279484c574ad4669c01ec02957dcd6b698": {
    "paperId": "df901d279484c574ad4669c01ec02957dcd6b698",
    "title": "AI-Generated Medical Advice-GPT and Beyond.",
    "year": 2023,
    "authors": "C. E. Haupt, Mason Marks",
    "abstract": "\n This Viewpoint describes medical applications of generative pretrained transformers (GPTs) and related artificial intelligence (AI) technologies and considers whether new forms of regulation are necessary to minimize safety and legal risks to patients and clinicians.\n",
    "citationCount": 253,
    "pdf_filename": "2023_AI_Generated_Medical_Advice_GPT_and_Beyo_df901d27.pdf"
  },
  "63f5c21f845b5f538f61e435b8f6e31c9d1c0a6a": {
    "paperId": "63f5c21f845b5f538f61e435b8f6e31c9d1c0a6a",
    "title": "A Survey on ChatGPT: AI–Generated Contents, Challenges, and Solutions",
    "year": 2023,
    "authors": "Yuntao Wang, Yanghe Pan, Miao Yan, Zhou Su, T. Luan",
    "abstract": "With the widespread use of large artificial intelligence (AI) models such as ChatGPT, AI-generated content (AIGC) has garnered increasing attention and is leading a paradigm shift in content creation and knowledge representation. AIGC uses generative large AI algorithms to assist or replace humans in creating massive, high-quality, and human-like content at a faster pace and lower cost, based on user-provided prompts. Despite the recent significant progress in AIGC, security, privacy, ethical, and legal challenges still need to be addressed. This paper presents an in-depth survey of working principles, security and privacy threats, state-of-the-art solutions, and future challenges of the AIGC paradigm. Specifically, we first explore the enabling technologies, general architecture of AIGC, and discuss its working modes and key characteristics. Then, we investigate the taxonomy of security and privacy threats to AIGC and highlight the ethical and societal implications of GPT and AIGC technologies. Furthermore, we review the state-of-the-art AIGC watermarking approaches for regulatable AIGC paradigms regarding the AIGC model and its produced content. Finally, we identify future challenges and open research directions related to AIGC.",
    "citationCount": 222,
    "pdf_filename": "2023_A_Survey_on_ChatGPT__AI_Generated_Conten_63f5c21f.pdf"
  },
  "69a4cb1a3d84e924ab79848910507ee34e80150a": {
    "paperId": "69a4cb1a3d84e924ab79848910507ee34e80150a",
    "title": "Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being",
    "year": 2023,
    "authors": "Han Li, Renwen Zhang, Yi-Chieh Lee, Robert E. Kraut, David C. Mohr",
    "abstract": "Conversational artificial intelligence (AI), particularly AI-based conversational agents (CAs), is gaining traction in mental health care. Despite their growing usage, there is a scarcity of comprehensive evaluations of their impact on mental health and well-being. This systematic review and meta-analysis aims to fill this gap by synthesizing evidence on the effectiveness of AI-based CAs in improving mental health and factors influencing their effectiveness and user experience. Twelve databases were searched for experimental studies of AI-based CAs’ effects on mental illnesses and psychological well-being published before May 26, 2023. Out of 7834 records, 35 eligible studies were identified for systematic review, out of which 15 randomized controlled trials were included for meta-analysis. The meta-analysis revealed that AI-based CAs significantly reduce symptoms of depression (Hedge’s g 0.64 [95% CI 0.17–1.12]) and distress (Hedge’s g 0.7 [95% CI 0.18–1.22]). These effects were more pronounced in CAs that are multimodal, generative AI-based, integrated with mobile/instant messaging apps, and targeting clinical/subclinical and elderly populations. However, CA-based interventions showed no significant improvement in overall psychological well-being (Hedge’s g 0.32 [95% CI –0.13 to 0.78]). User experience with AI-based CAs was largely shaped by the quality of human-AI therapeutic relationships, content engagement, and effective communication. These findings underscore the potential of AI-based CAs in addressing mental health issues. Future research should investigate the underlying mechanisms of their effectiveness, assess long-term effects across various mental health outcomes, and evaluate the safe integration of large language models (LLMs) in mental health care.",
    "citationCount": 210,
    "pdf_filename": "2023_Systematic_review_and_meta_analysis_of_A_69a4cb1a.pdf"
  },
  "0db79fa4f25545e57213e9acf22f2e72100d563f": {
    "paperId": "0db79fa4f25545e57213e9acf22f2e72100d563f",
    "title": "Semantic Segmentation with Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization",
    "year": 2021,
    "authors": "Daiqing Li, Junlin Yang, Karsten Kreis, A. Torralba, S. Fidler",
    "abstract": "Training deep networks with limited labeled data while achieving a strong generalization ability is key in the quest to reduce human annotation efforts. This is the goal of semi-supervised learning, which exploits more widely available unlabeled data to complement small labeled data sets. In this paper, we propose a novel framework for discriminative pixel-level tasks using a generative model of both images and labels. Concretely, we learn a generative adversarial network that captures the joint image-label distribution and is trained efficiently using a large set of un-labeled images supplemented with only few labeled ones. We build our architecture on top of StyleGAN2 [45], augmented with a label synthesis branch. Image labeling at test time is achieved by first embedding the target image into the joint latent space via an encoder network and test-time optimization, and then generating the label from the inferred embedding. We evaluate our approach in two important domains: medical image segmentation and part-based face segmentation. We demonstrate strong in-domain performance compared to several baselines, and are the first to showcase extreme out-of-domain generalization, such as transferring from CT to MRI in medical imaging, and photographs of real faces to paintings, sculptures, and even cartoons and animal faces. Project Page: https://nv-tlabs.github.io/semanticGAN/",
    "citationCount": 214,
    "pdf_filename": "2021_Semantic_Segmentation_with_Generative_Mo_0db79fa4.pdf"
  },
  "3dcf2db20082b480c6c091eea025465cc4fe57a6": {
    "paperId": "3dcf2db20082b480c6c091eea025465cc4fe57a6",
    "title": "AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap",
    "year": 2023,
    "authors": "Q. Liao, Jennifer Wortman Vaughan",
    "abstract": "The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused applications being built, and the new usage patterns and challenges around LLMs, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for LLMs, along with lessons learned from HCI and responsible AI research that has taken a human-centered perspective on AI transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to LLMs. We hope this provides a starting point for discussion and a useful roadmap for future research.",
    "citationCount": 216,
    "pdf_filename": "2023_AI_Transparency_in_the_Age_of_LLMs__A_Hu_3dcf2db2.pdf"
  },
  "95e74beb9f54e0312f7356391ba7c699b05ebdb0": {
    "paperId": "95e74beb9f54e0312f7356391ba7c699b05ebdb0",
    "title": "A survey on generative adversarial networks for imbalance problems in computer vision tasks",
    "year": 2020,
    "authors": "Vignesh Sampath, I. Maurtua, Juan José Aguilar Martín, Aitor Gutierrez",
    "abstract": "Any computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Neural Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets. In this paper, we examine the most recent developments of GANs based techniques for addressing imbalance problems in image data. The real-world challenges and implementations of synthetic image generation based on GANs are extensively covered in this survey. Our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examines key concepts such as deep generative image models and GANs. After that, we propose a taxonomy to summarize GANs based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. Image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. We elaborate the imbalance problems of each group, and provide GANs based solutions in each group. Readers will understand how GANs based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",
    "citationCount": 211,
    "pdf_filename": "2020_A_survey_on_generative_adversarial_netwo_95e74beb.pdf"
  },
  "5e8d3c2dc0fc53949794fc00600e25558c4a2441": {
    "paperId": "5e8d3c2dc0fc53949794fc00600e25558c4a2441",
    "title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
    "year": 2022,
    "authors": "Alisa Liu, Swabha Swayamdipta, Noah A. Smith, Yejin Choi",
    "abstract": "A recurring challenge of crowdsourcing NLP datasets at scale is that human writers often rely on repetitive patterns when crafting examples, leading to a lack of linguistic diversity. We introduce a novel approach for dataset creation based on worker and AI collaboration, which brings together the generative strength of language models and the evaluative strength of humans. Starting with an existing dataset, MultiNLI for natural language inference (NLI), our approach uses dataset cartography to automatically identify examples that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose new examples with similar patterns. Machine generated examples are then automatically filtered, and finally revised and labeled by human crowdworkers. The resulting dataset, WANLI, consists of 107,885 NLI examples and presents unique empirical strengths over existing NLI datasets. Remarkably, training a model on WANLI improves performance on eight out-of-domain test sets we consider, including by 11% on HANS and 9% on Adversarial NLI, compared to training on the 4x larger MultiNLI. Moreover, it continues to be more effective than MultiNLI augmented with other NLI datasets. Our results demonstrate the promise of leveraging natural language generation techniques and re-imagining the role of humans in the dataset creation process.",
    "citationCount": 247,
    "pdf_filename": "2022_WANLI__Worker_and_AI_Collaboration_for_N_5e8d3c2d.pdf"
  },
  "fa0e239edf60a5a38807d76a407ca2ae6f9a63be": {
    "paperId": "fa0e239edf60a5a38807d76a407ca2ae6f9a63be",
    "title": "Anonymization Through Data Synthesis Using Generative Adversarial Networks (ADS-GAN)",
    "year": 2020,
    "authors": "Jinsung Yoon, Lydia N. Drumright, M. van der Schaar",
    "abstract": "The medical and machine learning communities are relying on the promise of artificial intelligence (AI) to transform medicine through enabling more accurate decisions and personalized treatment. However, progress is slow. Legal and ethical issues around unconsented patient data and privacy is one of the limiting factors in data sharing, resulting in a significant barrier in accessing routinely collected electronic health records (EHR) by the machine learning community. We propose a novel framework for generating synthetic data that closely approximates the joint distribution of variables in an original EHR dataset, providing a readily accessible, legally and ethically appropriate solution to support more open data sharing, enabling the development of AI solutions. In order to address issues around lack of clarity in defining sufficient anonymization, we created a quantifiable, mathematical definition for “identifiability”. We used a conditional generative adversarial networks (GAN) framework to generate synthetic data while minimize patient identifiability that is defined based on the probability of re-identification given the combination of all data on any individual patient. We compared models fitted to our synthetically generated data to those fitted to the real data across four independent datasets to evaluate similarity in model performance, while assessing the extent to which original observations can be identified from the synthetic data. Our model, ADS-GAN, consistently outperformed state-of-the-art methods, and demonstrated reliability in the joint distributions. We propose that this method could be used to develop datasets that can be made publicly available while considerably lowering the risk of breaching patient confidentiality.",
    "citationCount": 231,
    "pdf_filename": "2020_Anonymization_Through_Data_Synthesis_Usi_fa0e239e.pdf"
  },
  "e8a026d2dd10af43f8bc7fc9fd7a4f888c74efe0": {
    "paperId": "e8a026d2dd10af43f8bc7fc9fd7a4f888c74efe0",
    "title": "House-GAN: Relational Generative Adversarial Networks for Graph-constrained House Layout Generation",
    "year": 2020,
    "authors": "Nelson Nauata, Kai-Hung Chang, Chin-Yi Cheng, Greg Mori, Yasutaka Furukawa",
    "abstract": "This paper proposes a novel graph-constrained generative adversarial network, whose generator and discriminator are built upon relational architecture. The main idea is to encode the constraint into the graph structure of its relational networks. We have demonstrated the proposed architecture for a new house layout generation problem, whose task is to take an architectural constraint as a graph (i.e., the number and types of rooms with their spatial adjacency) and produce a set of axis-aligned bounding boxes of rooms. We measure the quality of generated house layouts with the three metrics: the realism, the diversity, and the compatibility with the input graph constraint. Our qualitative and quantitative evaluations over 117,000 real floorplan images demonstrate that the proposed approach outperforms existing methods and baselines. We will publicly share all our code and data.",
    "citationCount": 249,
    "pdf_filename": "2020_House_GAN__Relational_Generative_Adversa_e8a026d2.pdf"
  },
  "b41e07349b87a178d904e6b5d05a2f90b16f8e1e": {
    "paperId": "b41e07349b87a178d904e6b5d05a2f90b16f8e1e",
    "title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models",
    "year": 2021,
    "authors": "Hannah Rose Kirk, Yennie Jun, Haider Iqbal, Elias Benussi, Filippo Volpin",
    "abstract": "The capabilities of natural language models trained on large-scale data have increased immensely over the past few years. Open source libraries such as HuggingFace have made these models easily available and accessible. While prior research has identified biases in large language models, this paper considers biases contained in the most popular versions of these models when applied `out-of-the-box' for downstream tasks. We focus on generative language models as they are well-suited for extracting biases inherited from training data. Specifically, we conduct an in-depth analysis of GPT-2, which is the most downloaded text generation model on HuggingFace, with over half a million downloads per month. We assess biases related to occupational associations for different protected categories by intersecting gender with religion, sexuality, ethnicity, political affiliation, and continental name origin. Using a template-based data collection pipeline, we collect 396K sentence completions made by GPT-2 and find: (i) The machine-predicted jobs are less diverse and more stereotypical for women than for men, especially for intersections; (ii) Intersectional interactions are highly relevant for occupational associations, which we quantify by fitting 262 logistic models; (iii) For most occupations, GPT-2 reflects the skewed gender and ethnicity distribution found in US Labor Bureau data, and even pulls the societally-skewed distribution towards gender parity in cases where its predictions deviate from real labor market observations. This raises the normative question of what language models should learn - whether they should reflect or correct for existing inequalities.",
    "citationCount": 218,
    "pdf_filename": "2021_Bias_Out_of_the_Box__An_Empirical_Analys_b41e0734.pdf"
  },
  "7437fb168cea92e1df8332ac618f7f07b071aca8": {
    "paperId": "7437fb168cea92e1df8332ac618f7f07b071aca8",
    "title": "Generative-Discriminative Feature Representations for Open-Set Recognition",
    "year": 2020,
    "authors": "Pramuditha Perera, Vlad I. Morariu, R. Jain, Varun Manjunatha, Curtis Wigington",
    "abstract": "We address the problem of open-set recognition, where the goal is to determine if a given sample belongs to one of the classes used for training a model (known classes). The main challenge in open-set recognition is to disentangle open-set samples that produce high class activations from known-set samples. We propose two techniques to force class activations of open-set samples to be low. First, we train a generative model for all known classes and then augment the input with the representation obtained from the generative model to learn a classifier. This network learns to associate high classification probabilities both when image content is from the correct class as well as when the input and the reconstructed image are consistent with each other. Second, we use self-supervision to force the network to learn more informative featues when assigning class scores to improve separation of classes from each other and from open-set samples. We evaluate the performance of the proposed method with recent open-set recognition works across three datasets, where we obtain state-of-the-art results.",
    "citationCount": 201,
    "pdf_filename": "2020_Generative_Discriminative_Feature_Repres_7437fb16.pdf"
  },
  "4a597a081721e436e20b4e85197072e22aaecfad": {
    "paperId": "4a597a081721e436e20b4e85197072e22aaecfad",
    "title": "From $r$ to $Q^*$: Your Language Model is Secretly a Q-Function",
    "year": 2024,
    "authors": "Rafael Rafailov, Joey Hejna, Ryan Park, Chelsea Finn",
    "abstract": "Reinforcement Learning From Human Feedback (RLHF) has been critical to the success of the latest generation of generative AI models. In response to the complex nature of the classical RLHF pipeline, direct alignment algorithms such as Direct Preference Optimization (DPO) have emerged as an alternative approach. Although DPO solves the same objective as the standard RLHF setup, there is a mismatch between the two approaches. Standard RLHF deploys reinforcement learning in a specific token-level MDP, while DPO is derived as a bandit problem in which the whole response of the model is treated as a single arm. In this work we rectify this difference. We theoretically show that we can derive DPO in the token-level MDP as a general inverse Q-learning algorithm, which satisfies the Bellman equation. Using our theoretical results, we provide three concrete empirical insights. First, we show that because of its token level interpretation, DPO is able to perform some type of credit assignment. Next, we prove that under the token level formulation, classical search-based algorithms, such as MCTS, which have recently been applied to the language generation space, are equivalent to likelihood-based search on a DPO policy. Empirically we show that a simple beam search yields meaningful improvement over the base DPO policy. Finally, we show how the choice of reference policy causes implicit rewards to decline during training. We conclude by discussing applications of our work, including information elicitation in multi-turn dialogue, reasoning, agentic applications and end-to-end training of multi-model systems.",
    "citationCount": 215,
    "pdf_filename": "2024_From__r__to__Q_____Your_Language_Model_i_4a597a08.pdf"
  },
  "77179e5ff669452b9bea479a4236a6e2009ee422": {
    "paperId": "77179e5ff669452b9bea479a4236a6e2009ee422",
    "title": "The Power of Noise: Redefining Retrieval for RAG Systems",
    "year": 2024,
    "authors": "Florin Cuconasu, Giovanni Trappolini, F. Siciliano, Simone Filice, Cesare Campagnano",
    "abstract": "Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area.",
    "citationCount": 287,
    "pdf_filename": "2024_The_Power_of_Noise__Redefining_Retrieval_77179e5f.pdf"
  },
  "03a281a176413ed4d140293edc5bf04a3ad7a1f1": {
    "paperId": "03a281a176413ed4d140293edc5bf04a3ad7a1f1",
    "title": "DragDiffusion: Harnessing Diffusion Models for Interactive Point-Based Image Editing",
    "year": 2023,
    "authors": "Yujun Shi, Chuhui Xue, Jiachun Pan, Wenqing Zhang, Vincent Y. F. Tan",
    "abstract": "Accurate and controllable image editing is a challenging task that has attracted significant attention recently. Notably, DRAGGAN developed by Pan et al. (2023) [33] is an interactive point-based image editing framework that achieves impressive editing results with pixel-level precision. However, due to its reliance on generative adversarial networks (GANs), its generality is limited by the capacity of pretrained GAN models. In this work, we extend this editing framework to diffusion models and propose a novel approach Dragdiffusion. By harnessing large-scale pretrained diffusion models, we greatly enhance the applicability of interactive point-based editing on both real and diffusion-generated images. Unlike other diffusion-based editing methods that provide guidance on diffusion latents of multiple time steps, our approach achieves efficient yet accurate spatial control by optimizing the latent of only one time step. This novel design is motivated by our observations that UNet features at a specific time step provides sufficient semantic and geometric information to support the drag-based editing. Moreover, we introduce two additional techniques, namely identity-preserving fine-tuning and reference-latent-control, to further preserve the identity of the original image. Lastly, we present a challenging benchmark dataset called DRAGBENCH─ the first benchmark to evaluate the performance of interactive point-based image editing methods. Experiments across a wide range of challenging cases (e.g., images with multiple objects, diverse object categories, various styles, etc.) demonstrate the versatility and generality of Dragdiffusion. Code and the Dragbench dataset: https://github.com/Yujun-Shi/DragDiffusion.",
    "citationCount": 296,
    "pdf_filename": "2023_DragDiffusion__Harnessing_Diffusion_Mode_03a281a1.pdf"
  },
  "4299b79ef41601cf6e3e0603f7216d72b6d1315f": {
    "paperId": "4299b79ef41601cf6e3e0603f7216d72b6d1315f",
    "title": "TripoSR: Fast 3D Object Reconstruction from a Single Image",
    "year": 2024,
    "authors": "Dmitry Tochilkin, David Pankratz, Zexiang Liu, Zixuan Huang, Adam Letts",
    "abstract": "This technical report introduces TripoSR, a 3D reconstruction model leveraging transformer architecture for fast feed-forward 3D generation, producing 3D mesh from a single image in under 0.5 seconds. Building upon the LRM network architecture, TripoSR integrates substantial improvements in data processing, model design, and training techniques. Evaluations on public datasets show that TripoSR exhibits superior performance, both quantitatively and qualitatively, compared to other open-source alternatives. Released under the MIT license, TripoSR is intended to empower researchers, developers, and creatives with the latest advancements in 3D generative AI.",
    "citationCount": 206,
    "pdf_filename": "2024_TripoSR__Fast_3D_Object_Reconstruction_f_4299b79e.pdf"
  },
  "536dcef9e5f22bb694bb154120050bfed07f8e90": {
    "paperId": "536dcef9e5f22bb694bb154120050bfed07f8e90",
    "title": "Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers",
    "year": 2023,
    "authors": "Zi-Xin Zou, Zhipeng Yu, Yuanchen Guo, Yangguang Li, Ding Liang",
    "abstract": "Recent advancements in 3D reconstruction from single images have been driven by the evolution of generative models. Prominent among these are methods based on Score Distillation Sampling (SDS) and the adaptation ofdiffusion models in the 3D domain. Despite their progress, these techniques often face limitations due to slow optimization or rendering processes, leading to extensive training and optimization times. In this paper, we introduce a novel approach for single-view reconstruction that efficiently generates a 3D model from a single image via feed-forward inference. Our method utilizes two transformer-based networks, namely a point decoder and a triplane decoder, to reconstruct 3D objects using a hybrid Triplane-Gaussian intermediate representation. This hybrid representation strikes a balance, achieving a faster rendering speed compared to implicit representations while simultaneously delivering superior rendering quality than explicit representations. The point decoder is designed for generating point clouds from single images, offering an explicit representation which is then utilized by the triplane decoder to query Gaussian features for each point. This design choice addresses the challenges associated with directly regressing explicit 3D Gaussian attributes characterized by their non-structural nature. Subsequently, the 3D Gaussians are decoded by an MLP to enable rapid rendering through splatting. Both decoders are built upon a scalable, transformer-based architecture and have been efficiently trained on large-scale 3D datasets. The evaluations conducted on both synthetic datasets and real-world images demonstrate that our method not only achieves higher quality but also ensures a faster runtime in comparison to previous state-of-the-art techniques. Please see our project page at https://zouzx.github.io/TriplaneGaussian/",
    "citationCount": 255,
    "pdf_filename": "2023_Triplane_Meets_Gaussian_Splatting__Fast__536dcef9.pdf"
  },
  "d33be7c99b7265652edbb2b0f832b479e2162ae1": {
    "paperId": "d33be7c99b7265652edbb2b0f832b479e2162ae1",
    "title": "StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis",
    "year": 2023,
    "authors": "Axel Sauer, Tero Karras, S. Laine, Andreas Geiger, Timo Aila",
    "abstract": "Text-to-image synthesis has recently seen significant progress thanks to large pretrained language models, large-scale training data, and the introduction of scalable model families such as diffusion and autoregressive models. However, the best-performing models require iterative evaluation to generate a single sample. In contrast, generative adversarial networks (GANs) only need a single forward pass. They are thus much faster, but they currently remain far behind the state-of-the-art in large-scale text-to-image synthesis. This paper aims to identify the necessary steps to regain competitiveness. Our proposed model, StyleGAN-T, addresses the specific requirements of large-scale text-to-image synthesis, such as large capacity, stable training on diverse datasets, strong text alignment, and controllable variation vs. text alignment tradeoff. StyleGAN-T significantly improves over previous GANs and outperforms distilled diffusion models - the previous state-of-the-art in fast text-to-image synthesis - in terms of sample quality and speed.",
    "citationCount": 258,
    "pdf_filename": "2023_StyleGAN_T__Unlocking_the_Power_of_GANs__d33be7c9.pdf"
  },
  "584915a73b8ff2ce29cf644e388279baa14be550": {
    "paperId": "584915a73b8ff2ce29cf644e388279baa14be550",
    "title": "Geometric Latent Diffusion Models for 3D Molecule Generation",
    "year": 2023,
    "authors": "Minkai Xu, Alexander Powers, R. Dror, Stefano Ermon, J. Leskovec",
    "abstract": "Generative models, especially diffusion models (DMs), have achieved promising results for generating feature-rich geometries and advancing foundational science problems such as molecule design. Inspired by the recent huge success of Stable (latent) Diffusion models, we propose a novel and principled method for 3D molecule generation named Geometric Latent Diffusion Models (GeoLDM). GeoLDM is the first latent DM model for the molecular geometry domain, composed of autoencoders encoding structures into continuous latent codes and DMs operating in the latent space. Our key innovation is that for modeling the 3D molecular geometries, we capture its critical roto-translational equivariance constraints by building a point-structured latent space with both invariant scalars and equivariant tensors. Extensive experiments demonstrate that GeoLDM can consistently achieve better performance on multiple molecule generation benchmarks, with up to 7\\% improvement for the valid percentage of large biomolecules. Results also demonstrate GeoLDM's higher capacity for controllable generation thanks to the latent modeling. Code is provided at \\url{https://github.com/MinkaiXu/GeoLDM}.",
    "citationCount": 214,
    "pdf_filename": "2023_Geometric_Latent_Diffusion_Models_for_3D_584915a7.pdf"
  },
  "be3b3a1c9b39bc9bcc207ce8e0ca5fbb73816089": {
    "paperId": "be3b3a1c9b39bc9bcc207ce8e0ca5fbb73816089",
    "title": "A Comprehensive Overview and Comparative Analysis on Deep Learning Models: CNN, RNN, LSTM, GRU",
    "year": 2023,
    "authors": "Farhad Shiri, Thinagaran Perumal, N. Mustapha, Raihani Mohamed",
    "abstract": "Deep learning (DL) has emerged as a powerful subset of machine learning (ML) and artificial intelligence (AI), outperforming traditional ML methods, especially in handling unstructured and large datasets. Its impact spans across various domains, including speech recognition, healthcare, autonomous vehicles, cybersecurity, predictive analytics, and more. However, the complexity and dynamic nature of real-world problems present challenges in designing effective deep learning models. Consequently, several deep learning models have been developed to address different problems and applications. In this article, we conduct a comprehensive survey of various deep learning models, including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Temporal Convolutional Networks (TCN), Transformer, Kolmogorov-Arnold networks (KAN), Generative Models, Deep Reinforcement Learning (DRL), and Deep Transfer Learning. We examine the structure, applications, benefits, and limitations of each model. Furthermore, we perform an analysis using three publicly available datasets: IMDB, ARAS, and Fruit-360. We compared the performance of six renowned deep learning models: CNN, RNN, Long Short-Term Memory (LSTM), Bidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU alongside two newer models, TCN and Transformer, using the IMDB and ARAS datasets. Additionally, we evaluated the performance of eight CNN-based models, including VGG (Visual Geometry Group), Inception, ResNet (Residual Network), InceptionResNet, Xception (Extreme Inception), MobileNet, DenseNet (Dense Convolutional Network), and NASNet (Neural Architecture Search Network), for image classification tasks using the Fruit-360 dataset.",
    "citationCount": 289,
    "pdf_filename": "2023_A_Comprehensive_Overview_and_Comparative_be3b3a1c.pdf"
  },
  "7e68ab8e1e984e0d97578574088b63141cd646b9": {
    "paperId": "7e68ab8e1e984e0d97578574088b63141cd646b9",
    "title": "Exploring the Boundaries of Reality: Investigating the Phenomenon of Artificial Intelligence Hallucination in Scientific Writing Through ChatGPT References",
    "year": 2023,
    "authors": "Sai Anirudh Athaluri, Sandeep Varma Manthena, V. S. R. K. M. Kesapragada, Vineel Yarlagadda, Tirth Dave",
    "abstract": "Background Chatbots are computer programs that use artificial intelligence (AI) and natural language processing (NLP) to simulate conversations with humans. One such chatbot is ChatGPT, which uses the third-generation generative pre-trained transformer (GPT-3) developed by OpenAI. ChatGPT has been praised for its ability to generate text, but concerns have been raised about its accuracy and precision in generating data, as well as legal issues related to references. This study aims to investigate the frequency of AI hallucination in research proposals entirely drafted by ChatGPT. Methodology An analytical design was employed to investigate AI hallucination by ChatGPT. A total of 178 references listed by ChatGPT were verified for inclusion in the study. Statistical analysis was performed by five researchers who entered their data into a Google Form, and the final results were represented using pie charts and tables. Results Out of the 178 references analyzed, 69 references did not have a Digital Object Identifier (DOI), and 28 references neither turned up on Google search nor had an existing DOI. Three references were listed from books and not research articles. These observations suggest that ChatGPT’s ability to generate reliable references for research topics may be limited by the availability of DOI and the accessibility of online articles. Conclusions The study highlights the potential limitations of ChatGPT’s ability to generate reliable references for research proposals. AI hallucination is a problem that may negatively impact decision-making and may give rise to ethical and legal problems. Improving the training inputs by including diverse, accurate, and contextually relevant data sets along with frequent updates to the training models could potentially help address these issues. However, until these issues are addressed, researchers using ChatGPT should exercise caution in relying solely on the references generated by the AI chatbot.",
    "citationCount": 261,
    "pdf_filename": "2023_Exploring_the_Boundaries_of_Reality__Inv_7e68ab8e.pdf"
  },
  "d91bd7bdea31775302a8a0b997b6d67bf20ac297": {
    "paperId": "d91bd7bdea31775302a8a0b997b6d67bf20ac297",
    "title": "Can ChatGPT Write a Good Boolean Query for Systematic Review Literature Search?",
    "year": 2023,
    "authors": "Shuai Wang, Harrisen Scells, B. Koopman, G. Zuccon",
    "abstract": "Systematic reviews are comprehensive literature reviews for a highly focused research question. These reviews are considered the highest form of evidence in medicine. Complex Boolean queries are developed as part of the systematic review creation process to retrieve literature, as they permit reproducibility and understandability. However, it is difficult and time-consuming to develop high-quality Boolean queries, often requiring the expertise of expert searchers like librarians. Recent advances in transformer-based generative models have shown their ability to effectively follow user instructions and generate answers based on these instructions. In this paper, we investigate ChatGPT as a means for automatically formulating and refining complex Boolean queries for systematic review literature search. Overall, our research finds that ChatGPT has the potential to generate effective Boolean queries. The ability of ChatGPT to follow complex instructions and generate highly precise queries makes it a tool of potential value for researchers conducting systematic reviews, particularly for rapid reviews where time is a constraint and where one can trade off higher precision for lower recall. We also identify several caveats in using ChatGPT for this task, highlighting that this technology needs further validation before it is suitable for widespread uptake.",
    "citationCount": 210,
    "pdf_filename": "2023_Can_ChatGPT_Write_a_Good_Boolean_Query_f_d91bd7bd.pdf"
  },
  "5fedb29a5068a3c0e576bfb5a0cf52afab20db60": {
    "paperId": "5fedb29a5068a3c0e576bfb5a0cf52afab20db60",
    "title": "A multilevel review of artificial intelligence in organizations: Implications for organizational behavior research and practice",
    "year": 2023,
    "authors": "Sarah Bankins, A. C. Ocampo, Mauricio Marrone, S. Restubog, S. E. Woo",
    "abstract": "The rising use of artificially intelligent (AI) technologies, including generative AI tools, in organizations is undeniable. As these systems become increasingly integrated into organizational practices and processes, understanding their impact on workers' experiences and job designs is critical. However, the ongoing discourse surrounding AI use in the workplace remains divided. Proponents of the technology extol its benefits for enhancing efficiency and productivity, while others voice concerns about the potential harm to human workers. To provide greater clarity on this pressing issue, this article presents a systematic review of empirical research that sheds light on the implications of AI use at work. Organized under five inductively generated themes within a multilevel framework, we uncover individual, group, and organizational factors that shape the interplay between humans and AI. Specifically, the themes are: (1) human–AI collaboration; (2) perceptions of algorithmic and human capabilities; (3) worker attitudes towards AI; (4) AI as a control mechanism in algorithmic management of platform‐based work; and (5) labor market implications of AI use. Our review offers insights into these themes and identifies five pathways for future research. Finally, we provide practical recommendations for organizational leaders seeking to implement AI technologies while prioritizing their employees' well‐being.",
    "citationCount": 274,
    "pdf_filename": "2023_A_multilevel_review_of_artificial_intell_5fedb29a.pdf"
  },
  "9f411fda2ad5b141a3115f707bcf5ee865b3fb94": {
    "paperId": "9f411fda2ad5b141a3115f707bcf5ee865b3fb94",
    "title": "Any-to-Any Generation via Composable Diffusion",
    "year": 2023,
    "authors": "Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, Mohit Bansal",
    "abstract": "We present Composable Diffusion (CoDi), a novel generative model capable of generating any combination of output modalities, such as language, image, video, or audio, from any combination of input modalities. Unlike existing generative AI systems, CoDi can generate multiple modalities in parallel and its input is not limited to a subset of modalities like text or image. Despite the absence of training datasets for many combinations of modalities, we propose to align modalities in both the input and output space. This allows CoDi to freely condition on any input combination and generate any group of modalities, even if they are not present in the training data. CoDi employs a novel composable generation strategy which involves building a shared multimodal space by bridging alignment in the diffusion process, enabling the synchronized generation of intertwined modalities, such as temporally aligned video and audio. Highly customizable and flexible, CoDi achieves strong joint-modality generation quality, and outperforms or is on par with the unimodal state-of-the-art for single-modality synthesis. The project page with demonstrations and code is at https://codi-gen.github.io",
    "citationCount": 234,
    "pdf_filename": "2023_Any_to_Any_Generation_via_Composable_Dif_9f411fda.pdf"
  },
  "13afd3c131dbb836bf9c6c65466ca8f5234bca11": {
    "paperId": "13afd3c131dbb836bf9c6c65466ca8f5234bca11",
    "title": "Deep Learning Approaches for Data Augmentation in Medical Imaging: A Review",
    "year": 2023,
    "authors": "Aghiles Kebaili, J. Lapuyade-Lahorgue, S. Ruan",
    "abstract": "Deep learning has become a popular tool for medical image analysis, but the limited availability of training data remains a major challenge, particularly in the medical field where data acquisition can be costly and subject to privacy regulations. Data augmentation techniques offer a solution by artificially increasing the number of training samples, but these techniques often produce limited and unconvincing results. To address this issue, a growing number of studies have proposed the use of deep generative models to generate more realistic and diverse data that conform to the true distribution of the data. In this review, we focus on three types of deep generative models for medical image augmentation: variational autoencoders, generative adversarial networks, and diffusion models. We provide an overview of the current state of the art in each of these models and discuss their potential for use in different downstream tasks in medical imaging, including classification, segmentation, and cross-modal translation. We also evaluate the strengths and limitations of each model and suggest directions for future research in this field. Our goal is to provide a comprehensive review about the use of deep generative models for medical image augmentation and to highlight the potential of these models for improving the performance of deep learning algorithms in medical image analysis.",
    "citationCount": 204,
    "pdf_filename": "2023_Deep_Learning_Approaches_for_Data_Augmen_13afd3c1.pdf"
  },
  "7a36247b89384236e795c5bbddba1bdb68c5bf28": {
    "paperId": "7a36247b89384236e795c5bbddba1bdb68c5bf28",
    "title": "A large-scale comparison of human-written versus ChatGPT-generated essays",
    "year": 2023,
    "authors": "Steffen Herbold, Annette Hautli-Janisz, Ute Heuer, Zlata Kikteva, Alexander Trautsch",
    "abstract": "ChatGPT and similar generative AI models have attracted hundreds of millions of users and have become part of the public discourse. Many believe that such models will disrupt society and lead to significant changes in the education system and information generation. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models—both lack scientific rigor. We systematically assess the quality of AI-generated content through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays. We use essays that were rated by a large number of human experts (teachers). We augment the analysis by considering a set of linguistic characteristics of the generated essays. Our results demonstrate that ChatGPT generates essays that are rated higher regarding quality than human-written essays. The writing style of the AI models exhibits linguistic characteristics that are different from those of the human-written essays. Since the technology is readily available, we believe that educators must act immediately. We must re-invent homework and develop teaching concepts that utilize these AI models in the same way as math utilizes the calculator: teach the general concepts first and then use AI tools to free up time for other learning objectives.",
    "citationCount": 252,
    "pdf_filename": "2023_A_large_scale_comparison_of_human_writte_7a36247b.pdf"
  },
  "b9505b57bf41d127ab786fd0d6c0a0fae7e69f07": {
    "paperId": "b9505b57bf41d127ab786fd0d6c0a0fae7e69f07",
    "title": "ChatGPT for Education and Research: A Review of Benefits and Risks",
    "year": 2023,
    "authors": "Sarin Sok, Kimkong Heng",
    "abstract": "Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI) tool that can quickly generate detailed responses to prompts and follow-up questions. This emerging AI tool was launched in November 2022 by an American AI research laboratory, called OpenAI, using large language models. In this article, the benefits and risks related to the use of ChatGPT in education and research are discussed. The article argues that ChatGPT has at least five main benefits, such as creating learning assessment, enhancing pedagogical practice, offering virtual personal tutoring, creating an essay or research article outline, and brainstorming ideas. However, there are risks related to academic integrity issues, unfair learning assessment, inaccurate information, and over-reliance on AI. The article offers a set of recommendations for effective use of ChatGPT for educational and research purposes.",
    "citationCount": 256,
    "pdf_filename": "2023_ChatGPT_for_Education_and_Research__A_Re_b9505b57.pdf"
  },
  "276f6117b8b8549a47461653b95e657278260ee3": {
    "paperId": "276f6117b8b8549a47461653b95e657278260ee3",
    "title": "HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models",
    "year": 2023,
    "authors": "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Wei Wei, Tingbo Hou",
    "abstract": "Personalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities. However, the process of personalization presents inherent challenges in terms of time and memory requirements. Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity. To overcome these challenges, we propose HyperDreamBooth—a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person. By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications. Our method achieves personalization on faces in roughly 20 seconds, 25x faster than DreamBooth and 125x faster than Textual Inversion, using as few as one reference image, with the same quality and style diversity as DreamBooth. Also our method yields a model that is 10,000x smaller than a normal DreamBooth model.",
    "citationCount": 220,
    "pdf_filename": "2023_HyperDreamBooth__HyperNetworks_for_Fast__276f6117.pdf"
  },
  "dfc66a53c836846d524765f44e111c94ebd2ad37": {
    "paperId": "dfc66a53c836846d524765f44e111c94ebd2ad37",
    "title": "Impact of Artificial Intelligence on Dental Education: A Review and Guide for Curriculum Update",
    "year": 2023,
    "authors": "Andrej Thurzo, Martin Strunga, R. Urban, Jana Surovková, K. Afrashtehfar",
    "abstract": "In this intellectual work, the clinical and educational aspects of dentistry were confronted with practical applications of artificial intelligence (AI). The aim was to provide an up-to-date overview of the upcoming changes and a brief analysis of the influential advancements in the use of AI in dental education since 2020. In addition, this review provides a guide for a dental curriculum update for undergraduate and postgraduate education in the context of advances in AI applications and their impact on dentistry. Unsurprisingly, most dental educators have limited knowledge and skills to assess AI applications, as they were not trained to do so. Also, AI technology has evolved exponentially in recent years. Factual reliability and opportunities with OpenAI Inc.’s ChatGPT are considered critical inflection points in the era of generative AI. Updating curricula at dental institutions is inevitable as advanced deep-learning approaches take over the clinical areas of dentistry and reshape diagnostics, treatment planning, management, and telemedicine screening. With recent advances in AI language models, communication with patients will change, and the foundations of dental education, including essay, thesis, or scientific paper writing, will need to adapt. However, there is a growing concern about its ethical and legal implications, and further consensus is needed for the safe and responsible implementation of AI in dental education.",
    "citationCount": 233,
    "pdf_filename": "2023_Impact_of_Artificial_Intelligence_on_Den_dfc66a53.pdf"
  },
  "6f648aeb5c5219cf021840eaf3df03ac86cebff4": {
    "paperId": "6f648aeb5c5219cf021840eaf3df03ac86cebff4",
    "title": "The Stable Signature: Rooting Watermarks in Latent Diffusion Models",
    "year": 2023,
    "authors": "Pierre Fernandez, Guillaume Couairon, Herv'e J'egou, Matthijs Douze, T. Furon",
    "abstract": "Generative image modeling enables a wide range of applications but raises ethical concerns about responsible deployment. We introduce an active content tracing method combining image watermarking and Latent Diffusion Models. The goal is for all generated images to conceal an invisible watermark allowing for future detection and/or identification. The method quickly fine-tunes the latent decoder of the image generator, conditioned on a binary signature. A pre-trained watermark extractor recovers the hidden signature from any generated image and a statistical test then determines whether it comes from the generative model. We evaluate the invisibility and robustness of the watermarks on a variety of generation tasks, showing that the Stable Signature is robust to image modifications. For instance, it detects the origin of an image generated from a text prompt, then cropped to keep 10% of the content, with 90+% accuracy at a false positive rate below 10−6.",
    "citationCount": 279,
    "pdf_filename": "2023_The_Stable_Signature__Rooting_Watermarks_6f648aeb.pdf"
  },
  "256979852e0e0a5fe5cc8ddbf54fa1af2a843722": {
    "paperId": "256979852e0e0a5fe5cc8ddbf54fa1af2a843722",
    "title": "ChatGPT for shaping the future of dentistry: the potential of multi-modal large language model",
    "year": 2023,
    "authors": "Hanyao Huang, Ou Zheng, Dongdong Wang, Jiayi Yin, Zijin Wang",
    "abstract": "The ChatGPT, a lite and conversational variant of Generative Pretrained Transformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large Language Models (LLMs) with billions of parameters. LLMs have stirred up much interest among researchers and practitioners in their impressive skills in natural language processing tasks, which profoundly impact various fields. This paper mainly discusses the future applications of LLMs in dentistry. We introduce two primary LLM deployment methods in dentistry, including automated dental diagnosis and cross-modal dental diagnosis, and examine their potential applications. Especially, equipped with a cross-modal encoder, a single LLM can manage multi-source data and conduct advanced natural language reasoning to perform complex clinical operations. We also present cases to demonstrate the potential of a fully automatic Multi-Modal LLM AI system for dentistry clinical application. While LLMs offer significant potential benefits, the challenges, such as data privacy, data quality, and model bias, need further study. Overall, LLMs have the potential to revolutionize dental diagnosis and treatment, which indicates a promising avenue for clinical application and research in dentistry.",
    "citationCount": 237,
    "pdf_filename": "2023_ChatGPT_for_shaping_the_future_of_dentis_25697985.pdf"
  },
  "2147a7112a24ef01f6492b5fafcd852f89101a64": {
    "paperId": "2147a7112a24ef01f6492b5fafcd852f89101a64",
    "title": "ChatGPT and the hospitality and tourism industry: an overview of current trends and future research directions",
    "year": 2023,
    "authors": "D. Gursoy, Yu Li, Hakjun Song",
    "abstract": "ABSTRACT Since its launch, ChatGPT, an artificial intelligence chatbot developed by Open AI based on the premises of generative pre-trained transformer autoregressive language models, has gained widespread popularity and is making significant impact on society with its unique features, such as natural language processing and contextual awareness. ChatGPT is viewed as a major disruptive innovation that is likely to revolutionize the operations in many industries including the hospitality and tourism industry. The adoption of ChatGPT will result in substantial changes throughout the hospitality and tourism industry by disrupting how customer search for information, make decisions, and how businesses produce, create, and deliver customized services and experiences. This conceptual paper provides a comprehensive discussion on generative pre-trained transformers’ (GPTs) benefits, and potential challenges and threats they pose to the hospitality and tourism industry. The feasibility of integrating GPT into different travel stages and decision-making processes is also discussed. The article concludes by proposing a potential future research agenda on using GPT in creating and delivering hospitality and tourism experiences, which can guide further advancements in the field.",
    "citationCount": 234,
    "pdf_filename": "2023_ChatGPT_and_the_hospitality_and_tourism__2147a711.pdf"
  },
  "b88142ec8741e74ddb3ee17d32bce0c6f84839d4": {
    "paperId": "b88142ec8741e74ddb3ee17d32bce0c6f84839d4",
    "title": "Artificial Intelligence Can Generate Fraudulent but Authentic-Looking Scientific Medical Articles: Pandora’s Box Has Been Opened",
    "year": 2023,
    "authors": "M. Májovský, M. Černý, Matěj Kasal, M. Komarc, D. Netuka",
    "abstract": "Background Artificial intelligence (AI) has advanced substantially in recent years, transforming many industries and improving the way people live and work. In scientific research, AI can enhance the quality and efficiency of data analysis and publication. However, AI has also opened up the possibility of generating high-quality fraudulent papers that are difficult to detect, raising important questions about the integrity of scientific research and the trustworthiness of published papers. Objective The aim of this study was to investigate the capabilities of current AI language models in generating high-quality fraudulent medical articles. We hypothesized that modern AI models can create highly convincing fraudulent papers that can easily deceive readers and even experienced researchers. Methods This proof-of-concept study used ChatGPT (Chat Generative Pre-trained Transformer) powered by the GPT-3 (Generative Pre-trained Transformer 3) language model to generate a fraudulent scientific article related to neurosurgery. GPT-3 is a large language model developed by OpenAI that uses deep learning algorithms to generate human-like text in response to prompts given by users. The model was trained on a massive corpus of text from the internet and is capable of generating high-quality text in a variety of languages and on various topics. The authors posed questions and prompts to the model and refined them iteratively as the model generated the responses. The goal was to create a completely fabricated article including the abstract, introduction, material and methods, discussion, references, charts, etc. Once the article was generated, it was reviewed for accuracy and coherence by experts in the fields of neurosurgery, psychiatry, and statistics and compared to existing similar articles. Results The study found that the AI language model can create a highly convincing fraudulent article that resembled a genuine scientific paper in terms of word usage, sentence structure, and overall composition. The AI-generated article included standard sections such as introduction, material and methods, results, and discussion, as well a data sheet. It consisted of 1992 words and 17 citations, and the whole process of article creation took approximately 1 hour without any special training of the human user. However, there were some concerns and specific mistakes identified in the generated article, specifically in the references. Conclusions The study demonstrates the potential of current AI language models to generate completely fabricated scientific articles. Although the papers look sophisticated and seemingly flawless, expert readers may identify semantic inaccuracies and errors upon closer inspection. We highlight the need for increased vigilance and better detection methods to combat the potential misuse of AI in scientific research. At the same time, it is important to recognize the potential benefits of using AI language models in genuine scientific writing and research, such as manuscript preparation and language editing.",
    "citationCount": 241,
    "pdf_filename": "2023_Artificial_Intelligence_Can_Generate_Fra_b88142ec.pdf"
  },
  "e416da90b398b6c598662bc4b4310b46fa9ca96f": {
    "paperId": "e416da90b398b6c598662bc4b4310b46fa9ca96f",
    "title": "User Intentions to Use ChatGPT for Self-Diagnosis and Health-Related Purposes: Cross-sectional Survey Study",
    "year": 2023,
    "authors": "Yeganeh Shahsavar, Avishek Choudhury",
    "abstract": "Background With the rapid advancement of artificial intelligence (AI) technologies, AI-powered chatbots, such as Chat Generative Pretrained Transformer (ChatGPT), have emerged as potential tools for various applications, including health care. However, ChatGPT is not specifically designed for health care purposes, and its use for self-diagnosis raises concerns regarding its adoption’s potential risks and benefits. Users are increasingly inclined to use ChatGPT for self-diagnosis, necessitating a deeper understanding of the factors driving this trend. Objective This study aims to investigate the factors influencing users’ perception of decision-making processes and intentions to use ChatGPT for self-diagnosis and to explore the implications of these findings for the safe and effective integration of AI chatbots in health care. Methods A cross-sectional survey design was used, and data were collected from 607 participants. The relationships between performance expectancy, risk-reward appraisal, decision-making, and intention to use ChatGPT for self-diagnosis were analyzed using partial least squares structural equation modeling (PLS-SEM). Results Most respondents were willing to use ChatGPT for self-diagnosis (n=476, 78.4%). The model demonstrated satisfactory explanatory power, accounting for 52.4% of the variance in decision-making and 38.1% in the intent to use ChatGPT for self-diagnosis. The results supported all 3 hypotheses: The higher performance expectancy of ChatGPT (β=.547, 95% CI 0.474-0.620) and positive risk-reward appraisals (β=.245, 95% CI 0.161-0.325) were positively associated with the improved perception of decision-making outcomes among users, and enhanced perception of decision-making processes involving ChatGPT positively impacted users’ intentions to use the technology for self-diagnosis (β=.565, 95% CI 0.498-0.628). Conclusions Our research investigated factors influencing users’ intentions to use ChatGPT for self-diagnosis and health-related purposes. Even though the technology is not specifically designed for health care, people are inclined to use ChatGPT in health care contexts. Instead of solely focusing on discouraging its use for health care purposes, we advocate for improving the technology and adapting it for suitable health care applications. Our study highlights the importance of collaboration among AI developers, health care providers, and policy makers in ensuring AI chatbots’ safe and responsible use in health care. By understanding users’ expectations and decision-making processes, we can develop AI chatbots, such as ChatGPT, that are tailored to human needs, providing reliable and verified health information sources. This approach not only enhances health care accessibility but also improves health literacy and awareness. As the field of AI chatbots in health care continues to evolve, future research should explore the long-term effects of using AI chatbots for self-diagnosis and investigate their potential integration with other digital health interventions to optimize patient care and outcomes. In doing so, we can ensure that AI chatbots, including ChatGPT, are designed and implemented to safeguard users’ well-being and support positive health outcomes in health care settings.",
    "citationCount": 205,
    "pdf_filename": "2023_User_Intentions_to_Use_ChatGPT_for_Self__e416da90.pdf"
  },
  "3c46517c408b36ee4e9a64666e6b7735a92dd2ce": {
    "paperId": "3c46517c408b36ee4e9a64666e6b7735a92dd2ce",
    "title": "Can ChatGPT draft a research article? An example of population-level vaccine effectiveness analysis",
    "year": 2023,
    "authors": "Calum Macdonald, Davies Adeloye, Aziz Sheikh, I. Rudan",
    "abstract": "We reflect on our experiences of using Generative Pre-trained Transformer ChatGPT, a chatbot launched by OpenAI in November 2022, to draft a research article. We aim to demonstrate how ChatGPT could help researchers to accelerate drafting their papers. We created a simulated data set of 100 000 health care workers with varying ages, Body Mass Index (BMI), and risk profiles. Simulation data allow analysts to test statistical analysis techniques, such as machine-learning based approaches, without compromising patient privacy. Infections were simulated with a randomized probability of hospitalisation. A subset of these fictitious people was vaccinated with a fictional vaccine that reduced this probability of hospitalisation after infection. We then used ChatGPT to help us decide how to handle the simulated data in order to determine vaccine effectiveness and draft a related research paper. AI-based language models in data analysis and scientific writing are an area of growing interest, and this exemplar analysis aims to contribute to the understanding of how ChatGPT can be used to facilitate these tasks.",
    "citationCount": 209,
    "pdf_filename": "2023_Can_ChatGPT_draft_a_research_article__An_3c46517c.pdf"
  },
  "2bdfd1fdf0b0c5dd9cf8414dc900cefac3d7d598": {
    "paperId": "2bdfd1fdf0b0c5dd9cf8414dc900cefac3d7d598",
    "title": "Artificial intelligence in logistics and supply chain management: A primer and roadmap for research",
    "year": 2023,
    "authors": "R. Richey, Soumyadeb Chowdhury, Beth Davis‐Sramek, M. Giannakis, Yogesh K. Dwivedi",
    "abstract": "The dawn of generative artificial intelligence (AI) has the potential to transform logistics and supply chain management radically. However, this promising innovation is met with a scholarly discourse grappling with an interplay between the promising capabilities and potential drawbacks. This conversation frequently includes dystopian forecasts of mass unemployment and detrimental repercussions concerning academic research integrity. Despite the current hype, existing research exploring the intersection between AI and the logistics and supply chain management (L&SCM) sector remains limited. Therefore, this editorial seeks to fill this void, synthesizing the potential applications of AI within the L&SCM domain alongside an analysis of the implementation challenges. In doing so, we propose a robust research framework as a primer and roadmap for future research. This will give researchers and organizations comprehensive insights and strategies to navigate the complex yet promising landscape of AI integration within the L&SCM domain.",
    "citationCount": 213,
    "pdf_filename": "2023_Artificial_intelligence_in_logistics_and_2bdfd1fd.pdf"
  },
  "4702d5a163477c734a54f3ed2d171dca1504eaae": {
    "paperId": "4702d5a163477c734a54f3ed2d171dca1504eaae",
    "title": "Your Diffusion Model is Secretly a Zero-Shot Classifier",
    "year": 2023,
    "authors": "Alexander C. Li, Mihir Prabhudesai, Shivam Duggal, Ellis Brown, Deepak Pathak",
    "abstract": "The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification, which we call Diffusion Classifier, attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. Although a gap remains between generative and discriminative approaches on zero-shot recognition tasks, our diffusion-based approach has stronger multimodal compositional reasoning abilities than competing discriminative approaches. Finally, we use Diffusion Classifier to extract standard classifiers from class-conditional diffusion models trained on ImageNet. These models approach the performance of SOTA discriminative classifiers and exhibit strong \"effective robustness\" to distribution shift. Overall, our results are a step toward using generative over discriminative models for downstream tasks. Results and visualizations on our website: diffusion-classifier.github.io/",
    "citationCount": 299,
    "pdf_filename": "2023_Your_Diffusion_Model_is_Secretly_a_Zero__4702d5a1.pdf"
  },
  "df2bbeb3a2dba8e6b3e9703637c2a0d09e29654b": {
    "paperId": "df2bbeb3a2dba8e6b3e9703637c2a0d09e29654b",
    "title": "SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution",
    "year": 2023,
    "authors": "Rongyuan Wu, Tao Yang, Lingchen Sun, Zhengqiang Zhang, Shuai Li",
    "abstract": "Owe to the powerful generative priors, the pretrained text-to-image (T2I) diffusion models have become increasingly popular in solving the real-world image super-resolution problem. However, as a consequence of the heavy quality degradation of input low-resolution (LR) images, the destruction of local structures can lead to ambiguous image semantics. As a result, the content of reproduced high-resolution image may have semantic errors, deteriorating the super-resolution performance. To address this issue, we present a semantics-aware approach to better preserve the semantic fidelity of generative real-world image super-resolution. First, we train a degradation-aware prompt extractor, which can generate accurate soft and hard semantic prompts even under strong degradation. The hard semantic prompts refer to the image tags, aiming to enhance the local perception ability of the T2I model, while the soft semantic prompts compensate for the hard ones to provide additional representation information. These semantic prompts encourage the T2I model to generate detailed and semantically accurate results. Further-more, during the inference process, we integrate the LR images into the initial sampling noise to mitigate the diffusion model's tendency to generate excessive random details. The experiments show that our method can reproduce more realistic image details and hold better the semantics. The source code of our method can be found at https://github.com/cswry/SeeSR.",
    "citationCount": 234,
    "pdf_filename": "2023_SeeSR__Towards_Semantics_Aware_Real_Worl_df2bbeb3.pdf"
  },
  "7b689adb8c156d6158660f90d1c86888ee281f63": {
    "paperId": "7b689adb8c156d6158660f90d1c86888ee281f63",
    "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation",
    "year": 2023,
    "authors": "Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge",
    "abstract": "This paper presents DreamLLM, a learning framework that first achieves versatile Multimodal Large Language Models (MLLMs) empowered with frequently overlooked synergy between multimodal comprehension and creation. DreamLLM operates on two fundamental principles. The first focuses on the generative modeling of both language and image posteriors by direct sampling in the raw multimodal space. This approach circumvents the limitations and information loss inherent to external feature extractors like CLIP, and a more thorough multimodal understanding is obtained. Second, DreamLLM fosters the generation of raw, interleaved documents, modeling both text and image contents, along with unstructured layouts. This allows DreamLLM to learn all conditional, marginal, and joint multimodal distributions effectively. As a result, DreamLLM is the first MLLM capable of generating free-form interleaved content. Comprehensive experiments highlight DreamLLM's superior performance as a zero-shot multimodal generalist, reaping from the enhanced learning synergy. Project page: https://dreamllm.github.io.",
    "citationCount": 268,
    "pdf_filename": "2023_DreamLLM__Synergistic_Multimodal_Compreh_7b689adb.pdf"
  },
  "8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b": {
    "paperId": "8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b",
    "title": "Language is All a Graph Needs",
    "year": 2023,
    "authors": "Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, Yongfeng Zhang",
    "abstract": "The emergence of large-scale pre-trained language models has revolutionized various AI research domains. Transformers-based Large Language Models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with independent data like images, videos or texts, graphs usually contain rich structural and relational information. Meanwhile, languages, especially natural language, being one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph problems into the generative language modeling framework remains very limited. Considering the rising prominence of LLMs, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model) with highly scalable prompts based on natural language instructions. We use natural language to describe multi-scale geometric structure of the graph and then instruction finetune an LLM to perform graph tasks, which enables Generative Graph Learning. Our method surpasses all GNN baselines on ogbn-arxiv, Cora and PubMed datasets, underscoring its effectiveness and sheds light on generative LLMs as new foundation model for graph machine learning. Our code is available at https://github.com/agiresearch/InstructGLM.",
    "citationCount": 229,
    "pdf_filename": "2023_Language_is_All_a_Graph_Needs_8d65b594.pdf"
  },
  "81244a5f36534b41d6265d259082933d951c503e": {
    "paperId": "81244a5f36534b41d6265d259082933d951c503e",
    "title": "FLUX.1 Kontext: Flow Matching for In-Context Image Generation and Editing in Latent Space",
    "year": 2025,
    "authors": "Black Forest Labs, Stephen Batifol, A. Blattmann, Frederic Boesel, Saksham Consul",
    "abstract": "We present evaluation results for FLUX.1 Kontext, a generative flow matching model that unifies image generation and editing. The model generates novel output views by incorporating semantic context from text and image inputs. Using a simple sequence concatenation approach, FLUX.1 Kontext handles both local editing and generative in-context tasks within a single unified architecture. Compared to current editing models that exhibit degradation in character consistency and stability across multiple turns, we observe that FLUX.1 Kontext improved preservation of objects and characters, leading to greater robustness in iterative workflows. The model achieves competitive performance with current state-of-the-art systems while delivering significantly faster generation times, enabling interactive applications and rapid prototyping workflows. To validate these improvements, we introduce KontextBench, a comprehensive benchmark with 1026 image-prompt pairs covering five task categories: local editing, global editing, character reference, style reference and text editing. Detailed evaluations show the superior performance of FLUX.1 Kontext in terms of both single-turn quality and multi-turn consistency, setting new standards for unified image processing models.",
    "citationCount": 258,
    "pdf_filename": "2025_FLUX_1_Kontext__Flow_Matching_for_In_Con_81244a5f.pdf"
  },
  "ec41ad3a2a538da7eda1a7b0979d6904ade17d82": {
    "paperId": "ec41ad3a2a538da7eda1a7b0979d6904ade17d82",
    "title": "Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance",
    "year": 2024,
    "authors": "Shenhao Zhu, Junming Leo Chen, Zuozhuo Dai, Yinghui Xu, Xun Cao",
    "abstract": "In this study, we introduce a methodology for human image animation by leveraging a 3D human parametric model within a latent diffusion framework to enhance shape alignment and motion guidance in curernt human generative techniques. The methodology utilizes the SMPL(Skinned Multi-Person Linear) model as the 3D human parametric model to establish a unified representation of body shape and pose. This facilitates the accurate capture of intricate human geometry and motion characteristics from source videos. Specifically, we incorporate rendered depth images, normal maps, and semantic maps obtained from SMPL sequences, alongside skeleton-based motion guidance, to enrich the conditions to the latent diffusion model with comprehensive 3D shape and detailed pose attributes. A multi-layer motion fusion module, integrating self-attention mechanisms, is employed to fuse the shape and motion latent representations in the spatial domain. By representing the 3D human parametric model as the motion guidance, we can perform parametric shape alignment of the human body between the reference image and the source video motion. Experimental evaluations conducted on benchmark datasets demonstrate the methodology's superior ability to generate high-quality human animations that accurately capture both pose and shape variations. Furthermore, our approach also exhibits superior generalization capabilities on the proposed in-the-wild dataset. Project page: https://fudan-generative-vision.github.io/champ.",
    "citationCount": 211,
    "pdf_filename": "2024_Champ__Controllable_and_Consistent_Human_ec41ad3a.pdf"
  },
  "ff091e91b74452924b1f8105731dbf15f358f875": {
    "paperId": "ff091e91b74452924b1f8105731dbf15f358f875",
    "title": "Deep learning model to predict complex stress and strain fields in hierarchical composites",
    "year": 2021,
    "authors": "Zhenze Yang, Chi-Hua Yu, M. Buehler",
    "abstract": "Deep learning predicts mechanical fields in hierarchical composites, as an alternative to conventional numerical methods. Materials-by-design is a paradigm to develop previously unknown high-performance materials. However, finding materials with superior properties is often computationally or experimentally intractable because of the astronomical number of combinations in design space. Here we report an AI-based approach, implemented in a game theory–based conditional generative adversarial neural network (cGAN), to bridge the gap between a material’s microstructure—the design space—and physical performance. Our end-to-end deep learning model predicts physical fields like stress or strain directly from the material microstructure geometry, and reaches an astonishing accuracy not only for predicted field data but also for derivative material property predictions. Furthermore, the proposed approach offers extensibility by predicting complex materials behavior regardless of component shapes, boundary conditions, and geometrical hierarchy, providing perspectives of performing physical modeling and simulations. The method vastly improves the efficiency of evaluating physical properties of hierarchical materials directly from the geometry of its structural makeup.",
    "citationCount": 269,
    "pdf_filename": "2021_Deep_learning_model_to_predict_complex_s_ff091e91.pdf"
  },
  "f5c165b6317896a65151050201c737536fa17c31": {
    "paperId": "f5c165b6317896a65151050201c737536fa17c31",
    "title": "mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections",
    "year": 2022,
    "authors": "Chenliang Li, Haiyang Xu, Junfeng Tian, Wei Wang, Ming Yan",
    "abstract": "Large-scale pre-trained foundation models have been an emerging paradigm for building artificial intelligence (AI) systems, which can be quickly adapted to a wide range of downstream tasks. This paper presents mPLUG, a new vision-language foundation model for both cross-modal understanding and generation. Most existing pre-trained models suffer from inefficiency and linguistic signal overwhelmed by long visual sequences in cross-modal alignment. To address both problems, mPLUG introduces an effective and efficient vision-language architecture with novel cross-modal skip-connections.mPLUG is pre-trained end-to-end on large-scale image-text pairs with both discriminative and generative objectives. It achieves state-of-the-art results on a wide range of vision-language downstream tasks, including image captioning, image-text retrieval, visual grounding and visual question answering. mPLUG also demonstrates strong zero-shot transferability on vision-language and video-language tasks. The code and pre-trained models are available at https://github.com/alibaba/AliceMind",
    "citationCount": 264,
    "pdf_filename": "2022_mPLUG__Effective_and_Efficient_Vision_La_f5c165b6.pdf"
  },
  "6b59cd34fe244592b8e5a364d1bb89a8a3b4c535": {
    "paperId": "6b59cd34fe244592b8e5a364d1bb89a8a3b4c535",
    "title": "GANs for Medical Image Synthesis: An Empirical Study",
    "year": 2021,
    "authors": "Youssef Skandarani, Pierre-Marc Jodoin, A. Lalande",
    "abstract": "Generative adversarial networks (GANs) have become increasingly powerful, generating mind-blowing photorealistic images that mimic the content of datasets they have been trained to replicate. One recurrent theme in medical imaging, is whether GANs can also be as effective at generating workable medical data, as they are for generating realistic RGB images. In this paper, we perform a multi-GAN and multi-application study, to gauge the benefits of GANs in medical imaging. We tested various GAN architectures, from basic DCGAN to more sophisticated style-based GANs, on three medical imaging modalities and organs, namely: cardiac cine-MRI, liver CT, and RGB retina images. GANs were trained on well-known and widely utilized datasets, from which their FID scores were computed, to measure the visual acuity of their generated images. We further tested their usefulness by measuring the segmentation accuracy of a U-Net trained on these generated images and the original data. The results reveal that GANs are far from being equal, as some are ill-suited for medical imaging applications, while others performed much better. The top-performing GANs are capable of generating realistic-looking medical images by FID standards, that can fool trained experts in a visual Turing test and comply to some metrics. However, segmentation results suggest that no GAN is capable of reproducing the full richness of medical datasets.",
    "citationCount": 227,
    "pdf_filename": "2021_GANs_for_Medical_Image_Synthesis__An_Emp_6b59cd34.pdf"
  },
  "d064cfd3ede3285c244fb6294083309da45441ef": {
    "paperId": "d064cfd3ede3285c244fb6294083309da45441ef",
    "title": "Self-supervised learning methods and applications in medical imaging analysis: a survey",
    "year": 2021,
    "authors": "Saeed Shurrab, R. Duwairi",
    "abstract": "The scarcity of high-quality annotated medical imaging datasets is a major problem that collides with machine learning applications in the field of medical imaging analysis and impedes its advancement. Self-supervised learning is a recent training paradigm that enables learning robust representations without the need for human annotation which can be considered an effective solution for the scarcity of annotated medical data. This article reviews the state-of-the-art research directions in self-supervised learning approaches for image data with a concentration on their applications in the field of medical imaging analysis. The article covers a set of the most recent self-supervised learning methods from the computer vision field as they are applicable to the medical imaging analysis and categorize them as predictive, generative, and contrastive approaches. Moreover, the article covers 40 of the most recent research papers in the field of self-supervised learning in medical imaging analysis aiming at shedding the light on the recent innovation in the field. Finally, the article concludes with possible future research directions in the field.",
    "citationCount": 224,
    "pdf_filename": "2021_Self_supervised_learning_methods_and_app_d064cfd3.pdf"
  },
  "15586fec836ffcb60eba81491e04c225e6914aac": {
    "paperId": "15586fec836ffcb60eba81491e04c225e6914aac",
    "title": "Protein structure generation via folding diffusion",
    "year": 2022,
    "authors": "Kevin E. Wu, Kevin Kaichuang Yang, Rianne van den Berg, James Zou, Alex X. Lu",
    "abstract": "The ability to computationally generate novel yet physically foldable protein structures could lead to new biological discoveries and new treatments targeting yet incurable diseases. Despite recent advances in protein structure prediction, directly generating diverse, novel protein structures from neural networks remains difficult. In this work, we present a diffusion-based generative model that generates protein backbone structures via a procedure inspired by the natural folding process. We describe a protein backbone structure as a sequence of angles capturing the relative orientation of the constituent backbone atoms, and generate structures by denoising from a random, unfolded state towards a stable folded structure. Not only does this mirror how proteins natively twist into energetically favorable conformations, the inherent shift and rotational invariance of this representation crucially alleviates the need for more complex equivariant networks. We train a denoising diffusion probabilistic model with a simple transformer backbone and demonstrate that our resulting model unconditionally generates highly realistic protein structures with complexity and structural patterns akin to those of naturally-occurring proteins. As a useful resource, we release an open-source codebase and trained models for protein structure diffusion.",
    "citationCount": 249,
    "pdf_filename": "2022_Protein_structure_generation_via_folding_15586fec.pdf"
  },
  "f2f11d2063464f5661f857e5fc4976cb3cb982a4": {
    "paperId": "f2f11d2063464f5661f857e5fc4976cb3cb982a4",
    "title": "Generating synthetic data in finance: opportunities, challenges and pitfalls",
    "year": 2020,
    "authors": "Samuel A. Assefa",
    "abstract": "Financial services generate a huge volume of data that is extremely complex and varied. These datasets are often stored in silos within organisations for various reasons, including but not limited to regulatory requirements and business needs. As a result, data sharing within different lines of business as well as outside of the organisation (e.g. to the research community) is severely limited. It is therefore critical to investigate methods for synthesising financial datasets that follow the same properties of the real data while respecting the need for privacy of the parties involved. This introductory paper aims to highlight the growing need for effective synthetic data generation in the financial domain. We highlight three main areas of focus that are of particular importance while generating synthetic financial datasets: 1) Generating realistic synthetic datasets. 2) Measuring the similarities between real and generated datasets. 3) Ensuring the generative process satisfies any privacy constraints. Although these challenges are also present in other domains, the additional regulatory and privacy requirements within financial services present unique questions that are not asked elsewhere. Due to the size and influence of the financial services industry, answering these questions has the potential for a great and lasting impact. Finally, we aim to develop a shared vocabulary and context for generating synthetic financial data using two types of financial datasets as examples.",
    "citationCount": 262,
    "pdf_filename": "2020_Generating_synthetic_data_in_finance__op_f2f11d20.pdf"
  },
  "897c0aedead3105b7b6cd1afbb6aeb4f62a06e11": {
    "paperId": "897c0aedead3105b7b6cd1afbb6aeb4f62a06e11",
    "title": "GLAZE: Protecting Artists from Style Mimicry by Text-to-Image Models",
    "year": 2023,
    "authors": "Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng, Rana Hanocka",
    "abstract": "Recent text-to-image diffusion models such as MidJourney and Stable Diffusion threaten to displace many in the professional artist community. In particular, models can learn to mimic the artistic style of specific artists after\"fine-tuning\"on samples of their art. In this paper, we describe the design, implementation and evaluation of Glaze, a tool that enables artists to apply\"style cloaks\"to their art before sharing online. These cloaks apply barely perceptible perturbations to images, and when used as training data, mislead generative models that try to mimic a specific artist. In coordination with the professional artist community, we deploy user studies to more than 1000 artists, assessing their views of AI art, as well as the efficacy of our tool, its usability and tolerability of perturbations, and robustness across different scenarios and against adaptive countermeasures. Both surveyed artists and empirical CLIP-based scores show that even at low perturbation levels (p=0.05), Glaze is highly successful at disrupting mimicry under normal conditions (>92%) and against adaptive countermeasures (>85%).",
    "citationCount": 235,
    "pdf_filename": "2023_GLAZE__Protecting_Artists_from_Style_Mim_897c0aed.pdf"
  },
  "6556d6399b3a75745537f1d90edf0b53bc1042c0": {
    "paperId": "6556d6399b3a75745537f1d90edf0b53bc1042c0",
    "title": "Analyzing User-Level Privacy Attack Against Federated Learning",
    "year": 2020,
    "authors": "Mengkai Song, Zhibo Wang, Zhifei Zhang, Yang Song, Qian Wang",
    "abstract": "Federated learning has emerged as an advanced privacy-preserving learning technique for mobile edge computing, where the model is trained in a decentralized manner by the clients, preventing the server from directly accessing those private data from the clients. This learning mechanism significantly challenges the attack from the server side. Although the state-of-the-art attacking techniques that incorporated the advance of Generative adversarial networks (GANs) could construct class representatives of the global data distribution among all clients, it is still challenging to distinguishably attack a specific client (i.e., user-level privacy leakage), which is a stronger privacy threat to precisely recover the private data from a specific client. To analyze the privacy leakage of federated learning, this paper gives the first attempt to explore user-level privacy leakage by the attack from a malicious server. We propose a framework incorporating GAN with a multi-task discriminator, called multi-task GAN – Auxiliary Identification (mGAN-AI), which simultaneously discriminates category, reality, and client identity of input samples. The novel discrimination on client identity enables the generator to recover user specified private data. Unlike existing works interfering the federated learning process, the proposed method works “invisibly” on the server side. Furthermore, considering the anonymization strategy for mitigating mGAN-AI, we propose a beforehand linkability attack which re-identifies the anonymized updates by associating the client representatives. A novel siamese network fusing the identification and verification models is developed for measuring the similarity of representatives. The experimental results demonstrate the effectiveness of the proposed approaches and the superior to the state-of-the-art.",
    "citationCount": 225,
    "pdf_filename": "2020_Analyzing_User_Level_Privacy_Attack_Agai_6556d639.pdf"
  },
  "731ac2fd7a5586d17cb8959c190158d429821a60": {
    "paperId": "731ac2fd7a5586d17cb8959c190158d429821a60",
    "title": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
    "year": 2023,
    "authors": "Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai, Fangzhou Hong",
    "abstract": "3D human motion generation is crucial for creative industry. Recent advances rely on generative models with domain knowledge for text-driven motion generation, leading to substantial progress in capturing common motions. However, the performance on more diverse motions remains unsatisfactory. In this work, we propose ReMoDiffuse, a diffusion-model-based motion generation framework that integrates a retrieval mechanism to refine the denoising process. ReMoDiffuse enhances the generalizability and diversity of text-driven motion generation with three key designs: 1) Hybrid Retrieval finds appropriate references from the database in terms of both semantic and kinematic similarities. 2) Semantic-Modulated Transformer selectively absorbs retrieval knowledge, adapting to the difference between retrieved samples and the target motion sequence. 3) Condition Mixture better utilizes the retrieval database during inference, overcoming the scale sensitivity in classifier-free guidance. Extensive experiments demonstrate that ReMoDiffuse outperforms state-of-the-art methods by balancing both text-motion consistency and motion quality, especially for more diverse motion generation. Project page: https://mingyuan-zhang.github.io/projects/ReMoDiffuse.html",
    "citationCount": 238,
    "pdf_filename": "2023_ReMoDiffuse__Retrieval_Augmented_Motion__731ac2fd.pdf"
  },
  "c325d0304cd10df0f82651c86c1214f6674ca71c": {
    "paperId": "c325d0304cd10df0f82651c86c1214f6674ca71c",
    "title": "Learning temporal coherence via self-supervision for GAN-based video generation",
    "year": 2020,
    "authors": "Mengyu Chu, You Xie, Jonas Mayer, L. Leal-Taix'e, Nils Thürey",
    "abstract": "Our work explores temporal self-supervision for GAN-based video generation tasks. While adversarial training successfully yields generative models for a variety of areas, temporal relationships in the generated data are much less explored. Natural temporal changes are crucial for sequential generation tasks, e.g. video super-resolution and unpaired video translation. For the former, state-of-the-art methods often favor simpler norm losses such as L2 over adversarial training. However, their averaging nature easily leads to temporally smooth results with an undesirable lack of spatial detail. For unpaired video translation, existing approaches modify the generator networks to form spatio-temporal cycle consistencies. In contrast, we focus on improving learning objectives and propose a temporally self-supervised algorithm. For both tasks, we show that temporal adversarial learning is key to achieving temporally coherent solutions without sacrificing spatial detail. We also propose a novel Ping-Pong loss to improve the long-term temporal consistency. It effectively prevents recurrent networks from accumulating artifacts temporally without depressing detailed features. Additionally, we propose a first set of metrics to quantitatively evaluate the accuracy as well as the perceptual quality of the temporal evolution. A series of user studies confirm the rankings computed with these metrics. Code, data, models, and results are provided at https://github.com/thunil/TecoGAN.",
    "citationCount": 253,
    "pdf_filename": "2020_Learning_temporal_coherence_via_self_sup_c325d030.pdf"
  },
  "0ad9db9f7a3a6f9c14b0ede8c25aa2e65f0e65d7": {
    "paperId": "0ad9db9f7a3a6f9c14b0ede8c25aa2e65f0e65d7",
    "title": "Dynamical Variational Autoencoders: A Comprehensive Review",
    "year": 2020,
    "authors": "Laurent Girin, Simon Leglaive, Xiaoyu Bie, Julien Diard, Thomas Hueber",
    "abstract": "The Variational Autoencoder (VAE) is a powerful deep generative model that is now extensively used to represent high-dimensional complex data via a low-dimensional latent space that is learned in an unsupervised manner. In the original VAE model, input data vectors are processed independently. In the recent years, a series of papers have presented different extensions of the VAE to sequential data, that not only model the latent space, but also model the temporal dependencies within a sequence of data vectors and/or corresponding latent vectors, relying on recurrent neural networks or state space models. In this paper we perform an extensive literature review of these models. Importantly, we introduce and discuss a general class of models called Dynamical Variational Autoencoders (DVAEs) that encompass a large subset of these temporal VAE extensions. Then we present in details seven different instances of DVAE that were recently proposed in the literature, with an effort to homogenize the notations and presentation lines, as well as to relate those models with existing classical temporal models (that are also presented for the sake of completeness). We reimplemented those seven DVAE models and we present the results of an experimental benchmark that we conducted on the speech analysis-resynthesis task (the PyTorch code will be made publicly available). An extensive discussion is presented at the end of the paper, aiming to comment on important issues concerning the DVAE class of models and to describe future research guidelines.",
    "citationCount": 256,
    "pdf_filename": "2020_Dynamical_Variational_Autoencoders__A_Co_0ad9db9f.pdf"
  },
  "671ee2b83b3489ce9b3b3b41162ec3c4a2bf9c59": {
    "paperId": "671ee2b83b3489ce9b3b3b41162ec3c4a2bf9c59",
    "title": "A Survey on Video Diffusion Models",
    "year": 2023,
    "authors": "Zhen Xing, Qijun Feng, Haoran Chen, Qi Dai, Hang-Rui Hu",
    "abstract": "The recent wave of AI-generated content (AIGC) has witnessed substantial success in computer vision, with the diffusion model playing a crucial role in this achievement. Due to their impressive generative capabilities, diffusion models are gradually superseding methods based on GANs and auto-regressive Transformers, demonstrating exceptional performance not only in image generation and editing, but also in the realm of video-related research. However, existing surveys mainly focus on diffusion models in the context of image generation, with few up-to-date reviews on their application in the video domain. To address this gap, this article presents a comprehensive review of video diffusion models in the AIGC era. Specifically, we begin with a concise introduction to the fundamentals and evolution of diffusion models. Subsequently, we present an overview of research on diffusion models in the video domain, categorizing the work into three key areas: video generation, video editing, and other video understanding tasks. We conduct a thorough review of the literature in these three key areas, including further categorization and practical contributions in the field. Finally, we discuss the challenges faced by research in this domain and outline potential future developmental trends. A comprehensive list of video diffusion models studied in this survey is available at https://github.com/ChenHsing/Awesome-Video-Diffusion-Models.",
    "citationCount": 204,
    "pdf_filename": "2023_A_Survey_on_Video_Diffusion_Models_671ee2b8.pdf"
  },
  "6fc1c18418a74b4ed46e00ee5f70e46c8ddc8460": {
    "paperId": "6fc1c18418a74b4ed46e00ee5f70e46c8ddc8460",
    "title": "ProDiff: Progressive Fast Diffusion Model for High-Quality Text-to-Speech",
    "year": 2022,
    "authors": "Rongjie Huang, Zhou Zhao, Huadai Liu, Jinglin Liu, Chenye Cui",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) have recently achieved leading performances in many generative tasks. However, the inherited iterative sampling process costs hinder their applications to text-to-speech deployment. Through the preliminary study on diffusion model parameterization, we find that previous gradient-based TTS models require hundreds or thousands of iterations to guarantee high sample quality, which poses a challenge for accelerating sampling. In this work, we propose ProDiff, on progressive fast diffusion model for high-quality text-to-speech. Unlike previous work estimating the gradient for data density, ProDiff parameterizes the denoising model by directly predicting clean data to avoid distinct quality degradation in accelerating sampling. To tackle the model convergence challenge with decreased diffusion iterations, ProDiff reduces the data variance in the target site via knowledge distillation. Specifically, the denoising model uses the generated mel-spectrogram from an N-step DDIM teacher as the training target and distills the behavior into a new model with N/2 steps. As such, it allows the TTS model to make sharp predictions and further reduces the sampling time by orders of magnitude. Our evaluation demonstrates that ProDiff needs only 2 iterations to synthesize high-fidelity mel-spectrograms, while it maintains sample quality and diversity competitive with state-of-the-art models using hundreds of steps. ProDiff enables a sampling speed of 24x faster than real-time on a single NVIDIA 2080Ti GPU, making diffusion models practically applicable to text-to-speech synthesis deployment for the first time. Our extensive ablation studies demonstrate that each design in ProDiff is effective, and we further show that ProDiff can be easily extended to the multi-speaker setting.",
    "citationCount": 227,
    "pdf_filename": "2022_ProDiff__Progressive_Fast_Diffusion_Mode_6fc1c184.pdf"
  },
  "d98f22eca403263a57018a160195950ebead3d33": {
    "paperId": "d98f22eca403263a57018a160195950ebead3d33",
    "title": "EditGAN: High-Precision Semantic Image Editing",
    "year": 2021,
    "authors": "Huan Ling, Karsten Kreis, Daiqing Li, Seung Wook Kim, A. Torralba",
    "abstract": "Generative adversarial networks (GANs) have recently found applications in image editing. However, most GAN based image editing methods often require large scale datasets with semantic segmentation annotations for training, only provide high level control, or merely interpolate between different images. Here, we propose EditGAN, a novel method for high quality, high precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. EditGAN builds on a GAN framework that jointly models images and their semantic segmentations, requiring only a handful of labeled examples, making it a scalable tool for editing. Specifically, we embed an image into the GAN latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. To amortize optimization, we find editing vectors in latent space that realize the edits. The framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. We experimentally show that EditGAN can manipulate images with an unprecedented level of detail and freedom, while preserving full image quality.We can also easily combine multiple edits and perform plausible edits beyond EditGAN training data. We demonstrate EditGAN on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks.",
    "citationCount": 227,
    "pdf_filename": "2021_EditGAN__High_Precision_Semantic_Image_E_d98f22ec.pdf"
  },
  "8214d2934b7ab7cb682566c01344bb1e24320b49": {
    "paperId": "8214d2934b7ab7cb682566c01344bb1e24320b49",
    "title": "Advances in De Novo Drug Design: From Conventional to Machine Learning Methods",
    "year": 2021,
    "authors": "Varnavas D. Mouchlis, A. Afantitis, A. Serra, Michele Fratello, A. Papadiamantis",
    "abstract": "De novo drug design is a computational approach that generates novel molecular structures from atomic building blocks with no a priori relationships. Conventional methods include structure-based and ligand-based design, which depend on the properties of the active site of a biological target or its known active binders, respectively. Artificial intelligence, including ma-chine learning, is an emerging field that has positively impacted the drug discovery process. Deep reinforcement learning is a subdivision of machine learning that combines artificial neural networks with reinforcement-learning architectures. This method has successfully been em-ployed to develop novel de novo drug design approaches using a variety of artificial networks including recurrent neural networks, convolutional neural networks, generative adversarial networks, and autoencoders. This review article summarizes advances in de novo drug design, from conventional growth algorithms to advanced machine-learning methodologies and high-lights hot topics for further development.",
    "citationCount": 226,
    "pdf_filename": "2021_Advances_in_De_Novo_Drug_Design__From_Co_8214d293.pdf"
  },
  "0b6106e4e4bd18310fd81957625fc912ea403159": {
    "paperId": "0b6106e4e4bd18310fd81957625fc912ea403159",
    "title": "CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets",
    "year": 2024,
    "authors": "Longwen Zhang, Ziyu Wang, Qixuan Zhang, Qiwei Qiu, Anqi Pang",
    "abstract": "In the realm of digital creativity, our potential to craft intricate 3D worlds from imagination is often hampered by the limitations of existing digital tools, which demand extensive expertise and efforts. To narrow this disparity, we introduce CLAY, a 3D geometry and material generator designed to effortlessly transform human imagination into intricate 3D digital structures. CLAY supports classic text or image inputs as well as 3D-aware controls from diverse primitives (multi-view images, voxels, bounding boxes, point clouds, implicit representations, etc). At its core is a large-scale generative model composed of a multi-resolution Variational Autoencoder (VAE) and a minimalistic latent Diffusion Transformer (DiT), to extract rich 3D priors directly from a diverse range of 3D geometries. Specifically, it adopts neural fields to represent continuous and complete surfaces and uses a geometry generative module with pure transformer blocks in latent space. We present a progressive training scheme to train CLAY on an ultra large 3D model dataset obtained through a carefully designed processing pipeline, resulting in a 3D native geometry generator with 1.5 billion parameters. For appearance generation, CLAY sets out to produce physically-based rendering (PBR) textures by employing a multi-view material diffusion model that can generate 2K resolution textures with diffuse, roughness, and metallic modalities. We demonstrate using CLAY for a range of controllable 3D asset creations, from sketchy conceptual designs to production ready assets with intricate details. Even first time users can easily use CLAY to bring their vivid 3D imaginations to life, unleashing unlimited creativity.",
    "citationCount": 293,
    "pdf_filename": "2024_CLAY__A_Controllable_Large_scale_Generat_0b6106e4.pdf"
  },
  "e788d5c6dc79f106296f8ad296bcbe512028d5f0": {
    "paperId": "e788d5c6dc79f106296f8ad296bcbe512028d5f0",
    "title": "3D-VLA: A 3D Vision-Language-Action Generative World Model",
    "year": 2024,
    "authors": "Haoyu Zhen, Xiaowen Qiu, Peihao Chen, Jincheng Yang, Xin Yan",
    "abstract": "Recent vision-language-action (VLA) models rely on 2D inputs, lacking integration with the broader realm of the 3D physical world. Furthermore, they perform action prediction by learning a direct mapping from perception to action, neglecting the vast dynamics of the world and the relations between actions and dynamics. In contrast, human beings are endowed with world models that depict imagination about future scenarios to plan actions accordingly. To this end, we propose 3D-VLA by introducing a new family of embodied foundation models that seamlessly link 3D perception, reasoning, and action through a generative world model. Specifically, 3D-VLA is built on top of a 3D-based large language model (LLM), and a set of interaction tokens is introduced to engage with the embodied environment. Furthermore, to inject generation abilities into the model, we train a series of embodied diffusion models and align them into the LLM for predicting the goal images and point clouds. To train our 3D-VLA, we curate a large-scale 3D embodied instruction dataset by extracting vast 3D-related information from existing robotics datasets. Our experiments on held-in datasets demonstrate that 3D-VLA significantly improves the reasoning, multimodal generation, and planning capabilities in embodied environments, showcasing its potential in real-world applications.",
    "citationCount": 202,
    "pdf_filename": "2024_3D_VLA__A_3D_Vision_Language_Action_Gene_e788d5c6.pdf"
  },
  "f52af2c0cf521b48edd50670e9ba9cd02646d2b4": {
    "paperId": "f52af2c0cf521b48edd50670e9ba9cd02646d2b4",
    "title": "MoMask: Generative Masked Modeling of 3D Human Motions",
    "year": 2023,
    "authors": "Chuan Guo, Yuxuan Mu, Muhammad Gohar Javed, Sen Wang, Li Cheng",
    "abstract": "We introduce MoMask, a novel masked modeling framework for text-driven 3D human motion generation. In Mo-Mask, a hierarchical quantization scheme is employed to represent human motion as multi-layer discrete motion tokens with high-fidelity details. Starting at the base layer, with a sequence of motion tokens obtained by vector quan-tization, the residual tokens of increasing orders are de-rived and stored at the subsequent layers of the hierar-chy. This is consequently followed by two distinct bidirectional transformers. For the base-layer motion tokens, a Masked Transformer is designated to predict randomly masked motion tokens conditioned on text input at training stage. During generation (i. e. inference) stage, starting from an empty sequence, our Masked Transformer iteratively fills up the missing tokens; Subsequently, a Residual Transformer learns to progressively predict the next-layer tokens based on the results from current layer. Extensive experiments demonstrate that MoMask outperforms the state-of-art methods on the text-to-motion generation task, with an FID of 0.045 (vs e.g. 0.141 of T2M-GPT) on the HumanML3D dataset, and 0.228 (vs 0.514) on KIT-ML, respectively. MoMask can also be seamlessly applied in related tasks without further model fine-tuning, such as text-guided temporal inpainting.",
    "citationCount": 244,
    "pdf_filename": "2023_MoMask__Generative_Masked_Modeling_of_3D_f52af2c0.pdf"
  },
  "39831c8c222a8d78fff4d67e7e56f5eeb90fdd7f": {
    "paperId": "39831c8c222a8d78fff4d67e7e56f5eeb90fdd7f",
    "title": "GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",
    "year": 2023,
    "authors": "Gokul Yenduri, M. Ramalingam, G. C. Selvi, Y. Supriya, Gautam Srivastava",
    "abstract": "The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",
    "citationCount": 292,
    "pdf_filename": "2023_GPT__Generative_Pre_Trained_Transformer__39831c8c.pdf"
  },
  "351a2d50b4aff8e9754dc7074dd589b10a7465d4": {
    "paperId": "351a2d50b4aff8e9754dc7074dd589b10a7465d4",
    "title": "Large language models for generative information extraction: a survey",
    "year": 2023,
    "authors": "Derong Xu, Wei Chen, Wenjun Peng, Chao Zhang, Tong Xu",
    "abstract": "Information Extraction (IE) aims to extract structural knowledge from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation. As a result, numerous works have been proposed to integrate LLMs for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and techniques, and then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on a thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related works and resources on GitHub (LLM4IE repository).",
    "citationCount": 283,
    "pdf_filename": "2023_Large_language_models_for_generative_inf_351a2d50.pdf"
  },
  "2eeff0f534d303581bc1199671600fbd04a2d01c": {
    "paperId": "2eeff0f534d303581bc1199671600fbd04a2d01c",
    "title": "Empowering Education with Generative Artificial Intelligence Tools: Approach with an Instructional Design Matrix",
    "year": 2023,
    "authors": "Lena Ivannova Ruiz-Rojas, Patricia Acosta-Vargas, Javier De-Moreta-Llovet, Mario González-Rodríguez",
    "abstract": "This study focuses on the potential of generative artificial intelligence tools in education, particularly through the practical application of the 4PADAFE instructional design matrix. The objective was to evaluate how these tools, in combination with the matrix, can enhance education and improve the teaching–learning process. Through surveys conducted with teachers from the University of ESPE Armed Forces who participated in the MOOC course “Generative Artificial Intelligence Tools for Education: GPT Chat Techniques”, the study explores the impact of these tools on education. The findings reveal that generative artificial intelligence tools are crucial in developing massive MOOC virtual classrooms when integrated with an instructional design matrix. The results demonstrate the potential of generative artificial intelligence tools in university education. By utilizing these tools in conjunction with an instructional design matrix, educators can design and deliver personalized and enriching educational experiences. The devices offer opportunities to enhance the teaching–learning process and tailor educational materials to individual needs, ultimately preparing students for the demands of the 21st century. The study concludes that generative artificial intelligence tools have significant potential in education. They provide innovative ways to engage students, adapt content, and promote personalized learning. Implementing the 4PADAFE instructional design matrix further enhances the effectiveness and coherence of educational activities. By embracing these technological advancements, education can stay relevant and effectively meet the digital world’s challenges.",
    "citationCount": 216,
    "pdf_filename": "2023_Empowering_Education_with_Generative_Art_2eeff0f5.pdf"
  },
  "4443c9a43bff8dcd717e5c75115ec6497af2b953": {
    "paperId": "4443c9a43bff8dcd717e5c75115ec6497af2b953",
    "title": "Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation",
    "year": 2023,
    "authors": "Hongtao Wu, Ya Jing, Chi-Hou Cheang, Guangzeng Chen, Jiafeng Xu",
    "abstract": "Generative pre-trained models have demonstrated remarkable effectiveness in language and vision domains by learning useful representations. In this paper, we extend the scope of this effectiveness by showing that visual robot manipulation can significantly benefit from large-scale video generative pre-training. We introduce GR-1, a straightforward GPT-style model designed for multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs a language instruction, a sequence of observation images, and a sequence of robot states. It predicts robot actions as well as future images in an end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly finetuned on robot data after pre-trained on a large-scale video dataset. We perform extensive experiments on the challenging CALVIN benchmark and a real robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline methods and improves the success rate from 88.9% to 94.9%. In the setting of zero-shot unseen scene generalization, GR-1 improves the success rate from 53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline methods and shows strong potentials in generalization to unseen scenes and objects. We provide inaugural evidence that a unified GPT-style transformer, augmented with large-scale video generative pre-training, exhibits remarkable generalization to multi-task visual robot manipulation. Project page: https://GR1-Manipulation.github.io",
    "citationCount": 213,
    "pdf_filename": "2023_Unleashing_Large_Scale_Video_Generative__4443c9a4.pdf"
  },
  "dfd1d219c7e1993bef152f79b81204a828b77d21": {
    "paperId": "dfd1d219c7e1993bef152f79b81204a828b77d21",
    "title": "Generative artificial intelligence empowers educational reform: current status, issues, and prospects",
    "year": 2023,
    "authors": "Haotian Yu, Yunyun Guo",
    "abstract": "The emergence of Chat GPT has once again sparked a wave of information revolution in generative artificial intelligence. This article provides a detailed overview of the development and technical support of generative artificial intelligence. It conducts an in-depth analysis of the current application of generative artificial intelligence in the field of education, and identifies problems in four aspects: opacity and unexplainability, data privacy and security, personalization and fairness, and effectiveness and reliability. Corresponding solutions are proposed, such as developing explainable and fair algorithms, upgrading encryption technology, and formulating relevant laws and regulations to protect data, as well as improving the quality and quantity of datasets. The article also looks ahead to the future development trends of generative artificial intelligence in education from four perspectives: personalized education, intelligent teaching, collaborative education, and virtual teaching. The aim of the study is to provide important reference value for research and practice in this field.",
    "citationCount": 204,
    "pdf_filename": "2023_Generative_artificial_intelligence_empow_dfd1d219.pdf"
  },
  "4c14b1c41cb0aaa68f5d3f4a432f55e7199657ea": {
    "paperId": "4c14b1c41cb0aaa68f5d3f4a432f55e7199657ea",
    "title": "AI and Memory Wall",
    "year": 2024,
    "authors": "A. Gholami, Z. Yao, Sehoon Kim, Coleman Hooper, Michael W. Mahoney",
    "abstract": "The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training large language models. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware floating-point operations per second have been scaling at 3.0${\\times}$× per two years, outpacing the growth of dynamic random-access memory and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every two years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.",
    "citationCount": 240,
    "pdf_filename": "2024_AI_and_Memory_Wall_4c14b1c4.pdf"
  },
  "331fa9e381cd219a3961cd5ef7dda401e8751606": {
    "paperId": "331fa9e381cd219a3961cd5ef7dda401e8751606",
    "title": "A Turing test of whether AI chatbots are behaviorally similar to humans",
    "year": 2024,
    "authors": "Qiaozhu Mei, Yutong Xie, Walter Yuan, Matthew O Jackson",
    "abstract": "Significance As AI interacts with humans on an increasing array of tasks, it is important to understand how it behaves. Since much of AI programming is proprietary, developing methods of assessing AI by observing its behaviors is essential. We develop a Turing test to assess the behavioral and personality traits exhibited by AI. Beyond administering a personality test, we have ChatGPT variants play games that are benchmarks for assessing traits: trust, fairness, risk-aversion, altruism, and cooperation. Their behaviors fall within the distribution of behaviors of humans and exhibit patterns consistent with learning. When deviating from mean and modal human behaviors, they are more cooperative and altruistic. This is a step in developing assessments of AI as it increasingly influences human experiences.",
    "citationCount": 203,
    "pdf_filename": "2024_A_Turing_test_of_whether_AI_chatbots_are_331fa9e3.pdf"
  },
  "3312af738432a817e0d3d913dca87d7445a85696": {
    "paperId": "3312af738432a817e0d3d913dca87d7445a85696",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations",
    "year": 2022,
    "authors": "Jaehyeong Jo, Seul Lee, Sung Ju Hwang",
    "abstract": "Generating graph-structured data requires learning the underlying distribution of graphs. Yet, this is a challenging problem, and the previous graph generative methods either fail to capture the permutation-invariance property of graphs or cannot sufficiently model the complex dependency between nodes and edges, which is crucial for generating real-world graphs such as molecules. To overcome such limitations, we propose a novel score-based generative model for graphs with a continuous-time framework. Specifically, we propose a new graph diffusion process that models the joint distribution of the nodes and edges through a system of stochastic differential equations (SDEs). Then, we derive novel score matching objectives tailored for the proposed diffusion process to estimate the gradient of the joint log-density with respect to each component, and introduce a new solver for the system of SDEs to efficiently sample from the reverse diffusion process. We validate our graph generation method on diverse datasets, on which it either achieves significantly superior or competitive performance to the baselines. Further analysis shows that our method is able to generate molecules that lie close to the training distribution yet do not violate the chemical valency rule, demonstrating the effectiveness of the system of SDEs in modeling the node-edge relationships. Our code is available at https://github.com/harryjo97/GDSS.",
    "citationCount": 283,
    "pdf_filename": "2022_Score_based_Generative_Modeling_of_Graph_3312af73.pdf"
  },
  "d651f7b09f554482bc7a5ffa1381dda1dc73050c": {
    "paperId": "d651f7b09f554482bc7a5ffa1381dda1dc73050c",
    "title": "A 3D Generative Model for Structure-Based Drug Design",
    "year": 2022,
    "authors": "Shitong Luo",
    "abstract": "We study a fundamental problem in structure-based drug design -- generating molecules that bind to specific protein binding sites. While we have witnessed the great success of deep generative models in drug design, the existing methods are mostly string-based or graph-based. They are limited by the lack of spatial information and thus unable to be applied to structure-based design tasks. Particularly, such models have no or little knowledge of how molecules interact with their target proteins exactly in 3D space. In this paper, we propose a 3D generative model that generates molecules given a designated 3D protein binding site. Specifically, given a binding site as the 3D context, our model estimates the probability density of atom's occurrences in 3D space -- positions that are more likely to have atoms will be assigned higher probability. To generate 3D molecules, we propose an auto-regressive sampling scheme -- atoms are sampled sequentially from the learned distribution until there is no room for new atoms. Combined with this sampling scheme, our model can generate valid and diverse molecules, which could be applicable to various structure-based molecular design tasks such as molecule sampling and linker design. Experimental results demonstrate that molecules sampled from our model exhibit high binding affinity to specific targets and good drug properties such as drug-likeness even if the model is not explicitly optimized for them.",
    "citationCount": 235,
    "pdf_filename": "2022_A_3D_Generative_Model_for_Structure_Base_d651f7b0.pdf"
  },
  "37355fe82b7a9cf96ead194018b1775eec9af605": {
    "paperId": "37355fe82b7a9cf96ead194018b1775eec9af605",
    "title": "Antigen-Specific Antibody Design and Optimization with Diffusion-Based Generative Models for Protein Structures",
    "year": 2022,
    "authors": "Shitong Luo, Yufeng Su, Xingang Peng, Sheng Wang, Jian Peng",
    "abstract": "Antibodies are immune system proteins that protect the host by binding to specific antigens such as viruses and bacteria. The binding between antibodies and antigens is mainly determined by the complementarity-determining regions (CDR) of the antibodies. In this work, we develop a deep generative model that jointly models sequences and structures of CDRs based on diffusion probabilistic models and equivariant neural networks. Our method is the first deep learning-based method that generates antibodies explicitly targeting specific antigen structures and is one of the earliest diffusion probabilistic models for protein structures. The model is a “Swiss Army Knife” capable of sequence-structure co-design, sequence design for given backbone structures, and antibody optimization. We conduct extensive experiments to evaluate the quality of both sequences and structures of designed antibodies. We find that our model could yield competitive results in binding affinity measured by biophysical energy functions and other protein design metrics.",
    "citationCount": 251,
    "pdf_filename": "2022_Antigen_Specific_Antibody_Design_and_Opt_37355fe8.pdf"
  },
  "a3eeaf02dbd05ffaddf71cc6e42b97bd8b51e827": {
    "paperId": "a3eeaf02dbd05ffaddf71cc6e42b97bd8b51e827",
    "title": "Masked Generative Distillation",
    "year": 2022,
    "authors": "Zhendong Yang, Zhe Li, Mingqi Shao, Dachuan Shi, Zehuan Yuan",
    "abstract": "Knowledge distillation has been applied to various tasks successfully. The current distillation algorithm usually improves students' performance by imitating the output of the teacher. This paper shows that teachers can also improve students' representation power by guiding students' feature recovery. From this point of view, we propose Masked Generative Distillation (MGD), which is simple: we mask random pixels of the student's feature and force it to generate the teacher's full feature through a simple block. MGD is a truly general feature-based distillation method, which can be utilized on various tasks, including image classification, object detection, semantic segmentation and instance segmentation. We experiment on different models with extensive datasets and the results show that all the students achieve excellent improvements. Notably, we boost ResNet-18 from 69.90% to 71.69% ImageNet top-1 accuracy, RetinaNet with ResNet-50 backbone from 37.4 to 41.0 Boundingbox mAP, SOLO based on ResNet-50 from 33.1 to 36.2 Mask mAP and DeepLabV3 based on ResNet-18 from 73.20 to 76.02 mIoU. Our codes are available at https://github.com/yzd-v/MGD.",
    "citationCount": 229,
    "pdf_filename": "2022_Masked_Generative_Distillation_a3eeaf02.pdf"
  },
  "2f68d3934b006fcd01732adbc1ab459b2485fc8e": {
    "paperId": "2f68d3934b006fcd01732adbc1ab459b2485fc8e",
    "title": "MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis",
    "year": 2022,
    "authors": "Tianhong Li, Huiwen Chang, Shlok Kumar Mishra, Han Zhang, D. Katabi",
    "abstract": "Generative modeling and representation learning are two key tasks in computer vision. However, these models are typically trained independently, which ignores the potential for each task to help the other, and leads to training and model maintenance overheads. In this work, we propose MAsked Generative Encoder (MAGE), the first framework to unify SOTA image generation and self-supervised representation learning. Our key insight is that using variable masking ratios in masked image modeling pre-training can allow generative training (very high masking ratio) and representation learning (lower masking ratio) under the same training framework. Inspired by previous generative models, MAGE uses semantic tokens learned by a vector-quantized GAN at inputs and outputs, combining this with masking. We can further improve the representation by adding a contrastive loss to the encoder output. We extensively evaluate the generation and representation learning capabilities of MAGE. On ImageNet-1K, a single MAGE ViT-L model obtains 9.10 FID in the task of class-unconditional image generation and 78.9% top-1 accuracy for linear probing, achieving state-of-the-art performance in both image generation and representation learning. Code is available at https://github.com/LTHl4/mage.",
    "citationCount": 220,
    "pdf_filename": "2022_MAGE__MAsked_Generative_Encoder_to_Unify_2f68d393.pdf"
  },
  "ef4741b12cb8f01bcc68708c8cffcdc4237383f7": {
    "paperId": "ef4741b12cb8f01bcc68708c8cffcdc4237383f7",
    "title": "Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks",
    "year": 2022,
    "authors": "Sihyun Yu, Jihoon Tack, Sangwoo Mo, Hyunsu Kim, Junho Kim",
    "abstract": "In the deep learning era, long video generation of high-quality still remains challenging due to the spatio-temporal complexity and continuity of videos. Existing prior works have attempted to model video distribution by representing videos as 3D grids of RGB values, which impedes the scale of generated videos and neglects continuous dynamics. In this paper, we found that the recent emerging paradigm of implicit neural representations (INRs) that encodes a continuous signal into a parameterized neural network effectively mitigates the issue. By utilizing INRs of video, we propose dynamics-aware implicit generative adversarial network (DIGAN), a novel generative adversarial network for video generation. Specifically, we introduce (a) an INR-based video generator that improves the motion dynamics by manipulating the space and time coordinates differently and (b) a motion discriminator that efficiently identifies the unnatural motions without observing the entire long frame sequences. We demonstrate the superiority of DIGAN under various datasets, along with multiple intriguing properties, e.g., long video synthesis, video extrapolation, and non-autoregressive video generation. For example, DIGAN improves the previous state-of-the-art FVD score on UCF-101 by 30.7% and can be trained on 128 frame videos of 128x128 resolution, 80 frames longer than the 48 frames of the previous state-of-the-art method.",
    "citationCount": 216,
    "pdf_filename": "2022_Generating_Videos_with_Dynamics_aware_Im_ef4741b1.pdf"
  },
  "36bb5573f4108a41fa559b8b068922fa4136707a": {
    "paperId": "36bb5573f4108a41fa559b8b068922fa4136707a",
    "title": "Generative models for molecular discovery: Recent advances and challenges",
    "year": 2022,
    "authors": "Camille L. Bilodeau, Wengong Jin, T. Jaakkola, R. Barzilay, K. Jensen",
    "abstract": "Development of new products often relies on the discovery of novel molecules. While conventional molecular design involves using human expertise to propose, synthesize, and test new molecules, this process can be cost and time intensive, limiting the number of molecules that can be reasonably tested. Generative modeling provides an alternative approach to molecular discovery by reformulating molecular design as an inverse design problem. Here, we review the recent advances in the state‐of‐the‐art of generative molecular design and discusses the considerations for integrating these models into real molecular discovery campaigns. We first review the model design choices required to develop and train a generative model including common 1D, 2D, and 3D representations of molecules and typical generative modeling neural network architectures. We then describe different problem statements for molecular discovery applications and explore the benchmarks used to evaluate models based on those problem statements. Finally, we discuss the important factors that play a role in integrating generative models into experimental workflows. Our aim is that this review will equip the reader with the information and context necessary to utilize generative modeling within their domain.",
    "citationCount": 250,
    "pdf_filename": "2022_Generative_models_for_molecular_discover_36bb5573.pdf"
  },
  "0f366306281a61428eb58302e39b42c0a96f72a9": {
    "paperId": "0f366306281a61428eb58302e39b42c0a96f72a9",
    "title": "Generative Adversarial Networks in Time Series: A Systematic Literature Review",
    "year": 2022,
    "authors": "Eoin Brophy, Zhengwei Wang, Qingyun She, Tomas E. Ward",
    "abstract": "Generative adversarial network (GAN) studies have grown exponentially in the past few years. Their impact has been seen mainly in the computer vision field with realistic image and video manipulation, especially generation, making significant advancements. Although these computer vision advances have garnered much attention, GAN applications have diversified across disciplines such as time series and sequence generation. As a relatively new niche for GANs, fieldwork is ongoing to develop high-quality, diverse, and private time series data. In this article, we review GAN variants designed for time series related applications. We propose a classification of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. Here we showcase the latest and most popular literature in this field—their architectures, results, and applications. We also provide a list of the most popular evaluation metrics and their suitability across applications. Also presented is a discussion of privacy measures for these GANs and further protections and directions for dealing with sensitive data. We aim to frame clearly and concisely the latest and state-of-the-art research in this area and their applications to real-world technologies.",
    "citationCount": 229,
    "pdf_filename": "2022_Generative_Adversarial_Networks_in_Time__0f366306.pdf"
  },
  "963e3287352051da5d113a3f511c2edc8a718a01": {
    "paperId": "963e3287352051da5d113a3f511c2edc8a718a01",
    "title": "A generative model for inorganic materials design",
    "year": 2025,
    "authors": "Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton",
    "abstract": "The design of functional materials with desired properties is essential in driving technological advances in areas such as energy storage, catalysis and carbon capture1, 2–3. Generative models accelerate materials design by directly generating new materials given desired property constraints, but current methods have a low success rate in proposing stable crystals or can satisfy only a limited set of property constraints4, 5, 6, 7, 8, 9, 10–11. Here we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. Compared with previous generative models4,12, structures produced by MatterGen are more than twice as likely to be new and stable, and more than ten times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, new materials with desired chemistry, symmetry and mechanical, electronic and magnetic properties. As a proof of concept, we synthesize one of the generated structures and measure its property value to be within 20% of our target. We believe that the quality of generated materials and the breadth of abilities of MatterGen represent an important advancement towards creating a foundational generative model for materials design. MatterGen is a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints.",
    "citationCount": 249,
    "pdf_filename": "2025_A_generative_model_for_inorganic_materia_963e3287.pdf"
  },
  "7d2ff802094eb24bed1faa363a8d07947905be3e": {
    "paperId": "7d2ff802094eb24bed1faa363a8d07947905be3e",
    "title": "Riemannian Score-Based Generative Modeling",
    "year": 2022,
    "authors": "Valentin De Bortoli, Emile Mathieu, M. Hutchinson, James Thornton, Y. Teh",
    "abstract": "Score-based generative models (SGMs) are a powerful class of generative models that exhibit remarkable empirical performance. Score-based generative modelling (SGM) consists of a ``noising'' stage, whereby a diffusion is used to gradually add Gaussian noise to data, and a generative model, which entails a ``denoising'' process defined by approximating the time-reversal of the diffusion. Existing SGMs assume that data is supported on a Euclidean space, i.e. a manifold with flat geometry. In many domains such as robotics, geoscience or protein modelling, data is often naturally described by distributions living on Riemannian manifolds and current SGM techniques are not appropriate. We introduce here Riemannian Score-based Generative Models (RSGMs), a class of generative models extending SGMs to Riemannian manifolds. We demonstrate our approach on a variety of manifolds, and in particular with earth and climate science spherical data.",
    "citationCount": 204,
    "pdf_filename": "2022_Riemannian_Score_Based_Generative_Modeli_7d2ff802.pdf"
  },
  "fff60ef90f7ebfcc48999da55866c79b9ee68549": {
    "paperId": "fff60ef90f7ebfcc48999da55866c79b9ee68549",
    "title": "Depth-Aware Generative Adversarial Network for Talking Head Video Generation",
    "year": 2022,
    "authors": "Fa-Ting Hong, Longhao Zhang, Li Shen, Dan Xu",
    "abstract": "Talking head video generation aims to produce a synthetic human face video that contains the identity and pose information respectively from a given source image and a driving video. Existing works for this task heavily rely on 2D representations (e.g. appearance and motion) learned from the input images. However, dense 3D facial geometry (e.g. pixel-wise depth) is extremely important for this task as it is particularly beneficial for us to essentially generate accurate 3D face structures and distinguish noisy information from the possibly cluttered background. Nevertheless, dense 3D geometry annotations are prohibitively costly for videos and are typically not available for this video generation task. In this paper, we introduce a self-supervised face-depth learning method to automatically recover dense 3D facial geometry (i.e. depth) from the face videos without the requirement of any expensive 3D annotation data. Based on the learned dense depth maps, we further propose to leverage them to estimate sparse facial keypoints that capture the critical movement of the human head. In a more dense way, the depth is also utilized to learn 3D-aware cross-modal (i.e. appearance and depth) attention to guide the generation of motion fields for warping source image representations. All these contributions compose a novel depth-aware generative adversarial network (DaGAN) for talking head generation. Extensive experiments conducted demonstrate that our proposed method can generate highly realistic faces, and achieve significant results on the unseen human faces. 11https://github.com/harlanhong/CVPR2022-DaGAN",
    "citationCount": 210,
    "pdf_filename": "2022_Depth_Aware_Generative_Adversarial_Netwo_fff60ef9.pdf"
  },
  "b9c6a52ef510f6a87ec865075652e6370cb6dfb8": {
    "paperId": "b9c6a52ef510f6a87ec865075652e6370cb6dfb8",
    "title": "Academic integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond",
    "year": 2023,
    "authors": "",
    "abstract": "This paper explores the academic integrity considerations of students’ use of Artificial Intelligence (AI) tools using Large Language Models (LLMs) such as ChatGPT in formal assessments. We examine the evolution of these tools, and highlight the potential ways that LLMs can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and AI, supporting EFL learners, and improving Automated Writing Evaluations (AWE). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that LLMs raise for both Higher Education Institutions (HEIs) and students, we conclude that it is not the student use of any AI tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of LLMs by students can be defined as academic misconduct is determined by the academic integrity policies of any given HEI, which must be updated to consider how these tools will be used in future educational environments.",
    "citationCount": 278,
    "pdf_filename": "2023_Academic_integrity_considerations_of_AI__b9c6a52e.pdf"
  },
  "75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc": {
    "paperId": "75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc",
    "title": "Provable Robust Watermarking for AI-Generated Text",
    "year": 2023,
    "authors": "Xuandong Zhao, P. Ananth, Lei Li, Yu-Xiang Wang",
    "abstract": "We study the problem of watermarking large language models (LLMs) generated text -- one of the most promising approaches for addressing the safety challenges of LLM usage. In this paper, we propose a rigorous theoretical framework to quantify the effectiveness and robustness of LLM watermarks. We propose a robust and high-quality watermark method, Unigram-Watermark, by extending an existing approach with a simplified fixed grouping strategy. We prove that our watermark method enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing. Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.",
    "citationCount": 258,
    "pdf_filename": "2023_Provable_Robust_Watermarking_for_AI_Gene_75b68d09.pdf"
  },
  "a28cdccba07dbf977795e15ff2c9b7ec80dac050": {
    "paperId": "a28cdccba07dbf977795e15ff2c9b7ec80dac050",
    "title": "Score-Based Generative Modeling with Critically-Damped Langevin Diffusion",
    "year": 2021,
    "authors": "Tim Dockhorn, Arash Vahdat, Karsten Kreis",
    "abstract": "Score-based generative models (SGMs) have demonstrated remarkable synthesis quality. SGMs rely on a diffusion process that gradually perturbs the data towards a tractable distribution, while the generative model learns to denoise. The complexity of this denoising task is, apart from the data distribution itself, uniquely determined by the diffusion process. We argue that current SGMs employ overly simplistic diffusions, leading to unnecessarily complex denoising processes, which limit generative modeling performance. Based on connections to statistical mechanics, we propose a novel critically-damped Langevin diffusion (CLD) and show that CLD-based SGMs achieve superior performance. CLD can be interpreted as running a joint diffusion in an extended space, where the auxiliary variables can be considered “velocities” that are coupled to the data variables as in Hamiltonian dynamics. We derive a novel score matching objective for CLD and show that the model only needs to learn the score function of the conditional distribution of the velocity given data, an easier task than learning scores of the data directly. We also derive a new sampling scheme for efﬁcient synthesis from CLD-based diffusion models. We ﬁnd that CLD outperforms previous SGMs in synthesis quality for similar network architectures and sampling compute budgets. We show that our novel sampler for CLD signiﬁcantly outperforms solvers such as Euler–Maruyama. Our framework provides new insights into score-based denoising diffusion models and can be readily used for high-resolution image synthesis. VPSDE. We leave the study of CLD with maximum likelihood training for high-dimensional (image) datasets to future work.",
    "citationCount": 267,
    "pdf_filename": "2021_Score_Based_Generative_Modeling_with_Cri_a28cdccb.pdf"
  },
  "a1f3a5f16faf9670f948f1e4e84d12f08dfe353b": {
    "paperId": "a1f3a5f16faf9670f948f1e4e84d12f08dfe353b",
    "title": "From \"Ban It Till We Understand It\" to \"Resistance is Futile\": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot",
    "year": 2023,
    "authors": "Sam Lau, Philip J. Guo",
    "abstract": "Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.",
    "citationCount": 219,
    "pdf_filename": "2023_From__Ban_It_Till_We_Understand_It__to___a1f3a5f1.pdf"
  },
  "f03f39f735186c4359b719724be6e1c2eb912fef": {
    "paperId": "f03f39f735186c4359b719724be6e1c2eb912fef",
    "title": "Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming",
    "year": 2023,
    "authors": "Majeed Kazemitabaar, J. Chow, Carl Ka To Ma, B. Ericson, David Weintrop",
    "abstract": "AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.",
    "citationCount": 280,
    "pdf_filename": "2023_Studying_the_effect_of_AI_Code_Generator_f03f39f7.pdf"
  },
  "c3ec9c6f4e82e90c0a3fea0802cc5b33f66e1b9b": {
    "paperId": "c3ec9c6f4e82e90c0a3fea0802cc5b33f66e1b9b",
    "title": "GRAM: Generative Radiance Manifolds for 3D-Aware Image Generation",
    "year": 2021,
    "authors": "Yu Deng, Jiaolong Yang, Jianfeng Xiang, Xin Tong",
    "abstract": "3D-aware image generative modeling aims to generate 3D-consistent images with explicitly controllable camera poses. Recent works have shown promising results by training neural radiance field (NeRF) generators on unstructured 2D images, but still cannot generate highly-realistic images with fine details. A critical reason is that the high memory and computation cost of volumetric representation learning greatly restricts the number of point samples for radiance integration during training. Deficient sampling not only limits the expressive power of the generator to handle fine details but also impedes effective GAN training due to the noise caused by unstable Monte Carlo sampling. We propose a novel approach that regulates point sampling and radiance field learning on 2D manifolds, embodied as a set of learned implicit surfaces in the 3D volume. For each viewing ray, we calculate ray-surface intersections and accumulate their radiance generated by the network. By training and rendering such radiance mani folds, our generator can produce high quality images with realistic fine details and strong visual 3D consistency. 11Project page: https://yudeng.github.io/GRAM/",
    "citationCount": 271,
    "pdf_filename": "2021_GRAM__Generative_Radiance_Manifolds_for__c3ec9c6f.pdf"
  },
  "328926c090b184c3c62b4d6224cc7b7fdc318c53": {
    "paperId": "328926c090b184c3c62b4d6224cc7b7fdc318c53",
    "title": "Using AI-generated suggestions from ChatGPT to optimize clinical decision support",
    "year": 2023,
    "authors": "Siru Liu, A. Wright, B. Patterson, J. Wanderer, R. Turer",
    "abstract": "Abstract Objective To determine if ChatGPT can generate useful suggestions for improving clinical decision support (CDS) logic and to assess noninferiority compared to human-generated suggestions. Methods We supplied summaries of CDS logic to ChatGPT, an artificial intelligence (AI) tool for question answering that uses a large language model, and asked it to generate suggestions. We asked human clinician reviewers to review the AI-generated suggestions as well as human-generated suggestions for improving the same CDS alerts, and rate the suggestions for their usefulness, acceptance, relevance, understanding, workflow, bias, inversion, and redundancy. Results Five clinicians analyzed 36 AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. The suggestions generated by AI were found to offer unique perspectives and were evaluated as highly understandable and relevant, with moderate usefulness, low acceptance, bias, inversion, redundancy. Conclusion AI-generated suggestions could be an important complementary part of optimizing CDS alerts, can identify potential improvements to alert logic and support their implementation, and may even be able to assist experts in formulating their own suggestions for CDS improvement. ChatGPT shows great potential for using large language models and reinforcement learning from human feedback to improve CDS alert logic and potentially other medical areas involving complex, clinical logic, a key step in the development of an advanced learning health system.",
    "citationCount": 282,
    "pdf_filename": "2023_Using_AI_generated_suggestions_from_Chat_328926c0.pdf"
  },
  "2996da066a48e4674454f5f75ad5cc6f85f23ff6": {
    "paperId": "2996da066a48e4674454f5f75ad5cc6f85f23ff6",
    "title": "Managing extreme AI risks amid rapid progress",
    "year": 2023,
    "authors": "Y. Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel",
    "abstract": "Preparation requires technical research and development, as well as adaptive, proactive governance Artificial intelligence (AI) is progressing rapidly, and companies are shifting their focus to developing generalist AI systems that can autonomously act and pursue goals. Increases in capabilities and autonomy may soon massively amplify AI’s impact, with risks that include large-scale social harms, malicious uses, and an irreversible loss of human control over autonomous AI systems. Although researchers have warned of extreme risks from AI (1), there is a lack of consensus about how to manage them. Society’s response, despite promising first steps, is incommensurate with the possibility of rapid, transformative progress that is expected by many experts. AI safety research is lagging. Present governance initiatives lack the mechanisms and institutions to prevent misuse and recklessness and barely address autonomous systems. Drawing on lessons learned from other safety-critical technologies, we outline a comprehensive plan that combines technical research and development (R&D) with proactive, adaptive governance mechanisms for a more commensurate preparation.",
    "citationCount": 296,
    "pdf_filename": "2023_Managing_extreme_AI_risks_amid_rapid_pro_2996da06.pdf"
  },
  "260b119dce61cdd8affb13782fec7e8f331f9c98": {
    "paperId": "260b119dce61cdd8affb13782fec7e8f331f9c98",
    "title": "Evaluating the efficacy of AI content detection tools in differentiating between human and AI-generated text",
    "year": 2023,
    "authors": "Ahmed M. Elkhatat, Khaled Elsaid, S. Almeer",
    "abstract": "The proliferation of artificial intelligence (AI)-generated content, particularly from models like ChatGPT, presents potential challenges to academic integrity and raises concerns about plagiarism. This study investigates the capabilities of various AI content detection tools in discerning human and AI-authored content. Fifteen paragraphs each from ChatGPT Models 3.5 and 4 on the topic of cooling towers in the engineering process and five human-witten control responses were generated for evaluation. AI content detection tools developed by OpenAI, Writer, Copyleaks, GPTZero, and CrossPlag were used to evaluate these paragraphs. Findings reveal that the AI detection tools were more accurate in identifying content generated by GPT 3.5 than GPT 4. However, when applied to human-written control responses, the tools exhibited inconsistencies, producing false positives and uncertain classifications. This study underscores the need for further development and refinement of AI content detection tools as AI-generated content becomes more sophisticated and harder to distinguish from human-written text.",
    "citationCount": 244,
    "pdf_filename": "2023_Evaluating_the_efficacy_of_AI_content_de_260b119d.pdf"
  },
  "c03452648d60b4acf3e98a582f660783a3be0ccc": {
    "paperId": "c03452648d60b4acf3e98a582f660783a3be0ccc",
    "title": "Artificial intelligence (AI) technology in OpenAI ChatGPT application: A review of ChatGPT in writing English essay",
    "year": 2023,
    "authors": "Tira Nur Fitria",
    "abstract": "ChatGPT is a product of AI that is currently being widely discussed on Twitter. This research reviews how ChatGPT writes English essays. This research is descriptive qualitative. The analysis shows that we can access ChatGPT on openai.com or chat.openai.com on the browser. If we do not have an account, we register via email, Google, or Microsoft account. After login, enter a question or statement in the conversation column provided. Send it and ChatGPT will respond and the answer appear quickly. The researcher tries ChatGPT “Can you help me in doing my English assignment?\", and the ChatBot replies \"Of course! I'd be happy to help you with your English assignment. What do you need help with? Do you have a specific question or task that you're working on, or is there a broader topic that you'd like help with? It would be helpful to have some more information so that I can better understand how I can assist you\". Based on several tries, ChatGPT can answer all questions on various topics such as English essays including a descriptive text about Solo and My Family, recount text about personal experience and unforgettable moments, resolution in 2023, and future career. ChatGPT considers the event orders and writing order, including using main, explanatory sentences, and a conclusion. It uses two voices both active and passive voice. Besides, it considers tenses use related to the given topic essay. However, from examples of English essays produced by ChatGPT, it certainly requires further research to find out that the essay results are grammatically accurate.",
    "citationCount": 261,
    "pdf_filename": "2023_Artificial_intelligence__AI__technology__c0345264.pdf"
  },
  "554b3ea5c82cde1884432259bf83bb8807bfb982": {
    "paperId": "554b3ea5c82cde1884432259bf83bb8807bfb982",
    "title": "The Current and Future State of AI Interpretation of Medical Images.",
    "year": 2023,
    "authors": "P. Rajpurkar, M. Lungren",
    "abstract": "(Abstracted from N Engl J Med 2023;388:1981–1990)\n Artificial intelligence (AI) is playing an increasing role in many aspects of business and health care, including in the interpretation of medical images. This article is a review and discussion about the progress, challenges, and opportunities associated with AI in assisting radiologists and other medical professionals, in addition to risks associated with AI interpretation of images.",
    "citationCount": 250,
    "pdf_filename": "2023_The_Current_and_Future_State_of_AI_Inter_554b3ea5.pdf"
  },
  "4a98355e240705ff6ebbcb5213b61e02cbc9c4a8": {
    "paperId": "4a98355e240705ff6ebbcb5213b61e02cbc9c4a8",
    "title": "A systematic review of Green AI",
    "year": 2023,
    "authors": "Roberto Verdecchia, June Sallou, Luís Cruz",
    "abstract": "With the ever‐growing adoption of artificial intelligence (AI)‐based systems, the carbon footprint of AI is no longer negligible. AI researchers and practitioners are therefore urged to hold themselves accountable for the carbon emissions of the AI models they design and use. This led in recent years to the appearance of researches tackling AI environmental sustainability, a field referred to as Green AI. Despite the rapid growth of interest in the topic, a comprehensive overview of Green AI research is to date still missing. To address this gap, in this article, we present a systematic review of the Green AI literature. From the analysis of 98 primary studies, different patterns emerge. The topic experienced a considerable growth from 2020 onward. Most studies consider monitoring AI model footprint, tuning hyperparameters to improve model sustainability, or benchmarking models. A mix of position papers, observational studies, and solution papers are present. Most papers focus on the training phase, are algorithm‐agnostic or study neural networks, and use image data. Laboratory experiments are the most common research strategy. Reported Green AI energy savings go up to 115%, with savings over 50% being rather common. Industrial parties are involved in Green AI studies, albeit most target academic readers. Green AI tool provisioning is scarce. As a conclusion, the Green AI research field results to have reached a considerable level of maturity. Therefore, from this review emerges that the time is suitable to adopt other Green AI research strategies, and port the numerous promising academic results to industrial practice.",
    "citationCount": 228,
    "pdf_filename": "2023_A_systematic_review_of_Green_AI_4a98355e.pdf"
  },
  "cb9c6ddc24457070d25506937c780c084337d128": {
    "paperId": "cb9c6ddc24457070d25506937c780c084337d128",
    "title": "An Overview of Catastrophic AI Risks",
    "year": 2023,
    "authors": "Dan Hendrycks, Mantas Mazeika, Thomas Woodside",
    "abstract": "Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose catastrophic risks. Although numerous risks have been detailed separately, there is a pressing need for a systematic discussion and illustration of the potential dangers to better inform efforts to mitigate them. This paper provides an overview of the main sources of catastrophic AI risks, which we organize into four categories: malicious use, in which individuals or groups intentionally use AIs to cause harm; AI race, in which competitive environments compel actors to deploy unsafe AIs or cede control to AIs; organizational risks, highlighting how human factors and complex systems can increase the chances of catastrophic accidents; and rogue AIs, describing the inherent difficulty in controlling agents far more intelligent than humans. For each category of risk, we describe specific hazards, present illustrative stories, envision ideal scenarios, and propose practical suggestions for mitigating these dangers. Our goal is to foster a comprehensive understanding of these risks and inspire collective and proactive efforts to ensure that AIs are developed and deployed in a safe manner. Ultimately, we hope this will allow us to realize the benefits of this powerful technology while minimizing the potential for catastrophic outcomes.",
    "citationCount": 235,
    "pdf_filename": "2023_An_Overview_of_Catastrophic_AI_Risks_cb9c6ddc.pdf"
  },
  "2addfdfbbc9db9cc23017ec2967b26484de6604c": {
    "paperId": "2addfdfbbc9db9cc23017ec2967b26484de6604c",
    "title": "AI and the transformation of social science research",
    "year": 2023,
    "authors": "I. Grossmann, M. Feinberg, D. C. Parker, N. Christakis, P. Tetlock",
    "abstract": "Careful bias management and data fidelity are key Advances in artificial intelligence (AI), particularly large language models (LLMs), are substantially affecting social science research. These transformer-based machine-learning models pretrained on vast amounts of text data are increasingly capable of simulating human-like responses and behaviors (1, 2), offering opportunities to test theories and hypotheses about human behavior at great scale and speed. This presents urgent challenges: How can social science research practices be adapted, even reinvented, to harness the power of foundational AI? And how can this be done while ensuring transparent and replicable research?",
    "citationCount": 239,
    "pdf_filename": "2023_AI_and_the_transformation_of_social_scie_2addfdfb.pdf"
  },
  "3e2fd4f099046ad3b61d8cad107d5883dc52370a": {
    "paperId": "3e2fd4f099046ad3b61d8cad107d5883dc52370a",
    "title": "Bias in AI-based models for medical applications: challenges and mitigation strategies",
    "year": 2023,
    "authors": "M. Mittermaier, Marium M. Raza, J. Kvedar",
    "abstract": "Artificial intelligence systems are increasingly being applied to healthcare. In surgery, AI applications hold promise as tools to predict surgical outcomes, assess technical skills, or guide surgeons intraoperatively via computer vision. On the other hand, AI systems can also suffer from bias, compounding existing inequities in socioeconomic status, race, ethnicity, religion, gender, disability, or sexual orientation. Bias particularly impacts disadvantaged populations, which can be subject to algorithmic predictions that are less accurate or underestimate the need for care. Thus, strategies for detecting and mitigating bias are pivotal for creating AI technology that is generalizable and fair. Here, we discuss a recent study that developed a new strategy to mitigate bias in surgical AI systems.",
    "citationCount": 223,
    "pdf_filename": "2023_Bias_in_AI_based_models_for_medical_appl_3e2fd4f0.pdf"
  },
  "988a1ab0c1ebd7eb4817fbc8ce41f962dd519998": {
    "paperId": "988a1ab0c1ebd7eb4817fbc8ce41f962dd519998",
    "title": "An introduction to deep generative modeling",
    "year": 2021,
    "authors": "Lars Ruthotto, E. Haber",
    "abstract": "Deep generative models (DGM) are neural networks with many hidden layers trained to approximate complicated, high‐dimensional probability distributions using samples. When trained successfully, we can use the DGM to estimate the likelihood of each observation and to create new samples from the underlying distribution. Developing DGMs has become one of the most hotly researched fields in artificial intelligence in recent years. The literature on DGMs has become vast and is growing rapidly. Some advances have even reached the public sphere, for example, the recent successes in generating realistic‐looking images, voices, or movies; so‐called deep fakes. Despite these successes, several mathematical and practical issues limit the broader use of DGMs: given a specific dataset, it remains challenging to design and train a DGM and even more challenging to find out why a particular model is or is not effective. To help advance the theoretical understanding of DGMs, we introduce DGMs and provide a concise mathematical framework for modeling the three most popular approaches: normalizing flows, variational autoencoders, and generative adversarial networks. We illustrate the advantages and disadvantages of these basic approaches using numerical experiments. Our goal is to enable and motivate the reader to contribute to this proliferating research area. Our presentation also emphasizes relations between generative modeling and optimal transport.",
    "citationCount": 271,
    "pdf_filename": "2021_An_introduction_to_deep_generative_model_988a1ab0.pdf"
  },
  "c744848da3ef33f971399b2afad6dfc6681873e9": {
    "paperId": "c744848da3ef33f971399b2afad6dfc6681873e9",
    "title": "How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard.",
    "year": 2023,
    "authors": "A. Rahsepar, Neda Tavakoli, G. Kim, Cameron Hassani, F. Abtin",
    "abstract": "Background The recent release of large language models (LLMs) for public use, such as ChatGPT and Google Bard, has opened up a multitude of potential benefits as well as challenges. Purpose To evaluate and compare the accuracy and consistency of responses generated by publicly available ChatGPT-3.5 and Google Bard to non-expert questions related to lung cancer prevention, screening, and terminology commonly used in radiology reports based on the recommendation of Lung Imaging Reporting and Data System (Lung-RADS) v2022 from American College of Radiology and Fleischner society. Materials and Methods Forty of the exact same questions were created and presented to ChatGPT-3.5 and Google Bard experimental version as well as Bing and Google search engines by three different authors of this paper. Each answer was reviewed by two radiologists for accuracy. Responses were scored as correct, partially correct, incorrect, or unanswered. Consistency was also evaluated among the answers. Here, consistency was defined as the agreement between the three answers provided by ChatGPT-3.5, Google Bard experimental version, Bing, and Google search engines regardless of whether the concept conveyed was correct or incorrect. The accuracy among different tools were evaluated using Stata. Results ChatGPT-3.5 answered 120 questions with 85 (70.8%) correct, 14 (11.7%) partially correct, and 21 (17.5%) incorrect. Google Bard did not answer 23 (19.1%) questions. Among the 97 questions answered by Google Bard, 62 (51.7%) were correct, 11 (9.2%) were partially correct, and 24 (20%) were incorrect. Bing answered 120 questions with 74 (61.7%) correct, 13 (10.8%) partially correct, and 33 (27.5%) incorrect. Google search engine answered 120 questions with 66 (55%) correct, 27 (22.5%) partially correct, and 27 (22.5%) incorrect. The ChatGPT-3.5 is more likely to provide correct or partially answer than Google Bard, approximately by 1.5 folds (OR = 1.55, P = 0.004). ChatGPT-3.5 and Google search engine were more likely to be consistent than Google Bard by approximately 7 and 29 folds (OR = 6.65, P = 0.002 for ChatGPT and OR = 28.83, P = 0.002 for Google search engine, respectively). Conclusion Although ChatGPT-3.5 had a higher accuracy in comparison with the other tools, neither ChatGPT nor Google Bard, Bing and Google search engines answered all questions correctly and with 100% consistency.",
    "citationCount": 227,
    "pdf_filename": "2023_How_AI_Responds_to_Common_Lung_Cancer_Qu_c744848d.pdf"
  },
  "57d71b30f2ff68bde4a0c50322bb93a5c3358ee0": {
    "paperId": "57d71b30f2ff68bde4a0c50322bb93a5c3358ee0",
    "title": "DeepCAD: A Deep Generative Network for Computer-Aided Design Models",
    "year": 2021,
    "authors": "Rundi Wu, Chang Xiao, Changxi Zheng",
    "abstract": "Deep generative models of 3D shapes have received a great deal of research interest. Yet, almost all of them generate discrete shape representations, such as voxels, point clouds, and polygon meshes. We present the first 3D generative model for a drastically different shape representation— describing a shape as a sequence of computer-aided design (CAD) operations. Unlike meshes and point clouds, CAD models encode the user creation process of 3D shapes, widely used in numerous industrial and engineering design tasks. However, the sequential and irregular structure of CAD operations poses significant challenges for existing 3D generative models. Drawing an analogy between CAD operations and natural language, we propose a CAD generative network based on the Transformer. We demonstrate the performance of our model for both shape autoencoding and random shape generation. To train our network, we create a new CAD dataset consisting of 178,238 models and their CAD construction sequences. We have made this dataset publicly available to promote future research on this topic.",
    "citationCount": 224,
    "pdf_filename": "2021_DeepCAD__A_Deep_Generative_Network_for_C_57d71b30.pdf"
  },
  "56e5f5810441f0ce72641cc8db2217510fd5f48d": {
    "paperId": "56e5f5810441f0ce72641cc8db2217510fd5f48d",
    "title": "Attention is all you need: utilizing attention in AI-enabled drug discovery",
    "year": 2023,
    "authors": "Yang Zhang, Caiqi Liu, Mujiexin Liu, Tianyuan Liu, Hao Lin",
    "abstract": "Abstract Recently, attention mechanism and derived models have gained significant traction in drug development due to their outstanding performance and interpretability in handling complex data structures. This review offers an in-depth exploration of the principles underlying attention-based models and their advantages in drug discovery. We further elaborate on their applications in various aspects of drug development, from molecular screening and target binding to property prediction and molecule generation. Finally, we discuss the current challenges faced in the application of attention mechanisms and Artificial Intelligence technologies, including data quality, model interpretability and computational resource constraints, along with future directions for research. Given the accelerating pace of technological advancement, we believe that attention-based models will have an increasingly prominent role in future drug discovery. We anticipate that these models will usher in revolutionary breakthroughs in the pharmaceutical domain, significantly accelerating the pace of drug development.",
    "citationCount": 246,
    "pdf_filename": "2023_Attention_is_all_you_need__utilizing_att_56e5f581.pdf"
  },
  "6b4e030193fc5a2cf82486ec3b3929dc3d3ac308": {
    "paperId": "6b4e030193fc5a2cf82486ec3b3929dc3d3ac308",
    "title": "How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models",
    "year": 2021,
    "authors": "A. Alaa, B. V. Breugel, Evgeny S. Saveliev, M. Schaar",
    "abstract": "Devising domain- and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis setup, exhibit a limited capacity for diagnosing the different modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional evaluation metric, ($\\alpha$-Precision, $\\beta$-Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a domain-agnostic fashion. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample- and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional, independent dimension (to the fidelity-diversity trade-off) that quantifies the extent to which a model copies training data -- a crucial performance indicator when modeling sensitive data with requirements on privacy. The three metric components correspond to (interpretable) probabilistic quantities, and are estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.",
    "citationCount": 239,
    "pdf_filename": "2021_How_Faithful_is_your_Synthetic_Data__Sam_6b4e0301.pdf"
  },
  "63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e": {
    "paperId": "63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e",
    "title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching",
    "year": 2021,
    "authors": "Chin-Wei Huang, Jae Hyun Lim, Aaron C. Courville",
    "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes that transform data into noise can be reversed via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap.",
    "citationCount": 226,
    "pdf_filename": "2021_A_Variational_Perspective_on_Diffusion_B_63d6a3cc.pdf"
  },
  "f6e0637d66ef12a675c1230613b995f63fd9693f": {
    "paperId": "f6e0637d66ef12a675c1230613b995f63fd9693f",
    "title": "SMPLicit: Topology-aware Generative Model for Clothed People",
    "year": 2021,
    "authors": "Enric Corona, Albert Pumarola, G. Alenyà, Gerard Pons-Moll, F. Moreno-Noguer",
    "abstract": "In this paper we introduce SMPLicit, a novel generative model to jointly represent body pose, shape and clothing geometry. In contrast to existing learning-based approaches that require training specific models for each type of garment, SMPLicit can represent in a unified manner different garment topologies (e.g. from sleeveless tops to hoodies and to open jackets), while controlling other properties like the garment size or tightness/looseness. We show our model to be applicable to a large variety of garments including T-shirts, hoodies, jackets, shorts, pants, skirts, shoes and even hair. The representation flexibility of SMPLicit builds upon an implicit model conditioned with the SMPL human body parameters and a learnable latent space which is semantically interpretable and aligned with the clothing attributes. The proposed model is fully differentiable, allowing for its use into larger end-to-end trainable systems. In the experimental section, we demonstrate SMPLicit can be readily used for fitting 3D scans and for 3D reconstruction in images of dressed people. In both cases we are able to go beyond state of the art, by retrieving complex garment geometries, handling situations with multiple clothing layers and providing a tool for easy outfit editing. To stimulate further research in this direction, we will make our code and model publicly available at http://www.iri.upc.edu/people/ecorona/smplicit/.",
    "citationCount": 208,
    "pdf_filename": "2021_SMPLicit__Topology_aware_Generative_Mode_f6e0637d.pdf"
  },
  "90c4081fd752df2bb4a6cabce728d116472d457d": {
    "paperId": "90c4081fd752df2bb4a6cabce728d116472d457d",
    "title": "Deep Generative Models in Engineering Design: A Review",
    "year": 2021,
    "authors": "Lyle Regenwetter, A. Nobari, Faez Ahmed",
    "abstract": "\n Automated design synthesis has the potential to revolutionize the modern engineering design process and improve access to highly optimized and customized products across countless industries. Successfully adapting generative Machine Learning to design engineering may enable such automated design synthesis and is a research subject of great importance. We present a review and analysis of Deep Generative Learning models in engineering design. Deep Generative Models (DGMs) typically leverage deep networks to learn from an input dataset and synthesize new designs. Recently, DGMs such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), feedforward Neural Networks (NNs) and certain Deep Reinforcement Learning (DRL) frameworks have shown promising results in design applications like structural optimization, materials design, and shape synthesis. The prevalence of DGMs in Engineering Design has skyrocketed since 2016. Anticipating continued growth, we conduct a review of recent advances with the hope of benefitting researchers interested in DGMs for design. We structure our review as an exposition of the algorithms, datasets, representation methods, and applications commonly used in the current literature. In particular, we discuss key works that have introduced new techniques and methods in DGMs, successfully applied DGMs to a design-related domain, or directly supported development of DGMs through datasets or auxiliary methods. We further identify key challenges and limitations currently seen in DGMs across design fields, such as design creativity, handling constraints and objectives, and modeling both form and functional performance simultaneously. In our discussion we identify possible solution pathways as key areas on which to target future work.",
    "citationCount": 242,
    "pdf_filename": "2021_Deep_Generative_Models_in_Engineering_De_90c4081f.pdf"
  },
  "0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde": {
    "paperId": "0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde",
    "title": "Plagiarism in the age of massive Generative Pre-trained Transformers (GPT-3)",
    "year": 2021,
    "authors": "N. Dehouche",
    "abstract": "As if 2020 was not a peculiar enough year, its fifth month saw the relatively quiet publication of a preprint describing the most powerful natural language processing (NLP) system to date—GPT-3 (Generative Pre-trained Transformer-3)—created by the Silicon Valley research firm OpenAI. Though the software implementation of GPT-3 is still in its initial beta release phase, and its full capabilities are still unknown as of the time of this writing, it has been shown that this artificial intelligence can comprehend prompts in natural language, on virtually any topic, and generate relevant original text content that is indistinguishable from human writing. Moreover, access to these capabilities, in a limited yet worrisome enough extent, is available to the general public. This paper presents examples of original content generated by the author using GPT-3. These examples illustrate some of the capabilities of GPT-3 in comprehending prompts in natural language and generating convincing content in response. I use these examples to raise specific fundamental questions pertaining to the intellectual property of this content and the potential use of GPT-3 to facilitate plagiarism. The goal is to instigate a sense of urgency, as well as a sense of present tardiness on the part of the academic community in addressing these questions.",
    "citationCount": 237,
    "pdf_filename": "2021_Plagiarism_in_the_age_of_massive_Generat_0c97903e.pdf"
  },
  "6e6e0979c07d3bc686af12b015f428790e05a6f7": {
    "paperId": "6e6e0979c07d3bc686af12b015f428790e05a6f7",
    "title": "PoisonGAN: Generative Poisoning Attacks Against Federated Learning in Edge Computing Systems",
    "year": 2021,
    "authors": "Jiale Zhang, Bing Chen, Xiang Cheng, H. Binh, Shui Yu",
    "abstract": "Edge computing is a key-enabling technology that meets continuously increasing requirements for the intelligent Internet-of-Things (IoT) applications. To cope with the increasing privacy leakages of machine learning while benefiting from unbalanced data distributions, federated learning has been wildly adopted as a novel intelligent edge computing framework with a localized training mechanism. However, recent studies found that the federated learning framework exhibits inherent vulnerabilities on active attacks, and poisoning attack is one of the most powerful and secluded attacks where the functionalities of the global model could be damaged through attacker’s well-crafted local updates. In this article, we give a comprehensive exploration of the poisoning attack mechanisms in the context of federated learning. We first present a poison data generation method, named Data_Gen, based on the generative adversarial networks (GANs). This method mainly relies upon the iteratively updated global model parameters to regenerate samples of interested victims. Second, we further propose a novel generative poisoning attack model, named PoisonGAN, against the federated learning framework. This model utilizes the designed Data_Gen method to efficiently reduce the attack assumptions and make attacks feasible in practice. We finally evaluate our data generation and attack models by implementing two types of typical poisoning attack strategies, label flipping and backdoor, on a federated learning prototype. The experimental results demonstrate that these two attack models are effective in federated learning.",
    "citationCount": 214,
    "pdf_filename": "2021_PoisonGAN__Generative_Poisoning_Attacks__6e6e0979.pdf"
  },
  "ca722c18eb6546d307f6c3a0c1efd064a53a6a29": {
    "paperId": "ca722c18eb6546d307f6c3a0c1efd064a53a6a29",
    "title": "Inverse design of 3d molecular structures with conditional generative neural networks",
    "year": 2021,
    "authors": "N. Gebauer, M. Gastegger, Stefaan S. P. Hessmann, Klaus-Robert Müller, Kristof T. Schütt",
    "abstract": "The rational design of molecules with desired properties is a long-standing challenge in chemistry. Generative neural networks have emerged as a powerful approach to sample novel molecules from a learned distribution. Here, we propose a conditional generative neural network for 3d molecular structures with specified chemical and structural properties. This approach is agnostic to chemical bonding and enables targeted sampling of novel molecules from conditional distributions, even in domains where reference calculations are sparse. We demonstrate the utility of our method for inverse design by generating molecules with specified motifs or composition, discovering particularly stable molecules, and jointly targeting multiple electronic properties beyond the training regime. The targeted discovery of molecules with specific structural and chemical properties is an open challenge in computational chemistry. Here, the authors propose a conditional generative neural network for the inverse design of 3d molecular structures.",
    "citationCount": 200,
    "pdf_filename": "2021_Inverse_design_of_3d_molecular_structure_ca722c18.pdf"
  },
  "b477a11b8934e36cda11b1b1f16e954d32e4a571": {
    "paperId": "b477a11b8934e36cda11b1b1f16e954d32e4a571",
    "title": "Generating three-dimensional structures from a two-dimensional slice with generative adversarial network-based dimensionality expansion",
    "year": 2021,
    "authors": "Steve Kench, Samuel J. Cooper",
    "abstract": "Generative adversarial networks (GANs) can be trained to generate three-dimensional (3D) image data, which are useful for design optimization. However, this conventionally requires 3D training data, which are challenging to obtain. Two-dimensional (2D) imaging techniques tend to be faster, higher resolution, better at phase identification and more widely available. Here we introduce a GAN architecture, SliceGAN, that is able to synthesize high-fidelity 3D datasets using a single representative 2D image. This is especially relevant for the task of material microstructure generation, as a cross-sectional micrograph can contain sufficient information to statistically reconstruct 3D samples. Our architecture implements the concept of uniform information density, which ensures both that generated volumes are equally high quality at all points in space and that arbitrarily large volumes can be generated. SliceGAN has been successfully trained on a diverse set of materials, demonstrating the widespread applicability of this tool. The quality of generated micrographs is shown through a statistical comparison of synthetic and real datasets of a battery electrode in terms of key microstructural metrics. Finally, we find that the generation time for a 108 voxel volume is on the order of a few seconds, yielding a path for future studies into high-throughput microstructural optimization. A generative approach called SliceGAN is demonstrated that can construct complex three-dimensional (3D) images from representative two-dimensional (2D) image examples. This is a promising approach in particular for studying microstructured materials where acquiring good-quality 3D data is challenging; 3D datasets can be created with SliceGAN, making use of high-quality 2D imaging techniques that are widely available.",
    "citationCount": 210,
    "pdf_filename": "2021_Generating_three_dimensional_structures__b477a11b.pdf"
  },
  "d4f6ef636e16b001986b541aa2afc76eed42ae34": {
    "paperId": "d4f6ef636e16b001986b541aa2afc76eed42ae34",
    "title": "Considering the possibilities and pitfalls of Generative Pre-trained Transformer 3 (GPT-3) in healthcare delivery",
    "year": 2021,
    "authors": "Diane M. Korngiebel, S. Mooney",
    "abstract": "Natural language computer applications are becoming increasingly sophisticated and, with the recent release of Generative Pre-trained Transformer 3, they could be deployed in healthcare-related contexts that have historically comprised human-to-human interaction. However, for GPT-3 and similar applications to be considered for use in health-related contexts, possibilities and pitfalls need thoughtful exploration. In this article, we briefly introduce some opportunities and cautions that would accompany advanced Natural Language Processing applications deployed in eHealth.",
    "citationCount": 203,
    "pdf_filename": "2021_Considering_the_possibilities_and_pitfal_d4f6ef63.pdf"
  },
  "cce6e863d5408244284d97f5a13e8c9ab103ad01": {
    "paperId": "cce6e863d5408244284d97f5a13e8c9ab103ad01",
    "title": "AI Tools in Society: Impacts on Cognitive Offloading and the Future of Critical Thinking",
    "year": 2025,
    "authors": "Michael Gerlich",
    "abstract": "The proliferation of artificial intelligence (AI) tools has transformed numerous aspects of daily life, yet its impact on critical thinking remains underexplored. This study investigates the relationship between AI tool usage and critical thinking skills, focusing on cognitive offloading as a mediating factor. Utilising a mixed-method approach, we conducted surveys and in-depth interviews with 666 participants across diverse age groups and educational backgrounds. Quantitative data were analysed using ANOVA and correlation analysis, while qualitative insights were obtained through thematic analysis of interview transcripts. The findings revealed a significant negative correlation between frequent AI tool usage and critical thinking abilities, mediated by increased cognitive offloading. Younger participants exhibited higher dependence on AI tools and lower critical thinking scores compared to older participants. Furthermore, higher educational attainment was associated with better critical thinking skills, regardless of AI usage. These results highlight the potential cognitive costs of AI tool reliance, emphasising the need for educational strategies that promote critical engagement with AI technologies. This study contributes to the growing discourse on AI’s cognitive implications, offering practical recommendations for mitigating its adverse effects on critical thinking. The findings underscore the importance of fostering critical thinking in an AI-driven world, making this research essential reading for educators, policymakers, and technologists.",
    "citationCount": 256,
    "pdf_filename": "2025_AI_Tools_in_Society__Impacts_on_Cognitiv_cce6e863.pdf"
  },
  "09d8841eeb362a2c04f055f70f16d634093c83bc": {
    "paperId": "09d8841eeb362a2c04f055f70f16d634093c83bc",
    "title": "Agentic AI: Autonomous Intelligence for Complex Goals—A Comprehensive Survey",
    "year": 2025,
    "authors": "D. Acharya, Karthigeyan Kuppan, Divya Bhaskaracharya",
    "abstract": "Agentic AI, an emerging paradigm in artificial intelligence, refers to autonomous systems designed to pursue complex goals with minimal human intervention. Unlike traditional AI, which depends on structured instructions and close oversight, Agentic AI demonstrates adaptability, advanced decision-making capabilities and self-sufficiency, enabling it to operate dynamically in evolving environments. This survey thoroughly explores the foundational concepts, unique characteristics, and core methodologies driving the development of Agentic AI. We examine its current and potential applications across various fields, including healthcare, finance, and adaptive software systems, emphasizing the advantages of deploying agentic systems in real-world scenarios. The paper also addresses the ethical challenges posed by Agentic AI, proposing solutions for goal alignment, resource constraints, and environmental adaptability. We outline a framework for safely and effectively integrating Agentic AI into society, highlighting the need for further research on ethical considerations to ensure beneficial societal impacts. This survey serves as a comprehensive introduction to Agentic AI, guiding researchers, developers, and policymakers in engaging with its transformative potential responsibly and creatively.",
    "citationCount": 228,
    "pdf_filename": "2025_Agentic_AI__Autonomous_Intelligence_for__09d8841e.pdf"
  },
  "c20f15b3a76d04b342f2b1c2d51a768d8c1a7c8a": {
    "paperId": "c20f15b3a76d04b342f2b1c2d51a768d8c1a7c8a",
    "title": "Explainable AI for Healthcare 5.0: Opportunities and Challenges",
    "year": 2022,
    "authors": "Deepti Saraswat, Pronaya Bhattacharya, A. Verma, V. Prasad, Sudeep Tanwar",
    "abstract": "In the healthcare domain, a transformative shift is envisioned towards Healthcare 5.0. It expands the operational boundaries of Healthcare 4.0 and leverages patient-centric digital wellness. Healthcare 5.0 focuses on real-time patient monitoring, ambient control and wellness, and privacy compliance through assisted technologies like artificial intelligence (AI), Internet-of-Things (IoT), big data, and assisted networking channels. However, healthcare operational procedures, verifiability of prediction models, resilience, and lack of ethical and regulatory frameworks are potential hindrances to the realization of Healthcare 5.0. Recently, explainable AI (EXAI) has been a disruptive trend in AI that focuses on the explainability of traditional AI models by leveraging the decision-making of the models and prediction outputs. The explainability factor opens new opportunities to the black-box models and brings confidence in healthcare stakeholders to interpret the machine learning (ML) and deep learning (DL) models. EXAI is focused on improving clinical health practices and brings transparency to the predictive analysis, which is crucial in the healthcare domain. Recent surveys on EXAI in healthcare have not significantly focused on the data analysis and interpretation of models, which lowers its practical deployment opportunities. Owing to the gap, the proposed survey explicitly details the requirements of EXAI in Healthcare 5.0, the operational and data collection process. Based on the review method and presented research questions, systematically, the article unfolds a proposed architecture that presents an EXAI ensemble on the computerized tomography (CT) image classification and segmentation process. A solution taxonomy of EXAI in Healthcare 5.0 is proposed, and operational challenges are presented. A supported case study on electrocardiogram (ECG) monitoring is presented that preserves the privacy of local models via federated learning (FL) and EXAI for metric validation. The case-study is supported through experimental validation. The analysis proves the efficacy of EXAI in health setups that envisions real-life model deployments in a wide range of clinical applications.",
    "citationCount": 245,
    "pdf_filename": "2022_Explainable_AI_for_Healthcare_5_0__Oppor_c20f15b3.pdf"
  },
  "18bf61eb27c146f8e11ea0590c9b6787d8274ce6": {
    "paperId": "18bf61eb27c146f8e11ea0590c9b6787d8274ce6",
    "title": "GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution",
    "year": 2020,
    "authors": "Kelvin C. K. Chan, Xintao Wang, Xiangyu Xu, Jinwei Gu, Chen Change Loy",
    "abstract": "We show that pre-trained Generative Adversarial Networks (GANs), e.g., StyleGAN, can be used as a latent bank to improve the restoration quality of large-factor image super-resolution (SR). While most existing SR approaches attempt to generate realistic textures through learning with adversarial loss, our method, Generative LatEnt bANk (GLEAN), goes beyond existing practices by directly leveraging rich and diverse priors encapsulated in a pre-trained GAN. But unlike prevalent GAN inversion methods that require expensive image-specific optimization at runtime, our approach only needs a single forward pass to generate the upscaled image. GLEAN can be easily incorporated in a simple encoder-bank-decoder architecture with multi-resolution skip connections. Switching the bank allows the method to deal with images from diverse categories, e.g., cat, building, human face, and car. Images upscaled by GLEAN show clear improvements in terms of fidelity and texture faithfulness in comparison to existing methods as shown in Fig. 1.",
    "citationCount": 280,
    "pdf_filename": "2020_GLEAN__Generative_Latent_Bank_for_Large__18bf61eb.pdf"
  },
  "69020e32bf20e0d06f94d611230315b021b33548": {
    "paperId": "69020e32bf20e0d06f94d611230315b021b33548",
    "title": "FD-GAN: Generative Adversarial Networks with Fusion-discriminator for Single Image Dehazing",
    "year": 2020,
    "authors": "Yu Dong, Yihao Liu, He Zhang, Shifeng Chen, Y. Qiao",
    "abstract": "Recently, convolutional neural networks (CNNs) have achieved great improvements in single image dehazing and attained much attention in research. Most existing learning-based dehazing methods are not fully end-to-end, which still follow the traditional dehazing procedure: first estimate the medium transmission and the atmospheric light, then recover the haze-free image based on the atmospheric scattering model. However, in practice, due to lack of priors and constraints, it is hard to precisely estimate these intermediate parameters. Inaccurate estimation further degrades the performance of dehazing, resulting in artifacts, color distortion and insufficient haze removal. To address this, we propose a fully end-to-end Generative Adversarial Networks with Fusion-discriminator (FD-GAN) for image dehazing. With the proposed Fusion-discriminator which takes frequency information as additional priors, our model can generator more natural and realistic dehazed images with less color distortion and fewer artifacts. Moreover, we synthesize a large-scale training dataset including various indoor and outdoor hazy images to boost the performance and we reveal that for learning-based dehazing methods, the performance is strictly influenced by the training data. Experiments have shown that our method reaches state-of-the-art performance on both public synthetic datasets and real-world images with more visually pleasing dehazed results.",
    "citationCount": 272,
    "pdf_filename": "2020_FD_GAN__Generative_Adversarial_Networks__69020e32.pdf"
  },
  "2a5a8db41940990dc8fe8e7717ed85ba043204e1": {
    "paperId": "2a5a8db41940990dc8fe8e7717ed85ba043204e1",
    "title": "Generative Causal Explanations for Graph Neural Networks",
    "year": 2021,
    "authors": "Wanyu Lin, Hao Lan, Baochun Li",
    "abstract": "This paper presents Gem, a model-agnostic approach for providing interpretable explanations for any GNNs on various graph learning tasks. Specifically, we formulate the problem of providing explanations for the decisions of GNNs as a causal learning task. Then we train a causal explanation model equipped with a loss function based on Granger causality. Different from existing explainers for GNNs, Gem explains GNNs on graph-structured data from a causal perspective. It has better generalization ability as it has no requirements on the internal structure of the GNNs or prior knowledge on the graph learning tasks. In addition, Gem, once trained, can be used to explain the target GNN very quickly. Our theoretical analysis shows that several recent explainers fall into a unified framework of additive feature attribution methods. Experimental results on synthetic and real-world datasets show that Gem achieves a relative increase of the explanation accuracy by up to $30\\%$ and speeds up the explanation process by up to $110\\times$ as compared to its state-of-the-art alternatives.",
    "citationCount": 203,
    "pdf_filename": "2021_Generative_Causal_Explanations_for_Graph_2a5a8db4.pdf"
  },
  "b4cbc3ce5fddfbf2d3271018ae697569834a3433": {
    "paperId": "b4cbc3ce5fddfbf2d3271018ae697569834a3433",
    "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data",
    "year": 2020,
    "authors": "Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz",
    "abstract": "Photorealistic image generation has reached a new level of quality due to the breakthroughs of generative adversarial networks (GANs). Yet, the dark side of such deepfakes, the malicious use of generated media, raises concerns about visual misinformation. While existing research work on deepfake detection demonstrates high accuracy, it is subject to advances in generation techniques and adversarial iterations on detection countermeasure techniques. Thus, we seek a proactive and sustainable solution on deepfake detection, that is agnostic to the evolution of generative models, by introducing artificial fingerprints into the models.Our approach is simple and effective. We first embed artificial fingerprints into training data, then validate a surprising discovery on the transferability of such fingerprints from training data to generative models, which in turn appears in the generated deepfakes. Experiments show that our fingerprinting solution (1) holds for a variety of cutting-edge generative models, (2) leads to a negligible side effect on generation quality, (3) stays robust against image-level and model-level perturbations, (4) stays hard to be detected by adversaries, and (5) converts deepfake detection and attribution into trivial tasks and outperforms the recent state-of-the-art baselines. Our solution closes the responsibility loop between publishing pre-trained generative model inventions and their possible misuses, which makes it independent of the current arms race.",
    "citationCount": 263,
    "pdf_filename": "2020_Artificial_Fingerprinting_for_Generative_b4cbc3ce.pdf"
  },
  "555c0d308a1c9faa089430133566bf0dd6e4613d": {
    "paperId": "555c0d308a1c9faa089430133566bf0dd6e4613d",
    "title": "The Synthesizability of Molecules Proposed by Generative Models",
    "year": 2020,
    "authors": "Wenhao Gao, Connor W. Coley",
    "abstract": "The discovery of functional molecules is an expensive and time-consuming process, exemplified by the rising costs of small molecule therapeutic discovery. One class of techniques of growing interest for early-stage drug discovery is de novo molecular generation and optimization, catalyzed by the development of new deep learning approaches. These techniques can suggest novel molecular structures intended to maximize a multi-objective function, e.g., suitability as a therapeutic against a particular target, without relying on brute-force exploration of a chemical space. However, the utility of these approaches is stymied by ignorance of synthesizability. To highlight the severity of this issue, we use a data-driven computer-aided synthesis planning program to quantify how often molecules proposed by state-of-the-art generative models cannot be readily synthesized. Our analysis demonstrates that there are several tasks for which these models generate unrealistic molecular structures despite performing well on popular quantitative benchmarks. Synthetic complexity heuristics can successfully bias generation toward synthetically-tractable chemical space, although doing so necessarily detracts from the primary objective. This analysis suggests that to improve the utility of these models in real discovery workflows, new algorithm development is warranted.",
    "citationCount": 285,
    "pdf_filename": "2020_The_Synthesizability_of_Molecules_Propos_555c0d30.pdf"
  },
  "047796039425ad33e57c0e92141c8321cf708197": {
    "paperId": "047796039425ad33e57c0e92141c8321cf708197",
    "title": "Power to the People? Opportunities and Challenges for Participatory AI",
    "year": 2022,
    "authors": "Abeba Birhane, William S. Isaac, Vinodkumar Prabhakaran, M. D'iaz, M. C. Elish",
    "abstract": "Participatory approaches to artificial intelligence (AI) and machine learning (ML) are gaining momentum: the increased attention comes partly with the view that participation opens the gateway to an inclusive, equitable, robust, responsible and trustworthy AI. Among other benefits, participatory approaches are essential to understanding and adequately representing the needs, desires and perspectives of historically marginalized communities. However, there currently exists lack of clarity on what meaningful participation entails and what it is expected to do. In this paper we first review participatory approaches as situated in historical contexts as well as participatory methods and practices within the AI and ML pipeline. We then introduce three case studies in participatory AI. Participation holds the potential for beneficial, emancipatory and empowering technology design, development and deployment while also being at risk for concerns such as cooptation and conflation with other activities. We lay out these limitations and concerns and argue that as participatory AI/ML becomes in vogue, a contextual and nuanced understanding of the term as well as consideration of who the primary beneficiaries of participatory activities ought to be constitute crucial factors to realizing the benefits and opportunities that participation brings.",
    "citationCount": 299,
    "pdf_filename": "2022_Power_to_the_People__Opportunities_and_C_04779603.pdf"
  },
  "ce3f027b68dad014a58aa35f52380932c8d0b209": {
    "paperId": "ce3f027b68dad014a58aa35f52380932c8d0b209",
    "title": "Do Users Write More Insecure Code with AI Assistants?",
    "year": 2022,
    "authors": "Neil Perry, Megha Srivastava, Deepak Kumar, D. Boneh",
    "abstract": "AI code assistants have emerged as powerful tools that can aid in the software development life-cycle and can improve developer productivity. Unfortunately, such assistants have also been found to produce insecure code in lab environments, raising significant concerns about their usage in practice. In this paper, we conduct a user study to examine how users interact with AI code assistants to solve a variety of security related tasks. Overall, we find that participants who had access to an AI assistant wrote significantly less secure code than those without access to an assistant. Participants with access to an AI assistant were also more likely to believe they wrote secure code, suggesting that such tools may lead users to be overconfident about security flaws in their code. To better inform the design of future AI-based code assistants, we release our user-study apparatus to researchers seeking to build on our work.",
    "citationCount": 251,
    "pdf_filename": "2022_Do_Users_Write_More_Insecure_Code_with_A_ce3f027b.pdf"
  },
  "59dbb2de2d80ef62d401c2f1cdf05766898b093e": {
    "paperId": "59dbb2de2d80ef62d401c2f1cdf05766898b093e",
    "title": "AI-synthesized faces are indistinguishable from real faces and more trustworthy",
    "year": 2022,
    "authors": "Sophie J. Nightingale, Hany Farid",
    "abstract": "Artificial intelligence (AI)–synthesized text, audio, image, and video are being weaponized for the purposes of nonconsensual intimate imagery, financial fraud, and disinformation campaigns. Our evaluation of the photorealism of AI-synthesized faces indicates that synthesis engines have passed through the uncanny valley and are capable of creating faces that are indistinguishable—and more trustworthy—than real faces.",
    "citationCount": 256,
    "pdf_filename": "2022_AI_synthesized_faces_are_indistinguishab_59dbb2de.pdf"
  },
  "0ea5edaae43b26798190fd6ead50d447033e7d13": {
    "paperId": "0ea5edaae43b26798190fd6ead50d447033e7d13",
    "title": "The uselessness of AI ethics",
    "year": 2022,
    "authors": "Luke Munn",
    "abstract": "As the awareness of AI’s power and danger has risen, the dominant response has been a turn to ethical principles. A flood of AI guidelines and codes of ethics have been released in both the public and private sector in the last several years. However, these are meaningless principles which are contested or incoherent, making them difficult to apply; they are isolated principles situated in an industry and education system which largely ignores ethics; and they are toothless principles which lack consequences and adhere to corporate agendas. For these reasons, I argue that AI ethical principles are useless, failing to mitigate the racial, social, and environmental damages of AI technologies in any meaningful sense. The result is a gap between high-minded principles and technological practice. Even when this gap is acknowledged and principles seek to be “operationalized,” the translation from complex social concepts to technical rulesets is non-trivial. In a zero-sum world, the dominant turn to AI principles is not just fruitless but a dangerous distraction, diverting immense financial and human resources away from potentially more effective activity. I conclude by highlighting alternative approaches to AI justice that go beyond ethical principles: thinking more broadly about systems of oppression and more narrowly about accuracy and auditing.",
    "citationCount": 247,
    "pdf_filename": "2022_The_uselessness_of_AI_ethics_0ea5edaa.pdf"
  },
  "094de5641baa0128489605185614bd7b5fe82187": {
    "paperId": "094de5641baa0128489605185614bd7b5fe82187",
    "title": "The application of AI technologies in STEM education: a systematic review from 2011 to 2021",
    "year": 2022,
    "authors": "Weiqi Xu, Ouyang Fan",
    "abstract": "Background The application of artificial intelligence (AI) in STEM education (AI-STEM), as an emerging field, is confronted with a challenge of integrating diverse AI techniques and complex educational elements to meet instructional and learning needs. To gain a comprehensive understanding of AI applications in STEM education, this study conducted a systematic review to examine 63 empirical AI-STEM research from 2011 to 2021, grounded upon a general system theory (GST) framework. Results The results examined the major elements in the AI-STEM system as well as the effects of AI in STEM education. Six categories of AI applications were summarized and the results further showed the distribution relationships of the AI categories with other elements (i.e., information, subject, medium, environment) in AI-STEM. Moreover, the review revealed the educational and technological effects of AI in STEM education. Conclusions The application of AI technology in STEM education is confronted with the challenge of integrating diverse AI techniques in the complex STEM educational system. Grounded upon a GST framework, this research reviewed the empirical AI-STEM studies from 2011 to 2021 and proposed educational, technological, and theoretical implications to apply AI techniques in STEM education. Overall, the potential of AI technology for enhancing STEM education is fertile ground to be further explored together with studies aimed at investigating the integration of technology and educational system.",
    "citationCount": 272,
    "pdf_filename": "2022_The_application_of_AI_technologies_in_ST_094de564.pdf"
  },
  "4086ee3526e0fe421ea3c768ff1993a34b10fb5e": {
    "paperId": "4086ee3526e0fe421ea3c768ff1993a34b10fb5e",
    "title": "Immersive virtual reality increases liking but not learning with a science simulation and generative learning strategies promote learning in immersive virtual reality.",
    "year": 2020,
    "authors": "G. Makransky, N. K. Andreasen, Sarune Baceviciute, R. Mayer",
    "abstract": "We investigated the instructional effectiveness of using an interactive and immersive virtual reality (IVR) simulation versus a video for teaching scientific knowledge in two betweensubject experiments. In Experiment 1, 131 high school students (84 females) used a science simulation that involved forensic analysis of a collected DNA sample in a virtual laboratory environment rendered in IVR or as a video covering the same material. In Experiment 2, 165 high school students (111 females) replicated the experiment with approximately half of each group being asked to engage in the generative learning strategy of enactment after the lesson-i.e., carrying out the learned procedures with concrete manipulatives. Across both experiments, the IVR groups reported significantly higher perceived enjoyment and presence than the video group. However, no significant differences were found between media for procedural knowledge in Experiment 1 and 2, or transfer in Experiment 2. Also, there was no difference in declarative knowledge across media in Experiment 1, and there was a media effect favoring video in Experiment 2 (ηp 2 = 0.028). Enactment lead to significantly better procedural knowledge (ηp 2 = 0.144) and transfer (ηp 2 = 0.088) in the IVR group but not in the video group. In conclusion, learning in IVR is not more effective than learning with video but incorporating generative learning strategies is specifically effective when learning through IVR. The results suggest that the value of IVR for learning science depends on how it is integrated into a classroom lesson.",
    "citationCount": 253,
    "pdf_filename": "2020_Immersive_virtual_reality_increases_liki_4086ee35.pdf"
  },
  "7f6231aae6e5eb5b62f85429f3ad8eaa96fee11e": {
    "paperId": "7f6231aae6e5eb5b62f85429f3ad8eaa96fee11e",
    "title": "Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks",
    "year": 2020,
    "authors": "Stephanie Stoll, N. C. Camgoz, Simon Hadfield, R. Bowden",
    "abstract": "We present a novel approach to automatic Sign Language Production using recent developments in Neural Machine Translation (NMT), Generative Adversarial Networks, and motion generation. Our system is capable of producing sign videos from spoken language sentences. Contrary to current approaches that are dependent on heavily annotated data, our approach requires minimal gloss and skeletal level annotations for training. We achieve this by breaking down the task into dedicated sub-processes. We first translate spoken language sentences into sign pose sequences by combining an NMT network with a Motion Graph. The resulting pose information is then used to condition a generative model that produces photo realistic sign language video sequences. This is the first approach to continuous sign video generation that does not use a classical graphical avatar. We evaluate the translation abilities of our approach on the PHOENIX14T Sign Language Translation dataset. We set a baseline for text-to-gloss translation, reporting a BLEU-4 score of 16.34/15.26 on dev/test sets. We further demonstrate the video generation capabilities of our approach for both multi-signer and high-definition settings qualitatively and quantitatively using broadcast quality assessment metrics.",
    "citationCount": 243,
    "pdf_filename": "2020_Text2Sign__Towards_Sign_Language_Product_7f6231aa.pdf"
  },
  "d255934eeb52a6b499c0d39754ed7e29e22d213d": {
    "paperId": "d255934eeb52a6b499c0d39754ed7e29e22d213d",
    "title": "Generative adversarial network for road damage detection",
    "year": 2020,
    "authors": "Hiroya Maeda, Takehiro Kashiyama, Y. Sekimoto, Toshikazu Seto, Hiroshi Omata",
    "abstract": "Machine learning can produce promising results when sufficient training data are available; however, infrastructure inspections typically do not provide sufficient training data for road damage. Given the differences in the environment, the type of road damage and the degree of its progress can vary from structure to structure. The use of generative models, such as a generative adversarial network (GAN) or a variational autoencoder, makes it possible to generate a pseudoimage that cannot be distinguished from a real one. Combining a progressive growing GAN along with Poisson blending artificially generates road damage images that can be used as new training data to improve the accuracy of road damage detection. The addition of a synthesized road damage image to the training data improves the F‐measure by 5% and 2% when the number of original images is small and relatively large, respectively. All of the results and the new Road Damage Dataset 2019 are publicly available (https://github.com/sekilab/RoadDamageDetector).",
    "citationCount": 256,
    "pdf_filename": "2020_Generative_adversarial_network_for_road__d255934e.pdf"
  },
  "98962528d113b47fd72ebe7ff205fb6a14d0d9e3": {
    "paperId": "98962528d113b47fd72ebe7ff205fb6a14d0d9e3",
    "title": "Human heuristics for AI-generated language are flawed",
    "year": 2022,
    "authors": "Maurice Jakesch, Jeffrey T. Hancock, Mor Naaman",
    "abstract": "Significance Human communication is now rife with language generated by AI. Every day, across the web, chat, email, and social media, AI systems produce billions of messages that could be perceived as created by humans. In this work, we analyze human judgments of self-presentations written by humans and generated by AI systems. We find that people cannot detect AI-generated self-presentations as their judgment is misguided by intuitive but flawed heuristics for AI-generated language. We demonstrate that AI systems can exploit these heuristics to produce text perceived as “more human than human.” Our results raise the question of how humanity will adapt to AI-generated text, illustrating the need to reorient the development of AI language systems to ensure that they support rather than undermine human cognition.",
    "citationCount": 242,
    "pdf_filename": "2022_Human_heuristics_for_AI_generated_langua_98962528.pdf"
  },
  "6432bcd4435ab79311f42b0336cef1d6cbf1231f": {
    "paperId": "6432bcd4435ab79311f42b0336cef1d6cbf1231f",
    "title": "Human–AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support",
    "year": 2022,
    "authors": "Ashish Sharma, Inna Wanyin Lin, Adam S. Miner, David C. Atkins, Tim Althoff",
    "abstract": "Advances in artificial intelligence (AI) are enabling systems that augment and collaborate with humans to perform simple, mechanistic tasks such as scheduling meetings and grammar-checking text. However, such human–AI collaboration poses challenges for more complex tasks, such as carrying out empathic conversations, due to the difficulties that AI systems face in navigating complex human emotions and the open-ended nature of these tasks. Here we focus on peer-to-peer mental health support, a setting in which empathy is critical for success, and examine how AI can collaborate with humans to facilitate peer empathy during textual, online supportive conversations. We develop HAILEY, an AI-in-the-loop agent that provides just-in-time feedback to help participants who provide support (peer supporters) respond more empathically to those seeking help (support seekers). We evaluate HAILEY in a non-clinical randomized controlled trial with real-world peer supporters on TalkLife ( N  = 300), a large online peer-to-peer support platform. We show that our human–AI collaboration approach leads to a 19.6% increase in conversational empathy between peers overall. Furthermore, we find a larger, 38.9% increase in empathy within the subsample of peer supporters who self-identify as experiencing difficulty providing support. We systematically analyse the human–AI collaboration patterns and find that peer supporters are able to use the AI feedback both directly and indirectly without becoming overly reliant on AI while reporting improved self-efficacy post-feedback. Our findings demonstrate the potential of feedback-driven, AI-in-the-loop writing systems to empower humans in open-ended, social and high-stakes tasks such as empathic conversations. AI language modelling and generation approaches have developed fast in the last decade, opening promising new directions in human–AI collaboration. An AI-in-the loop conversational system called HAILEY is developed to empower peer supporters in providing empathic responses to mental health support seekers.",
    "citationCount": 269,
    "pdf_filename": "2022_Human_AI_collaboration_enables_more_empa_6432bcd4.pdf"
  },
  "a38af38baeb1b5e25c089b699ab5072823ae6b4c": {
    "paperId": "a38af38baeb1b5e25c089b699ab5072823ae6b4c",
    "title": "The Fallacy of AI Functionality",
    "year": 2022,
    "authors": "Inioluwa Deborah Raji, Indra Elizabeth Kumar, Aaron Horowitz, Andrew D. Selbst",
    "abstract": "Deployed AI systems often do not work. They can be constructed haphazardly, deployed indiscriminately, and promoted deceptively. However, despite this reality, scholars, the press, and policymakers pay too little attention to functionality. This leads to technical and policy solutions focused on “ethical” or value-aligned deployments, often skipping over the prior question of whether a given system functions, or provides any benefits at all. To describe the harms of various types of functionality failures, we analyze a set of case studies to create a taxonomy of known AI functionality issues. We then point to policy and organizational responses that are often overlooked and become more readily available once functionality is drawn into focus. We argue that functionality is a meaningful AI policy challenge, operating as a necessary first step towards protecting affected communities from algorithmic harm.",
    "citationCount": 227,
    "pdf_filename": "2022_The_Fallacy_of_AI_Functionality_a38af38b.pdf"
  },
  "a307bf71c7b90bb931baacb4507b4eded0c74aca": {
    "paperId": "a307bf71c7b90bb931baacb4507b4eded0c74aca",
    "title": "Integrating Ethics and Career Futures with Technical Learning to Promote AI Literacy for Middle School Students: An Exploratory Study",
    "year": 2022,
    "authors": "Helen Zhang, Irene A. Lee, Safinah Ali, Daniella DiPaola, Yihong Cheng",
    "abstract": "The rapid expansion of artificial intelligence (AI) necessitates promoting AI education at the K-12 level. However, educating young learners to become AI literate citizens poses several challenges. The components of AI literacy are ill-defined and it is unclear to what extent middle school students can engage in learning about AI as a sociotechnical system with socio-political implications. In this paper we posit that students must learn three core domains of AI: technical concepts and processes, ethical and societal implications, and career futures in the AI era. This paper describes the design and implementation of the Developing AI Literacy (DAILy) workshop that aimed to integrate middle school students’ learning of the three domains. We found that after the workshop, most students developed a general understanding of AI concepts and processes (e.g., supervised learning and logic systems). More importantly, they were able to identify bias, describe ways to mitigate bias in machine learning, and start to consider how AI may impact their future lives and careers. At exit, nearly half of the students explained AI as not just a technical subject, but one that has personal, career, and societal implications. Overall, this finding suggests that the approach of incorporating ethics and career futures into AI education is age appropriate and effective for developing AI literacy among middle school students. This study contributes to the field of AI Education by presenting a model of integrating ethics into the teaching of AI that is appropriate for middle school students.",
    "citationCount": 228,
    "pdf_filename": "2022_Integrating_Ethics_and_Career_Futures_wi_a307bf71.pdf"
  },
  "0c9913dcf8287eadd2879b73c027b34d2f38458f": {
    "paperId": "0c9913dcf8287eadd2879b73c027b34d2f38458f",
    "title": "TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks",
    "year": 2020,
    "authors": "Alexander Geiger, Dongyu Liu, Sarah Alnegheimish, Alfredo Cuesta-Infante, K. Veeramachaneni",
    "abstract": "Time series anomalies can offer information relevant to critical situations facing various fields, from finance and aerospace to the IT, security, and medical domains. However, detecting anomalies in time series data is particularly challenging due to the vague definition o f a nomalies and said data’s frequent lack of labels and highly complex temporal correlations. Current state-of-the-art unsupervised machine learning methods for anomaly detection suffer from scalability and portability issues, and may have high false positive rates. In this paper, we propose TadGAN, an unsupervised anomaly detection approach built on Generative Adversarial Networks (GANs). To capture the temporal correlations of time series distributions, we use LSTM Recurrent Neural Networks as base models for Generators and Critics. TadGAN is trained with cycle consistency loss to allow for effective time-series data reconstruction. We further propose several novel methods to compute reconstruction errors, as well as different approaches to combine reconstruction errors and Critic outputs to compute anomaly scores. To demonstrate the performance and generalizability of our approach, we test several anomaly scoring techniques and report the best-suited one. We compare our approach to 8 baseline anomaly detection methods on 11 datasets from multiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter. The results show that our approach can effectively detect anomalies and outperform baseline methods in most cases (6 out of 11). Notably, our method has the highest averaged F1 score across all the datasets. Our code is open source and is available as a benchmarking tool.",
    "citationCount": 247,
    "pdf_filename": "2020_TadGAN__Time_Series_Anomaly_Detection_Us_0c9913dc.pdf"
  },
  "fd73cf67952b23cef67e78ce9ed7cc16e33de120": {
    "paperId": "fd73cf67952b23cef67e78ce9ed7cc16e33de120",
    "title": "Generative Deep Neural Networks for Inverse Materials Design Using Backpropagation and Active Learning",
    "year": 2020,
    "authors": "Chun-Teh Chen, Grace X. Gu",
    "abstract": "In recent years, machine learning (ML) techniques are seen to be promising tools to discover and design novel materials. However, the lack of robust inverse design approaches to identify promising candidate materials without exploring the entire design space causes a fundamental bottleneck. A general‐purpose inverse design approach is presented using generative inverse design networks. This ML‐based inverse design approach uses backpropagation to calculate the analytical gradients of an objective function with respect to design variables. This inverse design approach is capable of overcoming local minima traps by using backpropagation to provide rapid calculations of gradient information and running millions of optimizations with different initial values. Furthermore, an active learning strategy is adopted in the inverse design approach to improve the performance of candidate materials and reduce the amount of training data needed to do so. Compared to passive learning, the active learning strategy is capable of generating better designs and reducing the amount of training data by at least an order‐of‐magnitude in the case study on composite materials. The inverse design approach is compared with conventional gradient‐based topology optimization and gradient‐free genetic algorithms and the pros and cons of each method are discussed when applied to materials discovery and design problems.",
    "citationCount": 269,
    "pdf_filename": "2020_Generative_Deep_Neural_Networks_for_Inve_fd73cf67.pdf"
  },
  "88c984a21879a5fb203662e80af44646a00093c4": {
    "paperId": "88c984a21879a5fb203662e80af44646a00093c4",
    "title": "Experimental Quantum Generative Adversarial Networks for Image Generation",
    "year": 2020,
    "authors": "Heliang Huang, Yuxuan Du, M. Gong, You-Wei Zhao, Yulin Wu",
    "abstract": "Quantum machine learning is expected to be one of the first practical applications of near-term quantum devices. Pioneer theoretical works suggest that quantum generative adversarial networks (GANs) may exhibit a potential exponential advantage over classical GANs, thus attracting widespread attention. However, it remains elusive whether quantum GANs implemented on near-term quantum devices can actually solve real-world learning tasks. Here, we devise a flexible quantum GAN scheme to narrow this knowledge gap, which could accomplish image generation with arbitrarily high-dimensional features, and could also take advantage of quantum superposition to train multiple examples in parallel. For the first time, we experimentally achieve the learning and generation of real-world hand-written digit images on a superconducting quantum processor. Moreover, we utilize a gray-scale bar dataset to exhibit the competitive performance between quantum GANs and the classical GANs based on multilayer perceptron and convolutional neural network architectures, respectively, benchmarked by the Frechet Distance score. Our work provides guidance for developing advanced quantum generative models on near-term quantum devices and opens up an avenue for exploring quantum advantages in various GAN-related learning tasks.",
    "citationCount": 229,
    "pdf_filename": "2020_Experimental_Quantum_Generative_Adversar_88c984a2.pdf"
  },
  "baa8f524c82735f174b8d1ab512ac5750146d67e": {
    "paperId": "baa8f524c82735f174b8d1ab512ac5750146d67e",
    "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning",
    "year": 2020,
    "authors": "Ye Liu, Yao Wan, Lifang He, Hao Peng, Philip S. Yu",
    "abstract": "Generative commonsense reasoning which aims to empower machines to generate sentences with the capacity of reasoning over a set of concepts is a critical bottleneck for text generation. Even the state-of-the-art pre-trained language generation models struggle at this task and often produce implausible and anomalous sentences. One reason is that they rarely consider incorporating the knowledge graph which can provide rich relational information among the commonsense concepts. To promote the ability of commonsense reasoning for text generation, we propose a novel knowledge graph augmented pre-trained language generation model KG-BART, which encompasses the complex relations of concepts through the knowledge graph and produces more logical and natural sentences as output. Moreover, KG-BART can leverage the graph attention to aggregate the rich concept semantics that enhances the model generalization on unseen concept sets. Experiments on benchmark CommonGen dataset verify the effectiveness of our proposed approach by comparing with several strong pre-trained language generation models, particularly KG-BART outperforms BART by 5.80, 4.60, in terms of BLEU-3, 4. Moreover, we also show that the generated context by our model can work as background scenarios to benefit downstream commonsense QA tasks.",
    "citationCount": 207,
    "pdf_filename": "2020_KG_BART__Knowledge_Graph_Augmented_BART__baa8f524.pdf"
  },
  "62e99100119b361e878a9cc67d87b57fe2f463c4": {
    "paperId": "62e99100119b361e878a9cc67d87b57fe2f463c4",
    "title": "MEF-GAN: Multi-Exposure Image Fusion via Generative Adversarial Networks",
    "year": 2020,
    "authors": "Han Xu, Jiayi Ma, Xiao-Ping Zhang",
    "abstract": "In this paper, we present an end-to-end architecture for multi-exposure image fusion based on generative adversarial networks, termed as MEF-GAN. In our architecture, a generator network and a discriminator network are trained simultaneously to form an adversarial relationship. The generator is trained to generate a real-like fused image based on the given source images which is expected to fool the discriminator. Correspondingly, the discriminator is trained to distinguish the generated fused images from the ground truth. The adversarial relationship makes the fused image not limited to the restriction of the content loss. Therefore, the fused images are closer to the ground truth in terms of probability distribution, which can compensate for the insufficiency of single content loss. Moreover, aiming at the problem that the luminance of multi-exposure images varies greatly with spatial location, the self-attention mechanism is employed in our architecture to allow for attention-driven and long-range dependency. Thus, local distortion, confusing results, or inappropriate representation can be corrected in the fused image. Qualitative and quantitative experiments are performed on publicly available datasets, where the results demonstrate that MEF-GAN outperforms the state-of-the-art, in terms of both visual effect and objective evaluation metrics. Our code is publicly available at https://github.com/jiayi-ma/MEF-GAN.",
    "citationCount": 212,
    "pdf_filename": "2020_MEF_GAN__Multi_Exposure_Image_Fusion_via_62e99100.pdf"
  },
  "a1aed6c0f20b659bb0c5f559c6d33584d51c5aab": {
    "paperId": "a1aed6c0f20b659bb0c5f559c6d33584d51c5aab",
    "title": "Deep Generative Models for 3D Linker Design",
    "year": 2020,
    "authors": "F. Imrie, A. Bradley, M. Schaar, C. Deane",
    "abstract": "Rational compound design remains a challenging problem for both computational methods and medicinal chemists. Computational generative methods have begun to show promising results for the design problem. However, they have not yet used the power of three-dimensional (3D) structural information. We have developed a novel graph-based deep generative model that combines state-of-the-art machine learning techniques with structural knowledge. Our method (“DeLinker”) takes two fragments or partial structures and designs a molecule incorporating both. The generation process is protein-context-dependent, utilizing the relative distance and orientation between the partial structures. This 3D information is vital to successful compound design, and we demonstrate its impact on the generation process and the limitations of omitting such information. In a large-scale evaluation, DeLinker designed 60% more molecules with high 3D similarity to the original molecule than a database baseline. When considering the more relevant problem of longer linkers with at least five atoms, the outperformance increased to 200%. We demonstrate the effectiveness and applicability of this approach on a diverse range of design problems: fragment linking, scaffold hopping, and proteolysis targeting chimera (PROTAC) design. As far as we are aware, this is the first molecular generative model to incorporate 3D structural information directly in the design process. The code is available at https://github.com/oxpig/DeLinker.",
    "citationCount": 210,
    "pdf_filename": "2020_Deep_Generative_Models_for_3D_Linker_Des_a1aed6c0.pdf"
  },
  "2015fdfa00d67f6cf75e880724428c8e5f3995b8": {
    "paperId": "2015fdfa00d67f6cf75e880724428c8e5f3995b8",
    "title": "Generative Adversarial Networks for Crystal Structure Prediction",
    "year": 2020,
    "authors": "Sungwon Kim, Juhwan Noh, Geun Ho Gu, A. Aspuru‐Guzik, Yousung Jung",
    "abstract": "The constant demand for novel functional materials calls for efficient strategies to accelerate the materials discovery, and crystal structure prediction is one of the most fundamental tasks along that direction. In addressing this challenge, generative models can offer new opportunities since they allow for the continuous navigation of chemical space via latent spaces. In this work, we employ a crystal representation that is inversion-free based on unit cell and fractional atomic coordinates and build a generative adversarial network for crystal structures. The proposed model is applied to generate the Mg–Mn–O ternary materials with the theoretical evaluation of their photoanode properties for high-throughput virtual screening (HTVS). The proposed generative HTVS framework predicts 23 new crystal structures with reasonable calculated stability and band gap. These findings suggest that the generative model can be an effective way to explore hidden portions of the chemical space, an area that is usually unreachable when conventional substitution-based discovery is employed.",
    "citationCount": 212,
    "pdf_filename": "2020_Generative_Adversarial_Networks_for_Crys_2015fdfa.pdf"
  },
  "6fb797c92be72889c0948fcad854bd57d1a9674a": {
    "paperId": "6fb797c92be72889c0948fcad854bd57d1a9674a",
    "title": "Using Chatbots as AI Conversational Partners in Language Learning",
    "year": 2022,
    "authors": "Jose Belda-Medina, José Ramón Calvo-Ferrer",
    "abstract": "Recent advances in Artificial Intelligence (AI) and machine learning have paved the way for the increasing adoption of chatbots in language learning. Research published to date has mostly focused on chatbot accuracy and chatbot–human communication from students’ or in-service teachers’ perspectives. This study aims to examine the knowledge, level of satisfaction and perceptions concerning the integration of conversational AI in language learning among future educators. In this mixed method research based on convenience sampling, 176 undergraduates from two educational settings, Spain (n = 115) and Poland (n = 61), interacted autonomously with three conversational agents (Replika, Kuki, Wysa) over a four-week period. A learning module about Artificial Intelligence and language learning was specifically designed for this research, including an ad hoc model named the Chatbot–Human Interaction Satisfaction Model (CHISM), which was used by teacher candidates to evaluate different linguistic and technological features of the three conversational agents. Quantitative and qualitative data were gathered through a pre-post-survey based on the CHISM and the TAM2 (technology acceptance) models and a template analysis (TA), and analyzed through IBM SPSS 22 and QDA Miner software. The analysis yielded positive results regarding perceptions concerning the integration of conversational agents in language learning, particularly in relation to perceived ease of use (PeU) and attitudes (AT), but the scores for behavioral intention (BI) were more moderate. The findings also unveiled some gender-related differences regarding participants’ satisfaction with chatbot design and topics of interaction.",
    "citationCount": 205,
    "pdf_filename": "2022_Using_Chatbots_as_AI_Conversational_Part_6fb797c9.pdf"
  },
  "fe27a9fe3e547ca899985cfe071b14789a76c74a": {
    "paperId": "fe27a9fe3e547ca899985cfe071b14789a76c74a",
    "title": "Designing complex architectured materials with generative adversarial networks",
    "year": 2020,
    "authors": "Yunwei Mao, Qi He, Xuanhe Zhao",
    "abstract": "Complex architectured materials are designed with generative adversarial networks to approach Hashin-Shtrikman upper bounds. Architectured materials on length scales from nanometers to meters are desirable for diverse applications. Recent advances in additive manufacturing have made mass production of complex architectured materials technologically and economically feasible. Existing architecture design approaches such as bioinspiration, Edisonian, and optimization, however, generally rely on experienced designers’ prior knowledge, limiting broad applications of architectured materials. Particularly challenging is designing architectured materials with extreme properties, such as the Hashin-Shtrikman upper bounds on isotropic elasticity in an experience-free manner without prior knowledge. Here, we present an experience-free and systematic approach for the design of complex architectured materials with generative adversarial networks. The networks are trained using simulation data from millions of randomly generated architectures categorized based on different crystallographic symmetries. We demonstrate modeling and experimental results of more than 400 two-dimensional architectures that approach the Hashin-Shtrikman upper bounds on isotropic elastic stiffness with porosities from 0.05 to 0.75.",
    "citationCount": 240,
    "pdf_filename": "2020_Designing_complex_architectured_material_fe27a9fe.pdf"
  },
  "f396762bc127f3411128fa0f6db5cbf3d5594bb5": {
    "paperId": "f396762bc127f3411128fa0f6db5cbf3d5594bb5",
    "title": "Exploring AI chatbot affordances in the EFL classroom: young learners’ experiences and perspectives",
    "year": 2022,
    "authors": "Jae-Bong Jeon",
    "abstract": "Abstract Professionals within the field of language learning have predicted that chatbots would provide new opportunities for the teaching and learning of language. Despite the assumed benefits of utilizing chatbots in language classrooms, such as providing interactional chances or helping to create an anxiety-free atmosphere, little is known about learners’ actual use of chatbots during language classes or how chatbots affect their motivation to learn a language. To address these gaps, this exploratory study aimed to create an inventory of affordances that chatbots provide in the primary English as a foreign language (EFL) classroom and to explore how the affordances affect psychological aspects in language learners, particularly regarding their motivation to learn English through chatbots. Thirty-six Korean primary school learners participated in a 16-week EFL course that utilized customized chatbots. These chatbots were created using Google’s Dialogflow. After the course, individual in-depth interviews were conducted regarding the participants’ experiences and perceptions of the chatbots. Student-chatbot interaction logs produced during the course were also collected to supplement the interview data. Qualitative analysis of the interview transcripts and interaction logs revealed the presence of pedagogical, technological, and social affordances. Depending on the learner, the chatbot affordances were perceived differently; thus, each affordance acted as either an opportunity or a constraint for English language learning. In addition, this study specifically discussed how these chatbot affordances might have affected psychological states in language learners. Future recommendations regarding the use of chatbots in language classrooms were suggested from both pedagogical and technological perspectives.",
    "citationCount": 273,
    "pdf_filename": "2022_Exploring_AI_chatbot_affordances_in_the__f396762b.pdf"
  },
  "aac516e554a54a2440384ee74f726f805eede83f": {
    "paperId": "aac516e554a54a2440384ee74f726f805eede83f",
    "title": "Designing Creative AI Partners with COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems",
    "year": 2022,
    "authors": "Jeba Rezwana, M. Maher",
    "abstract": "Human-AI co-creativity involves both humans and AI collaborating on a shared creative product as partners. In a creative collaboration, interaction dynamics, such as turn-taking, contribution type, and communication, are the driving forces of the co-creative process. Therefore the interaction model is a critical and essential component for effective co-creative systems. There is relatively little research about interaction design in the co-creativity field, which is reflected in a lack of focus on interaction design in many existing co-creative systems. The primary focus of co-creativity research has been on the abilities of the AI. This article focuses on the importance of interaction design in co-creative systems with the development of the Co-Creative Framework for Interaction design (COFI) that describes the broad scope of possibilities for interaction design in co-creative systems. Researchers can use COFI for modeling interaction in co-creative systems by exploring alternatives in this design space of interaction. COFI can also be beneficial while investigating and interpreting the interaction design of existing co-creative systems. We coded a dataset of existing 92 co-creative systems using COFI and analyzed the data to show how COFI provides a basis to categorize the interaction models of existing co-creative systems. We identify opportunities to shift the focus of interaction models in co-creativity to enable more communication between the user and AI leading to human-AI partnerships.",
    "citationCount": 204,
    "pdf_filename": "2022_Designing_Creative_AI_Partners_with_COFI_aac516e5.pdf"
  },
  "e1aa981dd1bf1b05f88ad66e65469f84428247d4": {
    "paperId": "e1aa981dd1bf1b05f88ad66e65469f84428247d4",
    "title": "Unreal influence: leveraging AI in influencer marketing",
    "year": 2022,
    "authors": "S. Sands, Colin Campbell, Kirk Plangger, Carla Ferraro",
    "abstract": "\nPurpose\nThis paper aims to examine how consumers respond to social media influencers that are created through artificial intelligence (AI) and compares effects to traditional (human) influencers.\n\n\nDesign/methodology/approach\nAcross two empirical studies, the authors examine the efficacy of AI social media influencers. With Study 1, the authors establish baseline effects for AI influencers and investigate how social-psychological distance impacts consumer perceptions. The authors also investigate the role of an influencer’s agency – being autonomous or externally managed – to test the boundaries of the results and determine the interactive effects between influencer type and influencer agency. Study 2 acts as an extension and validation of Study 1, whereby the authors provide generalisability and overlay the role of need for uniqueness as a moderated mediator.\n\n\nFindings\nThe authors show that there are similarities and differences in the ways in which consumers view AI and human influencers. Importantly, the authors find no difference in terms of intention to follow or personalisation. This suggests that consumers are equally open to follow an AI or human influencer, and they perceive the level of personalisation provided by either influencer type as similar. Furthermore, while an AI influencer is generally perceived as having lower source trust, they are more likely to evoke word-of-mouth intentions. In understanding these effects, the authors show that social distance mediates the relationship between influencer type and the outcomes the authors investigate. Results also show that AI influencers can have a greater effect on consumers who have a high need for uniqueness. Finally, the authors find that a lack of influencer agency has a detrimental effect.\n\n\nResearch limitations/implications\nThe studies investigate consumers’ general response to AI influencers within the context of Instagram, however, future research might examine consumers’ response to posts promoting specific products across a variety of category contexts and within different social media platforms.\n\n\nPractical implications\nThe authors find that in some ways, an AI influencer can be as effective as a human influencer. Indeed, the authors suggest that there may be a spill-over effect from consumer experiences with other AI recommendation systems, meaning that consumers are open to AI influencer recommendations. However, the authors find consistent evidence that AI influencers are trusted less than traditional influencers, hence the authors caution brands from rushing to replace human influencers with their AI counterparts.\n\n\nOriginality/value\nThis paper offers novel insight into the increasingly prominent phenomenon of the AI influencer. Specifically, it takes initial steps towards developing understanding as to how consumers respond to AI influencers and contrast these effects with human influencers.\n",
    "citationCount": 201,
    "pdf_filename": "2022_Unreal_influence__leveraging_AI_in_influ_e1aa981d.pdf"
  },
  "d8ab3a2825cbd9c6a3683b850d07510b9ebec7fe": {
    "paperId": "d8ab3a2825cbd9c6a3683b850d07510b9ebec7fe",
    "title": "Toward data anomaly detection for automated structural health monitoring: Exploiting generative adversarial nets and autoencoders",
    "year": 2020,
    "authors": "J. Mao, Hongya Wang, B. Spencer",
    "abstract": "Damage detection is one of the most important tasks for structural health monitoring of civil infrastructure. Before a damage detection algorithm can be applied, the integrity of the data must be ensured; otherwise results may be misleading or incorrect. Indeed, sensor system malfunction, which results in anomalous data (often called faulty data), is a serious problem, as the sensors usually must operate in extremely harsh environments. Identifying and eliminating anomalies in the data is crucial to ensuring that reliable monitoring results can be achieved. Because of the vast amounts of data typically collected by a structural health monitoring system, manual removal of the anomalous data is prohibitive. Machine learning methods have the potential to automate the process of data anomaly detection. Although supervised methods have been proven to be effective for detecting data anomalies, two unresolved challenges reduce the accuracy of anomaly detection: (1) the class imbalance and (2) incompleteness of anomalous patterns of training dataset. Unsupervised methods have the potential to address these challenges, but improvements are required to deal with vast amounts of monitoring data. In this article, the generative adversarial networks are combined with a widely applied unsupervised method, that is, autoencoders, to improve the performance of existing unsupervised learning methods. In addition, the time-series data are transformed to Gramian Angular Field images so that advanced computer vision methods can be included in the network. Two structural health monitoring datasets from a full-scale bridge, including examples of anomalous data caused by sensor system malfunctions, are utilized to validate the proposed methodology. Results show that the proposed methodology can successfully identify data anomalies with good accuracy and robustness, hence can overcome one of the key difficulties in achieving automated structural health monitoring.",
    "citationCount": 207,
    "pdf_filename": "2020_Toward_data_anomaly_detection_for_automa_d8ab3a28.pdf"
  },
  "5e1746995debd1f17c24af01514c727598cc5613": {
    "paperId": "5e1746995debd1f17c24af01514c727598cc5613",
    "title": "Human-Centered Explainable AI (XAI): From Algorithms to User Experiences",
    "year": 2021,
    "authors": "Q. Liao, Microsoft Research, Canada Kush, R. Varshney, Kush R. Varshney",
    "abstract": "In recent years, the field of explainable AI (XAI) has produced a vast collection of algorithms, providing a useful toolbox for researchers and practitioners to build XAI applications. With the rich application opportunities, explainability is believed to have moved beyond a demand by data scientists or researchers to comprehend the models they develop, to an essential requirement for people to trust and adopt AI deployed in numerous domains. However, explainability is an inherently human-centric property and the field is starting to embrace human-centered approaches. Human-computer interaction (HCI) research and user experience (UX) design in this area are becoming increasingly important. In this chapter, we begin with a high-level overview of the technical landscape of XAI algorithms, then selectively survey our own and other recent HCI works that take human-centered approaches to design, evaluate, and provide conceptual and methodological tools for XAI. We ask the question\"what are human-centered approaches doing for XAI\"and highlight three roles that they play in shaping XAI technologies by helping navigate, assess and expand the XAI toolbox: to drive technical choices by users' explainability needs, to uncover pitfalls of existing XAI methods and inform new methods, and to provide conceptual frameworks for human-compatible XAI.",
    "citationCount": 277,
    "pdf_filename": "2021_Human_Centered_Explainable_AI__XAI___Fro_5e174699.pdf"
  },
  "5f6baf6a7342715060c389e9e1c71d23398e0f72": {
    "paperId": "5f6baf6a7342715060c389e9e1c71d23398e0f72",
    "title": "The AI gambit: leveraging artificial intelligence to combat climate change—opportunities, challenges, and recommendations",
    "year": 2021,
    "authors": "Josh Cowls, Andreas Tsamados, M. Taddeo, L. Floridi",
    "abstract": "In this article, we analyse the role that artificial intelligence (AI) could play, and is playing, to combat global climate change. We identify two crucial opportunities that AI offers in this domain: it can help improve and expand current understanding of climate change, and it can contribute to combatting the climate crisis effectively. However, the development of AI also raises two sets of problems when considering climate change: the possible exacerbation of social and ethical challenges already associated with AI, and the contribution to climate change of the greenhouse gases emitted by training data and computation-intensive AI systems. We assess the carbon footprint of AI research, and the factors that influence AI’s greenhouse gas (GHG) emissions in this domain. We find that the carbon footprint of AI research may be significant and highlight the need for more evidence concerning the trade-off between the GHG emissions generated by AI research and the energy and resource efficiency gains that AI can offer. In light of our analysis, we argue that leveraging the opportunities offered by AI for global climate change whilst limiting its risks is a gambit which requires responsive, evidence-based, and effective governance to become a winning strategy. We conclude by identifying the European Union as being especially well-placed to play a leading role in this policy response and provide 13 recommendations that are designed to identify and harness the opportunities of AI for combatting climate change, while reducing its impact on the environment.",
    "citationCount": 290,
    "pdf_filename": "2021_The_AI_gambit__leveraging_artificial_int_5f6baf6a.pdf"
  },
  "7699f04998490d0df2da50348d03313a0f72641a": {
    "paperId": "7699f04998490d0df2da50348d03313a0f72641a",
    "title": "Developing Middle School Students' AI Literacy",
    "year": 2021,
    "authors": "Irene A. Lee, Safinah Ali, Helen Zhang, Daniella DiPaola, C. Breazeal",
    "abstract": "In this experience report, we describe an AI summer workshop designed to prepare middle school students to become informed citizens and critical consumers of AI technology and to develop their foundational knowledge and skills to support future endeavors as AI-empowered workers. The workshop featured the 30-hour \"Developing AI Literacy\" or DAILy curriculum that is grounded in literature on child development, ethics education, and career development. The participants in the workshop were students between the ages of 10 and 14; 87% were from underrepresented groups in STEM and Computing. In this paper we describe the online curriculum, its implementation during synchronous online workshop sessions in summer of 2020, and preliminary findings on student outcomes. We reflect on the successes and lessons we learned in terms of supporting students' engagement and conceptual learning of AI, shifting attitudes toward AI, and fostering conceptions of future selves as AI-enabled workers. We conclude with discussions of the affordances and barriers to bringing AI education to students from underrepresented groups in STEM and Computing.",
    "citationCount": 228,
    "pdf_filename": "2021_Developing_Middle_School_Students__AI_Li_7699f049.pdf"
  },
  "2b44fd0e7875dc217f6877d25c70eb8c0e8051c7": {
    "paperId": "2b44fd0e7875dc217f6877d25c70eb8c0e8051c7",
    "title": "Artificial Intelligence and Reflections from Educational Landscape: A Review of AI Studies in Half a Century",
    "year": 2021,
    "authors": "Aras Bozkurt, Abdulkadir Karadeniz, David Bañeres, Ana-Elena Guerrero-Roldán, M. E. Rodríguez",
    "abstract": "Artificial intelligence (AI) has penetrated every layer of our lives, and education is not immune to the effects of AI. In this regard, this study examines AI studies in education in half a century (1970–2020) through a systematic review approach and benefits from social network analysis and text-mining approaches. Accordingly, the research identifies three research clusters (1) artificial intelligence, (2) pedagogical, and (3) technological issues, and suggests five broad research themes which are (1) adaptive learning and personalization of education through AI-based practices, (2) deep learning and machine Learning algorithms for online learning processes, (3) Educational human-AI interaction, (4) educational use of AI-generated data, and (5) AI in higher education. The study also highlights that ethics in AI studies is an ignored research area.",
    "citationCount": 238,
    "pdf_filename": "2021_Artificial_Intelligence_and_Reflections__2b44fd0e.pdf"
  },
  "bc54b3f4d00481a1b5231a458a7ba27f2f6a22ce": {
    "paperId": "bc54b3f4d00481a1b5231a458a7ba27f2f6a22ce",
    "title": "AI-assisted peer review",
    "year": 2021,
    "authors": "Alessandro Checco, L. Bracciale, P. Loreti, S. Pinfield, G. Bianchi",
    "abstract": "The scientific literature peer review workflow is under strain because of the constant growth of submission volume. One response to this is to make initial screening of submissions less time intensive. Reducing screening and review time would save millions of working hours and potentially boost academic productivity. Many platforms have already started to use automated screening tools, to prevent plagiarism and failure to respect format requirements. Some tools even attempt to flag the quality of a study or summarise its content, to reduce reviewers’ load. The recent advances in artificial intelligence (AI) create the potential for (semi) automated peer review systems, where potentially low-quality or controversial studies could be flagged, and reviewer-document matching could be performed in an automated manner. However, there are ethical concerns, which arise from such approaches, particularly associated with bias and the extent to which AI systems may replicate bias. Our main goal in this study is to discuss the potential, pitfalls, and uncertainties of the use of AI to approximate or assist human decisions in the quality assurance and peer-review process associated with research outputs. We design an AI tool and train it with 3300 papers from three conferences, together with their reviews evaluations. We then test the ability of the AI in predicting the review score of a new, unobserved manuscript, only using its textual content. We show that such techniques can reveal correlations between the decision process and other quality proxy measures, uncovering potential biases of the review process. Finally, we discuss the opportunities, but also the potential unintended consequences of these techniques in terms of algorithmic bias and ethical concerns.",
    "citationCount": 208,
    "pdf_filename": "2021_AI_assisted_peer_review_bc54b3f4.pdf"
  },
  "9ffcb3624f2637b5d0fe28c61ec8472293cfebc7": {
    "paperId": "9ffcb3624f2637b5d0fe28c61ec8472293cfebc7",
    "title": "All the News That’s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation",
    "year": 2020,
    "authors": "S. Kreps, Miles McCain, Miles Brundage",
    "abstract": "Abstract Online misinformation has become a constant; only the way actors create and distribute that information is changing. Advances in artificial intelligence (AI) such as GPT-2 mean that actors can now synthetically generate text in ways that mimic the style and substance of human-created news stories. We carried out three original experiments to study whether these AI-generated texts are credible and can influence opinions on foreign policy. The first evaluated human perceptions of AI-generated text relative to an original story. The second investigated the interaction between partisanship and AI-generated news. The third examined the distributions of perceived credibility across different AI model sizes. We find that individuals are largely incapable of distinguishing between AI- and human-generated text; partisanship affects the perceived credibility of the story; and exposure to the text does little to change individuals’ policy views. The findings have important implications in understanding AI in online misinformation campaigns.",
    "citationCount": 287,
    "pdf_filename": "2020_All_the_News_That_s_Fit_to_Fabricate__AI_9ffcb362.pdf"
  },
  "7eb03a3c0605d688959eef30518f6eb268996eae": {
    "paperId": "7eb03a3c0605d688959eef30518f6eb268996eae",
    "title": "How to Design AI for Social Good: Seven Essential Factors",
    "year": 2020,
    "authors": "L. Floridi, Josh Cowls, T. C. King, M. Taddeo",
    "abstract": "The idea of artificial intelligence for social good (henceforth AI4SG) is gaining traction within information societies in general and the AI community in particular. It has the potential to tackle social problems through the development of AI-based solutions. Yet, to date, there is only limited understanding of what makes AI socially good in theory, what counts as AI4SG in practice, and how to reproduce its initial successes in terms of policies. This article addresses this gap by identifying seven ethical factors that are essential for future AI4SG initiatives. The analysis is supported by 27 case examples of AI4SG projects. Some of these factors are almost entirely novel to AI, while the significance of other factors is heightened by the use of AI. From each of these factors, corresponding best practices are formulated which, subject to context and balance, may serve as preliminary guidelines to ensure that well-designed AI is more likely to serve the social good.",
    "citationCount": 275,
    "pdf_filename": "2020_How_to_Design_AI_for_Social_Good__Seven__7eb03a3c.pdf"
  },
  "2c9d71966e1e8a527a392bbe28aa53f8e0918755": {
    "paperId": "2c9d71966e1e8a527a392bbe28aa53f8e0918755",
    "title": "Human-centered Explainable AI: Towards a Reflective Sociotechnical Approach",
    "year": 2020,
    "authors": "Upol Ehsan, Mark O. Riedl",
    "abstract": "Explanations--a form of post-hoc interpretability--play an instrumental role in making systems accessible as AI continues to proliferate complex and sensitive sociotechnical systems. In this paper, we introduce Human-centered Explainable AI (HCXAI) as an approach that puts the human at the center of technology design. It develops a holistic understanding of \"who\" the human is by considering the interplay of values, interpersonal dynamics, and the socially situated nature of AI systems. In particular, we advocate for a reflective sociotechnical approach. We illustrate HCXAI through a case study of an explanation system for non-technical end-users that shows how technical advancements and the understanding of human factors co-evolve. Building on the case study, we lay out open research questions pertaining to further refining our understanding of \"who\" the human is and extending beyond 1-to-1 human-computer interactions. Finally, we propose that a reflective HCXAI paradigm-mediated through the perspective of Critical Technical Practice and supplemented with strategies from HCI, such as value-sensitive design and participatory design--not only helps us understand our intellectual blind spots, but it can also open up new design and research spaces.",
    "citationCount": 253,
    "pdf_filename": "2020_Human_centered_Explainable_AI__Towards_a_2c9d7196.pdf"
  },
  "22f018dfbb389ff49d67de0eb8ab137de4848138": {
    "paperId": "22f018dfbb389ff49d67de0eb8ab137de4848138",
    "title": "My Teacher Is a Machine: Understanding Students’ Perceptions of AI Teaching Assistants in Online Education",
    "year": 2020,
    "authors": "Jihyun Kim, Kelly Merrill, Kun Xu, Deanna D. Sellnow",
    "abstract": "ABSTRACT An increase in demand for online education has led to the creation of a new technology, machine teachers, or artificial intelligence (AI) teaching assistants. In fact, AI teaching assistants have already been implemented in a small number of courses in the United States. However, little is known about how students will perceive AI teaching assistants. Thus, the present study investigated students’ perceptions about AI teaching assistants in higher education by use of an online survey. Primary findings indicate that perceived usefulness of an AI teaching assistant and perceived ease of communication with an AI teaching assistant are key to understanding an eventual adoption of AI teaching assistant-based education. These findings provide support for AI teaching assistant adoption. Based on the present study’s findings, more research is needed to better understand the nuances associated with the learning experience one may have from an AI teaching assistant.",
    "citationCount": 217,
    "pdf_filename": "2020_My_Teacher_Is_a_Machine__Understanding_S_22f018df.pdf"
  },
  "5100a9ea286ef799be96d9948067badf60613b95": {
    "paperId": "5100a9ea286ef799be96d9948067badf60613b95",
    "title": "The Dark Sides of Artificial Intelligence: An Integrated AI Governance Framework for Public Administration",
    "year": 2020,
    "authors": "B. Wirtz, Jan C. Weyerer, B. Sturm",
    "abstract": "ABSTRACT As government and public administration lag behind the rapid development of AI in their efforts to provide adequate governance, they need respective concepts to keep pace with this dynamic progress. The literature provides few answers to the question of how government and public administration should respond to the great challenges associated with AI and use regulation to prevent harm. This study analyzes AI challenges and former AI regulation approaches. Based on this analysis and regulation theory, an integrated AI governance framework is developed that compiles key aspects of AI governance and provides a guide for the regulatory process of AI and its application. The article concludes with theoretical implications and recommendations for public officers.",
    "citationCount": 230,
    "pdf_filename": "2020_The_Dark_Sides_of_Artificial_Intelligenc_5100a9ea.pdf"
  },
  "0c471c3aa5aef737ee00cfe9c58e9097328a954e": {
    "paperId": "0c471c3aa5aef737ee00cfe9c58e9097328a954e",
    "title": "A Survey of Data-Driven and Knowledge-Aware eXplainable AI",
    "year": 2020,
    "authors": "Xiao-hui Li, Caleb Chen Cao, Yuhan Shi, Wei Bai, Han Gao",
    "abstract": "We are witnessing a fast development of Artificial Intelligence (AI), but it becomes dramatically challenging to explain AI models in the past decade. “Explanation” has a flexible philosophical concept of “satisfying the subjective curiosity for causal information”, driving a wide spectrum of methods being invented and/or adapted from many aspects and communities, including machine learning, visual analytics, human-computer interaction and so on. Nevertheless, from the view-point of data and knowledge engineering (DKE), a best explaining practice that is cost-effective in terms of extra intelligence acquisition should exploit the causal information and explaining scenarios which is hidden richly in the data itself. In the past several years, there are plenty of works contributing in this line but there is a lack of a clear taxonomy and systematic review of the current effort. To this end, we propose this survey, reviewing and taxonomizing existing efforts from the view-point of DKE, summarizing their contribution, technical essence and comparative characteristics. Specifically, we categorize methods into data-driven methods where explanation comes from the task-related data, and knowledge-aware methods where extraneous knowledge is incorporated. Furthermore, in the light of practice, we provide survey of state-of-art evaluation metrics and deployed explanation applications in industrial practice.",
    "citationCount": 203,
    "pdf_filename": "2020_A_Survey_of_Data_Driven_and_Knowledge_Aw_0c471c3a.pdf"
  },
  "03e2cfa44b64489fb98f09dfbd940043fbef90ad": {
    "paperId": "03e2cfa44b64489fb98f09dfbd940043fbef90ad",
    "title": "SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion",
    "year": 2024,
    "authors": "Vikram S. Voleti, Chun-Han Yao, Mark Boss, Adam Letts, David Pankratz",
    "abstract": "We present Stable Video 3D (SV3D) -- a latent video diffusion model for high-resolution, image-to-multi-view generation of orbital videos around a 3D object. Recent work on 3D generation propose techniques to adapt 2D generative models for novel view synthesis (NVS) and 3D optimization. However, these methods have several disadvantages due to either limited views or inconsistent NVS, thereby affecting the performance of 3D object generation. In this work, we propose SV3D that adapts image-to-video diffusion model for novel multi-view synthesis and 3D generation, thereby leveraging the generalization and multi-view consistency of the video models, while further adding explicit camera control for NVS. We also propose improved 3D optimization techniques to use SV3D and its NVS outputs for image-to-3D generation. Extensive experimental results on multiple datasets with 2D and 3D metrics as well as user study demonstrate SV3D's state-of-the-art performance on NVS as well as 3D reconstruction compared to prior works.",
    "citationCount": 298,
    "pdf_filename": "2024_SV3D__Novel_Multi_view_Synthesis_and_3D__03e2cfa4.pdf"
  },
  "e6cb30effd90d563bc680430ecc1317842d33b6e": {
    "paperId": "e6cb30effd90d563bc680430ecc1317842d33b6e",
    "title": "GRM: Large Gaussian Reconstruction Model for Efficient 3D Reconstruction and Generation",
    "year": 2024,
    "authors": "Yinghao Xu, Zifan Shi, Wang Yifan, Hansheng Chen, Ceyuan Yang",
    "abstract": "We introduce GRM, a large-scale reconstructor capable of recovering a 3D asset from sparse-view images in around 0.1s. GRM is a feed-forward transformer-based model that efficiently incorporates multi-view information to translate the input pixels into pixel-aligned Gaussians, which are unprojected to create a set of densely distributed 3D Gaussians representing a scene. Together, our transformer architecture and the use of 3D Gaussians unlock a scalable and efficient reconstruction framework. Extensive experimental results demonstrate the superiority of our method over alternatives regarding both reconstruction quality and efficiency. We also showcase the potential of GRM in generative tasks, i.e., text-to-3D and image-to-3D, by integrating it with existing multi-view diffusion models. Our project website is at: https://justimyhxu.github.io/projects/grm/.",
    "citationCount": 249,
    "pdf_filename": "2024_GRM__Large_Gaussian_Reconstruction_Model_e6cb30ef.pdf"
  },
  "3a63ae4086248e4ba4bd106839a26a08256909c4": {
    "paperId": "3a63ae4086248e4ba4bd106839a26a08256909c4",
    "title": "Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild",
    "year": 2024,
    "authors": "Fanghua Yu, Jinjin Gu, Zheyuan Li, Jinfan Hu, Xiangtao Kong",
    "abstract": "We introduce SUPIR (Scaling-UP Image Restoration), a groundbreaking image restoration method that harnesses generative prior and the power of model scaling up. Lever-aging multi-modal techniques and advanced generative prior, SUPIR marks a significant advance in intelligent and realistic image restoration. As a pivotal catalyst within SUPIR, model scaling dramatically enhances its capabil-ities and demonstrates new potential for image restoration. We collect a dataset comprising 20 million high-resolution, high-quality images for model training, each en-riched with descriptive text annotations. SUPIR provides the capability to restore images guided by textual prompts, broadening its application scope and potential. Moreover, we introduce negative-quality prompts to further improve perceptual quality. We also develop a restoration-guided sampling method to suppress the fidelity issue encountered in generative-based restoration. Experiments demonstrate SUPIR's exceptional restoration effects and its novel capac-ity to manipulate restoration through textual prompts.",
    "citationCount": 215,
    "pdf_filename": "2024_Scaling_Up_to_Excellence__Practicing_Mod_3a63ae40.pdf"
  },
  "f2bc968f5a7036f5c6c29ebd7cfaad9e1a677f4e": {
    "paperId": "f2bc968f5a7036f5c6c29ebd7cfaad9e1a677f4e",
    "title": "Sequence modeling and design from molecular to genome scale with Evo",
    "year": 2024,
    "authors": "Eric Nguyen, Michael Poli, Matthew G. Durrant, Armin W. Thomas, Brian Kang",
    "abstract": "The genome is a sequence that completely encodes the DNA, RNA, and proteins that orchestrate the function of a whole organism. Advances in machine learning combined with massive datasets of whole genomes could enable a biological foundation model that accelerates the mechanistic understanding and generative design of complex molecular interactions. We report Evo, a genomic foundation model that enables prediction and generation tasks from the molecular to genome scale. Using an architecture based on advances in deep signal processing, we scale Evo to 7 billion parameters with a context length of 131 kilobases (kb) at single-nucleotide, byte resolution. Trained on 2.7M prokaryotic and phage genomes, Evo can generalize across the three fundamental modalities of the central dogma of molecular biology to perform zero-shot function prediction that is competitive with, or outperforms, leading domain-specific language models. Evo also excels at multi-element generation tasks, which we demonstrate by generating synthetic CRISPR-Cas molecular complexes and entire transposable systems for the first time. Using information learned over whole genomes, Evo can also predict gene essentiality at nucleotide resolution and can generate coding-rich sequences up to 650 kb in length, orders of magnitude longer than previous methods. Advances in multi-modal and multiscale learning with Evo provides a promising path toward improving our understanding and control of biology across multiple levels of complexity.",
    "citationCount": 212,
    "pdf_filename": "2024_Sequence_modeling_and_design_from_molecu_f2bc968f.pdf"
  },
  "f6ab25605dc36db5e4b4f2f167d905944d5203c4": {
    "paperId": "f6ab25605dc36db5e4b4f2f167d905944d5203c4",
    "title": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation",
    "year": 2024,
    "authors": "Axel Sauer, Frederic Boesel, Tim Dockhorn, A. Blattmann, Patrick Esser",
    "abstract": "Diffusion models are the main driver of progress in image and video synthesis, but suffer from slow inference speed. Distillation methods, like the recently introduced adversarial diffusion distillation (ADD) aim to shift the model from many-shot to single-step inference, albeit at the cost of expensive and difficult optimization due to its reliance on a fixed pretrained DINOv2 discriminator. We introduce Latent Adversarial Diffusion Distillation (LADD), a novel distillation approach overcoming the limitations of ADD. In contrast to pixel-based ADD, LADD utilizes generative features from pretrained latent diffusion models. This approach simplifies training and enhances performance, enabling high-resolution multi-aspect ratio image synthesis. We apply LADD to Stable Diffusion 3 (8B) to obtain SD3-Turbo, a fast model that matches the performance of state-of-the-art text-to-image generators using only four unguided sampling steps. Moreover, we systematically investigate its scaling behavior and demonstrate LADD’s effectiveness in various applications such as image editing and inpainting.",
    "citationCount": 208,
    "pdf_filename": "2024_Fast_High_Resolution_Image_Synthesis_wit_f6ab2560.pdf"
  },
  "c8cc6ca886011e63c64bc9ac03b5a7798734fcec": {
    "paperId": "c8cc6ca886011e63c64bc9ac03b5a7798734fcec",
    "title": "A meta systematic review of artificial intelligence in higher education: a call for increased ethics, collaboration, and rigour",
    "year": 2024,
    "authors": "Melissa Bond, Hassan Khosravi, Maarten de Laat, Nina Bergdahl, Violeta Negrea",
    "abstract": "Although the field of Artificial Intelligence in Education (AIEd) has a substantial history as a research domain, never before has the rapid evolution of AI applications in education sparked such prominent public discourse. Given the already rapidly growing AIEd literature base in higher education, now is the time to ensure that the field has a solid research and conceptual grounding. This review of reviews is the first comprehensive meta review to explore the scope and nature of AIEd in higher education (AIHEd) research, by synthesising secondary research (e.g., systematic reviews), indexed in the Web of Science, Scopus, ERIC, EBSCOHost, IEEE Xplore, ScienceDirect and ACM Digital Library, or captured through snowballing in OpenAlex, ResearchGate and Google Scholar. Reviews were included if they synthesised applications of AI solely in formal higher or continuing education, were published in English between 2018 and July 2023, were journal articles or full conference papers, and if they had a method section 66 publications were included for data extraction and synthesis in EPPI Reviewer, which were predominantly systematic reviews (66.7%), published by authors from North America (27.3%), conducted in teams (89.4%) in mostly domestic-only collaborations (71.2%). Findings show that these reviews mostly focused on AIHEd generally (47.0%) or Profiling and Prediction (28.8%) as thematic foci, however key findings indicated a predominance of the use of Adaptive Systems and Personalisation in higher education. Research gaps identified suggest a need for greater ethical, methodological, and contextual considerations within future research, alongside interdisciplinary approaches to AIHEd application. Suggestions are provided to guide future primary and secondary research.",
    "citationCount": 298,
    "pdf_filename": "2024_A_meta_systematic_review_of_artificial_i_c8cc6ca8.pdf"
  },
  "62f441d5078bf77927c370364367c20f4e0010e6": {
    "paperId": "62f441d5078bf77927c370364367c20f4e0010e6",
    "title": "LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods",
    "year": 2024,
    "authors": "Haitao Li, Qian Dong, Junjie Chen, Huixue Su, Yujia Zhou",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has driven their expanding application across various fields. One of the most promising applications is their role as evaluators based on natural language responses, referred to as ''LLMs-as-judges''. This framework has attracted growing attention from both academia and industry due to their excellent effectiveness, ability to generalize across tasks, and interpretability in the form of natural language. This paper presents a comprehensive survey of the LLMs-as-judges paradigm from five key perspectives: Functionality, Methodology, Applications, Meta-evaluation, and Limitations. We begin by providing a systematic definition of LLMs-as-Judges and introduce their functionality (Why use LLM judges?). Then we address methodology to construct an evaluation system with LLMs (How to use LLM judges?). Additionally, we investigate the potential domains for their application (Where to use LLM judges?) and discuss methods for evaluating them in various contexts (How to evaluate LLM judges?). Finally, we provide a detailed analysis of the limitations of LLM judges and discuss potential future directions. Through a structured and comprehensive analysis, we aim aims to provide insights on the development and application of LLMs-as-judges in both research and practice. We will continue to maintain the relevant resource list at https://github.com/CSHaitao/Awesome-LLMs-as-Judges.",
    "citationCount": 241,
    "pdf_filename": "2024_LLMs_as_Judges__A_Comprehensive_Survey_o_62f441d5.pdf"
  },
  "ce806f8d32f6fb1eaa821248a1bc4fa2cd949fbb": {
    "paperId": "ce806f8d32f6fb1eaa821248a1bc4fa2cd949fbb",
    "title": "Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution",
    "year": 2023,
    "authors": "Aaron Lou, Chenlin Meng, Stefano Ermon",
    "abstract": "Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, integrates seamlessly to build discrete diffusion models, and significantly boosts performance. Experimentally, we test our Score Entropy Discrete Diffusion models (SEDD) on standard language modeling tasks. For comparable model sizes, SEDD beats existing language diffusion paradigms (reducing perplexity by $25$-$75$\\%) and is competitive with autoregressive models, in particular outperforming GPT-2. Furthermore, compared to autoregressive mdoels, SEDD generates faithful text without requiring distribution annealing techniques like temperature scaling (around $6$-$8\\times$ better generative perplexity than un-annealed GPT-2), can trade compute and quality (similar quality with $32\\times$ fewer network evaluations), and enables controllable infilling (matching nucleus sampling quality while enabling other strategies besides left to right prompting).",
    "citationCount": 271,
    "pdf_filename": "2023_Discrete_Diffusion_Modeling_by_Estimatin_ce806f8d.pdf"
  },
  "6f709278506813d04a074e6fa20188cce9bb927b": {
    "paperId": "6f709278506813d04a074e6fa20188cce9bb927b",
    "title": "LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching",
    "year": 2023,
    "authors": "Yixun Liang, Xin Yang, Jiantao Lin, Haodong Li, Xiaogang Xu",
    "abstract": "The recent advancements in text-to-3D generation mark a significant milestone in generative models, unlocking new possibilities for creating imaginative 3D assets across var-ious real-world scenarios. While recent advancements in text-to-3D generation have shown promise, they often fall short in rendering detailed and high-quality 3D models. This problem is especially prevalent as many methods base themselves on Score Distillation Sampling (SDS). This paper identifies a notable deficiency in SDS, that it brings inconsistent and low-quality updating direction for the 3D model, causing the over-smoothing effect. To address this, we propose a novel approach called Interval Score Matching (ISM). ISM employs deterministic diffusing trajectories and utilizes interval-based score matching to counteract over-smoothing. Furthermore, we incorporate 3D Gaussian Splatting into our text-to-3D generation pipeline. Extensive experiments show that our model largely outperforms the state-of-the-art in quality and training efficiency. Our code is available at: EnVision-Research/LucidDreamer",
    "citationCount": 272,
    "pdf_filename": "2023_LucidDreamer__Towards_High_Fidelity_Text_6f709278.pdf"
  },
  "59713b444d3268528416f23fe860ba63bb03fc04": {
    "paperId": "59713b444d3268528416f23fe860ba63bb03fc04",
    "title": "3D Equivariant Diffusion for Target-Aware Molecule Generation and Affinity Prediction",
    "year": 2023,
    "authors": "Jiaqi Guan, Wesley Wei Qian, Xingang Peng, Yufeng Su, Jian Peng",
    "abstract": "Rich data and powerful machine learning models allow us to design drugs for a specific protein target \\textit{in silico}. Recently, the inclusion of 3D structures during targeted drug design shows superior performance to other target-free models as the atomic interaction in the 3D space is explicitly modeled. However, current 3D target-aware models either rely on the voxelized atom densities or the autoregressive sampling process, which are not equivariant to rotation or easily violate geometric constraints resulting in unrealistic structures. In this work, we develop a 3D equivariant diffusion model to solve the above challenges. To achieve target-aware molecule design, our method learns a joint generative process of both continuous atom coordinates and categorical atom types with a SE(3)-equivariant network. Moreover, we show that our model can serve as an unsupervised feature extractor to estimate the binding affinity under proper parameterization, which provides an effective way for drug screening. To evaluate our model, we propose a comprehensive framework to evaluate the quality of sampled molecules from different dimensions. Empirical studies show our model could generate molecules with more realistic 3D structures and better affinities towards the protein targets, and improve binding affinity ranking and prediction without retraining.",
    "citationCount": 237,
    "pdf_filename": "2023_3D_Equivariant_Diffusion_for_Target_Awar_59713b44.pdf"
  },
  "c09ca9da1fce13b1560f45c38321c7bb971f13fc": {
    "paperId": "c09ca9da1fce13b1560f45c38321c7bb971f13fc",
    "title": "Unleashing Text-to-Image Diffusion Models for Visual Perception",
    "year": 2023,
    "authors": "Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou",
    "abstract": "Diffusion models (DMs) have become the new trend of generative models and have demonstrated a powerful ability of conditional synthesis. Among those, text-to-image diffusion models pre-trained on large-scale image-text pairs are highly controllable by customizable prompts. Unlike the unconditional generative models that focus on low-level attributes and details, text-to-image diffusion models contain more high-level knowledge thanks to the vision-language pre-training. In this paper, we propose VPD (Visual Perception with pre-trained Diffusion models), a new framework that exploits the semantic information of a pre-trained text-to-image diffusion model in visual perception tasks. Instead of using the pre-trained denoising autoencoder in a diffusion-based pipeline, we simply use it as a backbone and aim to study how to take full advantage of the learned knowledge. Specifically, we prompt the denoising decoder with proper textual inputs and refine the text features with an adapter, leading to a better alignment to the pre-trained stage and making the visual contents interact with the text prompts. We also propose to utilize the cross-attention maps between the visual features and the text features to provide explicit guidance. Compared with other pre-training methods, we show that vision-language pre-trained diffusion models can be faster adapted to downstream visual perception tasks using the proposed VPD. Extensive experiments on semantic segmentation, referring image segmentation, and depth estimation demonstrate the effectiveness of our method. Notably, VPD attains 0.254 RMSE on NYUv2 depth estimation and 73.3% oIoU on RefCOCO-val referring image segmentation, establishing new records on these two benchmarks. Code is available at https://github.com/wl-zhao/VPD.",
    "citationCount": 288,
    "pdf_filename": "2023_Unleashing_Text_to_Image_Diffusion_Model_c09ca9da.pdf"
  },
  "ccf43c35160954616b8f1c3c00e939883b666c2f": {
    "paperId": "ccf43c35160954616b8f1c3c00e939883b666c2f",
    "title": "Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization",
    "year": 2023,
    "authors": "Tao Yang, Peiran Ren, Xuansong Xie, Lei Zhang",
    "abstract": "Diffusion models have demonstrated impressive performance in various image generation, editing, enhancement and translation tasks. In particular, the pre-trained text-to-image stable diffusion models provide a potential solution to the challenging realistic image super-resolution (Real-ISR) and image stylization problems with their strong generative priors. However, the existing methods along this line often fail to keep faithful pixel-wise image structures. If extra skip connections between the encoder and the decoder of a VAE are used to reproduce details, additional training in image space will be required, limiting the application to tasks in latent space such as image stylization. In this work, we propose a pixel-aware stable diffusion (PASD) network to achieve robust Real-ISR and personalized image stylization. Specifically, a pixel-aware cross attention module is introduced to enable diffusion models perceiving image local structures in pixel-wise level, while a degradation removal module is used to extract degradation insensitive features to guide the diffusion process together with image high level information. An adjustable noise schedule is introduced to further improve the image restoration results. By simply replacing the base diffusion model with a stylized one, PASD can generate diverse stylized images without collecting pairwise training data, and by shifting the base model with an aesthetic one, PASD can bring old photos back to life. Extensive experiments in a variety of image enhancement and stylization tasks demonstrate the effectiveness of our proposed PASD approach. Our source codes are available at \\url{https://github.com/yangxy/PASD/}.",
    "citationCount": 220,
    "pdf_filename": "2023_Pixel_Aware_Stable_Diffusion_for_Realist_ccf43c35.pdf"
  },
  "f4793adffd6f67ffcb93ccfc5672ab301b8a2b96": {
    "paperId": "f4793adffd6f67ffcb93ccfc5672ab301b8a2b96",
    "title": "PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering",
    "year": 2023,
    "authors": "Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya Zhang",
    "abstract": "Medical Visual Question Answering (MedVQA) presents a significant opportunity to enhance diagnostic accuracy and healthcare delivery by leveraging artificial intelligence to interpret and answer questions based on medical images. In this study, we reframe the problem of MedVQA as a generation task that naturally follows the human-machine interaction and propose a generative-based model for medical visual understanding by aligning visual information from a pre-trained vision encoder with a large language model. We establish a scalable pipeline to construct a large-scale medical visual question-answering dataset, named PMC-VQA, which contains 227k VQA pairs of 149k images that cover various modalities or diseases. We train the proposed model on PMC-VQA and then fine-tune it on multiple public benchmarks, e.g., VQA-RAD, SLAKE, and Image-Clef-2019, significantly outperforming existing MedVQA models in generating relevant, accurate free-form answers. In addition, we propose a test set that has undergone manual verification, which is significantly more challenging, serving to better monitor the development of generative MedVQA methods. To facilitate comprehensive evaluation and comparison, we have maintained a leaderboard at https://paperswithcode.com/paper/pmc-vqa-visual-instruction-tuning-for-medical, offering a centralized resource for tracking progress and benchmarking state-of-the-art approaches. The PMC-VQA dataset emerges as a vital resource for the field of research, and the MedVInT presents a significant breakthrough in the area of MedVQA.",
    "citationCount": 256,
    "pdf_filename": "2023_PMC_VQA__Visual_Instruction_Tuning_for_M_f4793adf.pdf"
  },
  "9550076d9930dd3533ab9276126f1a9265fad7b4": {
    "paperId": "9550076d9930dd3533ab9276126f1a9265fad7b4",
    "title": "Human Preference Score: Better Aligning Text-to-image Models with Human Preference",
    "year": 2023,
    "authors": "Xiaoshi Wu, Keqiang Sun, Feng Zhu, Rui Zhao, Hongsheng Li",
    "abstract": "Recent years have witnessed a rapid growth of deep generative models, with text-to-image models gaining significant attention from the public. However, existing models often generate images that do not align well with human preferences, such as awkward combinations of limbs and facial expressions. To address this issue, we collect a dataset of human choices on generated images from the Stable Foundation Discord channel. Our experiments demonstrate that current evaluation metrics for generative models do not correlate well with human choices. Thus, we train a human preference classifier with the collected dataset and derive a Human Preference Score (HPS) based on the classifier. Using HPS, we propose a simple yet effective method to adapt Stable Diffusion to better align with human preferences. Our experiments show that HPS outperforms CLIP in predicting human choices and has good generalization capability toward images generated from other models. By tuning Stable Diffusion with the guidance of HPS, the adapted model is able to generate images that are more preferred by human users. The project page is available here: https://tgxs002.github.io/alignsd-web/.",
    "citationCount": 255,
    "pdf_filename": "2023_Human_Preference_Score__Better_Aligning__9550076d.pdf"
  },
  "66d927fdb6c2774131960c75275546fd5ee3dd72": {
    "paperId": "66d927fdb6c2774131960c75275546fd5ee3dd72",
    "title": "EvalCrafter: Benchmarking and Evaluating Large Video Generation Models",
    "year": 2023,
    "authors": "Yaofang Liu, Xiaodong Cun, Xuebo Liu, Xintao Wang, Yong Zhang",
    "abstract": "The vision and language generative models have been overgrown in recent years. For video generation, various open-sourced models and public-available services have been developed to generate high-quality videos. However, these methods often use a few metrics, e.g., FVD [56] or IS [45], to evaluate the performance. We argue that it is hard to judge the large conditional generative models from the simple metrics since these models are often trained on very large datasets with multi-aspect abilities. Thus, we propose a novel framework and pipeline for exhaustively evaluating the performance of the generated videos. Our approach involves generating a diverse and comprehensive list of 700 prompts for text-to-video generation, which is based on an analysis of real-world user data and generated with the assistance of a large language model. Then, we evaluate the state-of-the-art video generative models on our carefully designed benchmark, in terms of visual qualities, content qualities, motion qualities, and text-video alignment with 17 well-selected objective metrics. To obtain the finalleaderboard of the models, we further fit a series of coefficients to align the objective metrics to the users' opinions. Based on the proposed human alignment method, our final score shows a higher correlation than simply averaging the metrics, showing the effectiveness of the proposed evaluation method.",
    "citationCount": 219,
    "pdf_filename": "2023_EvalCrafter__Benchmarking_and_Evaluating_66d927fd.pdf"
  },
  "be7b764fe1c9c32cbe349bde1fbb19321fd1d71c": {
    "paperId": "be7b764fe1c9c32cbe349bde1fbb19321fd1d71c",
    "title": "Prompt, Generate, Then Cache: Cascade of Foundation Models Makes Strong Few-Shot Learners",
    "year": 2023,
    "authors": "Renrui Zhang, Xiangfei Hu, Bohao Li, Siyuan Huang, Hanqiu Deng",
    "abstract": "Visual recognition in low-data regimes requires deep neural networks to learn generalized representations from limited training samples. Recently, CLIP-based methods have shown promising few-shot performance benefited from the contrastive language-image pre-training. We then question, if the more diverse pre-training knowledge can be cascaded to further assist few-shot representation learning. In this paper, we propose CaFo, a Cascade of Foundation models that incorporates diverse prior knowledge of various pretraining paradigms for better few-shot learning. Our CaFo incorporates CLIP's language-contrastive knowledge, DINO's vision-contrastive knowledge, DALL-E's vision-generative knowledge, and GPT-3's language-generative knowledge. Specifically, CaFo works by ‘Prompt, Generate, then Cache’. Firstly, we leverage GPT-3 to produce textual inputs for prompting CLIP with rich downstream linguistic semantics. Then, we generate synthetic images via DALL-E to expand the few-shot training data without any manpower. At last, we introduce a learnable cache model to adaptively blend the predictions from CLIP and DINO. By such collaboration, CaFo can fully unleash the potential of different pre-training methods and unify them to perform state-of-the-art for few-shot classification. Code is available at https://github.com/ZrrSkywalker/CaFo.",
    "citationCount": 216,
    "pdf_filename": "2023_Prompt__Generate__Then_Cache__Cascade_of_be7b764f.pdf"
  },
  "905ba940236b00bebb2fd348d4d932e7887b0c0a": {
    "paperId": "905ba940236b00bebb2fd348d4d932e7887b0c0a",
    "title": "Photorealistic Video Generation with Diffusion Models",
    "year": 2023,
    "authors": "Agrim Gupta, Lijun Yu, Kihyuk Sohn, Xiuye Gu, Meera Hahn",
    "abstract": "We present W.A.L.T, a transformer-based approach for photorealistic video generation via diffusion modeling. Our approach has two key design decisions. First, we use a causal encoder to jointly compress images and videos within a unified latent space, enabling training and generation across modalities. Second, for memory and training efficiency, we use a window attention architecture tailored for joint spatial and spatiotemporal generative modeling. Taken together these design decisions enable us to achieve state-of-the-art performance on established video (UCF-101 and Kinetics-600) and image (ImageNet) generation benchmarks without using classifier free guidance. Finally, we also train a cascade of three models for the task of text-to-video generation consisting of a base latent video diffusion model, and two video super-resolution diffusion models to generate videos of $512 \\times 896$ resolution at $8$ frames per second.",
    "citationCount": 256,
    "pdf_filename": "2023_Photorealistic_Video_Generation_with_Dif_905ba940.pdf"
  },
  "ee73edebd42626d9c2d91e35fd2ed3cdb0fb26d0": {
    "paperId": "ee73edebd42626d9c2d91e35fd2ed3cdb0fb26d0",
    "title": "Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos",
    "year": 2023,
    "authors": "Yue Ma, Yin-Yin He, Xiaodong Cun, Xintao Wang, Ying Shan",
    "abstract": "Generating text-editable and pose-controllable character videos have an imperious demand in creating various digital human. Nevertheless, this task has been restricted by the absence of a comprehensive dataset featuring paired video-pose captions and the generative prior models for videos. In this work, we design a novel two-stage training scheme that can utilize easily obtained datasets (i.e., image pose pair and pose-free video) and the pre-trained text-to-image (T2I) model to obtain the pose-controllable character videos. Specifically, in the first stage, only the keypoint image pairs are used only for a controllable text-to-image generation. We learn a zero-initialized convolutional encoder to encode the pose information. In the second stage, we finetune the motion of the above network via a pose-free video dataset by adding the learnable temporal self-attention and reformed cross-frame self-attention blocks. Powered by our new designs, our method successfully generates continuously pose-controllable character videos while keeps the editing and concept composition ability of the pre-trained T2I model. The code and models are available on https://follow-your-pose.github.io/.",
    "citationCount": 258,
    "pdf_filename": "2023_Follow_Your_Pose__Pose_Guided_Text_to_Vi_ee73edeb.pdf"
  },
  "431031af5dff30525b2ec8cdff45d21a9f78d929": {
    "paperId": "431031af5dff30525b2ec8cdff45d21a9f78d929",
    "title": "Diffusion-based Generation, Optimization, and Planning in 3D Scenes",
    "year": 2023,
    "authors": "Siyuan Huang, Zan Wang, Puhao Li, Baoxiong Jia, Tengyu Liu",
    "abstract": "We introduce the SceneDiffuser, a conditional generative model for 3D scene understanding. SceneDiffuser provides a unified model for solving scene-conditioned generation, optimization, and planning. In contrast to prior work, SceneDiffuser is intrinsically scene-aware, physics-based, and goal-oriented. With an iterative sampling strategy, SceneDiffuser jointly formulates the scene-aware generation, physics-based optimization, and goal-oriented planning via a diffusion-based denoising process in a fully differentiable fashion. Such a design alleviates the discrepancies among different modules and the posterior collapse of previous scene-conditioned generative models. We evaluate the SceneDiffuser on various 3D scene understanding tasks, including human pose and motion generation, dexterous grasp generation, path planning for 3D navigation, and motion planning for robot arms. The results show significant improvements compared with previous models, demonstrating the tremendous potential of the SceneDiffuser for the broad community of 3D scene understanding.",
    "citationCount": 282,
    "pdf_filename": "2023_Diffusion_based_Generation__Optimization_431031af.pdf"
  },
  "b43330013a5abcccd366d71f2f66c493c790abc6": {
    "paperId": "b43330013a5abcccd366d71f2f66c493c790abc6",
    "title": "Imitating Human Behaviour with Diffusion Models",
    "year": 2023,
    "authors": "Tim Pearce, Tabish Rashid, A. Kanervisto, David Bignell, Mingfei Sun",
    "abstract": "Diffusion models have emerged as powerful generative models in the text-to-image domain. This paper studies their application as observation-to-action models for imitating human behaviour in sequential environments. Human behaviour is stochastic and multimodal, with structured correlations between action dimensions. Meanwhile, standard modelling choices in behaviour cloning are limited in their expressiveness and may introduce bias into the cloned policy. We begin by pointing out the limitations of these choices. We then propose that diffusion models are an excellent fit for imitating human behaviour, since they learn an expressive distribution over the joint action space. We introduce several innovations to make diffusion models suitable for sequential environments; designing suitable architectures, investigating the role of guidance, and developing reliable sampling strategies. Experimentally, diffusion models closely match human demonstrations in a simulated robotic control task and a modern 3D gaming environment.",
    "citationCount": 253,
    "pdf_filename": "2023_Imitating_Human_Behaviour_with_Diffusion_b4333001.pdf"
  },
  "48948ab1c05260171337730c0e9b26ec7be49b46": {
    "paperId": "48948ab1c05260171337730c0e9b26ec7be49b46",
    "title": "Performance of GPT-3.5 and GPT-4 on the Japanese Medical Licensing Examination: Comparison Study",
    "year": 2023,
    "authors": "Soshi Takagi, T. Watari, Ayano Erabi, Kota Sakaguchi",
    "abstract": "Background The competence of ChatGPT (Chat Generative Pre-Trained Transformer) in non-English languages is not well studied. Objective This study compared the performances of GPT-3.5 (Generative Pre-trained Transformer) and GPT-4 on the Japanese Medical Licensing Examination (JMLE) to evaluate the reliability of these models for clinical reasoning and medical knowledge in non-English languages. Methods This study used the default mode of ChatGPT, which is based on GPT-3.5; the GPT-4 model of ChatGPT Plus; and the 117th JMLE in 2023. A total of 254 questions were included in the final analysis, which were categorized into 3 types, namely general, clinical, and clinical sentence questions. Results The results indicated that GPT-4 outperformed GPT-3.5 in terms of accuracy, particularly for general, clinical, and clinical sentence questions. GPT-4 also performed better on difficult questions and specific disease questions. Furthermore, GPT-4 achieved the passing criteria for the JMLE, indicating its reliability for clinical reasoning and medical knowledge in non-English languages. Conclusions GPT-4 could become a valuable tool for medical education and clinical support in non–English-speaking regions, such as Japan.",
    "citationCount": 222,
    "pdf_filename": "2023_Performance_of_GPT_3_5_and_GPT_4_on_the__48948ab1.pdf"
  },
  "c2917da5abbf0f0cfb4ce366b180359ff8a9deae": {
    "paperId": "c2917da5abbf0f0cfb4ce366b180359ff8a9deae",
    "title": "DreamBooth3D: Subject-Driven Text-to-3D Generation",
    "year": 2023,
    "authors": "Amit Raj, S. Kaza, Ben Poole, Michael Niemeyer, Nataniel Ruiz",
    "abstract": "We present DreamBooth3D, an approach to personalize text-to-3D generative models from as few as 3-6 casually captured images of a subject. Our approach combines recent advances in personalizing text-to-image models (DreamBooth) with text-to-3D generation (DreamFusion). We find that naïvely combining these methods fails to yield satisfactory subject-specific 3D assets due to personalized text-to-image models overfitting to the input viewpoints of the subject. We overcome this through a 3-stage optimization strategy where we jointly leverage the 3D consistency of neural radiance fields together with the personalization capability of text-to-image models. Our method can produce high-quality, subject-specific 3D assets with text-driven modifications such as novel poses, colors and attributes that are not seen in any of the input images of the subject. More results are available at our project page: https://dreambooth3d.github.io",
    "citationCount": 264,
    "pdf_filename": "2023_DreamBooth3D__Subject_Driven_Text_to_3D__c2917da5.pdf"
  },
  "72570016bbb28e8fb15ab4667eb84887f5dd35ad": {
    "paperId": "72570016bbb28e8fb15ab4667eb84887f5dd35ad",
    "title": "Inpaint Anything: Segment Anything Meets Image Inpainting",
    "year": 2023,
    "authors": "Tao Yu, Runsen Feng, Ruoyu Feng, Jinming Liu, Xin Jin",
    "abstract": "Modern image inpainting systems, despite the significant progress, often struggle with mask selection and holes filling. Based on Segment-Anything Model (SAM), we make the first attempt to the mask-free image inpainting and propose a new paradigm of ``clicking and filling'', which is named as Inpaint Anything (IA). The core idea behind IA is to combine the strengths of different models in order to build a very powerful and user-friendly pipeline for solving inpainting-related problems. IA supports three main features: (i) Remove Anything: users could click on an object and IA will remove it and smooth the ``hole'' with the context; (ii) Fill Anything: after certain objects removal, users could provide text-based prompts to IA, and then it will fill the hole with the corresponding generative content via driving AIGC models like Stable Diffusion; (iii) Replace Anything: with IA, users have another option to retain the click-selected object and replace the remaining background with the newly generated scenes. We are also very willing to help everyone share and promote new projects based on our Inpaint Anything (IA). Our codes are available at https://github.com/geekyutao/Inpaint-Anything.",
    "citationCount": 276,
    "pdf_filename": "2023_Inpaint_Anything__Segment_Anything_Meets_72570016.pdf"
  },
  "746bb45433f6b24d3ae64d6cd51c4e9d00a0ffa7": {
    "paperId": "746bb45433f6b24d3ae64d6cd51c4e9d00a0ffa7",
    "title": "Large-scale Multi-modal Pre-trained Models: A Comprehensive Survey",
    "year": 2023,
    "authors": "Xiao Wang, Guangyao Chen, Guangwu Qian, Pengcheng Gao, Xiaoyong Wei",
    "abstract": "With the urgent demand for generalized deep models, many pre-trained big models are proposed, such as bidirectional encoder representations (BERT), vision transformer (ViT), generative pre-trained transformers (GPT), etc. Inspired by the success of these models in single domains (like computer vision and natural language processing), the multi-modal pre-trained big models have also drawn more and more attention in recent years. In this work, we give a comprehensive survey of these models and hope this paper could provide new insights and helps fresh researchers to track the most cutting-edge works. Specifically, we firstly introduce the background of multi-modal pre-training by reviewing the conventional deep learning, pre-training works in natural language process, computer vision, and speech. Then, we introduce the task definition, key challenges, and advantages of multi-modal pre-training models (MM-PTMs), and discuss the MM-PTMs with a focus on data, objectives, network architectures, and knowledge enhanced pre-training. After that, we introduce the downstream tasks used for the validation of large-scale MM-PTMs, including generative, classification, and regression tasks. We also give visualization and analysis of the model parameters and results on representative downstream tasks. Finally, we point out possible research directions for this topic that may benefit future works. In addition, we maintain a continuously updated paper list for large-scale pre-trained multi-modal big models: https://github.com/wangxiao5791509/MultiModal_BigModels_Survey.",
    "citationCount": 259,
    "pdf_filename": "2023_Large_scale_Multi_modal_Pre_trained_Mode_746bb454.pdf"
  },
  "2c67ee597ed38f43ec0f123a3f1cce38cbd3b5b4": {
    "paperId": "2c67ee597ed38f43ec0f123a3f1cce38cbd3b5b4",
    "title": "Sources of Hallucination by Large Language Models on Inference Tasks",
    "year": 2023,
    "authors": "Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark Johnson",
    "abstract": "Large Language Models (LLMs) are claimed to be capable of Natural Language Inference (NLI), necessary for applied tasks like question answering and summarization. We present a series of behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled experiments. We establish two biases originating from pretraining which predict much of their behavior, and show that these are major sources of hallucination in generative LLMs. First, memorization at the level of sentences: we show that, regardless of the premise, models falsely label NLI test samples as entailing when the hypothesis is attested in training data, and that entities are used as ``indices'' to access the memorized data. Second, statistical patterns of usage learned at the level of corpora: we further show a similar effect when the premise predicate is less frequent than that of the hypothesis in the training data, a bias following from previous studies. We demonstrate that LLMs perform significantly worse on NLI test samples which do not conform to these biases than those which do, and we offer these as valuable controls for future LLM evaluation.",
    "citationCount": 236,
    "pdf_filename": "2023_Sources_of_Hallucination_by_Large_Langua_2c67ee59.pdf"
  },
  "822d0ee6ea109ee8c61c5694e29c301d2cc55283": {
    "paperId": "822d0ee6ea109ee8c61c5694e29c301d2cc55283",
    "title": "Machine Learning for Synthetic Data Generation: a Review",
    "year": 2023,
    "authors": "Ying-Cheng Lu, Huazheng Wang, Wenqi Wei",
    "abstract": "Machine learning heavily relies on data, but real-world applications often encounter various data-related issues. These include data of poor quality, insufficient data points leading to under-fitting of machine learning models, and difficulties in data access due to concerns surrounding privacy, safety, and regulations. In light of these challenges, the concept of synthetic data generation emerges as a promising alternative that allows for data sharing and utilization in ways that real-world data cannot facilitate. This paper presents a comprehensive systematic review of existing studies that employ machine learning models for the purpose of generating synthetic data. The review encompasses various perspectives, starting with the applications of synthetic data generation, spanning computer vision, speech, natural language processing, healthcare, and business domains. Additionally, it explores different machine learning methods, with particular emphasis on neural network architectures and deep generative models. The paper also addresses the crucial aspects of privacy and fairness concerns related to synthetic data generation. Furthermore, this study identifies the challenges and opportunities prevalent in this emerging field, shedding light on the potential avenues for future research. By delving into the intricacies of synthetic data generation, this paper aims to contribute to the advancement of knowledge and inspire further exploration in synthetic data generation.",
    "citationCount": 217,
    "pdf_filename": "2023_Machine_Learning_for_Synthetic_Data_Gene_822d0ee6.pdf"
  },
  "6e5e65b3c0743024f21600643c4a54a804abdf01": {
    "paperId": "6e5e65b3c0743024f21600643c4a54a804abdf01",
    "title": "The Perception by University Students of the Use of ChatGPT in Education",
    "year": 2023,
    "authors": "Thi Cam Thuy Ngo",
    "abstract": "ChatGPT, a generative language model recently created by OpenAI, has drawn a lot of criticism from people all around the world. ChatGPT illustrates both potential opportunities and challenges in education. This study aims to investigate how university students perceive using ChatGPT for learning, including benefits, barriers, and potential solutions. To determine how students felt about using ChatGPT in their learning, a questionnaire was distributed to 200 students via an online survey, and 30 students participated in semi-structured interviews. The research results showed that, in general, students had a favorable opinion of ChatGPT’s application. The benefits of ChatGPT, according to students, included saving time, providing information in various areas, providing personalized tutoring and feedback, and illuminating ideas in writing. Also, several barriers to using ChatGPT were recognized, and some solutions were suggested for improvement of using ChatGPT in education. The most concerning issues for students while using ChatGPT were inability to assess the quality and reliability of sources, inability to cite sources accurately, and inability to replace words and use idioms accurately. To address these concerns, some potential solutions can be implemented; for example, verifying ChatGPT’s responses with reliable sources; using ChatGPT as a reference source or a consultant tool; providing guidelines for use; and promoting academic integrity to ensure ethical uses of ChatGPT in an academic context.",
    "citationCount": 204,
    "pdf_filename": "2023_The_Perception_by_University_Students_of_6e5e65b3.pdf"
  },
  "4ea8e22236681a09225ee3f8ff5fffd934ec9bae": {
    "paperId": "4ea8e22236681a09225ee3f8ff5fffd934ec9bae",
    "title": "From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference",
    "year": 2023,
    "authors": "S. Samsi, Dan Zhao, Joseph McDonald, Baolin Li, Adam Michaleas",
    "abstract": "Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs-despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies. In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA-a recent state-of-the-art LLM-developed by Meta AI on two generations of popular GPUs (NVIDIA V100 & A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice. We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs. To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale.",
    "citationCount": 232,
    "pdf_filename": "2023_From_Words_to_Watts__Benchmarking_the_En_4ea8e222.pdf"
  },
  "986839c6da75e8f9ed1c767400657e5de7b527a4": {
    "paperId": "986839c6da75e8f9ed1c767400657e5de7b527a4",
    "title": "StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners",
    "year": 2023,
    "authors": "Yonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, Dilip Krishnan",
    "abstract": "We investigate the potential of learning visual representations using synthetic images generated by text-to-image models. This is a natural question in the light of the excellent performance of such models in generating high-quality images. We consider specifically the Stable Diffusion, one of the leading open source text-to-image models. We show that (1) when the generative model is configured with proper classifier-free guidance scale, training self-supervised methods on synthetic images can match or beat the real image counterpart; (2) by treating the multiple images generated from the same text prompt as positives for each other, we develop a multi-positive contrastive learning method, which we call StableRep. With solely synthetic images, the representations learned by StableRep surpass the performance of representations learned by SimCLR and CLIP using the same set of text prompts and corresponding real images, on large scale datasets. When we further add language supervision, StableRep trained with 20M synthetic images achieves better accuracy than CLIP trained with 50M real images.",
    "citationCount": 203,
    "pdf_filename": "2023_StableRep__Synthetic_Images_from_Text_to_986839c6.pdf"
  },
  "8947ee00f2597ff9e4da5feb4b09e8cb2d8dec73": {
    "paperId": "8947ee00f2597ff9e4da5feb4b09e8cb2d8dec73",
    "title": "Evaluating Academic Answers Generated Using ChatGPT",
    "year": 2023,
    "authors": "S. Fergus, Michelle J Botha, M. Ostovar",
    "abstract": "The integration of technology in education has become ever more prioritized since the COVID-19 pandemic. Chat Generative Pre-Trained Transformer (ChatGPT) is an artificial intelligence technology that generates conversational interactions to user prompts. The trained model can answer follow-up questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests. The functionality of ChatGPT in answering chemistry assessment questions requires investigation to ascertain its potential impact on learning and assessment. Two chemistry-focused modules in year 1 and year 2 of a pharmaceutical science program are used to study and evaluate ChatGPT-generated responses in relation to the end-of-year exam assessments. For questions that focused on knowledge and understanding with \"describe” and \"discuss” verbs, the ChatGPT generated responses. For questions that focused on application of knowledge and interpretation with nontext information, the ChatGPT technology reached a limitation. A further analysis of the quality of responses is reported in this study. ChatGPT is not considered a high-risk technology tool in relation to cheating. Similar to the COVID-19 disruption, ChatGPT is expected to provide a catalyst for educational discussions on academic integrity and assessment design. © 2023 The Authors. Published by American Chemical Society and Division of Chemical Education, Inc.",
    "citationCount": 205,
    "pdf_filename": "2023_Evaluating_Academic_Answers_Generated_Us_8947ee00.pdf"
  },
  "008569e98f3ef3596eeeaa23725a0c9c0339802e": {
    "paperId": "008569e98f3ef3596eeeaa23725a0c9c0339802e",
    "title": "Rapid inverse design of metamaterials based on prescribed mechanical behavior through machine learning",
    "year": 2023,
    "authors": "Chan Soo Ha, Desheng Yao, Zhenpeng Xu, Chenang Liu, Han Liu",
    "abstract": "Designing and printing metamaterials with customizable architectures enables the realization of unprecedented mechanical behaviors that transcend those of their constituent materials. These behaviors are recorded in the form of response curves, with stress-strain curves describing their quasi-static footprint. However, existing inverse design approaches are yet matured to capture the full desired behaviors due to challenges stemmed from multiple design objectives, nonlinear behavior, and process-dependent manufacturing errors. Here, we report a rapid inverse design methodology, leveraging generative machine learning and desktop additive manufacturing, which enables the creation of nearly all possible uniaxial compressive stress‒strain curve cases while accounting for process-dependent errors from printing. Results show that mechanical behavior with full tailorability can be achieved with nearly 90% fidelity between target and experimentally measured results. Our approach represents a starting point to inverse design materials that meet prescribed yet complex behaviors and potentially bypasses iterative design-manufacturing cycles.",
    "citationCount": 222,
    "pdf_filename": "2023_Rapid_inverse_design_of_metamaterials_ba_008569e9.pdf"
  },
  "502195cecab51bb42684265474c9756077f1d564": {
    "paperId": "502195cecab51bb42684265474c9756077f1d564",
    "title": "Deep Learning in Mechanical Metamaterials: From Prediction and Generation to Inverse Design",
    "year": 2023,
    "authors": "Xiaoyang Zheng, Xubo Zhang, Ta-Te Chen, I. Watanabe",
    "abstract": "Mechanical metamaterials are meticulously designed structures with exceptional mechanical properties determined by their microstructures and constituent materials. Tailoring their material and geometric distribution unlocks the potential to achieve unprecedented bulk properties and functions. However, current mechanical metamaterial design considerably relies on experienced designers' inspiration through trial and error, while investigating their mechanical properties and responses entails time‐consuming mechanical testing or computationally expensive simulations. Nevertheless, recent advancements in deep learning have revolutionized the design process of mechanical metamaterials, enabling property prediction and geometry generation without prior knowledge. Furthermore, deep generative models can transform conventional forward design into inverse design. Many recent studies on the implementation of deep learning in mechanical metamaterials are highly specialized, and their pros and cons may not be immediately evident. This critical review provides a comprehensive overview of the capabilities of deep learning in property prediction, geometry generation, and inverse design of mechanical metamaterials. Additionally, this review highlights the potential of leveraging deep learning to create universally applicable datasets, intelligently designed metamaterials, and material intelligence. This article is expected to be valuable not only to researchers working on mechanical metamaterials but also those in the field of materials informatics.",
    "citationCount": 202,
    "pdf_filename": "2023_Deep_Learning_in_Mechanical_Metamaterial_502195ce.pdf"
  },
  "7c04ab297b59d4fe29285f339350882a3120b27f": {
    "paperId": "7c04ab297b59d4fe29285f339350882a3120b27f",
    "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs",
    "year": 2024,
    "authors": "Majeed Kazemitabaar, Runlong Ye, Xiaoning Wang, Austin Z Henley, Paul Denny",
    "abstract": "Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.",
    "citationCount": 205,
    "pdf_filename": "2024_CodeAid__Evaluating_a_Classroom_Deployme_7c04ab29.pdf"
  },
  "2ad26fd9ac2f88ac6705842b665f2f5c12cac108": {
    "paperId": "2ad26fd9ac2f88ac6705842b665f2f5c12cac108",
    "title": "A generalist vision–language foundation model for diverse biomedical tasks",
    "year": 2023,
    "authors": "Kai Zhang, Jun Yu, Zhiling Yan, Yixin Liu, Eashan Adhikarla",
    "abstract": "Traditional biomedical artificial intelligence (AI) models, designed for specific tasks or modalities, often exhibit limited flexibility in real-world deployment and struggle to utilize holistic information. Generalist AI holds the potential to address these limitations due to its versatility in interpreting different data types and generating tailored outputs for diverse needs. However, existing biomedical generalist AI solutions are typically heavyweight and closed source to researchers, practitioners and patients. Here, we describe BiomedGPT, the first open-source and lightweight vision–language foundation model, designed as a generalist capable of performing various biomedical tasks. BiomedGPT achieved state-of-the-art results in 16 out of 25 experiments while maintaining a computing-friendly model scale. We also conducted human evaluations to assess the capabilities of BiomedGPT in radiology visual question answering, report generation and summarization. BiomedGPT exhibits robust prediction ability with a low error rate of 3.8% in question answering, satisfactory performance with an error rate of 8.3% in writing complex radiology reports, and competitive summarization ability with a nearly equivalent preference score to human experts. Our method demonstrates that effective training with diverse data can lead to more practical biomedical AI for improving diagnosis and workflow efficiency. An open-source and computing-friendly vision–language model achieves state-of-the-art accuracy in 16 out of 25 biomedical tasks, with promising performance in a series of potential clinical applications.",
    "citationCount": 277,
    "pdf_filename": "2023_A_generalist_vision_language_foundation__2ad26fd9.pdf"
  },
  "e83a916a661f578350794301f0c4794b32002ad5": {
    "paperId": "e83a916a661f578350794301f0c4794b32002ad5",
    "title": "Students’ Acceptance of ChatGPT in Higher Education: An Extended Unified Theory of Acceptance and Use of Technology",
    "year": 2023,
    "authors": "Artur Strzelecki",
    "abstract": "AI-powered chat technology is an emerging topic worldwide, particularly in areas such as education, research, writing, publishing, and authorship. This study aims to explore the factors driving students' acceptance of ChatGPT in higher education. The study employs the unified theory of acceptance and use of technology (UTAUT2) theoretical model, with an extension of Personal innovativeness, to verify the Behavioral intention and Use behavior of ChatGPT by students. The study uses data from a sample of 503 Polish state university students. The PLS-SEM method is utilized to test the model. Results indicate that Habit has the most significant impact (0.339) on Behavioral intention, followed by Performance expectancy (0.260), and Hedonic motivation (0.187). Behavioral intention has the most significant effect (0.424) on Use behavior, followed by Habit (0.255) and Facilitating conditions (0.188). The model explains 72.8% of the Behavioral intention and 54.7% of the Use behavior variance. While the study is limited by the sample size and selection, it is expected to be a starting point for more research on ChatGPT-like technology in university education, given that this is a recently introduced technology.",
    "citationCount": 240,
    "pdf_filename": "2023_Students__Acceptance_of_ChatGPT_in_Highe_e83a916a.pdf"
  },
  "b05cb5bf173385b1696e219697beb9057bc5c64f": {
    "paperId": "b05cb5bf173385b1696e219697beb9057bc5c64f",
    "title": "Acceptance of artificial intelligence among pre-service teachers: a multigroup analysis",
    "year": 2023,
    "authors": "Chengming Zhang, Jessica Schießl, Lea Plößl, Florian Hofmann, M. Gläser-Zikuda",
    "abstract": "Over the past few years, there has been a significant increase in the utilization of artificial intelligence (AI)-based educational applications in education. As pre-service teachers’ attitudes towards educational technology that utilizes AI have a potential impact on the learning outcomes of their future students, it is essential to know more about pre-service teachers’ acceptance of AI. The aims of this study are (1) to discover what factors determine pre-service teachers’ intentions to utilize AI-based educational applications and (2) to determine whether gender differences exist within determinants that affect those behavioral intentions. A sample of 452 pre-service teachers (325 female) participated in a survey at one German university. Based on a prominent technology acceptance model, structural equation modeling, measurement invariance, and multigroup analysis were carried out. The results demonstrated that eight out of nine hypotheses were supported; perceived ease of use (β = 0.297***) and perceived usefulness (β = 0.501***) were identified as primary factors predicting pre-service teachers’ intention to use AI. Furthermore, the latent mean differences results indicated that two constructs, AI anxiety (z = − 3.217**) and perceived enjoyment (z = 2.556*), were significantly different by gender. In addition, it is noteworthy that the paths from AI anxiety to perceived ease of use (p = 0.018*) and from perceived ease of use to perceived usefulness (p = 0.002**) are moderated by gender. This study confirms the determinants influencing the behavioral intention based on the Technology Acceptance Model 3 of German pre-service teachers to use AI-based applications in education. Furthermore, the results demonstrate how essential it is to address gender-specific aspects in teacher education because there is a high percentage of female pre-service teachers, in general. This study contributes to state of the art in AI-powered education and teacher education.",
    "citationCount": 225,
    "pdf_filename": "2023_Acceptance_of_artificial_intelligence_am_b05cb5bf.pdf"
  },
  "e4bb1b1f97711a7634bf4bff72c56891be2222e6": {
    "paperId": "e4bb1b1f97711a7634bf4bff72c56891be2222e6",
    "title": "Cognitive Architectures for Language Agents",
    "year": 2023,
    "authors": "T. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths",
    "abstract": "Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.",
    "citationCount": 265,
    "pdf_filename": "2023_Cognitive_Architectures_for_Language_Age_e4bb1b1f.pdf"
  },
  "dfbc9f44f0ff3c994eecee83a48cb27dd20c51b0": {
    "paperId": "dfbc9f44f0ff3c994eecee83a48cb27dd20c51b0",
    "title": "Artificial intelligence in intelligent tutoring systems toward sustainable education: a systematic review",
    "year": 2023,
    "authors": "Chien-Chang Lin, Anna Y. Q. Huang, Owen H. T. Lu",
    "abstract": "Sustainable education is a crucial aspect of creating a sustainable future, yet it faces several key challenges, including inadequate infrastructure, limited resources, and a lack of awareness and engagement. Artificial intelligence (AI) has the potential to address these challenges and enhance sustainable education by improving access to quality education, creating personalized learning experiences, and supporting data-driven decision-making. One outcome of using AI and Information Technology (IT) systems in sustainable education is the ability to provide students with personalized learning experiences that cater to their unique learning styles and preferences. Additionally, AI systems can provide teachers with data-driven insights into student performance, emotions, and engagement levels, enabling them to tailor their teaching methods and approaches or provide assistance or intervention accordingly. However, the use of AI and IT systems in sustainable education also presents challenges, including issues related to privacy and data security, as well as potential biases in algorithms and machine learning models. Moreover, the deployment of these systems requires significant investments in technology and infrastructure, which can be a challenge for educators. In this review paper, we will provide different perspectives from educators and information technology solution architects to connect education and AI technology. The discussion areas include sustainable education concepts and challenges, technology coverage and outcomes, as well as future research directions. By addressing these challenges and pursuing further research, we can unlock the full potential of these technologies and support a more equitable and sustainable education system.",
    "citationCount": 280,
    "pdf_filename": "2023_Artificial_intelligence_in_intelligent_t_dfbc9f44.pdf"
  },
  "6d8fb47bf1022a9169875905aec106d8534e3052": {
    "paperId": "6d8fb47bf1022a9169875905aec106d8534e3052",
    "title": "Unveiling Security, Privacy, and Ethical Concerns of ChatGPT",
    "year": 2023,
    "authors": "Xiaodong Wu, R. Duan, Jianbing Ni",
    "abstract": "This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.",
    "citationCount": 273,
    "pdf_filename": "2023_Unveiling_Security__Privacy__and_Ethical_6d8fb47b.pdf"
  },
  "12d7f84baa7ecc258dbfb30914f18678b13dcfbf": {
    "paperId": "12d7f84baa7ecc258dbfb30914f18678b13dcfbf",
    "title": "Analyzing the role of ChatGPT as a writing assistant at higher education level: A systematic review of the literature",
    "year": 2023,
    "authors": "M. Imran, N. Almusharraf",
    "abstract": "This study examines the role of ChatGPT as a writing assistant in academia through a systematic literature review of the 30 most relevant articles. Since its release in November 2022, ChatGPT has become the most debated topic among scholars and is also being used by many users from different fields. Many articles, reviews, blogs, and opinion essays have been published in which the potential role of ChatGPT as a writing assistant is discussed. For this systematic review, 550 articles published six months after ChatGPT’s release (December 2022 to May 2023) were collected based on specific keywords, and the final 30 most relevant articles were finalized through PRISMA flowchart. The analyzed literature identifies different opinions and scenarios associated with using ChatGPT as a writing assistant and how to interact with it. Findings show that artificial intelligence (AI) in education is a part of the ongoing development process, and its latest chatbot, ChatGPT is a part of it. Therefore, the education process, particularly academic writing, has both opportunities and challenges in adopting ChatGPT as a writing assistant. The need is to understand its role as an aid and facilitator for both the learners and instructors, as chatbots are relatively beneficial devices to facilitate, create ease and support the academic process. However, academia should revisit and update students’ and teachers’ training, policies, and assessment ways in writing courses for academic integrity and originality, like plagiarism issues, AI-generated assignments, online/home-based exams, and auto-correction challenges.",
    "citationCount": 272,
    "pdf_filename": "2023_Analyzing_the_role_of_ChatGPT_as_a_writi_12d7f84b.pdf"
  },
  "22e2f488ecd88bd2adf79092d0d390d8f7b06a0f": {
    "paperId": "22e2f488ecd88bd2adf79092d0d390d8f7b06a0f",
    "title": "Auditing large language models: a three-layered approach",
    "year": 2023,
    "authors": "Jakob Mokander, Jonas Schuett, Hannah Rose Kirk, Luciano Floridi",
    "abstract": "Large language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",
    "citationCount": 259,
    "pdf_filename": "2023_Auditing_large_language_models__a_three__22e2f488.pdf"
  },
  "7d46a13a1edd02dd6ae2b9f713e6f91ea001dfb4": {
    "paperId": "7d46a13a1edd02dd6ae2b9f713e6f91ea001dfb4",
    "title": "When large language models meet personalization: perspectives of challenges and opportunities",
    "year": 2023,
    "authors": "Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu",
    "abstract": "The advent of large language models marks a revolutionary breakthrough in artificial intelligence. With the unprecedented scale of training and model parameters, the capability of large language models has been dramatically improved, leading to human-like performances in understanding, language synthesizing, common-sense reasoning, etc. Such a major leap forward in general AI capacity will fundamentally change the pattern of how personalization is conducted. For one thing, it will reform the way of interaction between humans and personalization systems. Instead of being a passive medium of information filtering, like conventional recommender systems and search engines, large language models present the foundation for active user engagement. On top of such a new foundation, users’ requests can be proactively explored, and users’ required information can be delivered in a natural, interactable, and explainable way. For another thing, it will also considerably expand the scope of personalization, making it grow from the sole function of collecting personalized information to the compound function of providing personalized services. By leveraging large language models as a general-purpose interface, the personalization systems may compile user’s requests into plans, calls the functions of external tools (e.g., search engines, calculators, service APIs, etc.) to execute the plans, and integrate the tools’ outputs to complete the end-to-end personalization tasks. Today, large language models are still being rapidly developed, whereas the application in personalization is largely unexplored. Therefore, we consider it to be right the time to review the challenges in personalization and the opportunities to address them with large language models. In particular, we dedicate this perspective paper to the discussion of the following aspects: the development and challenges for the existing personalization system, the newly emerged capabilities of large language models, and the potential ways of making use of large language models for personalization.",
    "citationCount": 227,
    "pdf_filename": "2023_When_large_language_models_meet_personal_7d46a13a.pdf"
  },
  "f80e7b5baa6adf0cd5dddb5ba973fed9d8a216cf": {
    "paperId": "f80e7b5baa6adf0cd5dddb5ba973fed9d8a216cf",
    "title": "Artificial Intelligence-Enabled Intelligent Assistant for Personalized and Adaptive Learning in Higher Education",
    "year": 2023,
    "authors": "Ramteja Sajja, Y. Sermet, Muhammed Cikmaz, David Cwiertny, Ibrahim Demir",
    "abstract": "This paper presents a novel framework, artificial intelligence-enabled intelligent assistant (AIIA), for personalized and adaptive learning in higher education. The AIIA system leverages advanced AI and natural language processing (NLP) techniques to create an interactive and engaging learning platform. This platform is engineered to reduce cognitive load on learners by providing easy access to information, facilitating knowledge assessment, and delivering personalized learning support tailored to individual needs and learning styles. The AIIA’s capabilities include understanding and responding to student inquiries, generating quizzes and flashcards, and offering personalized learning pathways. The research findings have the potential to significantly impact the design, implementation, and evaluation of AI-enabled virtual teaching assistants (VTAs) in higher education, informing the development of innovative educational tools that can enhance student learning outcomes, engagement, and satisfaction. The paper presents the methodology, system architecture, intelligent services, and integration with learning management systems (LMSs) while discussing the challenges, limitations, and future directions for the development of AI-enabled intelligent assistants in education.",
    "citationCount": 270,
    "pdf_filename": "2023_Artificial_Intelligence_Enabled_Intellig_f80e7b5b.pdf"
  },
  "f001698aeaa910e04b659f813dfc71dbc5c92655": {
    "paperId": "f001698aeaa910e04b659f813dfc71dbc5c92655",
    "title": "Managing the Strategic Transformation of Higher Education through Artificial Intelligence",
    "year": 2023,
    "authors": "Babu George, Ontario Wooden",
    "abstract": "Considering the rapid advancements in artificial intelligence (AI) and their potential implications for the higher education sector, this article seeks to critically evaluate the strategic adoption of AI in the framework of “smart universities”. We envisage these innovative institutions as the imminent evolution in higher education, harnessing AI and quantum technologies to reshape academic and administrative processes. The core presumption is that through such integration, universities can achieve personalized learning trajectories, enhanced accessibility, economic efficiency, and a boost in overall operational performance. However, venturing into this new educational paradigm necessitates a thorough exploration of potential pitfalls, including questions surrounding educational quality, potential job losses, risks of bias, privacy breaches, and safety concerns. Our primary objective is to offer a balanced assessment to aid stakeholders in making informed strategic decisions about endorsing and advancing the smart university model. A pivotal factor in this discourse is the acceptance of qualifications from AI-enriched institutions by employers, a variable that may drastically redefine the education sector’s trajectory. Within the context of a comprehensive analysis of its broader societal impact, this article also delves into the ramifications of AI-driven innovations for historically Black colleges and universities (HBCUs).",
    "citationCount": 261,
    "pdf_filename": "2023_Managing_the_Strategic_Transformation_of_f001698a.pdf"
  },
  "3bbb397ea3b09a10de198f167fba045da680b4e8": {
    "paperId": "3bbb397ea3b09a10de198f167fba045da680b4e8",
    "title": "The Utility of ChatGPT as an Example of Large Language Models in Healthcare Education, Research and Practice: Systematic Review on the Future Perspectives and Potential Limitations",
    "year": 2023,
    "authors": "Malik Sallam, Affiliations",
    "abstract": "An artificial intelligence (AI)-based conversational large language model (LLM) was launched in November 2022 namely, ChatGPT. Despite the wide array of potential applications of LLMs in healthcare education, research and practice, several valid concerns were raised. The current systematic review aimed to investigate the possible utility of ChatGPT and to highlight its limitations in healthcare education, research and practice. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar under the term ChatGPT. Eligibility criteria included the published research or preprints of any type that discussed ChatGPT in the context of healthcare education, research and practice. A total of 280 records were identified, and following full screening, a total of 60 records were eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records with the most common being the utility in scientific writing followed by benefits in healthcare research (efficient analysis of massive datasets, code generation and rapid concise literature reviews besides utility in drug discovery and development). Benefits in healthcare practice included cost saving, documentation, personalized medicine and improved health literacy. Concerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most common being the ethical issues including the risk of bias, plagiarism, copyright issues, transparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and inaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm shifts in healthcare education, research and practice, the embrace of this application should be done with extreme caution. Specific applications of ChatGPT in health education include the promising utility in personalized learning tools and shift towards more focus on critical thinking and problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining the workflow and refining personalized medicine. Saving time for the focus on experimental design and enhancing research equity and versatility are the benefits in scientific research. Regarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be listed as an author unless the ICMJE/COPE guidelines are revised and amended. An initiative involving all stakeholders involved in healthcare education, research and practice is urgently needed to set a code of ethics and conduct on the responsible practices involving ChatGPT among other LLMs.",
    "citationCount": 236,
    "pdf_filename": "2023_The_Utility_of_ChatGPT_as_an_Example_of__3bbb397e.pdf"
  },
  "e142df3d8f442048748b57dd7c2ba4e34a532736": {
    "paperId": "e142df3d8f442048748b57dd7c2ba4e34a532736",
    "title": "Exploring the potential of artificial intelligence tools in educational measurement and assessment",
    "year": 2023,
    "authors": "Valentine Joseph Owan, Kinsgley Bekom Abang, D. Idika, Eugene Onor Etta, B. Bassey",
    "abstract": "Artificial intelligence (AI) is transforming various industries, and education is no exception. Rapid advancements in AI technology have become essential for educators and educational assessment professionals to enhance teaching and learning experiences. AI-powered educational assessment tools provide numerous benefits, including improving the accuracy and efficiency of assessments, generating personalized feedback for students, and enabling teachers to adapt their teaching strategies to meet the unique needs of each student. Therefore, AI has the potential to revolutionize the way education is delivered and assessed, ultimately leading to better educational outcomes for students. This paper explores the various applications of AI tools in educational measurement and assessment. Specifically, it discusses the integration of large language AI models in classroom assessment, in specific areas such as test purpose determination and specification, developing, test blueprint, test item generation/development, preparation of test instructions, item assembly/selection, test administration, test scoring, interpretation of test results, test analysis/appraisal, and reporting. It analyses the role of teachers in AI-based assessment and the challenges of using AI-powered tools in educational assessment. Finally, the paper presents strategies to address these challenges and enhance the effectiveness of AI in educational assessment. In conclusion, using AI in educational assessment has benefits and limitations. As such, educators, policymakers, and stakeholders must work together to develop strategies that maximize the benefits of AI in educational assessment while mitigating the associated risks. The application of AI in educational assessment can ultimately transform education, improve learning outcomes, and equip students with the skills needed to succeed in the 21st century.",
    "citationCount": 220,
    "pdf_filename": "2023_Exploring_the_potential_of_artificial_in_e142df3d.pdf"
  },
  "378236591fc05e79204fd904e9f864efa31cdc74": {
    "paperId": "378236591fc05e79204fd904e9f864efa31cdc74",
    "title": "An Overview of Artificial Intelligence Ethics",
    "year": 2023,
    "authors": "Changwu Huang, Zeqi Zhang, Bifei Mao, X. Yao",
    "abstract": "Artificial intelligence (AI) has profoundly changed and will continue to change our lives. AI is being applied in more and more fields and scenarios such as autonomous driving, medical care, media, finance, industrial robots, and internet services. The widespread application of AI and its deep integration with the economy and society have improved efficiency and produced benefits. At the same time, it will inevitably impact the existing social order and raise ethical concerns. Ethical issues, such as privacy leakage, discrimination, unemployment, and security risks, brought about by AI systems have caused great trouble to people. Therefore, AI ethics, which is a field related to the study of ethical issues in AI, has become not only an important research topic in academia, but also an important topic of common concern for individuals, organizations, countries, and society. This article will give a comprehensive overview of this field by summarizing and analyzing the ethical risks and issues raised by AI, ethical guidelines and principles issued by different organizations, approaches for addressing ethical issues in AI, and methods for evaluating the ethics of AI. Additionally, challenges in implementing ethics in AI and some future perspectives are pointed out. We hope our work will provide a systematic and comprehensive overview of AI ethics for researchers and practitioners in this field, especially the beginners of this research discipline.",
    "citationCount": 216,
    "pdf_filename": "2023_An_Overview_of_Artificial_Intelligence_E_37823659.pdf"
  },
  "3fb9c55559ba7595166b1f6d8ed2483b9f07877b": {
    "paperId": "3fb9c55559ba7595166b1f6d8ed2483b9f07877b",
    "title": "A critical evaluation, challenges, and future perspectives of using artificial intelligence and emerging technologies in smart classrooms",
    "year": 2023,
    "authors": "E. Dimitriadou, A. Lanitis",
    "abstract": "The term \"Smart Classroom\" has evolved over time and nowadays reflects the technological advancements incorporated in educational spaces. The rapid advances in technology, and the need to create more efficient and creative classes that support both in-class and remote activities, have led to the integration of Artificial Intelligence and smart technologies in smart classes. In this paper we discuss the concept of Artificial Intelligence in Education and present a literature review related to smart classroom technology, with an emphasis on emerging technologies such as AI-related technologies. As part of this survey key technologies related to smart classes used for effective class management that enhance the convenience of classroom environments, the use of different types of smart teaching aids during the educational process and the use of automated performance assessment technologies are presented. Apart from discussing a variety of technological accomplishments in each of the aforementioned areas, the role of AI is discussed, allowing the readers to comprehend the importance of AI in key technologies related to smart classes. Furthermore, through a SWOT analysis, the Strengths, Weaknesses, Opportunities, and Threats of adopting AI in smart classes are presented, while the future perspectives and challenges in utilizing AI-based techniques in smart classes are discussed. This survey targets educators and AI professionals so that the former get informed about the potential, and limitations of AI in education, while the latter can get inspiration from the challenges and peculiarities of educational AI-based systems.",
    "citationCount": 218,
    "pdf_filename": "2023_A_critical_evaluation__challenges__and_f_3fb9c555.pdf"
  },
  "bf3010f74f6ae6379b3dcc15d3bd1d6fb210f439": {
    "paperId": "bf3010f74f6ae6379b3dcc15d3bd1d6fb210f439",
    "title": "An Exploratory Study of EFL Learners’ Use of ChatGPT for Language Learning Tasks: Experience and Perceptions",
    "year": 2023,
    "authors": "Yangyu Xiao, Yuying Zhi",
    "abstract": "ChatGPT, a general-purpose intelligent chatbot developed by OpenAI, has introduced numerous opportunities and challenges in the field of language education. With its remarkable ability to generate diverse forms of text, answer questions, and provide translations within minutes, ChatGPT has become an influential tool in the era of advanced AI technology. However, to what extent ChatGPT can be used to assist students in completing language learning tasks remains largely unexplored. Against this background, this study aimed to investigate students’ experiences with ChatGPT and their perceptions of its role in language learning through a small-scale qualitative study. The data were collected through semi-structured interviews with five students at a top-tier international university in China. Students’ responses revealed that ChatGPT has the potential to serve as a valuable learning partner and aid students in completing language-related tasks. Furthermore, participants exhibited critical judgment in evaluating the quality of ideas and outputs generated by ChatGPT, as well as the ability to modify prompts to maximize learning benefits. Such critical judgment offsets the potential threats to academic integrity posed by ChatGPT. Our findings contribute to the understanding of the potential of ChatGPT in language education by adding empirical evidence from students’ perspectives. This study supports the idea that ChatGPT can work as an effective tool for providing students with immediate feedback and personalized learning experiences. Such findings generate implications for future pedagogical practices in the new era by providing students with personalized guidance, designing technology-embedded language support, and developing students’ lifelong learning skills (e.g., autonomy and evaluative judgment) with the support of ChatGPT.",
    "citationCount": 207,
    "pdf_filename": "2023_An_Exploratory_Study_of_EFL_Learners__Us_bf3010f7.pdf"
  },
  "c1014f86c8d801c93b37eed58311da5f9c9da2e4": {
    "paperId": "c1014f86c8d801c93b37eed58311da5f9c9da2e4",
    "title": "ChatGPT and Software Testing Education: Promises & Perils",
    "year": 2023,
    "authors": "Sajed Jalil, Suzzana Rafi, Thomas D. Latoza, Kevin Moran, Wing Lam",
    "abstract": "Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose \"large language models\", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.",
    "citationCount": 202,
    "pdf_filename": "2023_ChatGPT_and_Software_Testing_Education___c1014f86.pdf"
  },
  "3aa22ac9e265cfb5158ad8b0b9e584e50504585e": {
    "paperId": "3aa22ac9e265cfb5158ad8b0b9e584e50504585e",
    "title": "The Political Biases of ChatGPT",
    "year": 2023,
    "authors": "David Rozado",
    "abstract": "Recent advancements in Large Language Models (LLMs) suggest imminent commercial applications of such AI systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular ChatGPT from OpenAI. The results are consistent across tests; 14 of the 15 instruments diagnose ChatGPT answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, ChatGPT often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical AI systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.",
    "citationCount": 207,
    "pdf_filename": "2023_The_Political_Biases_of_ChatGPT_3aa22ac9.pdf"
  },
  "f6e893b3e2ee7a62c2fe8a3b0e33920c3e596969": {
    "paperId": "f6e893b3e2ee7a62c2fe8a3b0e33920c3e596969",
    "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents",
    "year": 2023,
    "authors": "Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu",
    "abstract": "Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completion rate than humans and struggles to exhibit social commonsense reasoning and strategic communication skills. These findings demonstrate SOTOPIA's promise as a general platform for research on evaluating and improving social intelligence in artificial agents.",
    "citationCount": 214,
    "pdf_filename": "2023_SOTOPIA__Interactive_Evaluation_for_Soci_f6e893b3.pdf"
  },
  "2c4e1a6853eb92fdf9d4b80db661e83bd69adc6c": {
    "paperId": "2c4e1a6853eb92fdf9d4b80db661e83bd69adc6c",
    "title": "Accountability in artificial intelligence: what it is and how it works",
    "year": 2023,
    "authors": "Claudio Novelli, M. Taddeo, Luciano Floridi",
    "abstract": "Accountability is a cornerstone of the governance of artificial intelligence (AI). However, it is often defined too imprecisely because its multifaceted nature and the sociotechnical structure of AI systems imply a variety of values, practices, and measures to which accountability in AI can refer. We address this lack of clarity by defining accountability in terms of answerability, identifying three conditions of possibility (authority recognition, interrogation, and limitation of power), and an architecture of seven features (context, range, agent, forum, standards, process, and implications). We analyze this architecture through four accountability goals (compliance, report, oversight, and enforcement). We argue that these goals are often complementary and that policy-makers emphasize or prioritize some over others depending on the proactive or reactive use of accountability and the missions of AI governance.",
    "citationCount": 214,
    "pdf_filename": "2023_Accountability_in_artificial_intelligenc_2c4e1a68.pdf"
  },
  "9c3ceae3cf605f934cc5f04a44feae23b5252faa": {
    "paperId": "9c3ceae3cf605f934cc5f04a44feae23b5252faa",
    "title": "Diffusion-GAN: Training GANs with Diffusion",
    "year": 2022,
    "authors": "Zhendong Wang, Huangjie Zheng, Pengcheng He, Weizhu Chen, Mingyuan Zhou",
    "abstract": "Generative adversarial networks (GANs) are challenging to train stably, and a promising remedy of injecting instance noise into the discriminator input has not been very effective in practice. In this paper, we propose Diffusion-GAN, a novel GAN framework that leverages a forward diffusion chain to generate Gaussian-mixture distributed instance noise. Diffusion-GAN consists of three components, including an adaptive diffusion process, a diffusion timestep-dependent discriminator, and a generator. Both the observed and generated data are diffused by the same adaptive diffusion process. At each diffusion timestep, there is a different noise-to-data ratio and the timestep-dependent discriminator learns to distinguish the diffused real data from the diffused generated data. The generator learns from the discriminator's feedback by backpropagating through the forward diffusion chain, whose length is adaptively adjusted to balance the noise and data levels. We theoretically show that the discriminator's timestep-dependent strategy gives consistent and helpful guidance to the generator, enabling it to match the true data distribution. We demonstrate the advantages of Diffusion-GAN over strong GAN baselines on various datasets, showing that it can produce more realistic images with higher stability and data efficiency than state-of-the-art GANs.",
    "citationCount": 288,
    "pdf_filename": "2022_Diffusion_GAN__Training_GANs_with_Diffus_9c3ceae3.pdf"
  },
  "e04da3c945aae8e2211222d373e7bf771d6412a7": {
    "paperId": "e04da3c945aae8e2211222d373e7bf771d6412a7",
    "title": "Emu: Enhancing Image Generation Models Using Photogenic Needles in a Haystack",
    "year": 2023,
    "authors": "Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam S. Tsai, Jialiang Wang",
    "abstract": "Training text-to-image models with web scale image-text pairs enables the generation of a wide range of visual concepts from text. However, these pre-trained models often face challenges when it comes to generating highly aesthetic images. This creates the need for aesthetic alignment post pre-training. In this paper, we propose quality-tuning to effectively guide a pre-trained model to exclusively generate highly visually appealing images, while maintaining generality across visual concepts. Our key insight is that supervised fine-tuning with a set of surprisingly small but extremely visually appealing images can significantly improve the generation quality. We pre-train a latent diffusion model on $1.1$ billion image-text pairs and fine-tune it with only a few thousand carefully selected high-quality images. The resulting model, Emu, achieves a win rate of $82.9\\%$ compared with its pre-trained only counterpart. Compared to the state-of-the-art SDXLv1.0, Emu is preferred $68.4\\%$ and $71.3\\%$ of the time on visual appeal on the standard PartiPrompts and our Open User Input benchmark based on the real-world usage of text-to-image models. In addition, we show that quality-tuning is a generic approach that is also effective for other architectures, including pixel diffusion and masked generative transformer models.",
    "citationCount": 263,
    "pdf_filename": "2023_Emu__Enhancing_Image_Generation_Models_U_e04da3c9.pdf"
  },
  "ecd7332cd3d34220a8cf01c30385da123c61dff0": {
    "paperId": "ecd7332cd3d34220a8cf01c30385da123c61dff0",
    "title": "Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets",
    "year": 2022,
    "authors": "Xingang Peng, Shitong Luo, Jiaqi Guan, Qi Xie, Jian Peng",
    "abstract": "Deep generative models have achieved tremendous success in designing novel drug molecules in recent years. A new thread of works have shown the great potential in advancing the specificity and success rate of in silico drug design by considering the structure of protein pockets. This setting posts fundamental computational challenges in sampling new chemical compounds that could satisfy multiple geometrical constraints imposed by pockets. Previous sampling algorithms either sample in the graph space or only consider the 3D coordinates of atoms while ignoring other detailed chemical structures such as bond types and functional groups. To address the challenge, we develop Pocket2Mol, an E(3)-equivariant generative network composed of two modules: 1) a new graph neural network capturing both spatial and bonding relationships between atoms of the binding pockets and 2) a new efficient algorithm which samples new drug candidates conditioned on the pocket representations from a tractable distribution without relying on MCMC. Experimental results demonstrate that molecules sampled from Pocket2Mol achieve significantly better binding affinity and other drug properties such as druglikeness and synthetic accessibility.",
    "citationCount": 254,
    "pdf_filename": "2022_Pocket2Mol__Efficient_Molecular_Sampling_ecd7332c.pdf"
  },
  "53661ff6fdbfb8557c5b19895fad151792c62da7": {
    "paperId": "53661ff6fdbfb8557c5b19895fad151792c62da7",
    "title": "Few-shot training LLMs for project-specific code-summarization",
    "year": 2022,
    "authors": "Toufique Ahmed, Prem Devanbu",
    "abstract": "Very large language models (LLMs), such as GPT-3 and Codex have achieved state-of-the-art performance on several natural-language tasks, and show great promise also for code. A particularly exciting aspect of LLMs is their knack for few-shot and zero-shot learning: they can learn to perform a task with very few examples. Few-shotting has particular synergies in software engineering, where there are a lot of phenomena (identifier names, APIs, terminology, coding patterns) that are known to be highly project-specific. However, project-specific data can be quite limited, especially early in the history of a project; thus the few-shot learning capacity of LLMs might be very relevant. In this paper, we investigate the use few-shot training with the very large GPT (Generative Pre-trained Transformer) Codex model, and find evidence suggesting that one can significantly surpass state-of-the-art models for code-summarization, leveraging project-specific training.",
    "citationCount": 294,
    "pdf_filename": "2022_Few_shot_training_LLMs_for_project_speci_53661ff6.pdf"
  },
  "c7492913370b5726eaa6ced163a60de6c9d4bb7f": {
    "paperId": "c7492913370b5726eaa6ced163a60de6c9d4bb7f",
    "title": "A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics",
    "year": 2023,
    "authors": "Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan",
    "abstract": "The utilization of large language models (LLMs) in the Healthcare domain has generated both excitement and concern due to their ability to effectively respond to freetext queries with certain professional knowledge. This survey outlines the capabilities of the currently developed LLMs for Healthcare and explicates their development process, with the aim of providing an overview of the development roadmap from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, as well as comparing various LLMs with each other. Then we summarize related Healthcare training data, training methods, optimization strategies, and usage. Finally, the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics. Our survey provide a comprehensive investigation from perspectives of both computer science and Healthcare specialty. Besides the discussion about Healthcare concerns, we supports the computer science community by compiling a collection of open source resources, such as accessible datasets, the latest methodologies, code implementations, and evaluation benchmarks in the Github. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well as a shift from model-centered methodologies to data-centered methodologies. Also, we determine that the biggest obstacle of using LLMs in Healthcare are fairness, accountability, transparency and ethics.",
    "citationCount": 253,
    "pdf_filename": "2023_A_Survey_of_Large_Language_Models_for_He_c7492913.pdf"
  },
  "45b0f30ee83f324ccdffd608818ffb2d50de4a8f": {
    "paperId": "45b0f30ee83f324ccdffd608818ffb2d50de4a8f",
    "title": "Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory",
    "year": 2022,
    "authors": "Lian Siyao, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang",
    "abstract": "Driving 3D characters to dance following a piece of music is highly challenging due to the spatial constraints applied to poses by choreography norms. In addition, the generated dance sequence also needs to maintain temporal coherency with different music genres. To tackle these challenges, we propose a novel music-to-dance framework, Bailando, with two powerful components: 1) a choreographic memory that learns to summarize meaningful dancing units from 3D pose sequence to a quantized codebook, 2) an actor-critic Generative Pre-trained Transformer (GPT) that composes these units to a fluent dance coherent to the music. With the learned choreographic memory, dance generation is realized on the quantized units that meet high choreography standards, such that the generated dancing sequences are confined within the spatial constraints. To achieve synchronized alignment between diverse motion tempos and music beats, we introduce an actor-critic-based reinforcement learning scheme to the GPT with a newly-designed beat-align reward function. Extensive experiments on the standard benchmark demonstrate that our proposed framework achieves state-of-the-art performance both qualitatively and quantitatively. Notably, the learned choreographic memory is shown to discover human-interpretable dancing-style poses in an unsupervised manner. Code and video demo are available at https://github.com/lisiyao21/Bailando/",
    "citationCount": 241,
    "pdf_filename": "2022_Bailando__3D_Dance_Generation_by_Actor_C_45b0f30e.pdf"
  },
  "b4ece600c6dadd41b0b38d8359ce8e5b544305a9": {
    "paperId": "b4ece600c6dadd41b0b38d8359ce8e5b544305a9",
    "title": "SparseFusion: Distilling View-Conditioned Diffusion for 3D Reconstruction",
    "year": 2022,
    "authors": "Zhizhuo Zhou, Shubham Tulsiani",
    "abstract": "We propose SparseFusion, a sparse view 3D reconstruction approach that unifies recent advances in neural rendering and probabilistic image generation. Existing approaches typically build on neural rendering with reprojected features but fail to generate unseen regions or handle uncertainty under large viewpoint changes. Alternate methods treat this as a (probabilistic) 2D synthesis task, and while they can generate plausible 2D images, they do not infer a consistent underlying 3D. However, we find that this trade-off between 3D consistency and probabilistic image generation does not need to exist. In fact, we show that geometric consistency and generative inference can be complementary in a mode-seeking behavior. By distilling a 3D consistent scene representation from a view-conditioned latent diffusion model, we are able to recover a plausible 3D representation whose renderings are both accurate and realistic. We evaluate our approach across 51 categories in the CO3D dataset and show that it outperforms existing methods, in both distortion and perception metrics, for sparse-view novel view synthesis.",
    "citationCount": 252,
    "pdf_filename": "2022_SparseFusion__Distilling_View_Conditione_b4ece600.pdf"
  },
  "c17a983b11381fabb53f28066f76d4b2dc5a6a17": {
    "paperId": "c17a983b11381fabb53f28066f76d4b2dc5a6a17",
    "title": "FLAME: Free-form Language-based Motion Synthesis & Editing",
    "year": 2022,
    "authors": "Jihoon Kim, Jiseob Kim, Sungjoon Choi",
    "abstract": "Text-based motion generation models are drawing a surge of interest for their potential for automating the motion-making process in the game, animation, or robot industries. In this paper, we propose a diffusion-based motion synthesis and editing model named FLAME. Inspired by the recent successes in diffusion models, we integrate diffusion-based generative models into the motion domain. FLAME can generate high-fidelity motions well aligned with the given text. Also, it can edit the parts of the motion, both frame-wise and joint-wise, without any fine-tuning. FLAME involves a new transformer-based architecture we devise to better handle motion data, which is found to be crucial to manage variable-length motions and well attend to free-form text. In experiments, we show that FLAME achieves state-of-the-art generation performances on three text-motion datasets: HumanML3D, BABEL, and KIT. We also demonstrate that FLAME’s editing capability can be extended to other tasks such as motion prediction or motion in-betweening, which have been previously covered by dedicated models.",
    "citationCount": 246,
    "pdf_filename": "2022_FLAME__Free_form_Language_based_Motion_S_c17a983b.pdf"
  },
  "ef7993ab30d0a8afabb4ebab080e471c0d5c743c": {
    "paperId": "ef7993ab30d0a8afabb4ebab080e471c0d5c743c",
    "title": "Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models",
    "year": 2022,
    "authors": "Juan Miguel Lopez Alcaraz, N. Strodthoff",
    "abstract": "The imputation of missing values represents a significant obstacle for many real-world data analysis pipelines. Here, we focus on time series data and put forward SSSD, an imputation model that relies on two emerging technologies, (conditional) diffusion models as state-of-the-art generative models and structured state space models as internal model architecture, which are particularly suited to capture long-term dependencies in time series data. We demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic imputation and forecasting performance on a broad range of data sets and different missingness scenarios, including the challenging blackout-missing scenarios, where prior approaches failed to provide meaningful results.",
    "citationCount": 225,
    "pdf_filename": "2022_Diffusion_based_Time_Series_Imputation_a_ef7993ab.pdf"
  },
  "ec1ac8df419a241c3cc6bfd209a38b494af792ee": {
    "paperId": "ec1ac8df419a241c3cc6bfd209a38b494af792ee",
    "title": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
    "year": 2022,
    "authors": "Wenhu Chen, Hexiang Hu, Chitwan Saharia, William W. Cohen",
    "abstract": "Research on text-to-image generation has witnessed significant progress in generating diverse and photo-realistic images, driven by diffusion and auto-regressive models trained on large-scale image-text data. Though state-of-the-art models can generate high-quality images of common entities, they often have difficulty generating images of uncommon entities, such as `Chortai (dog)' or `Picarones (food)'. To tackle this issue, we present the Retrieval-Augmented Text-to-Image Generator (Re-Imagen), a generative model that uses retrieved information to produce high-fidelity and faithful images, even for rare or unseen entities. Given a text prompt, Re-Imagen accesses an external multi-modal knowledge base to retrieve relevant (image, text) pairs and uses them as references to generate the image. With this retrieval step, Re-Imagen is augmented with the knowledge of high-level semantics and low-level visual details of the mentioned entities, and thus improves its accuracy in generating the entities' visual appearances. We train Re-Imagen on a constructed dataset containing (image, text, retrieval) triples to teach the model to ground on both text prompt and retrieval. Furthermore, we develop a new sampling strategy to interleave the classifier-free guidance for text and retrieval conditions to balance the text and retrieval alignment. Re-Imagen achieves significant gain on FID score over COCO and WikiImage. To further evaluate the capabilities of the model, we introduce EntityDrawBench, a new benchmark that evaluates image generation for diverse entities, from frequent to rare, across multiple object categories including dogs, foods, landmarks, birds, and characters. Human evaluation on EntityDrawBench shows that Re-Imagen can significantly improve the fidelity of generated images, especially on less frequent entities.",
    "citationCount": 224,
    "pdf_filename": "2022_Re_Imagen__Retrieval_Augmented_Text_to_I_ec1ac8df.pdf"
  },
  "7e839c2667479d91e21e84583c27257dc7dc1a36": {
    "paperId": "7e839c2667479d91e21e84583c27257dc7dc1a36",
    "title": "Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality",
    "year": 2022,
    "authors": "Daniel Watson, William Chan, Jonathan Ho, Mohammad Norouzi",
    "abstract": "Diffusion models have emerged as an expressive family of generative models rivaling GANs in sample quality and autoregressive models in likelihood scores. Standard diffusion models typically require hundreds of forward passes through the model to generate a single high-fidelity sample. We introduce Differentiable Diffusion Sampler Search (DDSS): a method that optimizes fast samplers for any pre-trained diffusion model by differentiating through sample quality scores. We also present Generalized Gaussian Diffusion Models (GGDM), a family of flexible non-Markovian samplers for diffusion models. We show that optimizing the degrees of freedom of GGDM samplers by maximizing sample quality scores via gradient descent leads to improved sample quality. Our optimization procedure backpropagates through the sampling process using the reparametrization trick and gradient rematerialization. DDSS achieves strong results on unconditional image generation across various datasets (e.g., FID scores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82 with 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines). Our method is compatible with any pre-trained diffusion model without fine-tuning or re-training required.",
    "citationCount": 210,
    "pdf_filename": "2022_Learning_Fast_Samplers_for_Diffusion_Mod_7e839c26.pdf"
  },
  "f2209eb5ac6747319a29b87dedabb97770be3243": {
    "paperId": "f2209eb5ac6747319a29b87dedabb97770be3243",
    "title": "Can large language models provide useful feedback on research papers? A large-scale empirical analysis",
    "year": 2023,
    "authors": "Weixin Liang, Yuhui Zhang, Hancheng Cao, Binglu Wang, Daisy Ding",
    "abstract": "Expert feedback lays the foundation of rigorous research. However, the rapid growth of scholarly production and intricate knowledge specialization challenge the conventional scientific feedback mechanisms. High-quality peer reviews are increasingly difficult to obtain. Researchers who are more junior or from under-resourced settings have especially hard times getting timely feedback. With the breakthrough of large language models (LLM) such as GPT-4, there is growing interest in using LLMs to generate scientific feedback on research manuscripts. However, the utility of LLM-generated feedback has not been systematically studied. To address this gap, we created an automated pipeline using GPT-4 to provide comments on the full PDFs of scientific papers. We evaluated the quality of GPT-4's feedback through two large-scale studies. We first quantitatively compared GPT-4's generated feedback with human peer reviewer feedback in 15 Nature family journals (3,096 papers in total) and the ICLR machine learning conference (1,709 papers). The overlap in the points raised by GPT-4 and by human reviewers (average overlap 30.85% for Nature journals, 39.23% for ICLR) is comparable to the overlap between two human reviewers (average overlap 28.58% for Nature journals, 35.25% for ICLR). The overlap between GPT-4 and human reviewers is larger for the weaker papers. We then conducted a prospective user study with 308 researchers from 110 US institutions in the field of AI and computational biology to understand how researchers perceive feedback generated by our GPT-4 system on their own papers. Overall, more than half (57.4%) of the users found GPT-4 generated feedback helpful/very helpful and 82.4% found it more beneficial than feedback from at least some human reviewers. While our findings show that LLM-generated feedback can help researchers, we also identify several limitations.",
    "citationCount": 216,
    "pdf_filename": "2023_Can_large_language_models_provide_useful_f2209eb5.pdf"
  },
  "2287fa32ca9dda5f0c4c02728ca988c80c6d131d": {
    "paperId": "2287fa32ca9dda5f0c4c02728ca988c80c6d131d",
    "title": "Data Augmentation techniques in time series domain: a survey and taxonomy",
    "year": 2022,
    "authors": "G. Iglesias, Edgar Talavera, Ángel González-Prieto, Alberto Mozo, Sandra Gómez-Canaval",
    "abstract": "With the latest advances in deep learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using data augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state of the art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.",
    "citationCount": 233,
    "pdf_filename": "2022_Data_Augmentation_techniques_in_time_ser_2287fa32.pdf"
  },
  "0bfc05adcddd4fe5d1335d96cc313c41526d4558": {
    "paperId": "0bfc05adcddd4fe5d1335d96cc313c41526d4558",
    "title": "Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT",
    "year": 2022,
    "authors": "Thilo Hagendorff, Sarah Fabi, Michal Kosinski",
    "abstract": "We design a battery of semantic illusions and cognitive reflection tests, aimed to elicit intuitive yet erroneous responses. We administer these tasks, traditionally used to study reasoning and decision-making in humans, to OpenAI’s generative pre-trained transformer model family. The results show that as the models expand in size and linguistic proficiency they increasingly display human-like intuitive system 1 thinking and associated cognitive errors. This pattern shifts notably with the introduction of ChatGPT models, which tend to respond correctly, avoiding the traps embedded in the tasks. Both ChatGPT-3.5 and 4 utilize the input–output context window to engage in chain-of-thought reasoning, reminiscent of how people use notepads to support their system 2 thinking. Yet, they remain accurate even when prevented from engaging in chain-of-thought reasoning, indicating that their system-1-like next-word generation processes are more accurate than those of older models. Our findings highlight the value of applying psychological methodologies to study large language models, as this can uncover previously undetected emergent characteristics. The reasoning capabilities of OpenAI’s generative pre-trained transformer family were tested using semantic illusions and cognitive reflection tests that are typically used in human studies. While early models were prone to human-like cognitive errors, ChatGPT decisively outperformed humans, avoiding the cognitive traps embedded in the tasks.",
    "citationCount": 207,
    "pdf_filename": "2022_Human_like_intuitive_behavior_and_reason_0bfc05ad.pdf"
  },
  "59a1daf15ec80eb98f2a1fd29497021e6629f969": {
    "paperId": "59a1daf15ec80eb98f2a1fd29497021e6629f969",
    "title": "FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis",
    "year": 2022,
    "authors": "Rongjie Huang, Max W. Y. Lam, J. Wang, Dan Su, Dong Yu",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) have recently achieved leading performances in many generative tasks. However, the inherited iterative sampling process costs hindered their applications to speech synthesis. This paper proposes FastDiff, a fast conditional diffusion model for high-quality speech synthesis. FastDiff employs a stack of time-aware location-variable convolutions of diverse receptive field patterns to efficiently model long-term time dependencies with adaptive conditions. A noise schedule predictor is also adopted to reduce the sampling steps without sacrificing the generation quality. Based on FastDiff, we design an end-to-end text-to-speech synthesizer, FastDiff-TTS, which generates high-fidelity speech waveforms without any intermediate feature (e.g., Mel-spectrogram). Our evaluation of FastDiff demonstrates the state-of-the-art results with higher-quality (MOS 4.28) speech samples. Also, FastDiff enables a sampling speed of 58x faster than real-time on a V100 GPU, making diffusion models practically applicable to speech synthesis deployment for the first time. We further show that FastDiff generalized well to the mel-spectrogram inversion of unseen speakers, and FastDiff-TTS outperformed other competing methods in end-to-end text-to-speech synthesis. Audio samples are available at https://FastDiff.github.io/.",
    "citationCount": 204,
    "pdf_filename": "2022_FastDiff__A_Fast_Conditional_Diffusion_M_59a1daf1.pdf"
  },
  "0f733817e82026f7c29909a51cb4df7d2685f0e7": {
    "paperId": "0f733817e82026f7c29909a51cb4df7d2685f0e7",
    "title": "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",
    "year": 2022,
    "authors": "Tongshuang Sherry Wu, Ellen Jiang, Aaron Donsbach, J. Gray, A. Molina",
    "abstract": "While LLMs have made it possible to rapidly prototype new ML functionalities, many real-world applications involve complex tasks that cannot be easily handled via a single run of an LLM. Recent work has found that chaining multiple LLM runs together (with the output of one step being the input to the next) can help users accomplish these more complex tasks, and in a way that is perceived to be more transparent and controllable. However, it remains unknown what users need when authoring their own LLM chains – a key step to lowering the barriers for non-AI-experts to prototype AI-infused applications. In this work, we explore the LLM chain authoring process. We find from pilot studies that users need support transforming data between steps of a chain, as well as debugging the chain at multiple granularities. To address these needs, we designed PromptChainer, an interactive interface for visually programming chains. Through case studies with four designers and developers, we show that PromptChainer supports building prototypes for a range of applications, and conclude with open questions on scaling chains to even more complex tasks, as well as supporting low-fi chain prototyping.",
    "citationCount": 261,
    "pdf_filename": "2022_PromptChainer__Chaining_Large_Language_M_0f733817.pdf"
  },
  "e86e95855ac23b70c1c6877b5eca079294c4ab02": {
    "paperId": "e86e95855ac23b70c1c6877b5eca079294c4ab02",
    "title": "Artificial intelligence and the changing sources of competitive advantage",
    "year": 2022,
    "authors": "Sebastian Krakowski, Johannes Luger, Sebastian Raisch",
    "abstract": "Research Summary: We apply a resource-based view to investigate how the adoption of Artificial Intelligence (AI) affects competitive capabilities and performance. Following prior work on using chess as a controlled setting for studying competitive interactions, we compare the same players ’ capabilities and performance across conventional, centaur, and engine chess tournaments. Our analysis shows that AI adoption triggers interrelated sub-stitution and complementation dynamics, which make humans ’ traditional competitive capabilities obsolete, while creating new sources of persistent heterogeneity when humans interact with chess engines. These novel human-machine capabilities are unrelated, or even negatively related, to traditional capabilities. We contribute an integrated view of substitution and complementation, which identifies AI as the driver of these dynamics and explains how they jointly shift the sources of competitive advantage. Managerial Summary: AI-based technologies increasingly substitute and complement humans in managerial tasks such as decision making. We investigate how such change affects the sources of competitive advantage. AI-based engines ’ adoption in chess allows us to investigate competitive capabilities and performance in human, AI, and hybrid settings. We find that neither humans nor AI",
    "citationCount": 287,
    "pdf_filename": "2022_Artificial_intelligence_and_the_changing_e86e9585.pdf"
  },
  "92999f7a304e866a2be7176e59c745481ed01042": {
    "paperId": "92999f7a304e866a2be7176e59c745481ed01042",
    "title": "Co-Writing with Opinionated Language Models Affects Users’ Views",
    "year": 2023,
    "authors": "Maurice Jakesch, Advait Bhat, Daniel Buschek, Lior Zalmanson, Mor Naaman",
    "abstract": "If large language models like GPT-3 preferably produce a particular point of view, they may influence people’s opinions on an unknown scale. This study investigates whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write – and what they think. In an online experiment, we asked participants (N=1,506) to write a post discussing whether social media is good for society. Treatment group participants used a language-model-powered writing assistant configured to argue that social media is good or bad for society. Participants then completed a social media attitude survey, and independent judges (N=500) evaluated the opinions expressed in their writing. Using the opinionated language model affected the opinions expressed in participants’ writing and shifted their opinions in the subsequent attitude survey. We discuss the wider implications of our results and argue that the opinions built into AI language technologies need to be monitored and engineered more carefully.",
    "citationCount": 275,
    "pdf_filename": "2023_Co_Writing_with_Opinionated_Language_Mod_92999f7a.pdf"
  },
  "b42ab1a11c55fb9b7077cc8746f541409ed48b80": {
    "paperId": "b42ab1a11c55fb9b7077cc8746f541409ed48b80",
    "title": "The future of medical education and research: Is ChatGPT a blessing or blight in disguise?",
    "year": 2023,
    "authors": "T. Arif, Uzair Munaf, Ibtehaj Ul-Haque",
    "abstract": "To the editor, With the rapid evolution of scientific literature and technology, experts rely more on new artificial intelligence models for convenience and easy access to needs. The introduction of extensive language model tools by Google and Meta use programs by taking human prompts and devising sophisticated responses [1]. A large amount of data and computing techniques are used to make predictions to combine words in a meaningful way. Similarly, a new viral bot, ‘ChatGPT’, was released by the artificial intelligence company ‘Open AI’ in November 2022. This bot has been attracting millions of users and investors, and scientists believe it can replace humans in the future. To make a revolutionary move, Open AI created a user interface to allow the public to experiment with it directly [1]. Since the introduction of ChatGPT, it has been tested on various domains to check its functioning in its natural and conversational mode by different industries. Numerous ways of using this chatbot are education and training, entertainment, predicting questions, scheduling and booking appointments, and debugging codes. In healthcare, it has been used to provide medical information and assistance, such as answering medical questions or providing differentials for common symptoms [2]. Recently, Kung et al. found that ChatGPT performed at or near the passing threshold for all three United States Medical Licensing Exams, suggesting that large language models can assist with medical education and clinical decision-making [3]. The real question is how much ChatGPT can impact the world of medical research. According to Dr. Biswas, ChatGPT can revolutionize medical writing by making it a quick and time-efficient process. It can extract information, assist in literature searches, and create a rough draft for the medical writer to work further upon [4]. Many scientific experts and journals reject ChatGPT because it lacks critical thinking and presents information redundantly and irrationally [5]. As per many educationists, ChatGPT is easily used by students enrolled in communication and philosophy courses to cheat in exams but is easily recognizable. A rising concern is that the students will eventually lose their ability to produce original ideas and will not be able to present proper arguments to prove a point [5]. Similarly, the issue with using ChatGPT in scientific papers is the accountability of the bot’s content. With that comes ethical concerns, medicolegal and copyright issues, lack of creative thinking and reasoning, methodological biases, and the inaccuracy of the content [4,6]. There has yet to be a governing body formed nor are there any established rules or limits on how much AI can be used. On experimenting with ChatGPT for research, it could easily help with writing the content of paper using the evidence from online search engines. Albeit, it lacked the capacity to perform a thorough literature search or critical analysis and discussion of articles as documented in the past [7]. The only evident benefit was a rephrased text that is not entirely plagiarism-free and depends on the specific command given to the bot. As pointed out by the experts at Mayo Clinic, Thomas Davenport and Nitin Mittal, the number of times ChatGPT can be misused is infinite. In the future, it can cause the human mind to become dormant to even fundamental tasks. Moreover, John Halamka (President, Mayo Clinic platform) and Paul Cerrato (Senior research analyst and communications specialist, Mayo Clinic platform) highlighted that one of the significant barriers to using ChatGPT is its existing training data, which is updated till 2021 [8]. This, along with restricted access to the main databases, such as PubMed and Cochrane, not only limits its usage to only abstract writing but raises questions about its work credibility. On testing ChatGPT’s ability to extract information from articles, it replied, ‘I’m sorry, but as a language model I don’t have the ability to perform a real-time search of medical databases such as PubMed or Cochrane. However, you can easily perform a search on these websites yourself.’ ChatGPT can be used as an add-on to constructive writing, reviewing material, and rephrasing the text rather than providing a whole original blueprint [7]. As medical literature is a constant process of updated research, the rising concern is that ChatGPT can now be easily used for writing papers, which may lack clinical reasoning and critical thinking. We need an intellectual human mind and a group of policies to cross-check the data generated by such AI systems and control their access. Similarly, medical professionals should introduce a surveillance system to ensure students do not use ChatGPT in medical assignments. MEDICAL EDUCATION ONLINE 2023, VOL. 28, 2181052 https://doi.org/10.1080/10872981.2023.2181052",
    "citationCount": 265,
    "pdf_filename": "2023_The_future_of_medical_education_and_rese_b42ab1a1.pdf"
  },
  "b843659256fab83d508c883a5bbcf8b26676d419": {
    "paperId": "b843659256fab83d508c883a5bbcf8b26676d419",
    "title": "Machine Learning Methods for Small Data Challenges in Molecular Science.",
    "year": 2023,
    "authors": "Bozheng Dou, Zailiang Zhu, E. Merkurjev, Lu Ke, Long Chen",
    "abstract": "Small data are often used in scientific and engineering research due to the presence of various constraints, such as time, cost, ethics, privacy, security, and technical limitations in data acquisition. However, big data have been the focus for the past decade, small data and their challenges have received little attention, even though they are technically more severe in machine learning (ML) and deep learning (DL) studies. Overall, the small data challenge is often compounded by issues, such as data diversity, imputation, noise, imbalance, and high-dimensionality. Fortunately, the current big data era is characterized by technological breakthroughs in ML, DL, and artificial intelligence (AI), which enable data-driven scientific discovery, and many advanced ML and DL technologies developed for big data have inadvertently provided solutions for small data problems. As a result, significant progress has been made in ML and DL for small data challenges in the past decade. In this review, we summarize and analyze several emerging potential solutions to small data challenges in molecular science, including chemical and biological sciences. We review both basic machine learning algorithms, such as linear regression, logistic regression (LR), k-nearest neighbor (KNN), support vector machine (SVM), kernel learning (KL), random forest (RF), and gradient boosting trees (GBT), and more advanced techniques, including artificial neural network (ANN), convolutional neural network (CNN), U-Net, graph neural network (GNN), Generative Adversarial Network (GAN), long short-term memory (LSTM), autoencoder, transformer, transfer learning, active learning, graph-based semi-supervised learning, combining deep learning with traditional machine learning, and physical model-based data augmentation. We also briefly discuss the latest advances in these methods. Finally, we conclude the survey with a discussion of promising trends in small data challenges in molecular science.",
    "citationCount": 279,
    "pdf_filename": "2023_Machine_Learning_Methods_for_Small_Data__b8436592.pdf"
  },
  "d21c15a28720bd920875076bb9c3d8879e98d8e1": {
    "paperId": "d21c15a28720bd920875076bb9c3d8879e98d8e1",
    "title": "Artificial Intelligence for Assessment and Feedback to Enhance Student Success in Higher Education",
    "year": 2022,
    "authors": "Monika Hooda, Chhavi Rana, Omdev Dahiya, Ali Rizwan, Md. Shamim Hossain",
    "abstract": "The core focus of this review is to show how immediate and valid feedback, qualitative assessment influence enhances students learning in a higher education environment. With the rising trend of online education especially in this COVID-19 pandemic, the role of assessment and feedback also changes. Earlier the assessment part is not considered the main focus in learning and teaching in HEIs, but now with the increase in online education, it is observed that the paradigm is shifted toward assessing those activities of students that enhance their learning outcomes. A lot of research work has been done on developing assessment strategies and techniques that can support learning and teaching effectively. Yet, there is limited research that looks at how methods applied in learning analytics can be used and possibly constitutes the assessment process. The objective of this work is to provide an exploratory and comparative study of how assessment and feedback practices can enhance students learning outcomes using AI. The key contribution of this study attempts to capture an outline of the most used artificial intelligence and machine learning algorithms for student success. The results showed that I-FCN performed better than other techniques (ANN, XG Boost, SVM, Random Forest, and Decision Trees) in all measured performance metrics. Also, the result of the comparative analysis study will help the educators, instructors, and administrators on how they could take the advantage of a data-driven approach, design less pressurized, more valid, reliable, constructive assessment findings, and connect the power of assessment and feedback to enhance the learning outcomes.",
    "citationCount": 258,
    "pdf_filename": "2022_Artificial_Intelligence_for_Assessment_a_d21c15a2.pdf"
  },
  "8c46959d4ce047b857c351b89c88b08f6833208e": {
    "paperId": "8c46959d4ce047b857c351b89c88b08f6833208e",
    "title": "TensorFlow Quantum: A Software Framework for Quantum Machine Learning",
    "year": 2020,
    "authors": "",
    "abstract": "We introduce TensorFlow Quantum (TFQ), an open source library for the rapid prototyping of hybrid quantum-classical models for classical or quantum data. This framework offers high-level abstractions for the design and training of both discriminative and generative quantum models under TensorFlow and supports high-performance quantum circuit simulators. We provide an overview of the software architecture and building blocks through several examples and review the theory of hybrid quantum-classical neural networks. We illustrate TFQ functionalities via several basic applications including supervised learning for quantum classification, quantum control, and quantum approximate optimization. Moreover, we demonstrate how one can apply TFQ to tackle advanced quantum learning tasks including meta-learning, Hamiltonian learning, and sampling thermal states. We hope this framework provides the necessary tools for the quantum computing and machine learning research communities to explore models of both natural and artificial quantum systems, and ultimately discover new quantum algorithms which could potentially yield a quantum advantage.",
    "citationCount": 259,
    "pdf_filename": "2020_TensorFlow_Quantum__A_Software_Framework_8c46959d.pdf"
  },
  "70286a248345b1005814daec33b78bad7ec4044d": {
    "paperId": "70286a248345b1005814daec33b78bad7ec4044d",
    "title": "Towards a Standard for Identifying and Managing Bias in Artificial Intelligence",
    "year": 2022,
    "authors": "Reva Schwartz, Apostol T. Vassilev, Kristen Greene, Lori A. Perine, Andrew Burt",
    "abstract": "concert are a panacea against bias and each brings its own set of pitfalls. What is missing from current remedies is guidance from a broader SOCIO - TECHNICAL perspective that connects these practices to societal values. Experts in the area of Trustworthy and Responsible AI counsel that to successfully manage the risks of AI bias we must operationalize these values and create new norms around how AI is built and deployed. This document, and work by the National Institute of Standards and Technology (NIST) in the area of AI bias, is based on a socio-technical perspective.",
    "citationCount": 293,
    "pdf_filename": "2022_Towards_a_Standard_for_Identifying_and_M_70286a24.pdf"
  },
  "31e284d01686e257dabb978eb8ca10ceefca5be6": {
    "paperId": "31e284d01686e257dabb978eb8ca10ceefca5be6",
    "title": "Deepfake Detection: A Systematic Literature Review",
    "year": 2022,
    "authors": "M. Rana, M. N. Nobi, B. Murali, A. Sung",
    "abstract": "Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.",
    "citationCount": 294,
    "pdf_filename": "2022_Deepfake_Detection__A_Systematic_Literat_31e284d0.pdf"
  },
  "b0c63b16f9f519b631a46ce95fbe296d30b53896": {
    "paperId": "b0c63b16f9f519b631a46ce95fbe296d30b53896",
    "title": "GFlowNet Foundations",
    "year": 2021,
    "authors": "Yoshua Bengio, T. Deleu, J. E. Hu, Salem Lahlou, Mo Tiwari",
    "abstract": "Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets. They can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entropy and mutual information, sampling from a Pareto frontier, connections to reward-maximizing policies, and extensions to stochastic environments, continuous actions and modular energy functions.",
    "citationCount": 288,
    "pdf_filename": "2021_GFlowNet_Foundations_b0c63b16.pdf"
  },
  "a2f4115fb68b293b574fcbff40f3570f3a4a2a9f": {
    "paperId": "a2f4115fb68b293b574fcbff40f3570f3a4a2a9f",
    "title": "The General Attitudes towards Artificial Intelligence Scale (GAAIS): Confirmatory Validation and Associations with Personality, Corporate Distrust, and General Trust",
    "year": 2022,
    "authors": "A. Schepman, P. Rodway",
    "abstract": "Abstract Acceptance of Artificial Intelligence (AI) may be predicted by individual psychological correlates, examined here. Study 1 reports confirmatory validation of the General Attitudes towards Artificial Intelligence Scale (GAAIS) following initial validation elsewhere. Confirmatory Factor Analysis confirmed the two-factor structure (Positive, Negative) and showed good convergent and divergent validity with a related scale. Study 2 tested whether psychological factors (Big Five personality traits, corporate distrust, and general trust) predicted attitudes towards AI. Introverts had more positive attitudes towards AI overall, likely because of algorithm appreciation. Conscientiousness and agreeableness were associated with forgiving attitudes towards negative aspects of AI. Higher corporate distrust led to negative attitudes towards AI overall, while higher general trust led to positive views of the benefits of AI. The dissociation between general trust and corporate distrust may reflect the public’s attributions of the benefits and drawbacks of AI. Results are discussed in relation to theory and prior findings.",
    "citationCount": 251,
    "pdf_filename": "2022_The_General_Attitudes_towards_Artificial_a2f4115f.pdf"
  },
  "bb678afa2685e6493f9875b66ac2b32dce5e7e9b": {
    "paperId": "bb678afa2685e6493f9875b66ac2b32dce5e7e9b",
    "title": "Challenges to implementing artificial intelligence in healthcare: a qualitative interview study with healthcare leaders in Sweden",
    "year": 2022,
    "authors": "Lena Petersson, I. Larsson, J. Nygren, Per Nilsen, M. Neher",
    "abstract": "Background Artificial intelligence (AI) for healthcare presents potential solutions to some of the challenges faced by health systems around the world. However, it is well established in implementation and innovation research that novel technologies are often resisted by healthcare leaders, which contributes to their slow and variable uptake. Although research on various stakeholders’ perspectives on AI implementation has been undertaken, very few studies have investigated leaders’ perspectives on the issue of AI implementation in healthcare. It is essential to understand the perspectives of healthcare leaders, because they have a key role in the implementation process of new technologies in healthcare. The aim of this study was to explore challenges perceived by leaders in a regional Swedish healthcare setting concerning the implementation of AI in healthcare. Methods The study takes an explorative qualitative approach. Individual, semi-structured interviews were conducted from October 2020 to May 2021 with 26 healthcare leaders. The analysis was performed using qualitative content analysis, with an inductive approach. Results The analysis yielded three categories, representing three types of challenge perceived to be linked with the implementation of AI in healthcare: 1) Conditions external to the healthcare system; 2) Capacity for strategic change management; 3) Transformation of healthcare professions and healthcare practice. Conclusions In conclusion, healthcare leaders highlighted several implementation challenges in relation to AI within and beyond the healthcare system in general and their organisations in particular. The challenges comprised conditions external to the healthcare system, internal capacity for strategic change management, along with transformation of healthcare professions and healthcare practice. The results point to the need to develop implementation strategies across healthcare organisations to address challenges to AI-specific capacity building. Laws and policies are needed to regulate the design and execution of effective AI implementation strategies. There is a need to invest time and resources in implementation processes, with collaboration across healthcare, county councils, and industry partnerships.",
    "citationCount": 259,
    "pdf_filename": "2022_Challenges_to_implementing_artificial_in_bb678afa.pdf"
  },
  "5d556dd3afff529de8cb694f88916b2d95fbdd3a": {
    "paperId": "5d556dd3afff529de8cb694f88916b2d95fbdd3a",
    "title": "How to Train Your Energy-Based Models",
    "year": 2021,
    "authors": "Yang Song, Diederik P. Kingma",
    "abstract": "Energy-Based Models (EBMs), also known as non-normalized probabilistic models, specify probability density or mass functions up to an unknown normalizing constant. Unlike most other probabilistic models, EBMs do not place a restriction on the tractability of the normalizing constant, thus are more flexible to parameterize and can model a more expressive family of probability distributions. However, the unknown normalizing constant of EBMs makes training particularly difficult. Our goal is to provide a friendly introduction to modern approaches for EBM training. We start by explaining maximum likelihood training with Markov chain Monte Carlo (MCMC), and proceed to elaborate on MCMC-free approaches, including Score Matching (SM) and Noise Constrastive Estimation (NCE). We highlight theoretical connections among these three approaches, and end with a brief survey on alternative training methods, which are still under active research. Our tutorial is targeted at an audience with basic understanding of generative models who want to apply EBMs or start a research project in this direction.",
    "citationCount": 295,
    "pdf_filename": "2021_How_to_Train_Your_Energy_Based_Models_5d556dd3.pdf"
  },
  "ffd43946c7fe947ef3213e7a668a36e9d41c8f4b": {
    "paperId": "ffd43946c7fe947ef3213e7a668a36e9d41c8f4b",
    "title": "Projected GANs Converge Faster",
    "year": 2021,
    "authors": "Axel Sauer, Kashyap Chitta, Jens Muller, Andreas Geiger",
    "abstract": "Generative Adversarial Networks (GANs) produce high-quality images but are challenging to train. They need careful regularization, vast amounts of compute, and expensive hyper-parameter sweeps. We make significant headway on these issues by projecting generated and real samples into a fixed, pretrained feature space. Motivated by the finding that the discriminator cannot fully exploit features from deeper layers of the pretrained model, we propose a more effective strategy that mixes features across channels and resolutions. Our Projected GAN improves image quality, sample efficiency, and convergence speed. It is further compatible with resolutions of up to one Megapixel and advances the state-of-the-art Fr\\'echet Inception Distance (FID) on twenty-two benchmark datasets. Importantly, Projected GANs match the previously lowest FIDs up to 40 times faster, cutting the wall-clock time from 5 days to less than 3 hours given the same computational resources.",
    "citationCount": 276,
    "pdf_filename": "2021_Projected_GANs_Converge_Faster_ffd43946.pdf"
  },
  "9363e8e1fe2be2a13b4d6f5fc61bbaed14ab9a23": {
    "paperId": "9363e8e1fe2be2a13b4d6f5fc61bbaed14ab9a23",
    "title": "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training",
    "year": 2024,
    "authors": "Evan Hubinger, Carson E. Denison, Jesse Mu, Mike Lambert, Meg Tong",
    "abstract": "Humans are capable of strategically deceptive behavior: behaving helpfully in most situations, but then behaving very differently in order to pursue alternative objectives when given the opportunity. If an AI system learned such a deceptive strategy, could we detect it and remove it using current state-of-the-art safety training techniques? To study this question, we construct proof-of-concept examples of deceptive behavior in large language models (LLMs). For example, we train models that write secure code when the prompt states that the year is 2023, but insert exploitable code when the stated year is 2024. We find that such backdoor behavior can be made persistent, so that it is not removed by standard safety training techniques, including supervised fine-tuning, reinforcement learning, and adversarial training (eliciting unsafe behavior and then training to remove it). The backdoor behavior is most persistent in the largest models and in models trained to produce chain-of-thought reasoning about deceiving the training process, with the persistence remaining even when the chain-of-thought is distilled away. Furthermore, rather than removing backdoors, we find that adversarial training can teach models to better recognize their backdoor triggers, effectively hiding the unsafe behavior. Our results suggest that, once a model exhibits deceptive behavior, standard techniques could fail to remove such deception and create a false impression of safety.",
    "citationCount": 266,
    "pdf_filename": "2024_Sleeper_Agents__Training_Deceptive_LLMs__9363e8e1.pdf"
  },
  "5553f9508dd1056ecc20c5b1f367e9a07e2c7e81": {
    "paperId": "5553f9508dd1056ecc20c5b1f367e9a07e2c7e81",
    "title": "StyleSwin: Transformer-based GAN for High-resolution Image Generation",
    "year": 2021,
    "authors": "Bo Zhang, Shuyang Gu, Bo Zhang, Jianmin Bao, Dong Chen",
    "abstract": "Despite the tantalizing success in a broad of vision tasks, transformers have not yet demonstrated on-par ability as ConvNets in high-resolution image generative modeling. In this paper, we seek to explore using pure transformers to build a generative adversarial network for high-resolution image synthesis. To this end, we believe that local attention is crucial to strike the balance between computational efficiency and modeling capacity. Hence, the proposed generator adopts Swin transformer in a style-based architecture. To achieve a larger receptive field, we propose double attention which simultaneously leverages the context of the local and the shifted windows, leading to improved generation quality. Moreover, we show that offering the knowledge of the absolute position that has been lost in window-based transformers greatly benefits the generation quality. The proposed StyleSwin is scalable to high resolutions, with both the coarse geometry and fine structures benefit from the strong expressivity of transformers. However, blocking artifacts occur during high-resolution synthesis because performing the local attention in a block-wise manner may break the spatial coherency. To solve this, we empirically investigate various solutions, among which we find that employing a wavelet discriminator to examine the spectral discrepancy effectively suppresses the artifacts. Extensive experiments show the superiority over prior transformer-based GANs, especially on high resolutions, e.g., $1024 \\times$ 1024. The StyleSwin, without complex training strategies, excels over StyleGAN on CelebA-HQ 1024, and achieves on-par performance on FFHQ-1024, proving the promise of using transformers for high-resolution image generation. The code and pretrained models are available at https://github.com/microsoft/StyleSwin.",
    "citationCount": 284,
    "pdf_filename": "2021_StyleSwin__Transformer_based_GAN_for_Hig_5553f950.pdf"
  },
  "b66c1c7617b42f3814d516faf7d2ca3b771a0c9e": {
    "paperId": "b66c1c7617b42f3814d516faf7d2ca3b771a0c9e",
    "title": "The Creativity of Text-to-Image Generation",
    "year": 2022,
    "authors": "J. Oppenlaender",
    "abstract": "Text-guided synthesis of images has made a giant leap towards becoming a mainstream phenomenon. With text-to-image generation systems, anybody can create digital images and artworks. This provokes the question of whether text-to-image generation is creative. This paper expounds on the nature of human creativity involved in text-to-image art (so-called “AI art”) with a specific focus on the practice of prompt engineering. The paper argues that the current product-centered view of creativity falls short in the context of text-to-image generation. A case exemplifying this shortcoming is provided and the importance of online communities for the creative ecosystem of text-to-image art is highlighted. The paper provides a high-level summary of this online ecosystem drawing on Rhodes’ conceptual four P model of creativity. Challenges for evaluating the creativity of text-to-image generation and opportunities for research on text-to-image generation in the field of Human-Computer Interaction (HCI) are discussed.",
    "citationCount": 241,
    "pdf_filename": "2022_The_Creativity_of_Text_to_Image_Generati_b66c1c76.pdf"
  },
  "51bdcedbf11246000edab6afb66f6ed02cae6d35": {
    "paperId": "51bdcedbf11246000edab6afb66f6ed02cae6d35",
    "title": "Discourses of artificial intelligence in higher education: a critical literature review",
    "year": 2022,
    "authors": "M. Bearman, Juliana Ryan, R. Ajjawi",
    "abstract": "Artificial intelligence (AI) holds significant implications for higher education; however, references to AI in the literature are often vague and open to debate. In order to understand how to progress AI-related research and analysis, this critical review systematically searched top higher education journals for references to the term ‘artificial intelligence’. We reviewed definitions and conducted a discourse analysis of included texts. Our findings identify few, confusing definitions and little overt reference to AI as a research object. We delineated two Discourses. The Discourse of imperative change outlines how AI is seen as an inevitable change to which all must respond. Additionally, the Discourse of altering authority describes how texts position AI as decentring the teacher and spreading authority across staff, machines, corporations and students. Our analysis prompts a call for new research foci that attend to the social implications of AI, including tracing accountability in AI-mediated practices and exploring how AI influences learning and teaching relationships.",
    "citationCount": 240,
    "pdf_filename": "2022_Discourses_of_artificial_intelligence_in_51bdcedb.pdf"
  },
  "0173de47cce7b5e616aa8198b270b34abbd68645": {
    "paperId": "0173de47cce7b5e616aa8198b270b34abbd68645",
    "title": "CTAB-GAN: Effective Table Data Synthesizing",
    "year": 2021,
    "authors": "Zilong Zhao, A. Kunar, H. V. D. Scheer, R. Birke, L. Chen",
    "abstract": "While data sharing is crucial for knowledge development, privacy concerns and strict regulation (e.g., European General Data Protection Regulation (GDPR)) unfortunately limit its full effectiveness. Synthetic tabular data emerges as an alternative to enable data sharing while fulfilling regulatory and privacy constraints. The state-of-the-art tabular data synthesizers draw methodologies from generative Adversarial Networks (GAN) and address two main data types in the industry, i.e., continuous and categorical. In this paper, we develop CTAB-GAN, a novel conditional table GAN architecture that can effectively model diverse data types, including a mix of continuous and categorical variables. Moreover, we address data imbalance and long-tail issues, i.e., certain variables have drastic frequency differences across large values. To achieve those aims, we first introduce the information loss and classification loss to the conditional GAN. Secondly, we design a novel conditional vector, which efficiently encodes the mixed data type and skewed distribution of data variable. We extensively evaluate CTAB-GAN with the state of the art GANs that generate synthetic tables, in terms of data similarity and analysis utility. The results on five datasets show that the synthetic data of CTAB-GAN remarkably resembles the real data for all three types of variables and results into higher accuracy for five machine learning algorithms, by up to 17%.",
    "citationCount": 248,
    "pdf_filename": "2021_CTAB_GAN__Effective_Table_Data_Synthesiz_0173de47.pdf"
  },
  "5cba4b2a4d0b74c8aad0c94b6f468f6c86ee3db9": {
    "paperId": "5cba4b2a4d0b74c8aad0c94b6f468f6c86ee3db9",
    "title": "Catalyzing next-generation Artificial Intelligence through NeuroAI",
    "year": 2022,
    "authors": "A. Zador, Sean Escola, B. Richards, B. Ölveczky, Y. Bengio",
    "abstract": "One of the ambitions of computational neuroscience is that we will continue to make improvements in the field of artificial intelligence that will be informed by advances in our understanding of how the brains of various species evolved to process information. To that end, here the authors propose an expanded version of the Turing test that involves embodied sensorimotor interactions with the world as a new framework for accelerating progress in artificial intelligence. Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities – inherited from over 500 million years of evolution – that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.",
    "citationCount": 242,
    "pdf_filename": "2022_Catalyzing_next_generation_Artificial_In_5cba4b2a.pdf"
  },
  "9e011b36e9a53fb546943c705b22eca885998ffc": {
    "paperId": "9e011b36e9a53fb546943c705b22eca885998ffc",
    "title": "Exploring artificial intelligence adoption in public organizations: a comparative case study",
    "year": 2022,
    "authors": "O. Neumann, Katharina Guirguis, Reto Steiner",
    "abstract": "ABSTRACT Despite the enormous potential of artificial intelligence (AI), many public organizations struggle to adopt this technology. Simultaneously, empirical research on what determines successful AI adoption in public settings remains scarce. Using the technology organization environment (TOE) framework, we address this gap with a comparative case study of eight Swiss public organizations. Our findings suggest that the importance of technological and organizational factors varies depending on the organization’s stage in the adoption process, whereas environmental factors are generally less critical. Accordingly, this study advances our theoretical understanding of the specificities of AI adoption in public organizations throughout the different adoption stages.",
    "citationCount": 233,
    "pdf_filename": "2022_Exploring_artificial_intelligence_adopti_9e011b36.pdf"
  },
  "7625c390c6171ee8aa8ae01a7897d081226787c5": {
    "paperId": "7625c390c6171ee8aa8ae01a7897d081226787c5",
    "title": "Detecting False Data Injection Attacks in Smart Grids: A Semi-Supervised Deep Learning Approach",
    "year": 2021,
    "authors": "Ying Zhang, Jianhui Wang, Bo Chen",
    "abstract": "The dependence on advanced information and communication technology increases the vulnerability in smart grids under cyber-attacks. Recent research on unobservable false data injection attacks (FDIAs) reveals the high risk of secure system operation, since these attacks can bypass current bad data detection mechanisms. To mitigate this risk, this paper proposes a data-driven learning-based algorithm for detecting unobservable FDIAs in distribution systems. We use autoencoders for efficient dimension reduction and feature extraction of measurement datasets. Further, we integrate the autoencoders into an advanced generative adversarial network (GAN) framework, which successfully detects anomalies under FDIAs by capturing the unconformity between abnormal and secure measurements. Also, considering that the datasets collected from practical power systems are partially labeled due to expensive labeling costs and missing labels, the proposed method only requires a few labeled measurement data in addition to unlabeled data for training. Numerical simulations in three-phase unbalanced IEEE 13-bus and 123-bus distribution systems validate the detection accuracy and efficiency of this method.",
    "citationCount": 239,
    "pdf_filename": "2021_Detecting_False_Data_Injection_Attacks_i_7625c390.pdf"
  },
  "509e166d5e66df10675a0e15063daad518dcc5ad": {
    "paperId": "509e166d5e66df10675a0e15063daad518dcc5ad",
    "title": "Likelihood Training of Schrödinger Bridge using Forward-Backward SDEs Theory",
    "year": 2021,
    "authors": "T. Chen, Guan-Horng Liu, Evangelos A. Theodorou",
    "abstract": "Schr\\\"odinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory - a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimization principle that inherits the same SB optimality yet without losing applications of modern generative training techniques, and we show that the resulting training algorithm achieves comparable results on generating realistic images on MNIST, CelebA, and CIFAR10. Our code is available at https://github.com/ghliu/SB-FBSDE.",
    "citationCount": 217,
    "pdf_filename": "2021_Likelihood_Training_of_Schrödinger_Bridg_509e166d.pdf"
  },
  "a31c11e72a51ea482a59c9827a4fee199a854cd3": {
    "paperId": "a31c11e72a51ea482a59c9827a4fee199a854cd3",
    "title": "Combining EfficientNet and Vision Transformers for Video Deepfake Detection",
    "year": 2021,
    "authors": "D. Coccomini, Nicola Messina, C. Gennaro, F. Falchi",
    "abstract": "Deepfakes are the result of digital manipulation to forge realistic yet fake imagery. With the astonishing advances in deep generative models, fake images or videos are nowadays obtained using variational autoencoders (VAEs) or Generative Adversarial Networks (GANs). These technologies are becoming more accessible and accurate, resulting in fake videos that are very difficult to be detected. Traditionally, Convolutional Neural Networks (CNNs) have been used to perform video deepfake detection, with the best results obtained using methods based on EfficientNet B7. In this study, we focus on video deep fake detection on faces, given that most methods are becoming extremely accurate in the generation of realistic human faces. Specifically, we combine various types of Vision Transformers with a convolutional EfficientNet B0 used as a feature extractor, obtaining comparable results with some very recent methods that use Vision Transformers. Differently from the state-of-the-art approaches, we use neither distillation nor ensemble methods. Furthermore, we present a straightforward inference procedure based on a simple voting scheme for handling multiple faces in the same video shot. The best model achieved an AUC of 0.951 and an F1 score of 88.0%, very close to the state-of-the-art on the DeepFake Detection Challenge (DFDC).",
    "citationCount": 210,
    "pdf_filename": "2021_Combining_EfficientNet_and_Vision_Transf_a31c11e7.pdf"
  },
  "b75c05214cd21ed1e6a75e6aea9552e1b31b3974": {
    "paperId": "b75c05214cd21ed1e6a75e6aea9552e1b31b3974",
    "title": "Controllable Person Image Synthesis With Attribute-Decomposed GAN",
    "year": 2020,
    "authors": "Yifang Men, Yiming Mao, Yuning Jiang, Wei-Ying Ma, Z. Lian",
    "abstract": "This paper introduces the Attribute-Decomposed GAN, a novel generative model for controllable person image synthesis, which can produce realistic person images with desired human attributes (e.g., pose, head, upper clothes and pants) provided in various source inputs. The core idea of the proposed model is to embed human attributes into the latent space as independent codes and thus achieve flexible and continuous control of attributes via mixing and interpolation operations in explicit style representations. Specifically, a new architecture consisting of two encoding pathways with style block connections is proposed to decompose the original hard mapping into multiple more accessible subtasks. In source pathway, we further extract component layouts with an off-the-shelf human parser and feed them into a shared global texture encoder for decomposed latent codes. This strategy allows for the synthesis of more realistic output images and automatic separation of un-annotated attributes. Experimental results demonstrate the proposed method's superiority over the state of the art in pose transfer and its effectiveness in the brand-new task of component attribute transfer.",
    "citationCount": 270,
    "pdf_filename": "2020_Controllable_Person_Image_Synthesis_With_b75c0521.pdf"
  },
  "0a20dbbe78eab951bba116ac8bd8c84711d5e728": {
    "paperId": "0a20dbbe78eab951bba116ac8bd8c84711d5e728",
    "title": "Are GAN Generated Images Easy to Detect? A Critical Analysis of the State-Of-The-Art",
    "year": 2021,
    "authors": "Diego Gragnaniello, D. Cozzolino, Francesco Marra, G. Poggi, L. Verdoliva",
    "abstract": "The advent of deep learning has brought a significant improvement in the quality of generated media. However, with the increased level of photorealism, synthetic media are becoming hardly distinguishable from real ones, raising serious concerns about the spread of fake or manipulated information over the Internet. In this context, it is important to develop automated tools to reliably and timely detect synthetic media. In this work, we analyze the state-of-the-art methods for the detection of synthetic images, highlighting the key ingredients of the most successful approaches, and comparing their performance over existing generative architectures. We will devote special attention to realistic and challenging scenarios, like media uploaded on social networks or generated by new and unseen architectures, analyzing the impact of suitable augmentation and training strategies on the detectors’ generalization ability.",
    "citationCount": 205,
    "pdf_filename": "2021_Are_GAN_Generated_Images_Easy_to_Detect__0a20dbbe.pdf"
  },
  "3916cb5c5ead76dc3a3c126fb41d68bc21571a1b": {
    "paperId": "3916cb5c5ead76dc3a3c126fb41d68bc21571a1b",
    "title": "DeepFake Detection by Analyzing Convolutional Traces",
    "year": 2020,
    "authors": "Luca Guarnera, Oliver Giudice, S. Battiato",
    "abstract": "The Deepfake phenomenon has become very popular nowadays thanks to the possibility to create incredibly realistic images using deep learning tools, based mainly on ad-hoc Generative Adversarial Networks (GAN). In this work we focus on the analysis of Deepfakes of human faces with the objective of creating a new detection method able to detect a forensics trace hidden in images: a sort of fingerprint left in the image generation process. The proposed technique, by means of an Expectation Maximization (EM) algorithm, extracts a set of local features specifically addressed to model the underlying convolutional generative process. Ad-hoc validation has been employed through experimental tests with naive classifiers on five different architectures (GDWCT, STARGAN, ATTGAN, STYLEGAN, STYLEGAN2) against the CELEBA dataset as ground-truth for non-fakes. Results demonstrated the effectiveness of the technique in distinguishing the different architectures and the corresponding generation process.",
    "citationCount": 274,
    "pdf_filename": "2020_DeepFake_Detection_by_Analyzing_Convolut_3916cb5c.pdf"
  },
  "93d00ea9c87268f867b4addb8043be35d6996d18": {
    "paperId": "93d00ea9c87268f867b4addb8043be35d6996d18",
    "title": "Symbolic Music Generation with Diffusion Models",
    "year": 2021,
    "authors": "Gautam Mittal, Jesse Engel, Curtis Hawthorne, Ian Simon",
    "abstract": "Score-based generative models and diffusion probabilistic models have been successful at generating high-quality samples in continuous domains such as images and audio. However, due to their Langevin-inspired sampling mechanisms, their application to discrete and sequential data has been limited. In this work, we present a technique for training diffusion models on sequential data by parameterizing the discrete domain in the continuous latent space of a pre-trained variational autoencoder. Our method is non-autoregressive and learns to generate sequences of latent embeddings through the reverse process and offers parallel generation with a constant number of iterative refinement steps. We apply this technique to modeling symbolic music and show strong unconditional generation and post-hoc conditional infilling results compared to autoregressive language models operating over the same continuous embeddings.",
    "citationCount": 213,
    "pdf_filename": "2021_Symbolic_Music_Generation_with_Diffusion_93d00ea9.pdf"
  },
  "b8a2fb97fb72725210ffd8af52446a88c88f072d": {
    "paperId": "b8a2fb97fb72725210ffd8af52446a88c88f072d",
    "title": "Deep Cybersecurity: A Comprehensive Overview from Neural Network and Deep Learning Perspective",
    "year": 2021,
    "authors": "Iqbal H. Sarker",
    "abstract": "Deep learning, which is originated from an artificial neural network (ANN), is one of the major technologies of today’s smart cybersecurity systems or policies to function in an intelligent manner. Popular deep learning techniques, such as multi-layer perceptron, convolutional neural network, recurrent neural network or long short-term memory, self-organizing map, auto-encoder, restricted Boltzmann machine, deep belief networks, generative adversarial network, deep transfer learning, as well as deep reinforcement learning, or their ensembles and hybrid approaches can be used to intelligently tackle the diverse cybersecurity issues. In this paper, we aim to present a comprehensive overview from the perspective of these neural networks and deep learning techniques according to today’s diverse needs. We also discuss the applicability of these techniques in various cybersecurity tasks such as intrusion detection, identification of malware or botnets, phishing, predicting cyberattacks, e.g. denial of service, fraud detection or cyberanomalies, etc. Finally, we highlight several research issues and future directions within the scope of our study in the field. Overall, the ultimate goal of this paper is to serve as a reference point and guidelines for the academia and professionals in the cyber industries, especially from the deep learning point of view.",
    "citationCount": 214,
    "pdf_filename": "2021_Deep_Cybersecurity__A_Comprehensive_Over_b8a2fb97.pdf"
  },
  "04943f65c568f14c157b491bcda2c529b0fb8036": {
    "paperId": "04943f65c568f14c157b491bcda2c529b0fb8036",
    "title": "Inverse design of porous materials using artificial neural networks",
    "year": 2020,
    "authors": "Baekjun Kim, Sangwon Lee, Jihan Kim",
    "abstract": "We have developed a user-desired generative adversarial network and used them to generate 121 zeolite materials. Generating optimal nanomaterials using artificial neural networks can potentially lead to a notable revolution in future materials design. Although progress has been made in creating small and simple molecules, complex materials such as crystalline porous materials have yet to be generated using any of the neural networks. Here, we have implemented a generative adversarial network that uses a training set of 31,713 known zeolites to produce 121 crystalline porous materials. Our neural network takes in inputs in the form of energy and material dimensions, and we show that zeolites with a user-desired range of 4 kJ/mol methane heat of adsorption can be reliably produced using our neural network. The fine-tuning of user-desired capability can potentially accelerate materials development as it demonstrates a successful case of inverse design of porous materials.",
    "citationCount": 295,
    "pdf_filename": "2020_Inverse_design_of_porous_materials_using_04943f65.pdf"
  },
  "10f86e4979a0d625b1e0fc6a1a45613b8977d440": {
    "paperId": "10f86e4979a0d625b1e0fc6a1a45613b8977d440",
    "title": "DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis",
    "year": 2020,
    "authors": "Ming Tao, Hao Tang, Fei Wu, Xiaoyuan Jing, Bingkun Bao",
    "abstract": "Synthesizing high-quality realistic images from text descriptions is a challenging task. Existing text-to-image Generative Adversarial Networks generally employ a stacked architecture as the backbone yet still remain three flaws. First, the stacked architecture introduces the entanglements between generators of different image scales. Second, existing studies prefer to apply and fix extra networks in adversarial learning for text-image semantic consistency, which limits the supervision capability of these networks. Third, the cross-modal attention-based text-image fusion that widely adopted by previous works is limited on several special image scales because of the computational cost. To these ends, we propose a simpler but more effective Deep Fusion Generative Adversarial Networks (DF-GAN). To be specific, we propose: (i) a novel one-stage text-to-image backbone that directly synthesizes high-resolution images without entanglements between different generators, (ii) a novel Target-Aware Discriminator composed of Matching-Aware Gradient Penalty and One-Way Output, which enhances the text-image semantic consistency without introducing extra networks, (iii) a novel deep text-image fusion block, which deepens the fusion process to make a full fusion between text and visual features. Compared with current state-of-the-art methods, our proposed DF-GAN is simpler but more efficient to synthesize realistic and text-matching images and achieves better performance on widely used datasets. Code is available at https://github.com/tobran/DF-GAN.",
    "citationCount": 264,
    "pdf_filename": "2020_DF_GAN__A_Simple_and_Effective_Baseline__10f86e49.pdf"
  },
  "78bc767ebd02c0cc690fdb334c37bf64cfaf0115": {
    "paperId": "78bc767ebd02c0cc690fdb334c37bf64cfaf0115",
    "title": "Support-set bottlenecks for video-text representation learning",
    "year": 2020,
    "authors": "Mandela Patrick, Po-Yao (Bernie) Huang, Yuki M. Asano, Florian Metze, Alexander Hauptmann",
    "abstract": "The dominant paradigm for learning video-text representations -- noise contrastive learning -- increases the similarity of the representations of pairs of samples that are known to be related, such as text and video from the same sample, and pushes away the representations of all other pairs. We posit that this last behaviour is too strict, enforcing dissimilar representations even for samples that are semantically-related -- for example, visually similar videos or ones that share the same depicted action. In this paper, we propose a novel method that alleviates this by leveraging a generative model to naturally push these related samples together: each sample's caption must be reconstructed as a weighted combination of other support samples' visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. Our proposed method outperforms others by a large margin on MSR-VTT, VATEX and ActivityNet, for video-to-text and text-to-video retrieval.",
    "citationCount": 260,
    "pdf_filename": "2020_Support_set_bottlenecks_for_video_text_r_78bc767e.pdf"
  },
  "9438bc5626b2d9a771cecc7a41ecabf6639db53c": {
    "paperId": "9438bc5626b2d9a771cecc7a41ecabf6639db53c",
    "title": "Automatic Detection of Machine Generated Text: A Critical Survey",
    "year": 2020,
    "authors": "Ganesh Jawahar, Muhammad Abdul-Mageed, L. Lakshmanan",
    "abstract": "Text generative models (TGMs) excel in producing text that matches the style of human language reasonably well. Such TGMs can be misused by adversaries, e.g., by automatically generating fake news and fake product reviews that can look authentic and fool humans. Detectors that can distinguish text generated by TGM from human written text play a vital role in mitigating such misuse of TGMs. Recently, there has been a flurry of works from both natural language processing (NLP) and machine learning (ML) communities to build accurate detectors for English. Despite the importance of this problem, there is currently no work that surveys this fast-growing literature and introduces newcomers to important research challenges. In this work, we fill this void by providing a critical survey and review of this literature to facilitate a comprehensive understanding of this problem. We conduct an in-depth error analysis of the state-of-the-art detector and discuss research directions to guide future work in this exciting area.",
    "citationCount": 271,
    "pdf_filename": "2020_Automatic_Detection_of_Machine_Generated_9438bc56.pdf"
  },
  "2734bf6fd46357504fd1deef33ad69207b39fd57": {
    "paperId": "2734bf6fd46357504fd1deef33ad69207b39fd57",
    "title": "TweepFake: About detecting deepfake tweets",
    "year": 2020,
    "authors": "T. Fagni, F. Falchi, Margherita Gambini, Antonio Martella, Maurizio Tesconi",
    "abstract": "The recent advances in language modeling significantly improved the generative capabilities of deep neural models: in 2019 OpenAI released GPT-2, a pre-trained language model that can autonomously generate coherent, non-trivial and human-like text samples. Since then, ever more powerful text generative models have been developed. Adversaries can exploit these tremendous generative capabilities to enhance social bots that will have the ability to write plausible deepfake messages, hoping to contaminate public debate. To prevent this, it is crucial to develop deepfake social media messages detection systems. However, to the best of our knowledge no one has ever addressed the detection of machine-generated texts on social networks like Twitter or Facebook. With the aim of helping the research in this detection field, we collected the first dataset of real deepfake tweets, TweepFake. It is real in the sense that each deepfake tweet was actually posted on Twitter. We collected tweets from a total of 23 bots, imitating 17 human accounts. The bots are based on various generation techniques, i.e., Markov Chains, RNN, RNN+Markov, LSTM, GPT-2. We also randomly selected tweets from the humans imitated by the bots to have an overall balanced dataset of 25,572 tweets (half human and half bots generated). The dataset is publicly available on Kaggle. Lastly, we evaluated 13 deepfake text detection methods (based on various state-of-the-art approaches) to both demonstrate the challenges that Tweepfake poses and create a solid baseline of detection techniques. We hope that TweepFake can offer the opportunity to tackle the deepfake detection on social media messages as well.",
    "citationCount": 255,
    "pdf_filename": "2020_TweepFake__About_detecting_deepfake_twee_2734bf6f.pdf"
  },
  "6d9a86b22a612bad44dee0481b33970bfa556cc2": {
    "paperId": "6d9a86b22a612bad44dee0481b33970bfa556cc2",
    "title": "A deep transfer learning model with classical data augmentation and CGAN to detect COVID-19 from chest CT radiography digital images",
    "year": 2020,
    "authors": "Mohamed Loey, Gunasekaran Manogaran, Nour Eldeen M. Khalifa",
    "abstract": "The Coronavirus disease 2019 (COVID-19) is the fastest transmittable virus caused by severe acute respiratory syndrome Coronavirus 2 (SARS-CoV-2). The detection of COVID-19 using artificial intelligence techniques and especially deep learning will help to detect this virus in early stages which will reflect in increasing the opportunities of fast recovery of patients worldwide. This will lead to release the pressure off the healthcare system around the world. In this research, classical data augmentation techniques along with Conditional Generative Adversarial Nets (CGAN) based on a deep transfer learning model for COVID-19 detection in chest CT scan images will be presented. The limited benchmark datasets for COVID-19 especially in chest CT images are the main motivation of this research. The main idea is to collect all the possible images for COVID-19 that exists until the very writing of this research and use the classical data augmentations along with CGAN to generate more images to help in the detection of the COVID-19. In this study, five different deep convolutional neural network-based models (AlexNet, VGGNet16, VGGNet19, GoogleNet, and ResNet50) have been selected for the investigation to detect the Coronavirus-infected patient using chest CT radiographs digital images. The classical data augmentations along with CGAN improve the performance of classification in all selected deep transfer models. The outcomes show that ResNet50 is the most appropriate deep learning model to detect the COVID-19 from limited chest CT dataset using the classical data augmentation with testing accuracy of 82.91%, sensitivity 77.66%, and specificity of 87.62%.",
    "citationCount": 252,
    "pdf_filename": "2020_A_deep_transfer_learning_model_with_clas_6d9a86b2.pdf"
  },
  "7513e1dad29921b4639044fda2b6fd525ff0236c": {
    "paperId": "7513e1dad29921b4639044fda2b6fd525ff0236c",
    "title": "Artificial Intelligence Applications for Industry 4.0: A Literature-Based Study",
    "year": 2021,
    "authors": "M. Javaid, Abid Haleem, R. Singh, R. Suman",
    "abstract": "Artificial intelligence (AI) contributes to the recent developments in Industry 4.0. Industries are focusing on improving product consistency, productivity and reducing operating costs, and they want to achieve this with the collaborative partnership between robotics and people. In smart industries, hyperconnected manufacturing processes depend on different machines that interact using AI automation systems by capturing and interpreting all data types. Smart platforms of automation can play a decisive role in transforming modern production. AI provides appropriate information to take decision-making and alert people of possible malfunctions. Industries will use AI to process data transmitted from the Internet of things (IoT) devices and connected machines based on their desire to integrate them into their equipment. It provides companies with the ability to track their entire end-to-end activities and processes fully. This literature review-based paper aims to brief the vital role of AI in successfully implementing Industry 4.0. Accordingly, the research objectives are crafted to facilitate researchers, practitioners, students and industry professionals in this paper. First, it discusses the significant technological features and traits of AI, critical for Industry 4.0. Second, this paper identifies the significant advancements and various challenges enabling the implementation of AI for Industry 4.0. Finally, the paper identifies and discusses significant applications of AI for Industry 4.0. With an extensive review-based exploration, we see that the advantages of AI are widespread and the need for stakeholders in understanding the kind of automation platform they require in the new manufacturing order. Furthermore, this technology seeks correlations to avoid errors and eventually to anticipate them. Thus, AI technology is gradually accomplishing various goals of Industry 4.0.",
    "citationCount": 296,
    "pdf_filename": "2021_Artificial_Intelligence_Applications_for_7513e1da.pdf"
  },
  "7614bce18df2de3bc0039cd68594b2b8c601da73": {
    "paperId": "7614bce18df2de3bc0039cd68594b2b8c601da73",
    "title": "Unsupervised deep learning for super-resolution reconstruction of turbulence",
    "year": 2020,
    "authors": "Hyojin Kim, Junhyuk Kim, Sungjin Won, Changhoon Lee",
    "abstract": "Abstract Recent attempts to use deep learning for super-resolution reconstruction of turbulent flows have used supervised learning, which requires paired data for training. This limitation hinders more practical applications of super-resolution reconstruction. Therefore, we present an unsupervised learning model that adopts a cycle-consistent generative adversarial network (CycleGAN) that can be trained with unpaired turbulence data for super-resolution reconstruction. Our model is validated using three examples: (i) recovering the original flow field from filtered data using direct numerical simulation (DNS) of homogeneous isotropic turbulence; (ii) reconstructing full-resolution fields using partially measured data from the DNS of turbulent channel flows; and (iii) generating a DNS-resolution flow field from large-eddy simulation (LES) data for turbulent channel flows. In examples (i) and (ii), for which paired data are available for supervised learning, our unsupervised model demonstrates qualitatively and quantitatively similar performance as that of the best supervised learning model. More importantly, in example (iii), where supervised learning is impossible, our model successfully reconstructs the high-resolution flow field of statistical DNS quality from the LES data. Furthermore, we find that the present model has almost universal applicability to all values of Reynolds numbers within the tested range. This demonstrates that unsupervised learning of turbulence data is indeed possible, opening a new door for the wide application of super-resolution reconstruction of turbulent fields.",
    "citationCount": 266,
    "pdf_filename": "2020_Unsupervised_deep_learning_for_super_res_7614bce1.pdf"
  },
  "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563": {
    "paperId": "4fa24cc5b17e8ff1eb5a01fd37a9d267a57ac563",
    "title": "Recipes for Safety in Open-domain Chatbots",
    "year": 2020,
    "authors": "Jing Xu, Da Ju, Margaret Li, Y-Lan Boureau, J. Weston",
    "abstract": "Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior and unwanted biases. We investigate a variety of methods to mitigate these issues in the context of open-domain generative dialogue models. We introduce a new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time. We conduct experiments comparing these methods and find our new techniques are (i) safer than existing models as measured by automatic and human evaluations while (ii) maintaining usability metrics such as engagingness relative to the state of the art. We then discuss the limitations of this work by analyzing failure cases of our models.",
    "citationCount": 243,
    "pdf_filename": "2020_Recipes_for_Safety_in_Open_domain_Chatbo_4fa24cc5.pdf"
  },
  "50cd5d3ee5d55e0111c4ee960e5f79a6f1ea362d": {
    "paperId": "50cd5d3ee5d55e0111c4ee960e5f79a6f1ea362d",
    "title": "GS-WGAN: A Gradient-Sanitized Approach for Learning Differentially Private Generators",
    "year": 2020,
    "authors": "Dingfan Chen, Tribhuvanesh Orekondy, Mario Fritz",
    "abstract": "The wide-spread availability of rich data has fueled the growth of machine learning applications in numerous domains. However, growth in domains with highly-sensitive data (e.g., medical) is largely hindered as the private nature of data prohibits it from being shared. To this end, we propose Gradient-sanitized Wasserstein Generative Adversarial Networks (GS-WGAN), which allows releasing a sanitized form of the sensitive data with rigorous privacy guarantees. In contrast to prior work, our approach is able to distort gradient information more precisely, and thereby enabling training deeper models which generate more informative samples. Moreover, our formulation naturally allows for training GANs in both centralized and federated (i.e., decentralized) data scenarios. Through extensive experiments, we find our approach consistently outperforms state-of-the-art approaches across multiple metrics (e.g., sample quality) and datasets.",
    "citationCount": 203,
    "pdf_filename": "2020_GS_WGAN__A_Gradient_Sanitized_Approach_f_50cd5d3e.pdf"
  },
  "47cbd8cfd6fcba83d3b3714faef480260bc9d5de": {
    "paperId": "47cbd8cfd6fcba83d3b3714faef480260bc9d5de",
    "title": "Likelihood Regret: An Out-of-Distribution Detection Score For Variational Auto-encoder",
    "year": 2020,
    "authors": "Zhisheng Xiao, Qing Yan, Y. Amit",
    "abstract": "Deep probabilistic generative models enable modeling the likelihoods of very high dimensional data. An important application of generative modeling should be the ability to detect out-of-distribution (OOD) samples by setting a threshold on the likelihood. However, a recent study shows that probabilistic generative models can, in some cases, assign higher likelihoods on certain types of OOD samples, making the OOD detection rules based on likelihood threshold problematic. To address this issue, several OOD detection methods have been proposed for deep generative models. In this paper, we make the observation that some of these methods fail when applied to generative models based on Variational Auto-encoders (VAE). As an alternative, we propose Likelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed method over existing approaches, and empirical results suggest that our method obtains the best overall OOD detection performances compared with other OOD method applied on VAE.",
    "citationCount": 211,
    "pdf_filename": "2020_Likelihood_Regret__An_Out_of_Distributio_47cbd8cf.pdf"
  },
  "b48f1a8a99a64346232e4ebb9e4105aeb62a81a2": {
    "paperId": "b48f1a8a99a64346232e4ebb9e4105aeb62a81a2",
    "title": "Style‐Controllable Speech‐Driven Gesture Synthesis Using Normalising Flows",
    "year": 2020,
    "authors": "Simon Alexanderson, G. Henter, Taras Kucherenko, J. Beskow",
    "abstract": "Automatic synthesis of realistic gestures promises to transform the fields of animation, avatars and communicative agents. In off‐line applications, novel tools can alter the role of an animator to that of a director, who provides only high‐level input for the desired animation; a learned network then translates these instructions into an appropriate sequence of body poses. In interactive scenarios, systems for generating natural animations on the fly are key to achieving believable and relatable characters. In this paper we address some of the core issues towards these ends. By adapting a deep learning‐based motion synthesis method called MoGlow, we propose a new generative model for generating state‐of‐the‐art realistic speech‐driven gesticulation. Owing to the probabilistic nature of the approach, our model can produce a battery of different, yet plausible, gestures given the same input speech signal. Just like humans, this gives a rich natural variation of motion. We additionally demonstrate the ability to exert directorial control over the output style, such as gesture level, speed, symmetry and spacial extent. Such control can be leveraged to convey a desired character personality or mood. We achieve all this without any manual annotation of the data. User studies evaluating upper‐body gesticulation confirm that the generated motions are natural and well match the input speech. Our method scores above all prior systems and baselines on these measures, and comes close to the ratings of the original recorded motions. We furthermore find that we can accurately control gesticulation styles without unnecessarily compromising perceived naturalness. Finally, we also demonstrate an application of the same method to full‐body gesticulation, including the synthesis of stepping motion and stance.",
    "citationCount": 202,
    "pdf_filename": "2020_Style_Controllable_Speech_Driven_Gesture_b48f1a8a.pdf"
  },
  "a3d6928a2d1e12f506f6f9ef479bdf0ca68ea849": {
    "paperId": "a3d6928a2d1e12f506f6f9ef479bdf0ca68ea849",
    "title": "PulseGAN: Learning to Generate Realistic Pulse Waveforms in Remote Photoplethysmography",
    "year": 2020,
    "authors": "Rencheng Song, Huan Chen, Juan Cheng, Chang Li, Yu Liu",
    "abstract": "Remote photoplethysmography (rPPG) is a non-contact technique for measuring cardiac signals from facial videos. High-quality rPPG pulse signals are urgently demanded in many fields, such as health monitoring and emotion recognition. However, most of the existing rPPG methods can only be used to get average heart rate (HR) values due to the limitation of inaccurate pulse signals. In this paper, a new framework based on generative adversarial network, called PulseGAN, is introduced to generate realistic rPPG pulse signals through denoising the chrominance (CHROM) signals. Considering that the cardiac signal is quasi-periodic and has apparent time-frequency characteristics, the error losses defined in time and spectrum domains are both employed with the adversarial loss to enforce the model generating accurate pulse waveforms as its reference. The proposed framework is tested on three public databases. The results show that the PulseGAN framework can effectively improve the waveform quality, thereby enhancing the accuracy of HR, the interbeat interval (IBI) and the related heart rate variability (HRV) features. The proposed method significantly improves the quality of waveforms compared to the input CHROM signals, with the mean absolute error of AVNN (the average of all normal-to-normal intervals) reduced by 41.19%, 40.45%, 41.63%, and the mean absolute error of SDNN (the standard deviation of all NN intervals) reduced by 37.53%, 44.29%, 58.41%, in the cross-database test on the UBFC-RPPG, PURE, and MAHNOB-HCI databases, respectively. This framework can be easily integrated with other existing rPPG methods to further improve the quality of waveforms, thereby obtaining more reliable IBI features and extending the application scope of rPPG techniques.",
    "citationCount": 203,
    "pdf_filename": "2020_PulseGAN__Learning_to_Generate_Realistic_a3d6928a.pdf"
  },
  "982e937583efffc247bab32a8f0156863beb22a6": {
    "paperId": "982e937583efffc247bab32a8f0156863beb22a6",
    "title": "Catastrophic forgetting and mode collapse in GANs",
    "year": 2020,
    "authors": "Hoang Thanh-Tung, T. Tran",
    "abstract": "In this paper, we show that Generative Adversarial Networks (GANs) suffer from catastrophic forgetting even when they are trained to approximate a single target distribution. We show that GAN training is a continual learning problem in which the sequence of changing model distributions is the sequence of tasks to the discriminator. The level of mismatch between tasks in the sequence determines the level of forgetting. Catastrophic forgetting is interrelated to mode collapse and can make the training of GANs non-convergent. We investigate the landscape of the discriminator’s output in different variants of GANs and find that when a GAN converges to a good equilibrium, real training datapoints are wide local maxima of the discriminator. We empirically show the relationship between the sharpness of local maxima and mode collapse and generalization in GANs. We show how catastrophic forgetting prevents the discriminator from making real datapoints local maxima, and thus causes non-convergence. Finally, we study methods for preventing catastrophic forgetting in GANs.",
    "citationCount": 248,
    "pdf_filename": "2020_Catastrophic_forgetting_and_mode_collaps_982e9375.pdf"
  },
  "5598872d32fd15e367584eb99c07ae79f794243e": {
    "paperId": "5598872d32fd15e367584eb99c07ae79f794243e",
    "title": "Deep Fake Image Detection Based on Pairwise Learning",
    "year": 2020,
    "authors": "Chih-Chung Hsu, Yi-Xiu Zhuang, Chia-Yen Lee",
    "abstract": "Generative adversarial networks (GANs) can be used to generate a photo-realistic image from a low-dimension random noise. Such a synthesized (fake) image with inappropriate content can be used on social media networks, which can cause severe problems. With the aim to successfully detect fake images, an effective and efficient image forgery detector is necessary. However, conventional image forgery detectors fail to recognize fake images generated by the GAN-based generator since these images are generated and manipulated from the source image. Therefore, in this paper, we propose a deep learning-based approach for detecting the fake images by using the contrastive loss. First, several state-of-the-art GANs are employed to generate the fake–real image pairs. Next, the reduced DenseNet is developed to a two-streamed network structure to allow pairwise information as the input. Then, the proposed common fake feature network is trained using the pairwise learning to distinguish the features between the fake and real images. Finally, a classification layer is concatenated to the proposed common fake feature network to detect whether the input image is fake or real. The experimental results demonstrated that the proposed method significantly outperformed other state-of-the-art fake image detectors.",
    "citationCount": 236,
    "pdf_filename": "2020_Deep_Fake_Image_Detection_Based_on_Pairw_5598872d.pdf"
  },
  "827cd937ffbfd15c536809a8d5d375f791fb107f": {
    "paperId": "827cd937ffbfd15c536809a8d5d375f791fb107f",
    "title": "Deep Learning Approaches Applied to Remote Sensing Datasets for Road Extraction: A State-Of-The-Art Review",
    "year": 2020,
    "authors": "A. Abdollahi, B. Pradhan, N. Shukla, Subrata Chakraborty, A. Alamri",
    "abstract": "One of the most challenging research subjects in remote sensing is feature extraction, such as road features, from remote sensing images. Such an extraction influences multiple scenes, including map updating, traffic management, emergency tasks, road monitoring, and others. Therefore, a systematic review of deep learning techniques applied to common remote sensing benchmarks for road extraction is conducted in this study. The research is conducted based on four main types of deep learning methods, namely, the GANs model, deconvolutional networks, FCNs, and patch-based CNNs models. We also compare these various deep learning models applied to remote sensing datasets to show which method performs well in extracting road parts from high-resolution remote sensing images. Moreover, we describe future research directions and research gaps. Results indicate that the largest reported performance record is related to the deconvolutional nets applied to remote sensing images, and the F1 score metric of the generative adversarial network model, DenseNet method, and FCN-32 applied to UAV and Google Earth images are high: 96.08%, 95.72%, and 94.59%, respectively.",
    "citationCount": 240,
    "pdf_filename": "2020_Deep_Learning_Approaches_Applied_to_Remo_827cd937.pdf"
  },
  "fd78a4e619b02377497dbd7e9439adaff88dfbc4": {
    "paperId": "fd78a4e619b02377497dbd7e9439adaff88dfbc4",
    "title": "DCGAN-Based Data Augmentation for Tomato Leaf Disease Identification",
    "year": 2020,
    "authors": "Qiufeng Wu, Yiping Chen, Jun Meng",
    "abstract": "Tomato leaf disease seriously affects the yield of tomato. It is extremely vital for agricultural economy to identify agricultural diseases. The traditional data augmentation methods, such as rotation, flip and translation, are severely limited, which cannot achieve good generalization results. To improve the recognition accuracy of tomato leaf diseases, a new method of data augmentation by generative adversarial networks (GANs) is proposed for leaf disease recognition in this work. Generated images augmented by deep convolutional generative adversarial networks (DCGAN) and original images as the input of GoogLeNet, this model can achieve a top-1 average identification accuracy of 94.33%. By adjusting the hyper-parameters, modifying the architecture of the convolutional neural networks, and selecting different generative adversarial networks, an improved model for training and testing 5 classes of tomato leaf images was obtained. Meanwhile, images generated by DCGAN not only enlarge the size of the data set, but also have the characteristics of diversity, which makes the model have a good generalization effect. We have also visually confirmed that the images generated by DCGAN have much better quality and are more convincing through the t-Distributed Stochastic Neighbor Embedding (t-SNE) and Visual Turing Test. Experiments with tomato leaf disease identification show that DCGAN can generate data that approximate to real images, which can be used to (1) provide a larger data set for the training of large neural networks, and improve the performance of the recognition model through highly discriminating image generation technology; (2) reduce the cost of data collection; (3) enhance the diversity of data and the generalization ability of the recognition models.",
    "citationCount": 235,
    "pdf_filename": "2020_DCGAN_Based_Data_Augmentation_for_Tomato_fd78a4e6.pdf"
  },
  "cfb6f6f7a2563aa017c33452a936a2b96b9f7872": {
    "paperId": "cfb6f6f7a2563aa017c33452a936a2b96b9f7872",
    "title": "RL-CycleGAN: Reinforcement Learning Aware Simulation-to-Real",
    "year": 2020,
    "authors": "Kanishka Rao, Chris Harris, A. Irpan, S. Levine, Julian Ibarz",
    "abstract": "Deep neural network based reinforcement learning (RL) can learn appropriate visual representations for complex tasks like vision-based robotic grasping without the need for manually engineering or prior learning a perception system. However, data for RL is collected via running an agent in the desired environment, and for applications like robotics, running a robot in the real world may be extremely costly and time consuming. Simulated training offers an appealing alternative, but ensuring that policies trained in simulation can transfer effectively into the real world requires additional machinery. Simulations may not match reality, and typically bridging the simulation-to-reality gap requires domain knowledge and task-specific engineering. We can automate this process by employing generative models to translate simulated images into realistic ones. However, this sort of translation is typically task-agnostic, in that the translated images may not preserve all features that are relevant to the task. In this paper, we introduce the RL-scene consistency loss for image translation, which ensures that the translation operation is invariant with respect to the Q-values associated with the image. This allows us to learn a task-aware translation. Incorporating this loss into unsupervised domain translation, we obtain the RL-CycleGAN, a new approach for simulation-to-real-world transfer for reinforcement learning. In evaluations of RL-CycleGAN on two vision-based robotics grasping tasks, we show that RL-CycleGAN offers a substantial improvement over a number of prior methods for sim-to-real transfer, attaining excellent real-world performance with only a modest number of real-world observations.",
    "citationCount": 212,
    "pdf_filename": "2020_RL_CycleGAN__Reinforcement_Learning_Awar_cfb6f6f7.pdf"
  },
  "29bb2e304c56aa98c471697882023f603daa6e49": {
    "paperId": "29bb2e304c56aa98c471697882023f603daa6e49",
    "title": "Roles and Research Trends of Artificial Intelligence in Mathematics Education: A Bibliometric Mapping Analysis and Systematic Review",
    "year": 2021,
    "authors": "Gwo-jen Hwang, Y. Tu",
    "abstract": "Learning mathematics has been considered as a great challenge for many students. The advancement of computer technologies, in particular, artificial intelligence (AI), provides an opportunity to cope with this problem by diagnosing individual students’ learning problems and providing personalized supports to maximize their learning performances in mathematics courses. However, there is a lack of reviews from diverse perspectives to help researchers, especially novices, gain a whole picture of the research of AI in mathematics education. To this end, this research aims to conduct a bibliometric mapping analysis and systematic review to explore the role and research trends of AI in mathematics education by searching for the relevant articles published in the quality journals indexed by the Social Sciences Citation Index (SSCI) from the Web of Science (WOS) database. Moreover, by referring to the technology-based learning model, several dimensions of AI in mathematics education research, such as the application domains, participants, research methods, adopted technologies, research issues and the roles of AI as well as the citation and co-citation relationships, are taken into account. Accordingly, the advancements of AI in mathematics education research are reported, and potential research topics for future research are recommended.",
    "citationCount": 270,
    "pdf_filename": "2021_Roles_and_Research_Trends_of_Artificial__29bb2e30.pdf"
  },
  "cb8dcaf8e5fe7256577c6bc83e11dd64d8f3ae31": {
    "paperId": "cb8dcaf8e5fe7256577c6bc83e11dd64d8f3ae31",
    "title": "Towards artificial general intelligence via a multimodal foundation model",
    "year": 2021,
    "authors": "Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo",
    "abstract": "The fundamental goal of artificial intelligence (AI) is to mimic the core cognitive activities of human. Despite tremendous success in the AI research, most of existing methods have only single-cognitive ability. To overcome this limitation and take a solid step towards artificial general intelligence (AGI), we develop a foundation model pre-trained with huge multimodal data, which can be quickly adapted for various downstream cognitive tasks. To achieve this goal, we propose to pre-train our foundation model by self-supervised learning with weak semantic correlation data crawled from the Internet and show that promising results can be obtained on a wide range of downstream tasks. Particularly, with the developed model-interpretability tools, we demonstrate that strong imagination ability is now possessed by our foundation model. We believe that our work makes a transformative stride towards AGI, from our common practice of “weak or narrow AI” to that of “strong or generalized AI”. Artificial intelligence approaches inspired by human cognitive function have usually single learned ability. The authors propose a multimodal foundation model that demonstrates the cross-domain learning and adaptation for broad range of downstream cognitive tasks.",
    "citationCount": 272,
    "pdf_filename": "2021_Towards_artificial_general_intelligence__cb8dcaf8.pdf"
  },
  "9bac3c2ccf4b65f5346ed843adb92bd294c092b0": {
    "paperId": "9bac3c2ccf4b65f5346ed843adb92bd294c092b0",
    "title": "A Review on Artificial Intelligence in Education",
    "year": 2021,
    "authors": "Jiahui Huang, S. Saleh, Yufei Liu",
    "abstract": "The emergence of innovative technologies has an impact on the methods of teaching and learning. With the rapid development of artificial intelligence (AI) technology in recent years, using AI in education has become more and more apparent. This article first outlines the application of AI in the field of education, such as adaptive learning, teaching evaluation, virtual classroom, etc. And then analyzes its impact on teaching and learning, which has a positive meaning for improving teachers' teaching level and students' learning quality. Finally, it puts forward the challenges that AI applications may face in education in the future and provides references for AI to promote education reform. \n  \nReceived: 16 January 2021 / Accepted: 24 March 2021 / Published: 10 May 2021",
    "citationCount": 277,
    "pdf_filename": "2021_A_Review_on_Artificial_Intelligence_in_E_9bac3c2c.pdf"
  },
  "1fff265c708488beb59fe3746dccf4344338f31d": {
    "paperId": "1fff265c708488beb59fe3746dccf4344338f31d",
    "title": "Multiple knowledge representation for big data artificial intelligence: framework, applications, and case studies",
    "year": 2021,
    "authors": "Yi Yang, Yueting Zhuang, Yunhe Pan",
    "abstract": "In this paper, we present a multiple knowledge representation (MKR) framework and discuss its potential for developing big data artificial intelligence (AI) techniques with possible broader impacts across different AI areas. Typically, canonical knowledge representations and modern representations each emphasize a particular aspect of transforming inputs into symbolic encoding or vectors. For example, knowledge graphs focus on depicting semantic connections among concepts, whereas deep neural networks (DNNs) are more of a tool to perceive raw signal inputs. MKR is an advanced AI representation framework for more complete intelligent functions, such as raw signal perception, feature extraction and vectorization, knowledge symbolization, and logical reasoning. MKR has two benefits: (1) it makes the current AI techniques (dominated by deep learning) more explainable and generalizable, and (2) it expands current AI techniques by integrating MKR to facilitate the mutual benefits of the complementary capacity of each representation, e.g., raw signal perception and symbolic encoding. We expect that MKR research and its applications will drive the evolution of AI 2.0 and beyond.",
    "citationCount": 265,
    "pdf_filename": "2021_Multiple_knowledge_representation_for_bi_1fff265c.pdf"
  },
  "846f3770219dbdfe260c13070458deec909be914": {
    "paperId": "846f3770219dbdfe260c13070458deec909be914",
    "title": "Lack of Transparency and Potential Bias in Artificial Intelligence Data Sets and Algorithms: A Scoping Review.",
    "year": 2021,
    "authors": "R. Daneshjou, Mary P Smith, Mary D Sun, V. Rotemberg, James Zou",
    "abstract": "Importance\nClinical artificial intelligence (AI) algorithms have the potential to improve clinical care, but fair, generalizable algorithms depend on the clinical data on which they are trained and tested.\n\n\nObjective\nTo assess whether data sets used for training diagnostic AI algorithms addressing skin disease are adequately described and to identify potential sources of bias in these data sets.\n\n\nData Sources\nIn this scoping review, PubMed was used to search for peer-reviewed research articles published between January 1, 2015, and November 1, 2020, with the following paired search terms: deep learning and dermatology, artificial intelligence and dermatology, deep learning and dermatologist, and artificial intelligence and dermatologist.\n\n\nStudy Selection\nStudies that developed or tested an existing deep learning algorithm for triage, diagnosis, or monitoring using clinical or dermoscopic images of skin disease were selected, and the articles were independently reviewed by 2 investigators to verify that they met selection criteria.\n\n\nConsensus Process\nData set audit criteria were determined by consensus of all authors after reviewing existing literature to highlight data set transparency and sources of bias.\n\n\nResults\nA total of 70 unique studies were included. Among these studies, 1 065 291 images were used to develop or test AI algorithms, of which only 257 372 (24.2%) were publicly available. Only 14 studies (20.0%) included descriptions of patient ethnicity or race in at least 1 data set used. Only 7 studies (10.0%) included any information about skin tone in at least 1 data set used. Thirty-six of the 56 studies developing new AI algorithms for cutaneous malignant neoplasms (64.3%) met the gold standard criteria for disease labeling. Public data sets were cited more often than private data sets, suggesting that public data sets contribute more to new development and benchmarks.\n\n\nConclusions and Relevance\nThis scoping review identified 3 issues in data sets that are used to develop and test clinical AI algorithms for skin disease that should be addressed before clinical translation: (1) sparsity of data set characterization and lack of transparency, (2) nonstandard and unverified disease labels, and (3) inability to fully assess patient diversity used for algorithm development and testing.",
    "citationCount": 282,
    "pdf_filename": "2021_Lack_of_Transparency_and_Potential_Bias__846f3770.pdf"
  },
  "12789a8f912a44fd875cefd497920158ea1eb4b6": {
    "paperId": "12789a8f912a44fd875cefd497920158ea1eb4b6",
    "title": "Artificial intelligence in marketing: A systematic literature review",
    "year": 2021,
    "authors": "Srikrishna Chintalapati, S. Pandey",
    "abstract": "The digital transformation fostered by the increasing leverage of artificial intelligence (AI) has been a critical influencing factor unleashing the next wave of enterprise business disruption. Marketing is one of the business streams witnessing this transformation on a very intense scale. Contemporary marketing has begun to experiment with modern, cutting-edge technologies, such as AI, deploying them in mainstream operations to ensure accelerated success. This article explores the use of AI in marketing as an emergent stream of research. Based on inferences from earlier studies, the study categorizes marketing into five distinct functional themes—integrated digital marketing, content marketing, experiential marketing, marketing operations, and market research—and 19 sub-functional themes (activity levers). Across the chosen themes and sub-themes, the study further dovetails into and identifies 170 featured use cases of the extant literature, where AI is leveraged by marketing in delivering superior quality outcomes and experiences. By way of a systematic literature review (SLR), the article evaluates 57 qualifying publications in the context of AI-powered marketing and qualitatively and quantitatively ranks them based on their coverage, impact, relevance, and contributed guidance, and elucidates the findings across various sectors, research contexts, and scenarios. The study discusses the practitioner and academic research implications and proposes a future research agenda to study the continuous transformation fostered by accelerated adoption of AI across the marketing landscape.",
    "citationCount": 254,
    "pdf_filename": "2021_Artificial_intelligence_in_marketing__A__12789a8f.pdf"
  },
  "e7ed51a40d82931b657a4b364c832761cda21e21": {
    "paperId": "e7ed51a40d82931b657a4b364c832761cda21e21",
    "title": "Sustainable Curriculum Planning for Artificial Intelligence Education: A Self-Determination Theory Perspective",
    "year": 2020,
    "authors": "Thomas K. F. Chiu, C. Chai",
    "abstract": "The teaching of artificial intelligence (AI) topics in school curricula is an important global strategic initiative in educating the next generation. As AI technologies are new to K-12 schools, there is a lack of studies that inform schools’ teachers about AI curriculum design. How to prepare and engage teachers, and which approaches are suitable for planning the curriculum for sustainable development, are unclear. Therefore, this case study aimed to explore the views of teachers with and without AI teaching experience on key considerations for the preparation, implementation and continuous refinement of a formal AI curriculum for K-12 schools. It drew on the self-determination theory (SDT) and four basic curriculum planning approaches—content, product, process and praxis—as theoretical frameworks to explain the research problems and findings. We conducted semi-structured interviews with 24 teachers—twelve with and twelve without experience in teaching AI—and used thematic analysis to analyze the interview data. Our findings revealed that genuine curriculum creation should encompass all four forms of curriculum design approach that are coordinated by teachers’ self-determination to be orchestrators of student learning experiences. This study also proposed a curriculum development cycle for teachers and curriculum officers.",
    "citationCount": 287,
    "pdf_filename": "2020_Sustainable_Curriculum_Planning_for_Arti_e7ed51a4.pdf"
  },
  "a38b2e656c65fdf8e5bf6ca498db54525ad794d7": {
    "paperId": "a38b2e656c65fdf8e5bf6ca498db54525ad794d7",
    "title": "Occupational, industry, and geographic exposure to artificial intelligence: A novel dataset and its potential uses",
    "year": 2021,
    "authors": "E. Felten, Manav Raj, Robert C. Seamans",
    "abstract": "We create and validate a new measure of an occupation’s exposure to AI that we call the AI Occupational Exposure (AIOE). We use the AIOE to construct a measure of AI exposure at the industry level, which we call the AI Industry Exposure (AIIE) and a measure of AI exposure at the county level, which we call the AI Geographic Exposure (AIGE). We also describe several ways in which the AIOE can be used to create firm level measures of AI exposure. We validate the measures and describe how they can be used in different applications by management, organization and strategy scholars.",
    "citationCount": 228,
    "pdf_filename": "2021_Occupational__industry__and_geographic_e_a38b2e65.pdf"
  },
  "73c4417142eea24e290bf574de653fcc9604c591": {
    "paperId": "73c4417142eea24e290bf574de653fcc9604c591",
    "title": "Cognitive Challenges in Human-Artificial Intelligence Collaboration: Investigating the Path Toward Productive Delegation",
    "year": 2021,
    "authors": "A. Fügener, Jörn Grahl, Alok Gupta, W. Ketter",
    "abstract": "A consensus is beginning to emerge that the next phase of artificial intelligence (AI) induction in business organizations will require humans to work with AI in a variety of work arrangements. This article explores the issues related to human capabilities to work with AI. A key to working in many work arrangements is the ability to delegate work to entities that can do them most efficiently. Modern AI can do a remarkable job of efficient delegation to humans because it knows what it knows well and what it does not. Humans, on the other hand, are poor judges of their metaknowledge and are not good at delegating knowledge work to AI—this might prove to be a big stumbling block to create work environments where humans and AI work together. Humans have often created machines to serve them. The sentiment is perhaps exemplified by Oscar Wilde’s statement that “civilization requires slaves…. Human slavery is wrong, insecure and demoralizing. On mechanical slavery, on the slavery of the machine, the future of the world depends.” However, the time has come when humans might switch roles with machines. Our study highlights capabilities that humans need to effectively work with AI and still be in control rather than just being directed.",
    "citationCount": 245,
    "pdf_filename": "2021_Cognitive_Challenges_in_Human_Artificial_73c44171.pdf"
  },
  "51e4168a4df555a3b106cd05a62f4737dbd43f6e": {
    "paperId": "51e4168a4df555a3b106cd05a62f4737dbd43f6e",
    "title": "Impact of artificial intelligence on human loss in decision making, laziness and safety in education",
    "year": 2023,
    "authors": "S. Ahmad, Heesup Han, Muhammad Mansoor Alam, Mohd. Khairul Rehmat, Muhammad Irshad",
    "abstract": "This study examines the impact of artificial intelligence (AI) on loss in decision-making, laziness, and privacy concerns among university students in Pakistan and China. Like other sectors, education also adopts AI technologies to address modern-day challenges. AI investment will grow to USD 253.82 million from 2021 to 2025. However, worryingly, researchers and institutions across the globe are praising the positive role of AI but ignoring its concerns. This study is based on qualitative methodology using PLS-Smart for the data analysis. Primary data was collected from 285 students from different universities in Pakistan and China. The purposive Sampling technique was used to draw the sample from the population. The data analysis findings show that AI significantly impacts the loss of human decision-making and makes humans lazy. It also impacts security and privacy. The findings show that 68.9% of laziness in humans, 68.6% in personal privacy and security issues, and 27.7% in the loss of decision-making are due to the impact of artificial intelligence in Pakistani and Chinese society. From this, it was observed that human laziness is the most affected area due to AI. However, this study argues that significant preventive measures are necessary before implementing AI technology in education. Accepting AI without addressing the major human concerns would be like summoning the devils. Concentrating on justified designing and deploying and using AI for education is recommended to address the issue.",
    "citationCount": 245,
    "pdf_filename": "2023_Impact_of_artificial_intelligence_on_hum_51e4168a.pdf"
  },
  "22a15985ac8eb2ee4ba92f17d2a76039a603d482": {
    "paperId": "22a15985ac8eb2ee4ba92f17d2a76039a603d482",
    "title": "A Systematic Review of Digital Technology Adoption in Off-Site Construction: Current Status and Future Direction towards Industry 4.0",
    "year": 2020,
    "authors": "Mudan Wang, C. Wang, S. Sepasgozar, S. Zlatanova",
    "abstract": "Off-site construction (OSC) is known as an efficient construction method that could save time and cost, reduce waste of resources, and improve the overall productivity of projects. Coupled with digital technologies associated with the Industry 4.0 concept, OSC can offer a higher rate of productivity and safety. While there is a rich literature focusing on both OSC and Industry 4.0, the implementation of associated digital technologies in the OSC context has not been fully evaluated. This paper intends to evaluate the current literature of digital technology applications in OSC. Scientometric analyses and a systematic review were carried out evaluating fifteen typical digital technologies adopted by OSC projects, including building information modelling (BIM), radio frequency identification devices (RFID), global positioning systems (GPS), the Internet of Things (IoT), geographic information systems (GIS), sensors, augmented reality (AR), virtual reality (VR), photogrammetry, laser scanning, artificial intelligence (AI), 3D printing, robotics, big data, and blockchain. This review formulates a clear picture of the current practice of these digital technologies and summarizes the main area of application and limitations of each technology when utilized in OSC. The review also points out their potential and how they can be better adopted to improve OSC practice in the future.",
    "citationCount": 276,
    "pdf_filename": "2020_A_Systematic_Review_of_Digital_Technolog_22a15985.pdf"
  },
  "78814b1b5699796733afc871c277df056d0e28fa": {
    "paperId": "78814b1b5699796733afc871c277df056d0e28fa",
    "title": "Artificial Intelligence and Entrepreneurship: Implications for Venture Creation in the Fourth Industrial Revolution",
    "year": 2020,
    "authors": "Dominic Chalmers, Niall G. MacKenzie, S. Carter",
    "abstract": "This article explores the ways artificial intelligence (AI) may impact new venture processes, practices and outcomes. We examine how such technology will augment and replace tasks associated with idea production, selling, and scaling. These changes entail new ways of working, and we consider implications for the organizational design of entrepreneurial ventures. While AI can enhance entrepreneurial activities, liabilities stem from this technological leverage. We advance a research agenda that draws attention towards negative social and economic implications of AI, particularly for more traditional small firms at risk of disintermediation in an AI economy.",
    "citationCount": 291,
    "pdf_filename": "2020_Artificial_Intelligence_and_Entrepreneur_78814b1b.pdf"
  },
  "600f39fcedee486f3fd5a261c67a6d12dd16da4e": {
    "paperId": "600f39fcedee486f3fd5a261c67a6d12dd16da4e",
    "title": "Accessing Artificial Intelligence for Clinical Decision-Making",
    "year": 2021,
    "authors": "C. Giordano, M. Brennan, Basma Mohamed, Parisa Rashidi, François Modave",
    "abstract": "Advancements in computing and data from the near universal acceptance and implementation of electronic health records has been formative for the growth of personalized, automated, and immediate patient care models that were not previously possible. Artificial intelligence (AI) and its subfields of machine learning, reinforcement learning, and deep learning are well-suited to deal with such data. The authors in this paper review current applications of AI in clinical medicine and discuss the most likely future contributions that AI will provide to the healthcare industry. For instance, in response to the need to risk stratify patients, appropriately cultivated and curated data can assist decision-makers in stratifying preoperative patients into risk categories, as well as categorizing the severity of ailments and health for non-operative patients admitted to hospitals. Previous overt, traditional vital signs and laboratory values that are used to signal alarms for an acutely decompensating patient may be replaced by continuously monitoring and updating AI tools that can pick up early imperceptible patterns predicting subtle health deterioration. Furthermore, AI may help overcome challenges with multiple outcome optimization limitations or sequential decision-making protocols that limit individualized patient care. Despite these tremendously helpful advancements, the data sets that AI models train on and develop have the potential for misapplication and thereby create concerns for application bias. Subsequently, the mechanisms governing this disruptive innovation must be understood by clinical decision-makers to prevent unnecessary harm. This need will force physicians to change their educational infrastructure to facilitate understanding AI platforms, modeling, and limitations to best acclimate practice in the age of AI. By performing a thorough narrative review, this paper examines these specific AI applications, limitations, and requisites while reviewing a few examples of major data sets that are being cultivated and curated in the US.",
    "citationCount": 219,
    "pdf_filename": "2021_Accessing_Artificial_Intelligence_for_Cl_600f39fc.pdf"
  },
  "c2c499cbef33d76f1f06795496a2c785fb3f6152": {
    "paperId": "c2c499cbef33d76f1f06795496a2c785fb3f6152",
    "title": "Mediating effect of use perceptions on technology readiness and adoption of artificial intelligence in accounting",
    "year": 2021,
    "authors": "Hassan Damerji, Anwar Y. Salimi",
    "abstract": "ABSTRACT The use of Artificial Intelligence (AI) is growing rapidly in accounting practice, and firms desire new hires who have adopted this technology. Universities can prepare students to adopt AI. The purpose of this quantitative study was to examine whether perceived ease of use (PEOU) and perceived usefulness (PU) have an effect on the relationship between accounting students’ level of technology readiness and their decision to adopt AI. The study involved an examination of individual students’ perceptions of technology readiness and technology adoption. An online questionnaire consisting of 31 items gathering demographic information and perceptions of technology readiness, technology adoption, PEOU, and PU was administered to student participants. The findings from the study indicated that technology readiness has a significant influence on technology adoption. However, mediation analysis using hierarchical regression showed that the relationship between technology readiness and technology adoption of Artificial Intelligence is affected by both PEOU and PU.",
    "citationCount": 209,
    "pdf_filename": "2021_Mediating_effect_of_use_perceptions_on_t_c2c499cb.pdf"
  },
  "415c0ab71cd8d913b02bdcf7204a4bdcd70994ff": {
    "paperId": "415c0ab71cd8d913b02bdcf7204a4bdcd70994ff",
    "title": "Artificial Intelligence in Education (AIEd): a high-level academic and industry note 2021",
    "year": 2021,
    "authors": "Muhammad Ali Chaudhry, Emre Kazim",
    "abstract": "In the past few decades, technology has completely transformed the world around us. Indeed, experts believe that the next big digital transformation in how we live, communicate, work, trade and learn will be driven by Artificial Intelligence (AI) [83]. This paper presents a high-level industrial and academic overview of AI in Education (AIEd). It presents the focus of latest research in AIEd on reducing teachers’ workload, contextualized learning for students, revolutionizing assessments and developments in intelligent tutoring systems. It also discusses the ethical dimension of AIEd and the potential impact of the Covid-19 pandemic on the future of AIEd’s research and practice. The intended readership of this article is policy makers and institutional leaders who are looking for an introductory state of play in AIEd.",
    "citationCount": 211,
    "pdf_filename": "2021_Artificial_Intelligence_in_Education__AI_415c0ab7.pdf"
  },
  "97029b53d0252ea68472423dea33e5aa2316926d": {
    "paperId": "97029b53d0252ea68472423dea33e5aa2316926d",
    "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion Model",
    "year": 2022,
    "authors": "Xingqian Xu, Zhangyang Wang, Eric Zhang, Kai Wang, Humphrey Shi",
    "abstract": "Recent advances in diffusion models have set an impressive milestone in many generation tasks, and trending works such as DALL-E2, Imagen, and Stable Diffusion have attracted great interest. Despite the rapid landscape changes, recent new approaches focus on extensions and performance rather than capacity, thus requiring separate models for separate tasks. In this work, we expand the existing single-flow diffusion pipeline into a multi-task multimodal network, dubbed Versatile Diffusion (VD), that handles multiple flows of text-to-image, image-to-text, and variations in one unified model. The pipeline design of VD instantiates a unified multi-flow diffusion framework, consisting of sharable and swappable layer modules that enable the crossmodal generality beyond images and text. Through extensive experiments, we demonstrate that VD successfully achieves the following: a) VD outperforms the baseline approaches and handles all its base tasks with competitive quality; b) VD enables novel extensions such as disentanglement of style and semantics, dual- and multi-context blending, etc.; c) The success of our multi-flow multimodal framework over images and text may inspire further diffusion-based universal AI research. Our code and models are open-sourced at https://github.com/SHI-Labs/Versatile-Diffusion.",
    "citationCount": 238,
    "pdf_filename": "2022_Versatile_Diffusion__Text__Images_and_Va_97029b53.pdf"
  },
  "49f905eb03958c7cfae52ac759ea8978b8b2a6ea": {
    "paperId": "49f905eb03958c7cfae52ac759ea8978b8b2a6ea",
    "title": "Alignment of Language Agents",
    "year": 2021,
    "authors": "Zachary Kenton, Tom Everitt, Laura Weidinger, Iason Gabriel, Vladimir Mikulik",
    "abstract": "For artificial intelligence to be beneficial to humans the behaviour of AI agents needs to be aligned with what humans want. In this paper we discuss some behavioural issues for language agents, arising from accidental misspecification by the system designer. We highlight some ways that misspecification can occur and discuss some behavioural issues that could arise from misspecification, including deceptive or manipulative language, and review some approaches for avoiding these issues.",
    "citationCount": 200,
    "pdf_filename": "2021_Alignment_of_Language_Agents_49f905eb.pdf"
  },
  "0945860de08f9f5dcb724a54b9c5c14c107d60ee": {
    "paperId": "0945860de08f9f5dcb724a54b9c5c14c107d60ee",
    "title": "Artificial Intelligence as Augmenting Automation: Implications for Employment",
    "year": 2020,
    "authors": "F. Tschang, Esteve Almirall Mezquita",
    "abstract": "There has been great concern in recent years that artificial intelligence (AI) may cause widespread unemployment, but proponents say that AI augments existing jobs. Both of these positions have sub...",
    "citationCount": 261,
    "pdf_filename": "2020_Artificial_Intelligence_as_Augmenting_Au_0945860d.pdf"
  },
  "db7fdce14b3a8fff465dcbab844c4a5a7756f555": {
    "paperId": "db7fdce14b3a8fff465dcbab844c4a5a7756f555",
    "title": "Role of Artificial Intelligence Applications in Real-Life Clinical Practice: Systematic Review",
    "year": 2020,
    "authors": "Jiamin Yin, K. Ngiam, H. Teo",
    "abstract": "BACKGROUND\nArtificial intelligence (AI) applications are growing at an unprecedented pace in health care, including disease diagnosis, triage or screening, risk analysis, surgical operations, and so forth. Despite a great deal of research in the development and validation of health care AI, only few applications have been actually implemented at the frontlines of clinical practice.\n\n\nOBJECTIVE\nThe objective of this study was to systematically review AI applications that have been implemented in real-life clinical practice.\n\n\nMETHODS\nWe conducted a literature search in PubMed, Embase, Cochrane Central, and CINAHL to identify relevant articles published between January 2010 and May 2020. We also hand searched premier computer science journals and conferences as well as registered clinical trials. Studies were included if they reported AI applications that had been implemented in real-world clinical settings.\n\n\nRESULTS\nWe identified 51 relevant studies that reported the implementation and evaluation of AI applications in clinical practice, of which 13 adopted a randomized controlled trial design and eight adopted an experimental design. The AI applications targeted various clinical tasks, such as screening or triage (n=16), disease diagnosis (n=16), risk analysis (n=14), and treatment (n=7). The most commonly addressed diseases and conditions were sepsis (n=6), breast cancer (n=5), diabetic retinopathy (n=4), and polyp and adenoma (n=4). Regarding the evaluation outcomes, we found that 26 studies examined the performance of AI applications in clinical settings, 33 studies examined the effect of AI applications on clinician outcomes, 14 studies examined the effect on patient outcomes, and one study examined the economic impact associated with AI implementation.\n\n\nCONCLUSIONS\nThis review indicates that research on the clinical implementation of AI applications is still at an early stage despite the great potential. More research needs to assess the benefits and challenges associated with clinical AI applications through a more rigorous methodology.",
    "citationCount": 260,
    "pdf_filename": "2020_Role_of_Artificial_Intelligence_Applicat_db7fdce1.pdf"
  },
  "b68b3ae4fde4cff909422bb51c2e03ba10ecbbae": {
    "paperId": "b68b3ae4fde4cff909422bb51c2e03ba10ecbbae",
    "title": "Artificial intelligence and machine learning‐aided drug discovery in central nervous system diseases: State‐of‐the‐arts and future directions",
    "year": 2020,
    "authors": "Sezen Vatansever, A. Schlessinger, Daniel Wacker, H. Kaniskan, Jian Jin",
    "abstract": "Neurological disorders significantly outnumber diseases in other therapeutic areas. However, developing drugs for central nervous system (CNS) disorders remains the most challenging area in drug discovery, accompanied with the long timelines and high attrition rates. With the rapid growth of biomedical data enabled by advanced experimental technologies, artificial intelligence (AI) and machine learning (ML) have emerged as an indispensable tool to draw meaningful insights and improve decision making in drug discovery. Thanks to the advancements in AI and ML algorithms, now the AI/ML‐driven solutions have an unprecedented potential to accelerate the process of CNS drug discovery with better success rate. In this review, we comprehensively summarize AI/ML‐powered pharmaceutical discovery efforts and their implementations in the CNS area. After introducing the AI/ML models as well as the conceptualization and data preparation, we outline the applications of AI/ML technologies to several key procedures in drug discovery, including target identification, compound screening, hit/lead generation and optimization, drug response and synergy prediction, de novo drug design, and drug repurposing. We review the current state‐of‐the‐art of AI/ML‐guided CNS drug discovery, focusing on blood–brain barrier permeability prediction and implementation into therapeutic discovery for neurological diseases. Finally, we discuss the major challenges and limitations of current approaches and possible future directions that may provide resolutions to these difficulties.",
    "citationCount": 250,
    "pdf_filename": "2020_Artificial_intelligence_and_machine_lear_b68b3ae4.pdf"
  },
  "09f1b39a2e92860acb5ad6506766ca863e751e8e": {
    "paperId": "09f1b39a2e92860acb5ad6506766ca863e751e8e",
    "title": "Out of the laboratory and into the classroom: the future of artificial intelligence in education",
    "year": 2020,
    "authors": "Daniel S. Schiff",
    "abstract": "Like previous educational technologies, artificial intelligence in education (AIEd) threatens to disrupt the status quo, with proponents highlighting the potential for efficiency and democratization, and skeptics warning of industrialization and alienation. However, unlike frequently discussed applications of AI in autonomous vehicles, military and cybersecurity concerns, and healthcare, AI’s impacts on education policy and practice have not yet captured the public’s attention. This paper, therefore, evaluates the status of AIEd, with special attention to intelligent tutoring systems and anthropomorphized artificial educational agents. I discuss AIEd’s purported capacities, including the abilities to simulate teachers, provide robust student differentiation, and even foster socio-emotional engagement. Next, to situate developmental pathways for AIEd going forward, I contrast sociotechnical possibilities and risks through two idealized futures. Finally, I consider a recent proposal to use peer review as a gatekeeping strategy to prevent harmful research. This proposal serves as a jumping off point for recommendations to AIEd stakeholders towards improving their engagement with socially responsible research and implementation of AI in educational systems.",
    "citationCount": 208,
    "pdf_filename": "2020_Out_of_the_laboratory_and_into_the_class_09f1b39a.pdf"
  },
  "2618e0319a724f0cd9ba5edade429aec77a01b4d": {
    "paperId": "2618e0319a724f0cd9ba5edade429aec77a01b4d",
    "title": "Artificial Intelligence in Organizations: Current State and Future Opportunities",
    "year": 2020,
    "authors": "Hind Benbya, T. Davenport, S. Pachidi",
    "abstract": "Artificial intelligence (AI) is currently viewed as the most important and disruptive new technology for large organizations. However, the technology is still in a relatively early state in large enterprises, and largely absent from smaller ones other than technology startups. Surveys suggest that fewer than half of large organizations have meaningful AI initiatives underway, although the percentage is increasing over time. This essay titled “AI in organizations: current state and future opportunities” details current challenges and implications that might arise from AI applications, and the ways to overcome such challenges to realize the potential of this emerging technology. First, the paper provide a brief history of AI and an overview of AI typologies. We discuss current challenges, implications and future opportunities regarding AI. Finally, we summarize the special issue articles and highlight the contributions each makes.",
    "citationCount": 228,
    "pdf_filename": "2020_Artificial_Intelligence_in_Organizations_2618e031.pdf"
  },
  "02471925d8cd9cc14bfb575bd8ef2ded74d2e86f": {
    "paperId": "02471925d8cd9cc14bfb575bd8ef2ded74d2e86f",
    "title": "Artificial intelligence, transparency, and public decision-making",
    "year": 2020,
    "authors": "Karl de Fine Licht, Jenny de Fine Licht",
    "abstract": "The increasing use of Artificial Intelligence (AI) for making decisions in public affairs has sparked a lively debate on the benefits and potential harms of self-learning technologies, ranging from the hopes of fully informed and objectively taken decisions to fear for the destruction of mankind. To prevent the negative outcomes and to achieve accountable systems, many have argued that we need to open up the “black box” of AI decision-making and make it more transparent. Whereas this debate has primarily focused on how transparency can secure high-quality, fair, and reliable decisions, far less attention has been devoted to the role of transparency when it comes to how the general public come to perceive AI decision-making as legitimate and worthy of acceptance. Since relying on coercion is not only normatively problematic but also costly and highly inefficient, perceived legitimacy is fundamental to the democratic system. This paper discusses how transparency in and about AI decision-making can affect the public’s perception of the legitimacy of decisions and decision-makers and produce a framework for analyzing these questions. We argue that a limited form of transparency that focuses on providing justifications for decisions has the potential to provide sufficient ground for perceived legitimacy without producing the harms full transparency would bring.",
    "citationCount": 203,
    "pdf_filename": "2020_Artificial_intelligence__transparency__a_02471925.pdf"
  },
  "51bb51b06f57fada5d8f338aa484a87f93226468": {
    "paperId": "51bb51b06f57fada5d8f338aa484a87f93226468",
    "title": "Accelerating materials discovery using artificial intelligence, high performance computing and robotics",
    "year": 2022,
    "authors": "Edward O. Pyzer-Knapp, J. Pitera, P. Staar, Seiji Takeda, T. Laino",
    "abstract": "New tools enable new ways of working, and materials science is no exception. In materials discovery, traditional manual, serial, and human-intensive work is being augmented by automated, parallel, and iterative processes driven by Artificial Intelligence (AI), simulation and experimental automation. In this perspective, we describe how these new capabilities enable the acceleration and enrichment of each stage of the discovery cycle. We show, using the example of the development of a novel chemically amplified photoresist, how these technologies’ impacts are amplified when they are used in concert with each other as powerful, heterogeneous workflows.",
    "citationCount": 296,
    "pdf_filename": "2022_Accelerating_materials_discovery_using_a_51bb51b0.pdf"
  },
  "11b4b30b567fe9251852c9a628eda6e0134d3b15": {
    "paperId": "11b4b30b567fe9251852c9a628eda6e0134d3b15",
    "title": "Learning Gradient Fields for Molecular Conformation Generation",
    "year": 2021,
    "authors": "Chence Shi, Shitong Luo, Minkai Xu, Jian Tang",
    "abstract": "We study a fundamental problem in computational chemistry known as molecular conformation generation, trying to predict stable 3D structures from 2D molecular graphs. Existing machine learning approaches usually first predict distances between atoms and then generate a 3D structure satisfying the distances, where noise in predicted distances may induce extra errors during 3D coordinate generation. Inspired by the traditional force field methods for molecular dynamics simulation, in this paper, we propose a novel approach called ConfGF by directly estimating the gradient fields of the log density of atomic coordinates. The estimated gradient fields allow directly generating stable conformations via Langevin dynamics. However, the problem is very challenging as the gradient fields are roto-translation equivariant. We notice that estimating the gradient fields of atomic coordinates can be translated to estimating the gradient fields of interatomic distances, and hence develop a novel algorithm based on recent score-based generative models to effectively estimate these gradients. Experimental results across multiple tasks show that ConfGF outperforms previous state-of-the-art baselines by a significant margin.",
    "citationCount": 237,
    "pdf_filename": "2021_Learning_Gradient_Fields_for_Molecular_C_11b4b30b.pdf"
  },
  "ccd561625ae82694965d6cbc724086d5f0e00db9": {
    "paperId": "ccd561625ae82694965d6cbc724086d5f0e00db9",
    "title": "Human activity recognition in artificial intelligence framework: a narrative review",
    "year": 2022,
    "authors": "Neha Gupta, S. Gupta, R. K. Pathak, Vanita Jain, P. Rashidi",
    "abstract": "Human activity recognition (HAR) has multifaceted applications due to its worldly usage of acquisition devices such as smartphones, video cameras, and its ability to capture human activity data. While electronic devices and their applications are steadily growing, the advances in Artificial intelligence (AI) have revolutionized the ability to extract deep hidden information for accurate detection and its interpretation. This yields a better understanding of rapidly growing acquisition devices, AI, and applications, the three pillars of HAR under one roof. There are many review articles published on the general characteristics of HAR, a few have compared all the HAR devices at the same time, and few have explored the impact of evolving AI architecture. In our proposed review, a detailed narration on the three pillars of HAR is presented covering the period from 2011 to 2021. Further, the review presents the recommendations for an improved HAR design, its reliability, and stability. Five major findings were: (1) HAR constitutes three major pillars such as devices, AI and applications; (2) HAR has dominated the healthcare industry; (3) Hybrid AI models are in their infancy stage and needs considerable work for providing the stable and reliable design. Further, these trained models need solid prediction, high accuracy, generalization, and finally, meeting the objectives of the applications without bias; (4) little work was observed in abnormality detection during actions; and (5) almost no work has been done in forecasting actions. We conclude that: (a) HAR industry will evolve in terms of the three pillars of electronic devices, applications and the type of AI. (b) AI will provide a powerful impetus to the HAR industry in future.",
    "citationCount": 220,
    "pdf_filename": "2022_Human_activity_recognition_in_artificial_ccd56162.pdf"
  },
  "63d2f88b6d3d912d5898b18e8c796c19779d4823": {
    "paperId": "63d2f88b6d3d912d5898b18e8c796c19779d4823",
    "title": "Deep learning in drug discovery: an integrative review and future challenges",
    "year": 2022,
    "authors": "Heba Askr, Enas Elgeldawi, Heba Aboul Ella, Y. Elshaier, M. Gomaa",
    "abstract": "Recently, using artificial intelligence (AI) in drug discovery has received much attention since it significantly shortens the time and cost of developing new drugs. Deep learning (DL)-based approaches are increasingly being used in all stages of drug development as DL technology advances, and drug-related data grows. Therefore, this paper presents a systematic Literature review (SLR) that integrates the recent DL technologies and applications in drug discovery Including, drug–target interactions (DTIs), drug–drug similarity interactions (DDIs), drug sensitivity and responsiveness, and drug-side effect predictions. We present a review of more than 300 articles between 2000 and 2022. The benchmark data sets, the databases, and the evaluation measures are also presented. In addition, this paper provides an overview of how explainable AI (XAI) supports drug discovery problems. The drug dosing optimization and success stories are discussed as well. Finally, digital twining (DT) and open issues are suggested as future research challenges for drug discovery problems. Challenges to be addressed, future research directions are identified, and an extensive bibliography is also included.",
    "citationCount": 232,
    "pdf_filename": "2022_Deep_learning_in_drug_discovery__an_inte_63d2f88b.pdf"
  },
  "50295e262d2c7c89d7f5aae28503f2efd294e5a5": {
    "paperId": "50295e262d2c7c89d7f5aae28503f2efd294e5a5",
    "title": "An evolution-based model for designing chorismate mutase enzymes",
    "year": 2020,
    "authors": "W. P. Russ, M. Figliuzzi, Christian Stocker, Pierre Barrat-Charlaix, M. Socolich",
    "abstract": "Learning from evolution Protein sequences contain information specifying their three-dimensional structure and function, and statistical analysis of families of sequences has been used to predict these properties. Building from sequence data, Russ et al. used statistical models that take into account conservation at amino acid positions and correlations in the evolution of pairs of amino acids to predict new artificial sequences that will have the properties of the protein family. For the chorismate mutase family of metabolic enzymes, the authors demonstrate experimentally that the artificial sequences display natural-like catalytic function. Because the models access an enormous space of diverse sequences, such evolution-based statistical approaches may guide the search for functional proteins with altered chemical activities. Science, this issue p. 440 An evolution-based, data-driven engineering process can build artificial functional enzymes. The rational design of enzymes is an important goal for both fundamental and practical reasons. Here, we describe a process to learn the constraints for specifying proteins purely from evolutionary sequence data, design and build libraries of synthetic genes, and test them for activity in vivo using a quantitative complementation assay. For chorismate mutase, a key enzyme in the biosynthesis of aromatic amino acids, we demonstrate the design of natural-like catalytic function with substantial sequence diversity. Further optimization focuses the generative model toward function in a specific genomic context. The data show that sequence-based statistical models suffice to specify proteins and provide access to an enormous space of functional sequences. This result provides a foundation for a general process for evolution-based design of artificial proteins.",
    "citationCount": 258,
    "pdf_filename": "2020_An_evolution_based_model_for_designing_c_50295e26.pdf"
  },
  "2ebd5df74980a37370b0bcdf16deff958289c041": {
    "paperId": "2ebd5df74980a37370b0bcdf16deff958289c041",
    "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities",
    "year": 2023,
    "authors": "Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, P. Abbeel",
    "abstract": "Foundation models pretrained on diverse data at scale have demonstrated extraordinary capabilities in a wide range of vision and language tasks. When such models are deployed in real world environments, they inevitably interface with other entities and agents. For example, language models are often used to interact with human beings through dialogue, and visual perception models are used to autonomously navigate neighborhood streets. In response to these developments, new paradigms are emerging for training foundation models to interact with other agents and perform long-term reasoning. These paradigms leverage the existence of ever-larger datasets curated for multimodal, multitask, and generalist interaction. Research at the intersection of foundation models and decision making holds tremendous promise for creating powerful new systems that can interact effectively across a diverse range of applications such as dialogue, autonomous driving, healthcare, education, and robotics. In this manuscript, we examine the scope of foundation models for decision making, and provide conceptual tools and technical background for understanding the problem space and exploring new research directions. We review recent approaches that ground foundation models in practical decision making applications through a variety of methods such as prompting, conditional generative modeling, planning, optimal control, and reinforcement learning, and discuss common challenges and open problems in the field.",
    "citationCount": 205,
    "pdf_filename": "2023_Foundation_Models_for_Decision_Making__P_2ebd5df7.pdf"
  },
  "822964fa693ed2ee57515cdf4bc1c4c634ed412d": {
    "paperId": "822964fa693ed2ee57515cdf4bc1c4c634ed412d",
    "title": "The impact of a virtual teaching assistant (chatbot) on students' learning in Ghanaian higher education",
    "year": 2022,
    "authors": "H. B. Essel, D. Vlachopoulos, A. Tachie-Menson, Esi Eduafua Johnson, Papa Kwame Baah",
    "abstract": "Chatbot usage is evolving rapidly in various fields, including higher education. The present study’s purpose is to discuss the effect of a virtual teaching assistant (chatbot) that automatically responds to a student’s question. A pretest–posttest design was implemented, with the 68 participating undergraduate students being randomly allocated to scenarios representing a 2 × 2 design (experimental and control cohorts). Data was garnered utilizing an academic achievement test and focus groups, which allowed more in depth analysis of the students’ experience with the chatbot. The results of the study demonstrated that the students who interacted with the chatbot performed better academically comparing to those who interacted with the course instructor. Besides, the focus group data garnered from the experimental cohort illustrated that they were confident about the chatbot’s integration into the course. The present study essentially focused on the learning of the experimental cohort and their view regarding interaction with the chatbot. This study contributes the emerging artificial intelligence (AI) chatbot literature to improve student academic performance. To our knowledge, this is the first study in Ghana to integrate a chatbot to engage undergraduate students. This study provides critical information on the use and development of virtual teaching assistants using a zero-coding technique, which is the most suitable approach for organizations with limited financial and human resources.",
    "citationCount": 280,
    "pdf_filename": "2022_The_impact_of_a_virtual_teaching_assista_822964fa.pdf"
  },
  "66476832701361c9f9b2a7eb2354ee8cd9f72e67": {
    "paperId": "66476832701361c9f9b2a7eb2354ee8cd9f72e67",
    "title": "Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models",
    "year": 2022,
    "authors": "Yinlin Deng, Chun Xia, Haoran Peng, Chenyuan Yang, Lingming Zhang",
    "abstract": "Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations. To address these limitations, we propose TitanFuzz – the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38%/50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs. This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.",
    "citationCount": 276,
    "pdf_filename": "2022_Large_Language_Models_Are_Zero_Shot_Fuzz_66476832.pdf"
  },
  "a129b8ce13b257f19384c4b7ca6c207c9343e366": {
    "paperId": "a129b8ce13b257f19384c4b7ca6c207c9343e366",
    "title": "Equivariant 3D-conditional diffusion model for molecular linker design",
    "year": 2022,
    "authors": "Ilia Igashov, Hannes Stärk, Clément Vignac, Arne Schneuing, Victor Garcia Satorras",
    "abstract": "Fragment-based drug discovery has been an effective paradigm in early-stage drug development. An open challenge in this area is designing linkers between disconnected molecular fragments of interest to obtain chemically relevant candidate drug molecules. In this work, we propose DiffLinker, an E(3)-equivariant three-dimensional conditional diffusion model for molecular linker design. Given a set of disconnected fragments, our model places missing atoms in between and designs a molecule incorporating all the initial fragments. Unlike previous approaches that are only able to connect pairs of molecular fragments, our method can link an arbitrary number of fragments. Additionally, the model automatically determines the number of atoms in the linker and its attachment points to the input fragments. We demonstrate that DiffLinker outperforms other methods on the standard datasets, generating more diverse and synthetically accessible molecules. We experimentally test our method in real-world applications, showing that it can successfully generate valid linkers conditioned on target protein pockets. Fragment-based molecular design uses chemical motifs and combines them into bio-active compounds. While this approach has grown in capability, molecular linker methods are restricted to linking fragments one by one, which makes the search for effective combinations harder. Igashov and colleagues use a conditional diffusion model to link multiple fragments in a one-shot generative process.",
    "citationCount": 212,
    "pdf_filename": "2022_Equivariant_3D_conditional_diffusion_mod_a129b8ce.pdf"
  },
  "106875ff362c66d160d26a006a456201830fc941": {
    "paperId": "106875ff362c66d160d26a006a456201830fc941",
    "title": "Toward Semantic Communications: Deep Learning-Based Image Semantic Coding",
    "year": 2022,
    "authors": "Danlan Huang, F. Gao, Xiaoming Tao, Qiyuan Du, Jianhua Lu",
    "abstract": "Semantic communications has received growing interest since it can remarkably reduce the amount of data to be transmitted without missing critical information. Most existing works explore the semantic encoding and transmission for text and apply techniques in Natural Language Processing (NLP) to interpret the meaning of the text. In this paper, we conceive the semantic communications for image data that is much more richer in semantics and bandwidth sensitive. We propose an reinforcement learning based adaptive semantic coding (RL-ASC) approach that encodes images beyond pixel level. Firstly, we define the semantic concept of image data that includes the category, spatial arrangement, and visual feature as the representation unit, and propose a convolutional semantic encoder to extract semantic concepts. Secondly, we propose the image reconstruction criterion that evolves from the traditional pixel similarity to semantic similarity and perceptual performance. Thirdly, we design a novel RL-based semantic bit allocation model, whose reward is the increase in rate-semantic-perceptual performance after encoding a certain semantic concept with adaptive quantization level. Thus, the task-related information is preserved and reconstructed properly while less important data is discarded. Finally, we propose the Generative Adversarial Nets (GANs) based semantic decoder that fuses both locally and globally features via an attention module. Experimental results demonstrate that the proposed RL-ASC is noise robust and could reconstruct visually pleasant and semantic consistent image in low bit rate condition.",
    "citationCount": 224,
    "pdf_filename": "2022_Toward_Semantic_Communications__Deep_Lea_106875ff.pdf"
  },
  "68f14f333dad84ec35fc0eb9fcfd2c41fdc02596": {
    "paperId": "68f14f333dad84ec35fc0eb9fcfd2c41fdc02596",
    "title": "ATISS: Autoregressive Transformers for Indoor Scene Synthesis",
    "year": 2021,
    "authors": "Despoina Paschalidou, Amlan Kar, Maria Shugrina, Karsten Kreis, Andreas Geiger",
    "abstract": "The ability to synthesize realistic and diverse indoor furniture layouts automatically or based on partial input, unlocks many applications, from better interactive 3D tools to data synthesis for training and simulation. In this paper, we present ATISS, a novel autoregressive transformer architecture for creating diverse and plausible synthetic indoor environments, given only the room type and its floor plan. In contrast to prior work, which poses scene synthesis as sequence generation, our model generates rooms as unordered sets of objects. We argue that this formulation is more natural, as it makes ATISS generally useful beyond fully automatic room layout synthesis. For example, the same trained model can be used in interactive applications for general scene completion, partial room re-arrangement with any objects specified by the user, as well as object suggestions for any partial room. To enable this, our model leverages the permutation equivariance of the transformer when conditioning on the partial scene, and is trained to be permutation-invariant across object orderings. Our model is trained end-to-end as an autoregressive generative model using only labeled 3D bounding boxes as supervision. Evaluations on four room types in the 3D-FRONT dataset demonstrate that our model consistently generates plausible room layouts that are more realistic than existing methods. In addition, it has fewer parameters, is simpler to implement and train and runs up to 8 times faster than existing methods.",
    "citationCount": 202,
    "pdf_filename": "2021_ATISS__Autoregressive_Transformers_for_I_68f14f33.pdf"
  },
  "3c1d9195508fdf7281f4e01a40f58ebce03cca50": {
    "paperId": "3c1d9195508fdf7281f4e01a40f58ebce03cca50",
    "title": "Applications of Deep Learning in Molecule Generation and Molecular Property Prediction.",
    "year": 2020,
    "authors": "W. Patrick Walters, R. Barzilay",
    "abstract": "ConspectusRecent advances in computer hardware and software have led to a revolution in deep neural networks that has impacted fields ranging from language translation to computer vision. Deep learning has also impacted a number of areas in drug discovery, including the analysis of cellular images and the design of novel routes for the synthesis of organic molecules. While work in these areas has been impactful, a complete review of the applications of deep learning in drug discovery would be beyond the scope of a single Account. In this Account, we will focus on two key areas where deep learning has impacted molecular design: the prediction of molecular properties and the de novo generation of suggestions for new molecules.One of the most significant advances in the development of quantitative structure-activity relationships (QSARs) has come from the application of deep learning methods to the prediction of the biological activity and physical properties of molecules in drug discovery programs. Rather than employing the expert-derived chemical features typically used to build predictive models, researchers are now using deep learning to develop novel molecular representations. These representations, coupled with the ability of deep neural networks to uncover complex, nonlinear relationships, have led to state-of-the-art performance. While deep learning has changed the way that many researchers approach QSARs, it is not a panacea. As with any other machine learning task, the design of predictive models is dependent on the quality, quantity, and relevance of available data. Seemingly fundamental issues, such as optimal methods for creating a training set, are still open questions for the field. Another critical area that is still the subject of multiple research efforts is the development of methods for assessing the confidence in a model.Deep learning has also contributed to a renaissance in the application of de novo molecule generation. Rather than relying on manually defined heuristics, deep learning methods learn to generate new molecules based on sets of existing molecules. Techniques that were originally developed for areas such as image generation and language translation have been adapted to the generation of molecules. These deep learning methods have been coupled with the predictive models described above and are being used to generate new molecules with specific predicted biological activity profiles. While these generative algorithms appear promising, there have been only a few reports on the synthesis and testing of molecules based on designs proposed by generative models. The evaluation of the diversity, quality, and ultimate value of molecules produced by generative models is still an open question. While the field has produced a number of benchmarks, it has yet to agree on how one should ultimately assess molecules \"invented\" by an algorithm.",
    "citationCount": 290,
    "pdf_filename": "2020_Applications_of_Deep_Learning_in_Molecul_3c1d9195.pdf"
  },
  "d3b1fd3348f040814effaada60c1b6761ef0170f": {
    "paperId": "d3b1fd3348f040814effaada60c1b6761ef0170f",
    "title": "Generative AI in Higher Education: A Global Perspective of Institutional Adoption Policies and Guidelines",
    "year": 2024,
    "authors": "Yueqiao Jin, Lixiang Yan, Vanessa Echeverría, D. Gašević, Roberto Martínez Maldonado",
    "abstract": "Integrating generative AI (GAI) into higher education is crucial for preparing a future generation of GAI-literate students. Yet a thorough understanding of the global institutional adoption policy remains absent, with most of the prior studies focused on the Global North and the promises and challenges of GAI, lacking a theoretical lens. This study utilizes the Diffusion of Innovations Theory to examine GAI adoption strategies in higher education across 40 universities from six global regions. It explores the characteristics of GAI innovation, including compatibility, trialability, and observability, and analyses the communication channels and roles and responsibilities outlined in university policies and guidelines. The findings reveal a proactive approach by universities towards GAI integration, emphasizing academic integrity, teaching and learning enhancement, and equity. Despite a cautious yet optimistic stance, a comprehensive policy framework is needed to evaluate the impacts of GAI integration and establish effective communication strategies that foster broader stakeholder engagement. The study highlights the importance of clear roles and responsibilities among faculty, students, and administrators for successful GAI integration, supporting a collaborative model for navigating the complexities of GAI in education. This study contributes insights for policymakers in crafting detailed strategies for its integration.",
    "citationCount": 127,
    "pdf_filename": "2024_Generative_AI_in_Higher_Education__A_Glo_d3b1fd33.pdf"
  },
  "4fda99880cdbf8f178f01eb4c8dbdae7f959ea94": {
    "paperId": "4fda99880cdbf8f178f01eb4c8dbdae7f959ea94",
    "title": "Red-Teaming for Generative AI: Silver Bullet or Security Theater?",
    "year": 2024,
    "authors": "Michael Feffer, Anusha Sinha, Zachary Chase Lipton, Hoda Heidari",
    "abstract": "In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming’s central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.",
    "citationCount": 102,
    "pdf_filename": "2024_Red_Teaming_for_Generative_AI__Silver_Bu_4fda9988.pdf"
  },
  "e8113869163d47043ef1278777f2fb8b93ca2346": {
    "paperId": "e8113869163d47043ef1278777f2fb8b93ca2346",
    "title": "Modelling Generative AI Acceptance, Perceived Teachers' Enthusiasm and Self‐Efficacy to English as a Foreign Language Learners' Well‐Being in the Digital Era",
    "year": 2024,
    "authors": "Fangwei Huang, Yongliang Wang, Haijing Zhang",
    "abstract": "As artificial intelligence (AI) has been integrated into foreign language (FL) education, learners' well‐being is influenced by various factors, including technological, personal and contextual elements. However, few studies explored how external and internal factors jointly shape FL learners' well‐being in the era of generative AI. To fill this gap, this study explores the effects of generative AI acceptance, perceived teachers' enthusiasm and self‐efficacy on FL learners' well‐being by investigating 613 university learners of English as a foreign language (EFL). The structural equation modelling results reveal that (1) generative AI acceptance positively predicts EFL learners' well‐being and self‐efficacy; (2) perceived teachers' enthusiasm does not predict learners' well‐being and positively predicts EFL learners' self‐efficacy; and (3) the self‐efficacy for receptive skills mediates the relationship between generative AI acceptance/perceived teachers' enthusiasm and EFL learners' well‐being, whereas self‐efficacy for productive skills does not play the mediation role. This research broadens the understanding of the antecedents of EFL learners' well‐being and extends the application of self‐efficacy theory in the AI‐driven educational environment, providing significant pedagogical implications.",
    "citationCount": 140,
    "pdf_filename": "2024_Modelling_Generative_AI_Acceptance__Perc_e8113869.pdf"
  },
  "e815233db9fb476d7bece1d5e5c62a3bfdad3d12": {
    "paperId": "e815233db9fb476d7bece1d5e5c62a3bfdad3d12",
    "title": "Ethical Challenges and Solutions of Generative AI: An Interdisciplinary Perspective",
    "year": 2024,
    "authors": "Mousa Al-kfairy, Dheya Ghazi Mustafa, N. Kshetri, Mazen Insiew, Omar Alfandi",
    "abstract": "This paper conducts a systematic review and interdisciplinary analysis of the ethical challenges of generative AI technologies (N = 37), highlighting significant concerns such as privacy, data protection, copyright infringement, misinformation, biases, and societal inequalities. The ability of generative AI to produce convincing deepfakes and synthetic media, which threaten the foundations of truth, trust, and democratic values, exacerbates these problems. The paper combines perspectives from various disciplines, including education, media, and healthcare, underscoring the need for AI systems that promote equity and do not perpetuate social inequalities. It advocates for a proactive approach to the ethical development of AI, emphasizing the necessity of establishing policies, guidelines, and frameworks that prioritize human rights, fairness, and transparency. The paper calls for a multidisciplinary dialogue among policymakers, technologists, and researchers to ensure responsible AI development that conforms to societal values and ethical standards. It stresses the urgency of addressing these ethical concerns and advocates for the development of generative AI in a socially beneficial and ethically sound manner, contributing significantly to the discourse on managing AI’s ethical implications in the modern digital era. The study highlights the theoretical and practical implications of these challenges and suggests a number of future research directions.",
    "citationCount": 158,
    "pdf_filename": "2024_Ethical_Challenges_and_Solutions_of_Gene_e815233d.pdf"
  },
  "628f241e6ccf6ce5ceb4a1d866935abf31d586da": {
    "paperId": "628f241e6ccf6ce5ceb4a1d866935abf31d586da",
    "title": "Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges",
    "year": 2024,
    "authors": "Yan Chen, Pouyan Esmaeilzadeh",
    "abstract": "As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data-intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.",
    "citationCount": 176,
    "pdf_filename": "2024_Generative_AI_in_Medical_Practice__In_De_628f241e.pdf"
  },
  "15d04a7c607785c6f264cf3369d9fad01f6e319e": {
    "paperId": "15d04a7c607785c6f264cf3369d9fad01f6e319e",
    "title": "The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers",
    "year": 2024,
    "authors": "James Prather, Brent N. Reeves, Juho Leinonen, Stephen Macneil, Arisoa S. Randrianasolo",
    "abstract": "Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.",
    "citationCount": 116,
    "pdf_filename": "2024_The_Widening_Gap__The_Benefits_and_Harms_15d04a7c.pdf"
  },
  "c713ade0d479355c8e155ca720fbe36c34e9e2f6": {
    "paperId": "c713ade0d479355c8e155ca720fbe36c34e9e2f6",
    "title": "Sentiment Analysis in the Age of Generative AI",
    "year": 2024,
    "authors": "Jan Ole Krugmann, Jochen Hartmann",
    "abstract": "In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.",
    "citationCount": 126,
    "pdf_filename": "2024_Sentiment_Analysis_in_the_Age_of_Generat_c713ade0.pdf"
  },
  "b229fe5912caf7daca6d15b9ddbcfdfac818d326": {
    "paperId": "b229fe5912caf7daca6d15b9ddbcfdfac818d326",
    "title": "A Comprehensive Review on Generative AI for Education",
    "year": 2024,
    "authors": "Uday Mittal, Siva Sai, V. Chamola, Devika Sangwan",
    "abstract": "Artificial Intelligence (AI) has immense potential for personalized learning experiences, content generation, and vivid educational support. This paper delves into generative AI (GAI) and its potential applications within GAI, specifically mentioning generative adversarial networks (GANs). The article delves into the transformative impact of GAI in education, underscoring its expertise in creating diverse instructional materials, from texts and images to videos. Adaptive learning, one of the chief abilities of GAI, has been highlighted, emphasizing its capability to select content customized to individual student profiles, learning habits, and preferences. The paper further explores the fusion of GAI with innovative education systems, highlighting how these models can mimic conversational interfaces, promoting an engaging, customized learning journey. The exploration doesn’t stop at the benefits; it delves into challenges like ensuring data privacy, mitigating biases, and ensuring accountability in AI-driven educational systems. The conclusion contemplates the potential limitations and assurances of embedding GAI within educational setups. An appeal has been made for more profound research and enhancement of AI’s educational function. The intersection of pedagogical insights and effective human-AI collaboration is pivotal in this journey. This paper serves as a compass, guiding educators, researchers, and policymakers toward harnessing GAI’s potential to sculpt enriched, immersive educational landscapes.",
    "citationCount": 100,
    "pdf_filename": "2024_A_Comprehensive_Review_on_Generative_AI__b229fe59.pdf"
  },
  "515db5fefd215c05649aaa5adc4d64075d2518ab": {
    "paperId": "515db5fefd215c05649aaa5adc4d64075d2518ab",
    "title": "Design Principles for Generative AI Applications",
    "year": 2024,
    "authors": "Justin D. Weisz, Jessica He, Michael Muller, Gabriela Hoefer, Rachel Miles",
    "abstract": "Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving actionable design recommendations.",
    "citationCount": 193,
    "pdf_filename": "2024_Design_Principles_for_Generative_AI_Appl_515db5fe.pdf"
  },
  "37e6fa1ff0bab38ccf0335aeb4fcc9dd65a1666c": {
    "paperId": "37e6fa1ff0bab38ccf0335aeb4fcc9dd65a1666c",
    "title": "Exploring students’ perspectives on Generative AI-assisted academic writing",
    "year": 2024,
    "authors": "Jinhee Kim, Seongryeong Yu, Rita Detrick, Na Li",
    "abstract": "The rapid development of generative artificial intelligence (GenAI), including large language models (LLM), has merged to support students in their academic writing process. Keeping pace with the technical and educational landscape requires careful consideration of the opportunities and challenges that GenAI-assisted systems create within education. This serves as a useful and necessary starting point for fully leveraging its potential for learning and teaching. Hence, it is crucial to gather insights from diverse perspectives and use cases from actual users, particularly the unique voices and needs of student-users. Therefore, this study explored and examined students' perceptions and experiences about GenAI-assisted academic writing by conducting in-depth interviews with 20 Chinese students in higher education after completing academic writing tasks using a ChatGPT4-embedded writing system developed by the research team. The study found that students expected AI to serve multiple roles, including multi-tasking writing assistant, virtual tutor, and digital peer to support multifaceted writing processes and performance. Students perceived that GenAI-assisted writing could benefit them in three areas including the writing process, performance, and their affective domain. Meanwhile, they also identified AI-related, student-related, and task-related challenges that were experienced during the GenAI-assisted writing activity. These findings contribute to a more nuanced understanding of GenAI's impact on academic writing that is inclusive of student perspectives, offering implications for educational AI design and instructional design.",
    "citationCount": 166,
    "pdf_filename": "2024_Exploring_students__perspectives_on_Gene_37e6fa1f.pdf"
  },
  "02b910aa9e5f9928f2ae0b0d2c0adeb5478e138c": {
    "paperId": "02b910aa9e5f9928f2ae0b0d2c0adeb5478e138c",
    "title": "The Rapid Adoption of Generative AI",
    "year": 2024,
    "authors": "Alexander Bick, A. Blandin, David J. Deming",
    "abstract": "Generative artificial intelligence (AI) is a potentially important new technology, but its impact on the economy depends on the speed and intensity of adoption. This paper reports results from a series of nationally representative U",
    "citationCount": 100,
    "pdf_filename": "2024_The_Rapid_Adoption_of_Generative_AI_02b910aa.pdf"
  },
  "6f01ca395514bfe216aade6b2d3c5c43f1e9dd42": {
    "paperId": "6f01ca395514bfe216aade6b2d3c5c43f1e9dd42",
    "title": "Privacy and Security Concerns in Generative AI: A Comprehensive Survey",
    "year": 2024,
    "authors": "Abenezer Golda, K. Mekonen, Amit Pandey, Anushka Singh, Vikas Hassija",
    "abstract": "Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",
    "citationCount": 120,
    "pdf_filename": "2024_Privacy_and_Security_Concerns_in_Generat_6f01ca39.pdf"
  },
  "d4eb4adfa36b5dd0480793f1d0a89a43a8847661": {
    "paperId": "d4eb4adfa36b5dd0480793f1d0a89a43a8847661",
    "title": "The promise and challenges of generative AI in education",
    "year": 2024,
    "authors": "Michail N. Giannakos, Roger Azevedo, Peter Brusilovsky, Mutlu Cukurova, Y. Dimitriadis",
    "abstract": "ABSTRACT Generative artificial intelligence (GenAI) tools, such as large language models (LLMs), generate natural language and other types of content to perform a wide range of tasks. This represents a significant technological advancement that poses opportunities and challenges to educational research and practice. This commentary brings together contributions from nine experts working in the intersection of learning and technology and presents critical reflections on the opportunities, challenges, and implications related to GenAI technologies in the context of education. In the commentary, it is acknowledged that GenAI’s capabilities can enhance some teaching and learning practices, such as learning design, regulation of learning, automated content, feedback, and assessment. Nevertheless, we also highlight its limitations, potential disruptions, ethical consequences, and potential misuses. The identified avenues for further research include the development of new insights into the roles human experts can play, strong and continuous evidence, human-centric design of technology, necessary policy, and support and competence mechanisms. Overall, we concur with the general skeptical optimism about the use of GenAI tools such as LLMs in education. Moreover, we highlight the danger of hastily adopting GenAI tools in education without deep consideration of the efficacy, ecosystem-level implications, ethics, and pedagogical soundness of such practices.",
    "citationCount": 137,
    "pdf_filename": "2024_The_promise_and_challenges_of_generative_d4eb4adf.pdf"
  },
  "4a1d533193d8e6607c381d231aaea06a5522622a": {
    "paperId": "4a1d533193d8e6607c381d231aaea06a5522622a",
    "title": "A Systematic Review of Synthetic Data Generation Techniques Using Generative AI",
    "year": 2024,
    "authors": "Mandeep Goyal, Q. Mahmoud",
    "abstract": "Synthetic data are increasingly being recognized for their potential to address serious real-world challenges in various domains. They provide innovative solutions to combat the data scarcity, privacy concerns, and algorithmic biases commonly used in machine learning applications. Synthetic data preserve all underlying patterns and behaviors of the original dataset while altering the actual content. The methods proposed in the literature to generate synthetic data vary from large language models (LLMs), which are pre-trained on gigantic datasets, to generative adversarial networks (GANs) and variational autoencoders (VAEs). This study provides a systematic review of the various techniques proposed in the literature that can be used to generate synthetic data to identify their limitations and suggest potential future research areas. The findings indicate that while these technologies generate synthetic data of specific data types, they still have some drawbacks, such as computational requirements, training stability, and privacy-preserving measures which limit their real-world usability. Addressing these issues will facilitate the broader adoption of synthetic data generation techniques across various disciplines, thereby advancing machine learning and data-driven solutions.",
    "citationCount": 124,
    "pdf_filename": "2024_A_Systematic_Review_of_Synthetic_Data_Ge_4a1d5331.pdf"
  },
  "a2f03ff74dc1ee8bd8b6ccfbcbb931f58c93db4b": {
    "paperId": "a2f03ff74dc1ee8bd8b6ccfbcbb931f58c93db4b",
    "title": "Investigation of the moderation effect of gender and study level on the acceptance and use of generative AI by higher education students: Comparative evidence from Poland and Egypt",
    "year": 2024,
    "authors": "Artur Strzelecki, Sara ElArabawy",
    "abstract": "This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT—performance expectancy, effort expectancy, social influence and facilitating conditions—to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education.\n\nChatGPT is a tool that is quickly gaining worldwide recognition.\nChatGPT helps with writing essays and solving assignments.\nChatGPT raises ethical concerns about authorship, plagiarism and ethics.\n\n\nThis study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously.\nWe used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students.\nWe conducted a multiple study in Poland and Egypt based on sampling strategy from six universities.\n\n\nChatGPT is a global game changer and should be incorporated into study programmes.\nThe limitations of ChatGPT should be well explained and known since it is prone to making mistakes.\nHigher education teachers should be aware of ChatGPT's capabilities.\n",
    "citationCount": 151,
    "pdf_filename": "2024_Investigation_of_the_moderation_effect_o_a2f03ff7.pdf"
  },
  "79adf90f279f05ffc53ded255f9c5825515e398a": {
    "paperId": "79adf90f279f05ffc53ded255f9c5825515e398a",
    "title": "Generative AI for Customizable Learning Experiences",
    "year": 2024,
    "authors": "Ivica Pesovski, Ricardo Santos, Roberto Henriques, V. Trajkovik",
    "abstract": "The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI’s API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student’s tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students’ study time, especially for students who have not mastered the topic otherwise. The study’s small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.",
    "citationCount": 129,
    "pdf_filename": "2024_Generative_AI_for_Customizable_Learning__79adf90f.pdf"
  },
  "0b9d0bee85e4ef4261147f35be885010e62ad1fb": {
    "paperId": "0b9d0bee85e4ef4261147f35be885010e62ad1fb",
    "title": "Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations",
    "year": 2024,
    "authors": "Siva Sai, Aanchal Gaur, Revant Sai, V. Chamola, Mohsen Guizani",
    "abstract": "Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.",
    "citationCount": 102,
    "pdf_filename": "2024_Generative_AI_for_Transformative_Healthc_0b9d0bee.pdf"
  },
  "275fb93244b5a465d7e30fc6111e3403b47557be": {
    "paperId": "275fb93244b5a465d7e30fc6111e3403b47557be",
    "title": "scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI",
    "year": 2023,
    "authors": "Haotian Cui, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo",
    "abstract": "Generative pre-trained models have achieved remarkable success in various domains such as natural language processing and computer vision. Specifically, the combination of large-scale diverse datasets and pre-trained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between linguistic constructs and cellular biology — where texts comprise words, similarly, cells are defined by genes — our study probes the applicability of foundation models to advance cellular biology and genetics research. Utilizing the burgeoning single-cell sequencing data, we have pioneered the construction of a foundation model for single-cell biology, scGPT, which is based on generative pre-trained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT, a generative pre-trained transformer, effectively distills critical biological insights concerning genes and cells. Through the further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell-type annotation, multi-batch integration, multi-omic integration, genetic perturbation prediction, and gene network inference. The scGPT codebase is publicly available at https://github.com/bowang-lab/scGPT.",
    "citationCount": 100,
    "pdf_filename": "2023_scGPT__Towards_Building_a_Foundation_Mod_275fb932.pdf"
  },
  "c68b786ccdddc6d902644bd594df9c815ec45b92": {
    "paperId": "c68b786ccdddc6d902644bd594df9c815ec45b92",
    "title": "Generative AI and Teachers’ Perspectives on Its Implementation in Education",
    "year": 2023,
    "authors": "Regina Kaplan‐Rakowski, Kimberly Grotewold, P. Hartwick, Kevin Papin",
    "abstract": "While artificial intelligence (AI) has been integral in daily life for decades, the release of open generative AI (GAI) such as ChatGPT has considerably accelerated scholars’ interest in the impact of GAI in education. Both promises and fears of GAI have been becoming apparent. This quantitative study explored teachers' perspectives on GAI and its potential implementation in education. A diverse group of teachers (N = 147) completed a validated survey sharing their views on GAI technology in terms of its use, integration, potential, and concerns. Overall, the teachers express positive perspectives towards GAI regardless of their teaching style. The findings of the study suggest that the more frequently teachers used GAI, the more positive their perspectives became. The teachers believed that GAI could enhance their professional development and could be a valuable tool for students. Although no guarantee exists that teachers’ perspectives translate into actions, previous research shows that technology integration and diffusion is highly dependent on teachers’ initial views (Ismail et al., 2010; Sugar et al., 2004). The findings of this study have implications on how GAI may be integrated in teaching and learning practices.",
    "citationCount": 162,
    "pdf_filename": "2023_Generative_AI_and_Teachers__Perspectives_c68b786c.pdf"
  },
  "f0b57ff93ab51bec3d85f444c89d1af3d1771928": {
    "paperId": "f0b57ff93ab51bec3d85f444c89d1af3d1771928",
    "title": "On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML",
    "year": 2023,
    "authors": "J. Cámara, J. Troya, Lola Burgueño, Antonio Vallecillo",
    "abstract": "Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling.",
    "citationCount": 186,
    "pdf_filename": "2023_On_the_assessment_of_generative_AI_in_mo_f0b57ff9.pdf"
  },
  "4de290467d903b9977e31b3d4084006789bd6ebd": {
    "paperId": "4de290467d903b9977e31b3d4084006789bd6ebd",
    "title": "One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era",
    "year": 2023,
    "authors": "Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng",
    "abstract": "OpenAI has recently released GPT-4 (a.k.a. ChatGPT plus), which is demonstrated to be one small step for generative AI (GAI), but one giant leap for artificial general intelligence (AGI). Since its official release in November 2022, ChatGPT has quickly attracted numerous users with extensive media coverage. Such unprecedented attention has also motivated numerous researchers to investigate ChatGPT from various aspects. According to Google scholar, there are more than 500 articles with ChatGPT in their titles or mentioning it in their abstracts. Considering this, a review is urgently needed, and our work fills this gap. Overall, this work is the first to survey ChatGPT with a comprehensive review of its underlying technology, applications, and challenges. Moreover, we present an outlook on how ChatGPT might evolve to realize general-purpose AIGC (a.k.a. AI-generated content), which will be a significant milestone for the development of AGI.",
    "citationCount": 150,
    "pdf_filename": "2023_One_Small_Step_for_Generative_AI__One_Gi_4de29046.pdf"
  },
  "d0c48d3b80efb9c170e7100cb9d78d1e7f7710bf": {
    "paperId": "d0c48d3b80efb9c170e7100cb9d78d1e7f7710bf",
    "title": "Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration",
    "year": 2023,
    "authors": "Ping Yu, Hua Xu, Xia Hu, C. Deng",
    "abstract": "Generative artificial intelligence (AI) and large language models (LLMs), exemplified by ChatGPT, are promising for revolutionizing data and information management in healthcare and medicine. However, there is scant literature guiding their integration for non-AI professionals. This study conducts a scoping literature review to address the critical need for guidance on integrating generative AI and LLMs into healthcare and medical practices. It elucidates the distinct mechanisms underpinning these technologies, such as Reinforcement Learning from Human Feedback (RLFH), including few-shot learning and chain-of-thought reasoning, which differentiates them from traditional, rule-based AI systems. It requires an inclusive, collaborative co-design process that engages all pertinent stakeholders, including clinicians and consumers, to achieve these benefits. Although global research is examining both opportunities and challenges, including ethical and legal dimensions, LLMs offer promising advancements in healthcare by enhancing data management, information retrieval, and decision-making processes. Continued innovation in data acquisition, model fine-tuning, prompt strategy development, evaluation, and system implementation is imperative for realizing the full potential of these technologies. Organizations should proactively engage with these technologies to improve healthcare quality, safety, and efficiency, adhering to ethical and legal guidelines for responsible application.",
    "citationCount": 193,
    "pdf_filename": "2023_Leveraging_Generative_AI_and_Large_Langu_d0c48d3b.pdf"
  },
  "1b492746ee3a304a13950cad1a59861b9ee44645": {
    "paperId": "1b492746ee3a304a13950cad1a59861b9ee44645",
    "title": "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?",
    "year": 2023,
    "authors": "Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li",
    "abstract": "As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to analyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the opportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that ChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for diversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our work comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative AI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling methods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological development of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the full potential of ChatGPT's future. Moreover, we summarize their significant applications in some mainstream industries, such as education and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI might evolve in the near future.",
    "citationCount": 190,
    "pdf_filename": "2023_A_Complete_Survey_on_Generative_AI__AIGC_1b492746.pdf"
  },
  "6e720226396cd3a9f0dc4836d6d391509b9df285": {
    "paperId": "6e720226396cd3a9f0dc4836d6d391509b9df285",
    "title": "Sociotechnical Safety Evaluation of Generative AI Systems",
    "year": 2023,
    "authors": "Laura Weidinger, Maribeth Rauh, Nahema Marchal, Arianna Manzini, L. Hendricks",
    "abstract": "Generative AI systems produce a range of risks. To ensure the safety of generative AI systems, these risks must be evaluated. In this paper, we make two main contributions toward establishing such evaluations. First, we propose a three-layered framework that takes a structured, sociotechnical approach to evaluating these risks. This framework encompasses capability evaluations, which are the main current approach to safety evaluation. It then reaches further by building on system safety principles, particularly the insight that context determines whether a given capability may cause harm. To account for relevant context, our framework adds human interaction and systemic impacts as additional layers of evaluation. Second, we survey the current state of safety evaluation of generative AI systems and create a repository of existing evaluations. Three salient evaluation gaps emerge from this analysis. We propose ways forward to closing these gaps, outlining practical steps as well as roles and responsibilities for different actors. Sociotechnical safety evaluation is a tractable approach to the robust and comprehensive safety evaluation of generative AI systems.",
    "citationCount": 179,
    "pdf_filename": "2023_Sociotechnical_Safety_Evaluation_of_Gene_6e720226.pdf"
  },
  "a1ba4bbc0ec996278d8dc9acbcf64e444e2ada39": {
    "paperId": "a1ba4bbc0ec996278d8dc9acbcf64e444e2ada39",
    "title": "The Metacognitive Demands and Opportunities of Generative AI",
    "year": 2023,
    "authors": "Lev Tankelevitch, Viktor Kewenig, Auste Simkute, A. E. Scott, Advait Sarkar",
    "abstract": "Generative AI (GenAI) systems offer unprecedented opportunities for transforming professional and personal work, yet present challenges around prompting, evaluating and relying on outputs, and optimizing workflows. We argue that metacognition—the psychological ability to monitor and control one’s thoughts and behavior—offers a valuable lens to understand and design for these usability challenges. Drawing on research in psychology and cognitive science, and recent GenAI user studies, we illustrate how GenAI systems impose metacognitive demands on users, requiring a high degree of metacognitive monitoring and control. We propose these demands could be addressed by integrating metacognitive support strategies into GenAI systems, and by designing GenAI systems to reduce their metacognitive demand by targeting explainability and customizability. Metacognition offers a coherent framework for understanding the usability challenges posed by GenAI, and provides novel research and design directions to advance human-AI interaction.",
    "citationCount": 187,
    "pdf_filename": "2023_The_Metacognitive_Demands_and_Opportunit_a1ba4bbc.pdf"
  },
  "5eb0850336e5cb952999dc8522d21799e815ec5f": {
    "paperId": "5eb0850336e5cb952999dc8522d21799e815ec5f",
    "title": "Generative AI and ChatGPT in School Children’s Education: Evidence from a School Lesson",
    "year": 2023,
    "authors": "Jussi S. Jauhiainen, Agustín Garagorry Guerra",
    "abstract": "In 2023, the global use of generative AI, particularly ChatGPT-3.5 and -4, witnessed a significant surge, sparking discussions on its sustainable implementation across various domains, including education from primary schools to universities. However, practical testing and evaluation in school education are still relatively unexplored. This article examines the utilization of generative AI in primary school education. The study involved 110 pupils, aged 8–14 years old, studying in the 4th–6th grades across four classes in two schools. Using laptops, pupils participated in test lessons where content, text, figures, and exercises were generated and modified using generative AI, specifically ChatGPT-3.5. The results demonstrated that it was possible to use ChatGPT-3.5, as one example of generative AI, to personify learning material so that it would meet the knowledge and learning skills of pupils with different levels of knowledge. A clear majority of pupils enjoyed learning the generative AI-modified material. There is a promising potential of generative AI use in school education, supporting pupils’ motivated learning and skills development. However, these tools need to be developed, refined and optimized to ensure proper adaptation and to create impactful, inclusive, and sustainable learning in schools to benefit pupils, teachers and education managers alike.",
    "citationCount": 147,
    "pdf_filename": "2023_Generative_AI_and_ChatGPT_in_School_Chil_5eb08503.pdf"
  },
  "cea4c7e52db428f4618e03d32a774cceb2bc570a": {
    "paperId": "cea4c7e52db428f4618e03d32a774cceb2bc570a",
    "title": "Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers",
    "year": 2023,
    "authors": "Staphord Bengesi, Hoda El-Sayed, Md Kamruzzaman Sarker, Yao Houkpati, John Irungu",
    "abstract": "The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.",
    "citationCount": 155,
    "pdf_filename": "2023_Advancements_in_Generative_AI__A_Compreh_cea4c7e5.pdf"
  },
  "421193bfb4a1fc21866d65f80e8f8e8806e1f35b": {
    "paperId": "421193bfb4a1fc21866d65f80e8f8e8806e1f35b",
    "title": "How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research? An exploratory study",
    "year": 2023,
    "authors": "F. Megahed, Ying-Ju Chen, Joshua A. Ferris, S. Knoth, L. A. Jones‐Farmer",
    "abstract": "Abstract Generative Artificial Intelligence (AI) models such as OpenAI’s ChatGPT have the potential to revolutionize Statistical Process Control (SPC) practice, learning, and research. However, these tools are in the early stages of development and can be easily misused or misunderstood. In this paper, we give an overview of the development of Generative AI. Specifically, we explore ChatGPT’s ability to provide code, explain basic concepts, and create knowledge related to SPC practice, learning, and research. By investigating responses to structured prompts, we highlight the benefits and limitations of the results. Our study indicates that the current version of ChatGPT performs well for structured tasks, such as translating code from one language to another and explaining well-known concepts but struggles with more nuanced tasks, such as explaining less widely known terms and creating code from scratch. We find that using new AI tools may help practitioners, educators, and researchers to be more efficient and productive. However, in their current stages of development, some results are misleading and wrong. Overall, the use of generative AI models in SPC must be properly validated and used in conjunction with other methods to ensure accurate results.",
    "citationCount": 145,
    "pdf_filename": "2023_How_generative_AI_models_such_as_ChatGPT_421193bf.pdf"
  },
  "367a161324a3b6d1b64b75bb8b44a797fc6a948b": {
    "paperId": "367a161324a3b6d1b64b75bb8b44a797fc6a948b",
    "title": "Generative AI meets copyright",
    "year": 2023,
    "authors": "Pamela Samuelson",
    "abstract": "Description Ongoing lawsuits could affect everyone who uses generative AI Generative artificial intelligence (AI) is a disruptive technology that is widely adopted by members of the general public as well as scientists and technologists who are enthusiastic about the potential to accelerate research in a wide variety of fields. But some professional artists, writers, and programmers fiercely object to the use of their creations as training data for generative AI systems and to outputs that may compete with or displace their works (1, 2). Lack of attribution and compensation for use of their original creations are other sources of aggravation to critics of generative AI. Copyright lawsuits that are now underway in the United States have substantial implications for the future of generative AI systems. If the plaintiffs prevail, the only generative AI systems that may be lawful in the United States would be those trained on public domain works or under licenses, which will affect everyone who deploys generative AI, integrates it into their products, and uses it for scientific research.",
    "citationCount": 163,
    "pdf_filename": "2023_Generative_AI_meets_copyright_367a1613.pdf"
  },
  "ed2db05074b86da6fbcb01b45bd0f1693baa93c4": {
    "paperId": "ed2db05074b86da6fbcb01b45bd0f1693baa93c4",
    "title": "Reducing the Carbon Impact of Generative AI Inference (today and in 2035)",
    "year": 2023,
    "authors": "A. Chien, Liuzixuan Lin, H. Nguyen, V. Rao, Tristan Sharma",
    "abstract": "Generative AI, exemplified in ChatGPT, Dall-E 2, and Stable Diffusion, are exciting new applications consuming growing quantities of computing. We study the compute, energy, and carbon impacts of generative AI inference. Using ChatGPT as an exemplar, we create a workload model and compare request direction approaches (Local, Balance, CarbonMin), assessing their power use and carbon impacts. Our workload model shows that for ChatGPT-like services, inference dominates emissions, in one year producing 25x the carbon-emissions of training GPT-3. The workload model characterizes user experience, and experiments show that carbon emissions-aware algorithms (CarbonMin) can both maintain user experience and reduce carbon emissions dramatically (35%). We also consider a future scenario (2035 workload and power grids), and show that CarbonMin can reduce emissions by 56%. In both cases, the key is intelligent direction of requests to locations with low-carbon power. Combined with hardware technology advances, CarbonMin can keep emissions increase to only 20% compared to 2022 levels for 55x greater workload. Finally we consider datacenter headroom to increase effectiveness of shifting. With headroom, CarbonMin reduces 2035 emissions by 71%.",
    "citationCount": 140,
    "pdf_filename": "2023_Reducing_the_Carbon_Impact_of_Generative_ed2db050.pdf"
  },
  "a80d106b4536884af8da68078babc70086b1a607": {
    "paperId": "a80d106b4536884af8da68078babc70086b1a607",
    "title": "Evaluating the Social Impact of Generative AI Systems in Systems and Society",
    "year": 2023,
    "authors": "Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker",
    "abstract": "Generative AI systems across modalities, ranging from text (including code), image, audio, and video, have broad social impacts, but there is no official standard for means of evaluating those impacts or for which impacts should be evaluated. In this paper, we present a guide that moves toward a standard approach in evaluating a base generative AI system for any modality in two overarching categories: what can be evaluated in a base system independent of context and what can be evaluated in a societal context. Importantly, this refers to base systems that have no predetermined application or deployment context, including a model itself, as well as system components, such as training data. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to listed generative modalities and analyses of the limitations of existing evaluations serve as a starting point for necessary investment in future evaluations. We offer five overarching categories for what can be evaluated in a broader societal context, each with its own subcategories: trustworthiness and autonomy; inequality, marginalization, and violence; concentration of authority; labor and creativity; and ecosystem and environment. Each subcategory includes recommendations for mitigating harm.",
    "citationCount": 143,
    "pdf_filename": "2023_Evaluating_the_Social_Impact_of_Generati_a80d106b.pdf"
  },
  "f6943500f55c8b67b2396238ea71d2b18f574323": {
    "paperId": "f6943500f55c8b67b2396238ea71d2b18f574323",
    "title": "Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education",
    "year": 2023,
    "authors": "Adele Smolansky, Andrew Cram, Corina Raduescu, S. Zeivots, E. Huber",
    "abstract": "The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.",
    "citationCount": 142,
    "pdf_filename": "2023_Educator_and_Student_Perspectives_on_the_f6943500.pdf"
  },
  "c11dad59cbca5cc4875391ebf5360f945aec933a": {
    "paperId": "c11dad59cbca5cc4875391ebf5360f945aec933a",
    "title": "Identifying and Mitigating the Security Risks of Generative AI",
    "year": 2023,
    "authors": "Clark W. Barrett, Bradley L Boyd, Ellie Burzstein, Nicholas Carlini, Brad Chen",
    "abstract": "Every major technical invention resurfaces the dual-use dilemma -- the new technology has the potential to be used for good as well as for harm. Generative AI (GenAI) techniques, such as large language models (LLMs) and diffusion models, have shown remarkable capabilities (e.g., in-context learning, code-completion, and text-to-image generation and editing). However, GenAI can be used just as well by attackers to generate new attacks and increase the velocity and efficacy of existing attacks. This paper reports the findings of a workshop held at Google (co-organized by Stanford University and the University of Wisconsin-Madison) on the dual-use dilemma posed by GenAI. This paper is not meant to be comprehensive, but is rather an attempt to synthesize some of the interesting findings from the workshop. We discuss short-term and long-term goals for the community on this topic. We hope this paper provides both a launching point for a discussion on this important topic as well as interesting problems that the research community can work to address.",
    "citationCount": 118,
    "pdf_filename": "2023_Identifying_and_Mitigating_the_Security__c11dad59.pdf"
  },
  "09b7e2d4e0ca51667197faa54bf9227a91e3b656": {
    "paperId": "09b7e2d4e0ca51667197faa54bf9227a91e3b656",
    "title": "Towards social generative AI for education: theory, practices and ethics",
    "year": 2023,
    "authors": "M. Sharples",
    "abstract": "ABSTRACT This opinion paper explores educational interactions involving humans and artificial intelligences not as sequences of prompts and responses, but as a social process of conversation and exploration. In this conception, learners continually converse with AI language models and other human learners within a dynamic computational medium of internet tools and resources. Learning happens when this distributed human-AI system sets goals, builds meaning from data, consolidates understanding, reconciles differences, and transfers knowledge to new domains. Building social generative AI for education will require development of powerful AI systems that can converse with each other as well as humans, construct external representations such as knowledge maps, access and contribute to internet resources, and act as teachers, learners, guides and mentors. This raises fundamental problems of ethics. Such systems should be aware of their limitations, their responsibility to learners and the integrity of the internet, and their respect for human teachers and experts. We need to consider how to design and constrain social generative AI for education.",
    "citationCount": 113,
    "pdf_filename": "2023_Towards_social_generative_AI_for_educati_09b7e2d4.pdf"
  },
  "449ab79be2d6086b88832cfc9c5d502524c8524f": {
    "paperId": "449ab79be2d6086b88832cfc9c5d502524c8524f",
    "title": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors",
    "year": 2023,
    "authors": "Tung Phung, Victor-Alexandru Pădurean, J. Cambronero, Sumit Gulwani, Tobias Kohn",
    "abstract": "Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT [8] and GPT-4 [9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning [1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education [4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex [3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org [5] (see Figure 1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.",
    "citationCount": 115,
    "pdf_filename": "2023_Generative_AI_for_Programming_Education__449ab79b.pdf"
  },
  "6ea2e402d9d573b6303db35a8347b2a002074fd4": {
    "paperId": "6ea2e402d9d573b6303db35a8347b2a002074fd4",
    "title": "Challenges for higher education in the era of widespread access to Generative AI",
    "year": 2023,
    "authors": "K. Walczak, W. Cellary",
    "abstract": "Abstract The aim of this paper is to discuss the role and impact of Generative Artificial Intelligence (AI) systems in higher education. The proliferation of AI models such as GPT-4, Open Assistant and DALL-E presents a paradigm shift in information acquisition and learning. This transformation poses substantial challenges for traditional teaching approaches and the role of educators. The paper explores the advantages and potential threats of using Generative AI in education and necessary changes in curricula. It further discusses the need to foster digital literacy and the ethical use of AI. The paper’s findings are based on a survey conducted among university students exploring their usage and perception of these AI systems. Finally, recommendations for the use of AI in higher education are offered, which emphasize the need to harness AI’s potential while mitigating its risks. This discourse aims at stimulating policy and strategy development to ensure relevant and effective education in the rapidly evolving digital landscape.",
    "citationCount": 110,
    "pdf_filename": "2023_Challenges_for_higher_education_in_the_e_6ea2e402.pdf"
  },
  "6dd1859af3f4856a0d3f9cca81c8d2121fb3979a": {
    "paperId": "6dd1859af3f4856a0d3f9cca81c8d2121fb3979a",
    "title": "A Survey on Audio Diffusion Models: Text To Speech Synthesis and Enhancement in Generative AI",
    "year": 2023,
    "authors": "Chenshuang Zhang, Chaoning Zhang, Sheng Zheng, Mengchun Zhang, Maryam Qamar",
    "abstract": "Generative AI has demonstrated impressive performance in various fields, among which speech synthesis is an interesting direction. With the diffusion model as the most popular generative model, numerous works have attempted two active tasks: text to speech and speech enhancement. This work conducts a survey on audio diffusion model, which is complementary to existing surveys that either lack the recent progress of diffusion-based speech synthesis or highlight an overall picture of applying diffusion model in multiple fields. Specifically, this work first briefly introduces the background of audio and diffusion model. As for the text-to-speech task, we divide the methods into three categories based on the stage where diffusion model is adopted: acoustic model, vocoder and end-to-end framework. Moreover, we categorize various speech enhancement tasks by either certain signals are removed or added into the input speech. Comparisons of experimental results and discussions are also covered in this survey.",
    "citationCount": 104,
    "pdf_filename": "2023_A_Survey_on_Audio_Diffusion_Models__Text_6dd1859a.pdf"
  },
  "f2154bedb033b07b838d9ac90a657b4ab4243be4": {
    "paperId": "f2154bedb033b07b838d9ac90a657b4ab4243be4",
    "title": "A survey of Generative AI Applications",
    "year": 2023,
    "authors": "Roberto Gozalo-Brizuela, Eduardo C. Garrido-Merch'an",
    "abstract": "Generative AI has experienced remarkable growth in recent years, leading to a wide array of applications across diverse domains. In this paper, we present a comprehensive survey of more than 350 generative AI applications, providing a structured taxonomy and concise descriptions of various unimodal and even multimodal generative AIs. The survey is organized into sections, covering a wide range of unimodal generative AI applications such as text, images, video, gaming and brain information. Our survey aims to serve as a valuable resource for researchers and practitioners to navigate the rapidly expanding landscape of generative AI, facilitating a better understanding of the current state-of-the-art and fostering further innovation in the field.",
    "citationCount": 122,
    "pdf_filename": "2023_A_survey_of_Generative_AI_Applications_f2154bed.pdf"
  },
  "91c24e12ca61268cd784309bfcb4fdd3f7eaa609": {
    "paperId": "91c24e12ca61268cd784309bfcb4fdd3f7eaa609",
    "title": "Towards Adoption of Generative AI in Organizational Settings",
    "year": 2023,
    "authors": "K. Agrawal",
    "abstract": "ABSTRACT As an emerging technology, Generative Artificial Intelligence (AI) holds immense potential for application across various levels of business and management. However, current studies have not yet investigated the elements that impact the acceptance and implementation of generative AI tools, such as ChatGPT, within organizational settings. To fully leverage its benefits, organizations must embrace and integrate Generative AI at a comprehensive and profound level, making it a valuable area of study. This study aims to put forth and examine the influencing factors impacting the adoption of generative AI technology by utilizing the Technology-Organization-Environment framework in conjunction with the institutional theory and the diffusion of innovation theory. Data from 108 organizations in India is collected and analyzed, leading to valuable insights and implications that contribute to a deeper understanding of the key determinants of generative AI adoption. The study digs out valuable knowledge for organizations looking to embrace this technology.",
    "citationCount": 131,
    "pdf_filename": "2023_Towards_Adoption_of_Generative_AI_in_Org_91c24e12.pdf"
  },
  "04266c4ef791e7d9682d609cd0fa7877c5c5ef6d": {
    "paperId": "04266c4ef791e7d9682d609cd0fa7877c5c5ef6d",
    "title": "Generative AI-Empowered Simulation for Autonomous Driving in Vehicular Mixed Reality Metaverses",
    "year": 2023,
    "authors": "Minrui Xu, Dusist Niyato, Junlong Chen, Hongliang Zhang, Jiawen Kang",
    "abstract": "In the vehicular mixed reality (MR) Metaverse, the discrepancy between physical and virtual entities can be overcome by fusing the physical and virtual environments with multi-dimensional communications in autonomous driving systems. Assisted by digital twin (DT) technologies, connected autonomous vehicles (AVs), roadside units (RSUs), and virtual simulators can maintain the vehicular MR Metaverse via simulations for sharing data and making driving decisions collaboratively. However, it is challenging and costly to enable large-scale traffic and driving simulation via realistic data collection and fusion from the physical world for online prediction and offline training in autonomous driving systems. In this paper, we propose an autonomous driving architecture, where generative AI is leveraged to synthesize unlimited conditioned traffic and driving data via simulations for improving driving safety and traffic control efficiency. First, we propose a multi-task DT offloading model for the reliable execution of heterogeneous DT tasks with different requirements at RSUs. Then, based on the preferences of AV's DTs and real-world data, virtual simulators can synthesize unlimited conditioned driving and traffic datasets for improved robustness. Finally, we propose a multi-task enhanced auction-based mechanism to provide fine-grained incentives for RSUs on providing resources for autonomous driving. The property analysis and experimental results demonstrate that the proposed mechanism and architecture are strategy-proof and effective.",
    "citationCount": 104,
    "pdf_filename": "2023_Generative_AI_Empowered_Simulation_for_A_04266c4e.pdf"
  },
  "0f75ec8510247bbaf95ca6e4474976fc40bf2b51": {
    "paperId": "0f75ec8510247bbaf95ca6e4474976fc40bf2b51",
    "title": "Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods",
    "year": 2023,
    "authors": "Volker Bilgram, F. Laarmann",
    "abstract": "Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.",
    "citationCount": 134,
    "pdf_filename": "2023_Accelerating_Innovation_With_Generative__0f75ec85.pdf"
  },
  "db5dc8a44511654dc7e0bbebd44f7b502e5e90be": {
    "paperId": "db5dc8a44511654dc7e0bbebd44f7b502e5e90be",
    "title": "Generative AI for Medical Imaging: extending the MONAI Framework",
    "year": 2023,
    "authors": "W. H. Pinaya, M. Graham, E. Kerfoot, Petru-Daniel Tudosiu, Jessica Dafflon",
    "abstract": "Recent advances in generative AI have brought incredible breakthroughs in several areas, including medical imaging. These generative models have tremendous potential not only to help safely share medical data via synthetic datasets but also to perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due to the complexity of these models, their implementation and reproducibility can be difficult. This complexity can hinder progress, act as a use barrier, and dissuade the comparison of new methods with existing works. In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-art studies in a standardised way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalisable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (like CT, MRI, and X-Ray data) and from different anatomical areas. Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.",
    "citationCount": 101,
    "pdf_filename": "2023_Generative_AI_for_Medical_Imaging__exten_db5dc8a4.pdf"
  },
  "07e738d7c10505b8562d0b282a3cae94b485b24a": {
    "paperId": "07e738d7c10505b8562d0b282a3cae94b485b24a",
    "title": "The Gradient of Generative AI Release: Methods and Considerations",
    "year": 2023,
    "authors": "Irene Solaiman",
    "abstract": "As increasingly powerful generative AI systems are developed, the release method greatly varies. We propose a framework to assess six levels of access to generative AI systems: fully closed; gradual or staged access; hosted access; cloud-based or API access; downloadable access; and fully open. Each level, from fully closed to fully open, can be viewed as an option along a gradient. We outline key considerations across this gradient: release methods come with tradeoffs, especially around the tension between concentrating power and mitigating risks. Diverse and multidisciplinary perspectives are needed to examine and mitigate risk in generative AI systems from conception to deployment. We show trends in generative system release over time, noting closedness among large companies for powerful systems and openness among organizations founded on principles of openness. We also enumerate safety controls and guardrails for generative systems and necessary investments to improve future releases.",
    "citationCount": 122,
    "pdf_filename": "2023_The_Gradient_of_Generative_AI_Release__M_07e738d7.pdf"
  },
  "6c0d7495b2fffb3233c9a22acd719db0637dc07d": {
    "paperId": "6c0d7495b2fffb3233c9a22acd719db0637dc07d",
    "title": "Designing Participatory AI: Creative Professionals’ Worries and Expectations about Generative AI",
    "year": 2023,
    "authors": "Nanna Inie, Jeanette Falk, Steve Tanimoto",
    "abstract": "Generative AI, i.e., the group of technologies that automatically generate visual or written content based on text prompts, has undergone a leap in complexity and become widely available within just a few years. Such technologies potentially introduce a massive disruption to creative fields. This paper presents the results of a qualitative survey (N = 23) investigating how creative professionals think about generative AI. The results show that the advancement of these AI models prompts important reflections on what defines creativity and how creatives imagine using AI to support their workflows. Based on these reflections, we discuss how we might design participatory AI in the domain of creative expertise with the goal of empowering creative professionals in their present and future coexistence with AI.",
    "citationCount": 110,
    "pdf_filename": "2023_Designing_Participatory_AI__Creative_Pro_6c0d7495.pdf"
  },
  "916ffbf18036025e71d9384ea5a726a95f08589d": {
    "paperId": "916ffbf18036025e71d9384ea5a726a95f08589d",
    "title": "From fiction to fact: the growing role of generative AI in business and finance",
    "year": 2023,
    "authors": "Boyang Chen, Zongxiao Wu, Ruoran Zhao",
    "abstract": "ABSTRACT Generative Artificial Intelligence (AI), such as ChatGPT by OpenAI, has revolutionized the business world, with benefits including improved accessibility, efficiency, and cost reduction. This article reviews recent developments of generative AI in business and finance, summarizes its practical applications, provides examples of the latest generative AI tools, and demonstrates that generative AI can revolutionize data analysis in industry and academia. To test the ability of generative AI to support decision-making in financial markets, we use the ChatGPT to capture corporate sentiments towards environmental policy by inputting text extracted from corporate financial statements. Our results demonstrate that the sentiment scores generated by ChatGPT can predict firms’ risk-management capabilities and stock return performance. This study also highlights the potential challenges and limitations associated with generative AI. Finally, we propose several questions for future research at the intersection of generative AI with business and finance.",
    "citationCount": 111,
    "pdf_filename": "2023_From_fiction_to_fact__the_growing_role_o_916ffbf1.pdf"
  },
  "1332261d94c1de6e5e9d5b6191644b0fe53eaa42": {
    "paperId": "1332261d94c1de6e5e9d5b6191644b0fe53eaa42",
    "title": "Generative AI for Economic Research: Use Cases and Implications for Economists",
    "year": 2023,
    "authors": "Anton Korinek",
    "abstract": "Generative artificial intelligence (AI) has the potential to revolutionize research. I analyze how large language models (LLMs) such as ChatGPT can assist economists by describing dozens of use cases in six areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro-tasks. Moreover, these gains will grow as the performance of AI systems continues to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper explain how to get started and will provide regular updates on the latest capabilities of generative AI in economics. (JEL A11, C45, D83, I23, O33)",
    "citationCount": 126,
    "pdf_filename": "2023_Generative_AI_for_Economic_Research__Use_1332261d.pdf"
  },
  "eb22629ba7dd88761c39173f8abc69b589acc5cd": {
    "paperId": "eb22629ba7dd88761c39173f8abc69b589acc5cd",
    "title": "Generative AI for Software Practitioners",
    "year": 2023,
    "authors": "C. Ebert, Panos Louridas, C. Ebert",
    "abstract": "Generative artificial intelligence (AI) tools, such as Bard, ChatGPT, and CoPilot, have rapidly gained widespread usage. They also have the potential to boost software engineering productivity. In this article, we elaborate technologies and usage of generative AI in the software industry. We address questions, such as: How does generative AI improve software productivity? How to connect generative AI to software development, and what are the risks? Which technologies have what sorts of benefits? Practitioner guidance and case studies are shared from our industry context. I look forward to hearing from you about this column and the technologies that matter most for your work.—Christof Ebert",
    "citationCount": 131,
    "pdf_filename": "2023_Generative_AI_for_Software_Practitioners_eb22629b.pdf"
  },
  "0e41ae9360a962430650d5bb174de223aa8deea5": {
    "paperId": "0e41ae9360a962430650d5bb174de223aa8deea5",
    "title": "Navigating the Complexity of Generative AI Adoption in Software Engineering",
    "year": 2023,
    "authors": "Daniel Russo",
    "abstract": "This article explores the adoption of Generative Artificial Intelligence (AI) tools within the domain of software engineering, focusing on the influencing factors at the individual, technological, and social levels. We applied a convergent mixed-methods approach to offer a comprehensive understanding of AI adoption dynamics. We initially conducted a questionnaire survey with 100 software engineers, drawing upon the Technology Acceptance Model, the Diffusion of Innovation Theory, and the Social Cognitive Theory as guiding theoretical frameworks. Employing the Gioia methodology, we derived a theoretical model of AI adoption in software engineering: the Human-AI Collaboration and Adaptation Framework. This model was then validated using Partial Least Squares–Structural Equation Modeling based on data from 183 software engineers. Findings indicate that at this early stage of AI integration, the compatibility of AI tools within existing development workflows predominantly drives their adoption, challenging conventional technology acceptance theories. The impact of perceived usefulness, social factors, and personal innovativeness seems less pronounced than expected. The study provides crucial insights for future AI tool design and offers a framework for developing effective organizational implementation strategies.",
    "citationCount": 142,
    "pdf_filename": "2023_Navigating_the_Complexity_of_Generative__0e41ae93.pdf"
  },
  "0c5fbcd73343d7527863ddd15c91fbcb774fca49": {
    "paperId": "0c5fbcd73343d7527863ddd15c91fbcb774fca49",
    "title": "Large Generative AI Models for Telecom: The Next Big Thing?",
    "year": 2023,
    "authors": "Lina Bariah, Qiyang Zhao, Han Zou, Yu Tian, F. Bader",
    "abstract": "The evolution of generative artificial intelligence (GenAI) constitutes a turning point in reshaping the future of technology in different aspects. Wireless networks, in particular, with the blooming of self-evolving networks, represent a rich field for exploiting GenAI and reaping several benefits that can fundamentally change the way wireless networks are designed and operated nowadays. To be specific, large GenAI models are envisioned to open up a new era of autonomous wireless networks, in which multi-modal GenAI models trained over various Telecom data, can be fine-tuned to perform several downstream tasks, eliminating the need for building and training dedicated AI models for each specific task, and paving the way for the realization of artificial general intelligence (AGI)-empowered wireless networks. In this article, we aim to unfold the opportunities that can be reaped from integrating large GenAI models into the Telecom domain. In particular, we first highlight the applications of large GenAI models in future wireless networks, defining potential use-cases and revealing insights on the associated theoretical and practical challenges. Furthermore, we unveil how 6G can open up new opportunities through connecting multiple on-device large GenAI models, and hence, pave the way to the collective intelligence paradigm. Finally, we put a forward-looking vision of how large GenAI models will be the key to realize self-evolving networks.",
    "citationCount": 115,
    "pdf_filename": "2023_Large_Generative_AI_Models_for_Telecom___0c5fbcd7.pdf"
  },
  "8d1211cbbdf161feaae2c87832ede063346e76dd": {
    "paperId": "8d1211cbbdf161feaae2c87832ede063346e76dd",
    "title": "Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI",
    "year": 2023,
    "authors": "Mahyar Abbasian, Elahe Khatibi, Iman Azimi, David Oniani, Zahra Shakeri Hossein Abad",
    "abstract": "Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, dynamic scheduling of follow-ups, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients’ well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present a comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.",
    "citationCount": 116,
    "pdf_filename": "2023_Foundation_metrics_for_evaluating_effect_8d1211cb.pdf"
  },
  "a221f7fd6b40168123e6577d983cdd0d51c54297": {
    "paperId": "a221f7fd6b40168123e6577d983cdd0d51c54297",
    "title": "The Generative AI Paradox: \"What It Can Create, It May Not Understand\"",
    "year": 2023,
    "authors": "Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li",
    "abstract": "The recent wave of generative AI has sparked unprecedented global attention, with both excitement and concern over potentially superhuman levels of artificial intelligence: models now take only seconds to produce outputs that would challenge or exceed the capabilities even of expert humans. At the same time, models still show basic errors in understanding that would not be expected even in non-expert humans. This presents us with an apparent paradox: how do we reconcile seemingly superhuman capabilities with the persistence of errors that few humans would make? In this work, we posit that this tension reflects a divergence in the configuration of intelligence in today's generative models relative to intelligence in humans. Specifically, we propose and test the Generative AI Paradox hypothesis: generative models, having been trained directly to reproduce expert-like outputs, acquire generative capabilities that are not contingent upon -- and can therefore exceed -- their ability to understand those same types of outputs. This contrasts with humans, for whom basic understanding almost always precedes the ability to generate expert-level outputs. We test this hypothesis through controlled experiments analyzing generation vs. understanding in generative models, across both language and image modalities. Our results show that although models can outperform humans in generation, they consistently fall short of human capabilities in measures of understanding, as well as weaker correlation between generation and understanding performance, and more brittleness to adversarial inputs. Our findings support the hypothesis that models' generative capability may not be contingent upon understanding capability, and call for caution in interpreting artificial intelligence by analogy to human intelligence.",
    "citationCount": 102,
    "pdf_filename": "2023_The_Generative_AI_Paradox___What_It_Can__a221f7fd.pdf"
  },
  "a6af8c13a3a12735f9cbe855ccc265f77765c3e9": {
    "paperId": "a6af8c13a3a12735f9cbe855ccc265f77765c3e9",
    "title": "The Janus Effect of Generative AI: Charting the Path for Responsible Conduct of Scholarly Activities in Information Systems",
    "year": 2023,
    "authors": "Anjana Susarla, R. Gopal, J. Thatcher, Suprateek Sarker",
    "abstract": "Funding: A. Susarla was funded by an R01 grant from the National Library of Medicine, through [Grant R01LM013443].",
    "citationCount": 165,
    "pdf_filename": "2023_The_Janus_Effect_of_Generative_AI__Chart_a6af8c13.pdf"
  },
  "5fc12e18163db6857b46cdc2787534c8c9d3803f": {
    "paperId": "5fc12e18163db6857b46cdc2787534c8c9d3803f",
    "title": "Reinvent 4: Modern AI–driven generative molecule design",
    "year": 2024,
    "authors": "Hannes H. Loeffler, Jiazhen He, Alessandro Tibo, J. Janet, Alexey Voronov",
    "abstract": "REINVENT 4 is a modern open-source generative AI framework for the design of small molecules. The software utilizes recurrent neural networks and transformer architectures to drive molecule generation. These generators are seamlessly embedded within the general machine learning optimization algorithms, transfer learning, reinforcement learning and curriculum learning. REINVENT 4 enables and facilitates de novo design, R-group replacement, library design, linker design, scaffold hopping and molecule optimization. This contribution gives an overview of the software and describes its design. Algorithms and their applications are discussed in detail. REINVENT 4 is a command line tool which reads a user configuration in either TOML or JSON format. The aim of this release is to provide reference implementations for some of the most common algorithms in AI based molecule generation. An additional goal with the release is to create a framework for education and future innovation in AI based molecular design. The software is available from https://github.com/MolecularAI/REINVENT4 and released under the permissive Apache 2.0 license. Scientific contribution. The software provides an open–source reference implementation for generative molecular design where the software is also being used in production to support in–house drug discovery projects. The publication of the most common machine learning algorithms in one code and full documentation thereof will increase transparency of AI and foster innovation, collaboration and education.",
    "citationCount": 165,
    "pdf_filename": "2024_Reinvent_4__Modern_AI_driven_generative__5fc12e18.pdf"
  },
  "08a4e7a22d52f78e11b53f13415324a86f2a0497": {
    "paperId": "08a4e7a22d52f78e11b53f13415324a86f2a0497",
    "title": "Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study",
    "year": 2023,
    "authors": "Kostis Giannakopoulos, Argyro Kavadella, Anas Aaqel Salim, Vassilis Stamatopoulos, E. Kaklamanos",
    "abstract": "Background The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy. Objective This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry. Methods The LLMs were queried with 20 open-type, clinical dentistry–related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs’ answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs’ answers. Results Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate. Conclusions This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist’s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.",
    "citationCount": 130,
    "pdf_filename": "2023_Evaluation_of_the_Performance_of_Generat_08a4e7a2.pdf"
  },
  "ff809cfc1351ef20cd667533cbc51d0ce6b6e16c": {
    "paperId": "ff809cfc1351ef20cd667533cbc51d0ce6b6e16c",
    "title": "Generative AI-Driven Semantic Communication Networks: Architecture, Technologies, and Applications",
    "year": 2023,
    "authors": "Chengsi Liang, Hongyang Du, Yao Sun, Dusist Niyato, Jiawen Kang",
    "abstract": "Generative artificial intelligence (GAI) has emerged as a rapidly burgeoning field demonstrating significant potential in creating diverse content intelligently and automatically. To support such artificial intelligence-generated content (AIGC) services, future communication systems must fulfill stringent requirements, including high data rates, throughput, and low latency, while efficiently utilizing limited spectrum resources. Semantic communication (SemCom) has been deemed as a revolutionary communication scheme to tackle this challenge by conveying the meaning of messages instead of bit reproduction. GAI algorithms serve as the foundation for enabling intelligent and efficient SemCom systems in terms of model pre-training and fine-tuning, knowledge base construction, and resource allocation. Conversely, SemCom can provide AIGC services with low latency and high reliability due to its ability to perform semantic-aware encoding and compression of data, as well as knowledge- and context-based reasoning. In this survey, we break new ground by investigating the architecture, wireless communication schemes, and network management of GAI-driven SemCom networks. We first introduce a novel architecture for GAI-driven SemCom networks, comprising the data plane, physical infrastructure, and network control plane. In turn, we provide an in-depth analysis of the transceiver design and semantic effectiveness calculation of end-to-end GAI-driven SemCom systems. Subsequently, we present innovative generation level and knowledge management strategies in the proposed networks, including knowledge construction, update, and sharing, ensuring accurate and timely knowledge-based reasoning. Finally, we explore several promising use cases, i.e., autonomous driving, smart cities, and the Metaverse, to provide a comprehensive understanding and future direction of GAI-driven SemCom networks.",
    "citationCount": 104,
    "pdf_filename": "2023_Generative_AI_Driven_Semantic_Communicat_ff809cfc.pdf"
  },
  "71353200a4f9757e10d0243e231fc5bcd14d8387": {
    "paperId": "71353200a4f9757e10d0243e231fc5bcd14d8387",
    "title": "Factors Influencing University Students’ Behavioral Intention to Use Generative Artificial Intelligence: Integrating the Theory of Planned Behavior and AI Literacy",
    "year": 2024,
    "authors": "Chengliang Wang, Haoming Wang, Yuanyuan Li, Jian Dai, Xiaoqing Gu",
    "abstract": "Abstract Generative artificial intelligence (GAI) advancements have ignited new expectations for artificial intelligence (AI)-enabled educational transformations. Based on the theory of planned behavior (TPB), this study combines structural equation modeling and interviews to analyze the influencing factors of Chinese university students’ GAI technology usage intention. Regarding AI literacy, students’ cognitive literacy in AI ethics scored the highest (M = 5.740), while AI awareness literacy scored the lowest (M = 4.578). Students’ attitudes toward GAI significantly and positively influenced their usage intention, with the combined TPB framework and AI literacy explaining 59.3% of the variance. AI literacy and subjective norms positively influenced students’ attitudes toward GAI technology and perceived behavioral control, and attitude mediated the impact of AI literacy and subjective norms on GAI usage intention. Further, the interviews provide new insights for university management and educational leadership regarding the construction of an educational ecosystem under the application of GAI technology.",
    "citationCount": 157,
    "pdf_filename": "2024_Factors_Influencing_University_Students__71353200.pdf"
  },
  "496dab67b98785b46867173f0d777eaa9a32ca9c": {
    "paperId": "496dab67b98785b46867173f0d777eaa9a32ca9c",
    "title": "Detection of GPT-4 Generated Text in Higher Education: Combining Academic Judgement and Software to Identify Generative AI Tool Misuse",
    "year": 2023,
    "authors": "Mike Perkins, Jasper Roe, Darius Postma, James McGaughran, Don Hickerson British University Vietnam",
    "abstract": "This study explores the capability of academic staff assisted by the Turnitin Artificial Intelligence (AI) detection tool to identify the use of AI-generated content in university assessments. 22 different experimental submissions were produced using Open AI’s ChatGPT tool, with prompting techniques used to reduce the likelihood of AI detectors identifying AI-generated content. These submissions were marked by 15 academic staff members alongside genuine student submissions. Although the AI detection tool identified 91% of the experimental submissions as containing AI-generated content, only 54.8% of the content was identified as AI-generated, underscoring the challenges of detecting AI content when advanced prompting techniques are used. When academic staff members marked the experimental submissions, only 54.5% were reported to the academic misconduct process, emphasising the need for greater awareness of how the results of AI detectors may be interpreted. Similar performance in grades was obtained between student submissions and AI-generated content (AI mean grade: 52.3, Student mean grade: 54.4), showing the capabilities of AI tools in producing human-like responses in real-life assessment situations. Recommendations include adjusting the overall strategies for assessing university students in light of the availability of new Generative AI tools. This may include reducing the overall reliance on assessments where AI tools may be used to mimic human writing, or by using AI-inclusive assessments. Comprehensive training must be provided for both academic staff and students so that academic integrity may be preserved.",
    "citationCount": 110,
    "pdf_filename": "2023_Detection_of_GPT_4_Generated_Text_in_Hig_496dab67.pdf"
  },
  "d933f21acd5308a10e6b4729b72098ade33733c1": {
    "paperId": "d933f21acd5308a10e6b4729b72098ade33733c1",
    "title": "When ChatGPT Gives Incorrect Answers: The Impact of Inaccurate Information by Generative AI on Tourism Decision-Making",
    "year": 2023,
    "authors": "Jeong Hyun Kim, Jungkeun Kim, Jooyoung Park, Changju Kim, J. Jhang",
    "abstract": "This study investigates how inaccurate information provided by ChatGPT impacts travelers’ acceptance of recommendations. Six experiments were conducted based on the accessibility-diagnosticity framework. These examined the moderating role of the prominence and type of incorrect information and their effects on decision-making. The results show that participants perceived more accuracy and trustworthiness, leading to stronger intentions to visit when incorrect information was absent. However, there was a decline in their intentions to visit when incorrect information was present and more prominent or in the same domain. This effect diminished when multiple domains were involved or when participants were focused on the initial task. The research highlights that both the prominence and type of incorrect information are boundary conditions and provides insights into AI applications in tourism. Furthermore, it offers practical implications for online travel agencies in terms of user interface and user experience design planning.",
    "citationCount": 105,
    "pdf_filename": "2023_When_ChatGPT_Gives_Incorrect_Answers__Th_d933f21a.pdf"
  },
  "ecede1602cb72756a2220cbc39a2b1150fe8cdac": {
    "paperId": "ecede1602cb72756a2220cbc39a2b1150fe8cdac",
    "title": "Prompt Problems: A New Programming Exercise for the Generative AI Era",
    "year": 2023,
    "authors": "Paul Denny, Juho Leinonen, J. Prather, Andrew Luxton-Reilly, Thezyrie Amarouche",
    "abstract": "Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.",
    "citationCount": 128,
    "pdf_filename": "2023_Prompt_Problems__A_New_Programming_Exerc_ecede160.pdf"
  },
  "0019e876188f781fdca0c0ed3bca39d0c70c2ad2": {
    "paperId": "0019e876188f781fdca0c0ed3bca39d0c70c2ad2",
    "title": "Artificial intelligence prompt engineering as a new digital competence: Analysis of generative AI technologies such as ChatGPT",
    "year": 2023,
    "authors": "P. Korzyński, G. Mazurek, Pamela Krzypkowska, Artur Kurasiński",
    "abstract": "Objective: The article aims to offer a thorough examination and comprehension of the challenges and pro‐ spects connected with artificial intelligence (AI) prompt engineering. Our research aimed to create a theoret‐ ical framework that would highlight optimal approaches in the field of AI prompt engineering. Research Design & Methods: This research utilized a narrative and critical literature review and established a conceptual framework derived from existing literature taking into account both academic and practitioner sources. This article should be regarded as a conceptual work that emphasizes the best practices in the domain of AI prompt engineering. Findings: Based on the conducted deep and extensive query of academic and practitioner literature on the subject, as well as professional press and Internet portals, we identified various insights for effective AI prompt engineering. We provide specific prompting strategies. Implications & Recommendations: The study revealed the profound implications of AI prompt engineering across various domains such as entrepreneurship, art, science, and healthcare. We demonstrated how the effective crafting of prompts can significantly enhance the performance of large language models (LLMs), gen‐ erating more accurate and contextually relevant results. Our findings offer valuable insights for AI practition‐ ers, researchers, educators, and organizations integrating AI into their operations, emphasizing the need to invest time and resources in prompt engineering. Moreover, we contributed the AI PROMPT framework to the field, providing clear and actionable guidelines for text‐to‐text prompt engineering. Contribution & Value Added: The value of this study lies in its comprehensive exploration of AI prompt engineer‐ ing as a digital competence. By building upon existing research and prior literature, this study aimed to provide a deeper understanding of the intricacies involved in AI prompt engineering and its role as a digital competence. Article",
    "citationCount": 108,
    "pdf_filename": "2023_Artificial_intelligence_prompt_engineeri_0019e876.pdf"
  },
  "4130156e2aecb8e102ef7e065dd4384df75e7ada": {
    "paperId": "4130156e2aecb8e102ef7e065dd4384df75e7ada",
    "title": "Advancing Requirements Engineering through Generative AI: Assessing the Role of LLMs",
    "year": 2023,
    "authors": "Chetan Arora, John C. Grundy, Mohamed Abdelrazek",
    "abstract": "Requirements Engineering (RE) is a critical phase in software development including the elicitation, analysis, specification, and validation of software requirements. Despite the importance of RE, it remains a challenging process due to the complexities of communication, uncertainty in the early stages and inadequate automation support. In recent years, large-language models (LLMs) have shown significant promise in diverse domains, including natural language processing, code generation, and program understanding. This chapter explores the potential of LLMs in driving RE processes, aiming to improve the efficiency and accuracy of requirements-related tasks. We propose key directions and SWOT analysis for research and development in using LLMs for RE, focusing on the potential for requirements elicitation, analysis, specification, and validation. We further present the results from a preliminary evaluation, in this context.",
    "citationCount": 123,
    "pdf_filename": "2023_Advancing_Requirements_Engineering_throu_4130156e.pdf"
  },
  "a824d990e6f930760bf9dc56ca1599dc8e488191": {
    "paperId": "a824d990e6f930760bf9dc56ca1599dc8e488191",
    "title": "Chatbots and Mental Health: Insights into the Safety of Generative AI",
    "year": 2023,
    "authors": "Julian De Freitas, A. Uğuralp, Zeliha Oğuz‐Uğuralp, Stefano Puntoni",
    "abstract": "Chatbots are now able to engage in sophisticated conversations with consumers. Due to the ‘black box’ nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and “companion AI”: applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a non‐negligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies.",
    "citationCount": 103,
    "pdf_filename": "2023_Chatbots_and_Mental_Health__Insights_int_a824d990.pdf"
  },
  "0394864f253fd69284462664d5725ad6ba7aa6e1": {
    "paperId": "0394864f253fd69284462664d5725ad6ba7aa6e1",
    "title": "Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education",
    "year": 2024,
    "authors": "Rong Liu, Carter Zenke, Charlie Liu, Andrew Holmes, Patrick Thornton",
    "abstract": "In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had \"a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.",
    "citationCount": 141,
    "pdf_filename": "2024_Teaching_CS50_with_AI__Leveraging_Genera_0394864f.pdf"
  },
  "0c462483d18b5ce55e5f813faa160f056e80326e": {
    "paperId": "0c462483d18b5ce55e5f813faa160f056e80326e",
    "title": "GenAICHI: Generative AI and HCI",
    "year": 2022,
    "authors": "Michael J. Muller, Lydia B. Chilton, Anna Kantosalo, C. P. Martin, Greg Walsh",
    "abstract": "This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities. Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together. It is time to convene the interdisciplinary research domain of generative AI and HCI. Participation in this invitational workshop is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",
    "citationCount": 100,
    "pdf_filename": "2022_GenAICHI__Generative_AI_and_HCI_0c462483.pdf"
  },
  "926012222b0932b256ab717113cba49d8de34501": {
    "paperId": "926012222b0932b256ab717113cba49d8de34501",
    "title": "AI as Social Glue: Uncovering the Roles of Deep Generative AI during Social Music Composition",
    "year": 2021,
    "authors": "Minhyang Suh, Emily Youngblom, Michael Terry, Carrie J. Cai",
    "abstract": "Recent advances in deep generative neural networks have made it possible for artificial intelligence to actively collaborate with human beings in co-creating novel content (e.g. music, art). While substantial research focuses on (individual) human-AI collaborations, comparatively less research examines how AI can play a role in human-human collaborations during co-creation. In a qualitative lab study, we observed 30 participants (15 pairs) compose a musical phrase in pairs, both with and without AI. Our findings reveal that AI may play important roles in influencing human social dynamics during creativity, including: 1) implicitly seeding a common ground at the start of collaboration, 2) acting as a psychological safety net in creative risk-taking, 3) providing a force for group progress, 4) mitigating interpersonal stalling and friction, and 5) altering users’ collaborative and creative roles. This work contributes to the future of generative AI in social creativity by providing implications for how AI could enrich, impede, or alter creative social dynamics in the years to come.",
    "citationCount": 119,
    "pdf_filename": "2021_AI_as_Social_Glue__Uncovering_the_Roles__92601222.pdf"
  },
  "5a5e03c3c8bf5052a99f4631e874b1e608e59319": {
    "paperId": "5a5e03c3c8bf5052a99f4631e874b1e608e59319",
    "title": "Artificial intelligence in developing countries: The impact of generative artificial intelligence (AI) technologies for development",
    "year": 2023,
    "authors": "Nishith Reddy Mannuru, Sakib Shahriar, Z. A. Teel, Ting Wang, Brady D. Lund",
    "abstract": "This paper explores the potential impact of Generative Artificial Intelligence (Generative AI) on developing countries, considering both positive and negative effects across various domains of information, culture, and industry. Generative Artificial Intelligence refers to artificial intelligence (AI) systems that generate content, such as text, audio, or video, aiming to produce novel and creative outputs based on training data. Compared to conversational artificial intelligence, generative artificial intelligence systems have the unique capability of not only providing replies but also generating the content of those responses. Recent advancements in Artificial Intelligence during the Fourth Industrial Revolution, exemplified by tools like ChatGPT, have gained popularity and reshaped content production and creation. However, the benefits of generative artificial intelligence are not equally accessible to all, especially in developing countries, where limited access to cutting-edge technologies and inadequate infrastructure pose challenges. This paper seeks to understand the potential impact of generative AI technologies on developing countries, considering economic growth, access to technology, and the potential paradigm shift in education, healthcare, and the environment. The findings emphasize the importance of providing the necessary support and infrastructure to ensure that generative AI contributes to inclusive development rather than deepening existing inequalities. The study highlights the significance of integrating Generative AI into the context of the Fourth Industrial Revolution in developing countries, where technological change is a crucial determinant of progress and equitable growth.",
    "citationCount": 184,
    "pdf_filename": "2023_Artificial_intelligence_in_developing_co_5a5e03c3.pdf"
  },
  "f60965bc7450f0a1d9dc9ae9165037a16fdcf747": {
    "paperId": "f60965bc7450f0a1d9dc9ae9165037a16fdcf747",
    "title": "An Enhanced AI-Based Network Intrusion Detection System Using Generative Adversarial Networks",
    "year": 2023,
    "authors": "Cheolhee Park, Jonghoon Lee, Youngsoo Kim, Jong-Geun Park, Hyunjin Kim",
    "abstract": "As communication technology advances, various and heterogeneous data are communicated in distributed environments through network systems. Meanwhile, along with the development of communication technology, the attack surface has expanded, and concerns regarding network security have increased. Accordingly, to deal with potential threats, research on network intrusion detection systems (NIDSs) has been actively conducted. Among the various NIDS technologies, recent interest is focused on artificial intelligence (AI)-based anomaly detection systems, and various models have been proposed to improve the performance of NIDS. However, there still exists the problem of data imbalance, in which AI models cannot sufficiently learn malicious behavior and thus fail to detect network threats accurately. In this study, we propose a novel AI-based NIDS that can efficiently resolve the data imbalance problem and improve the performance of the previous systems. To address the aforementioned problem, we leveraged a state-of-the-art generative model that could generate plausible synthetic data for minor attack traffic. In particular, we focused on the reconstruction error and Wasserstein distance-based generative adversarial networks, and autoencoder-driven deep learning models. To demonstrate the effectiveness of our system, we performed comprehensive evaluations over various data sets and demonstrated that the proposed systems significantly outperformed the previous AI-based NIDS.",
    "citationCount": 188,
    "pdf_filename": "2023_An_Enhanced_AI_Based_Network_Intrusion_D_f60965bc.pdf"
  },
  "93a07d548608d2368ae2e3287275e3caf42a562c": {
    "paperId": "93a07d548608d2368ae2e3287275e3caf42a562c",
    "title": "The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers",
    "year": 2025,
    "authors": "Hao-Ping Lee, Advait Sarkar, Lev Tankelevitch, Ian Drosos, Sean Rintel",
    "abstract": "The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user’s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.",
    "citationCount": 186,
    "pdf_filename": "2025_The_Impact_of_Generative_AI_on_Critical__93a07d54.pdf"
  },
  "23f4c8d980d8288131f80cbdb4173f05a21e8724": {
    "paperId": "23f4c8d980d8288131f80cbdb4173f05a21e8724",
    "title": "RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions",
    "year": 2023,
    "authors": "Yunlong Wang, Shuyuan Shen, Brian Y. Lim",
    "abstract": "Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.",
    "citationCount": 121,
    "pdf_filename": "2023_RePrompt__Automatic_Prompt_Editing_to_Re_23f4c8d9.pdf"
  },
  "6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a": {
    "paperId": "6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a",
    "title": "How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models",
    "year": 2022,
    "authors": "Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, Daniel Buschek",
    "abstract": "Deep generative models have the potential to fundamentally change the way we create high-fidelity digital content but are often hard to control. Prompting a generative model is a promising recent development that in principle enables end-users to creatively leverage zero-shot and few-shot learning to assign new tasks to an AI ad-hoc, simply by writing them down. However, for the majority of end-users writing effective prompts is currently largely a trial and error process. To address this, we discuss the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction. Based on our analysis, we propose four design goals for user interfaces that support prompting. We illustrate these with concrete UI design sketches, focusing on the use case of creative writing. The research community in HCI and AI can take these as starting points to develop adequate user interfaces for models capable of zero- and few-shot learning.",
    "citationCount": 134,
    "pdf_filename": "2022_How_to_Prompt__Opportunities_and_Challen_6b5d1e50.pdf"
  },
  "a1a05b4c7e8adfe15345885da40c73c12f189e39": {
    "paperId": "a1a05b4c7e8adfe15345885da40c73c12f189e39",
    "title": "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations",
    "year": 2024,
    "authors": "Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li",
    "abstract": "Large-scale recommendation systems are characterized by their reliance on high cardinality, heterogeneous features and the need to handle tens of billions of user actions on a daily basis. Despite being trained on huge volume of data with thousands of features, most Deep Learning Recommendation Models (DLRMs) in industry fail to scale with compute. Inspired by success achieved by Transformers in language and vision domains, we revisit fundamental design choices in recommendation systems. We reformulate recommendation problems as sequential transduction tasks within a generative modeling framework (\"Generative Recommenders\"), and propose a new architecture, HSTU, designed for high cardinality, non-stationary streaming recommendation data. HSTU outperforms baselines over synthetic and public datasets by up to 65.8% in NDCG, and is 5.3x to 15.2x faster than FlashAttention2-based Transformers on 8192 length sequences. HSTU-based Generative Recommenders, with 1.5 trillion parameters, improve metrics in online A/B tests by 12.4% and have been deployed on multiple surfaces of a large internet platform with billions of users. More importantly, the model quality of Generative Recommenders empirically scales as a power-law of training compute across three orders of magnitude, up to GPT-3/LLaMa-2 scale, which reduces carbon footprint needed for future model developments, and further paves the way for the first foundational models in recommendations.",
    "citationCount": 121,
    "pdf_filename": "2024_Actions_Speak_Louder_than_Words__Trillio_a1a05b4c.pdf"
  },
  "14faed00db373d87bf90e8ee8f2c0dbbeed768dd": {
    "paperId": "14faed00db373d87bf90e8ee8f2c0dbbeed768dd",
    "title": "Generative artificial intelligence in supply chain and operations management: a capability-based framework for analysis and implementation",
    "year": 2024,
    "authors": "Ilya Jackson, Dmitry A. Ivanov, Alexandre Dolgui, Jafar Namdar",
    "abstract": "This research examines the transformative potential of artificial intelligence (AI) in general and Generative AI (GAI) in particular in supply chain and operations management (SCOM). Through the lens of the resource-based view and based on key AI capabilities such as learning, perception, prediction, interaction, adaptation, and reasoning, we explore how AI and GAI can impact 13 distinct SCOM decision-making areas. These areas include but are not limited to demand forecasting, inventory management, supply chain design, and risk management. With its outcomes, this study provides a comprehensive understanding of AI and GAI's functionality and applications in the SCOM context, offering a practical framework for both practitioners and researchers. The proposed framework systematically identifies where and how AI and GAI can be applied in SCOM, focussing on decision-making enhancement, process optimisation, investment prioritisation, and skills development. Managers can use it as a guidance to evaluate their operational processes and identify areas where AI and GAI can deliver improved efficiency, accuracy, resilience, and overall effectiveness. The research underscores that AI and GAI, with their multifaceted capabilities and applications, open a revolutionary potential and substantial implications for future SCOM practices, innovations, and research.",
    "citationCount": 162,
    "pdf_filename": "2024_Generative_artificial_intelligence_in_su_14faed00.pdf"
  },
  "cc4a3422e011ca4715403f3bd818d37dc32d9d84": {
    "paperId": "cc4a3422e011ca4715403f3bd818d37dc32d9d84",
    "title": "Enhancing Work Productivity through Generative Artificial Intelligence: A Comprehensive Literature Review",
    "year": 2024,
    "authors": "Humaid Al Naqbi, Zied Bahroun, Vian Ahmed",
    "abstract": "In this review, utilizing the PRISMA methodology, a comprehensive analysis of the use of Generative Artificial Intelligence (GAI) across diverse professional sectors is presented, drawing from 159 selected research publications. This study provides an insightful overview of the impact of GAI on enhancing institutional performance and work productivity, with a specific focus on sectors including academia, research, technology, communications, agriculture, government, and business. It highlights the critical role of GAI in navigating AI challenges, ethical considerations, and the importance of analytical thinking in these domains. The research conducts a detailed content analysis, uncovering significant trends and gaps in current GAI applications and projecting future prospects. A key aspect of this study is the bibliometric analysis, which identifies dominant tools like Chatbots and Conversational Agents, notably ChatGPT, as central to GAI’s evolution. The findings indicate a robust and accelerating trend in GAI research, expected to continue through 2024 and beyond. Additionally, this study points to potential future research directions, emphasizing the need for improved GAI design and strategic long-term planning, particularly in assessing its impact on user experience across various professional fields.",
    "citationCount": 164,
    "pdf_filename": "2024_Enhancing_Work_Productivity_through_Gene_cc4a3422.pdf"
  },
  "90a3410bc1632ba3340de7259186c66ba03f1668": {
    "paperId": "90a3410bc1632ba3340de7259186c66ba03f1668",
    "title": "Promises and challenges of generative artificial intelligence for human learning",
    "year": 2024,
    "authors": "Lixiang Yan, Samuel Greiff, Ziwen Teuber, D. Gašević",
    "abstract": "Generative artificial intelligence (GenAI) holds the potential to transform the delivery, cultivation and evaluation of human learning. Here the authors examine the integration of GenAI as a tool for human learning, addressing its promises and challenges from a holistic viewpoint that integrates insights from learning sciences, educational technology and human–computer interaction. GenAI promises to enhance learning experiences by scaling personalized support, diversifying learning materials, enabling timely feedback and innovating assessment methods. However, it also presents critical issues such as model imperfections, ethical dilemmas and the disruption of traditional assessments. Thus, cultivating AI literacy and adaptive skills is imperative for facilitating informed engagement with GenAI technologies. Rigorous research across learning contexts is essential to evaluate GenAI’s effect on human cognition, metacognition and creativity. Humanity must learn with and about GenAI, ensuring that it becomes a powerful ally in the pursuit of knowledge and innovation, rather than a crutch that undermines our intellectual abilities. This Perspective describes the roles of generative AI in providing personalized support, diversity and innovative assessment in learning. However, it also raises ethical concerns and highlights issues such as model imperfection, underscoring the need for AI literacy and adaptability.",
    "citationCount": 164,
    "pdf_filename": "2024_Promises_and_challenges_of_generative_ar_90a3410b.pdf"
  },
  "97a5fb3512be8dfd9c8a32f4c556ad9db6030288": {
    "paperId": "97a5fb3512be8dfd9c8a32f4c556ad9db6030288",
    "title": "Beware of Metacognitive Laziness: Effects of Generative Artificial Intelligence on Learning Motivation, Processes, and Performance",
    "year": 2024,
    "authors": "Yizhou Fan, Luzhen Tang, Huixiao Le, Kejie Shen, Shufang Tan",
    "abstract": "With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human‐AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human‐AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self‐regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi‐channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post‐task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self‐regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self‐regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger “metacognitive laziness”. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.\nWhat is already known about this topic\n\nHybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.\nGenerative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.\nThe effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.\nWhat this paper adds\n\nWe conducted a randomised experimental study in the lab setting and compared learners' motivations, self‐regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).\nWe found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive \"laziness\", which can potentially hinder their ability to self‐regulate and engage deeply in learning.\nWe also found that ChatGPT can significantly improve short‐term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.\nImplications for practice and/or policy\n\nWhen using AI in learning, learners should focus on deepening their understanding of knowledge and actively engage in metacognitive processes such as evaluation, monitoring, and orientation, rather than blindly following ChatGPT's feedback solely to complete tasks efficiently.\nWhen using AI in teaching, teachers should think about which tasks are suitable for learners to complete with the assistance of AI, pay attention to stimulating learners' intrinsic motivations, and develop scaffolding to assist learners in active learning.\nResearcher should design multi‐task and cross‐context studies in the future to deepen our understanding of how learners could ethically and effectively learn, regulate, collaborate and evolve with AI.\n\n",
    "citationCount": 170,
    "pdf_filename": "2024_Beware_of_Metacognitive_Laziness__Effect_97a5fb35.pdf"
  },
  "4e9fefd759c0d0f920533cd70676a59e291729e2": {
    "paperId": "4e9fefd759c0d0f920533cd70676a59e291729e2",
    "title": "Collaborative Working and Critical Thinking: Adoption of Generative Artificial Intelligence Tools in Higher Education",
    "year": 2024,
    "authors": "Lena Ivannova Ruiz-Rojas, Luis Salvador-Ullauri, Patricia Acosta-Vargas",
    "abstract": "This study explores the impact of generative artificial intelligence tools on critical thinking and collaboration among university students, highlighting the importance of investigating these technologies due to their increasing integration into higher education and their potential to transform traditional pedagogical practices. A predominantly female sample was surveyed to assess their familiarity with and experience and perceptions of these tools. A total of 87% of the respondents had prior knowledge of generative AI tools, with 38% using them occasionally. Among the most popular tools are Canva 2024 (33%), Chat PDF (26%), and YOU.COM (24%). Additionally, 64% of the respondents believe that these tools significantly improve their critical thinking ability. Despite their high familiarity with and occasional use of these tools, the need for continuous training and technical support was identified. While generative AI tools show promising potential for enhancing collaboration and critical thinking in higher education, previous research has limitations, such as the lack of longitudinal data and the inadequacy in addressing ethical considerations and potential biases. More comprehensive research is needed to understand their long-term impact better and maximize their potential benefits.",
    "citationCount": 105,
    "pdf_filename": "2024_Collaborative_Working_and_Critical_Think_4e9fefd7.pdf"
  },
  "de0ee1e7970e9ffff4add57f1fe72623453dae19": {
    "paperId": "de0ee1e7970e9ffff4add57f1fe72623453dae19",
    "title": "A scoping review on how generative artificial intelligence transforms assessment in higher education",
    "year": 2024,
    "authors": "Qi Xia, Xiaojing Weng, Ouyang Fan, Tzung-Jin Lin, T. Chiu",
    "abstract": "Generative artificial intelligence provides both opportunities and challenges for higher education. Existing literature has not properly investigated how this technology would impact assessment in higher education. This scoping review took a forward-thinking approach to investigate how generative artificial intelligence transforms assessment in higher education. We used the PRISMA extension for scoping reviews to select articles for review and report the results. In the screening, we retrieved 969 articles and selected 32 empirical studies for analysis. Most of the articles were published in 2023. We used three levels—students, teachers, and institutions—to analyses the articles. Our results suggested that assessment should be transformed to cultivate students’ self-regulated learning skills, responsible learning, and integrity. To successfully transform assessment in higher education, the review suggested that (i) teacher professional development activities for assessment, AI, and digital literacy should be provided, (ii) teachers’ beliefs about human and AI assessment should be strengthened, and (iii) teachers should be innovative and holistic in their teaching to reflect the assessment transformation. Educational institutions are recommended to review and rethink their assessment policies, as well as provide more inter-disciplinary programs and teaching.",
    "citationCount": 128,
    "pdf_filename": "2024_A_scoping_review_on_how_generative_artif_de0ee1e7.pdf"
  },
  "5b8b994117d9d3273d91e9c671da495e9e20e889": {
    "paperId": "5b8b994117d9d3273d91e9c671da495e9e20e889",
    "title": "Generative artificial intelligence: a systematic review and applications",
    "year": 2024,
    "authors": "S. S. Sengar, Affan Bin Hasan, Sanjay Kumar, Fiona Carroll",
    "abstract": "In recent years, the study of artificial intelligence (AI) has undergone a paradigm shift. This has been propelled by the groundbreaking capabilities of generative models both in supervised and unsupervised learning scenarios. Generative AI has shown state-of-the-art performance in solving perplexing real-world conundrums in fields such as image translation, medical diagnostics, textual imagery fusion, natural language processing, and beyond. This paper documents the systematic review and analysis of recent advancements and techniques in Generative AI with a detailed discussion of their applications including application-specific models. Indeed, the major impact that generative AI has made to date, has been in language generation with the development of large language models, in the field of image translation and several other interdisciplinary applications of generative AI. Moreover, the primary contribution of this paper lies in its coherent synthesis of the latest advancements in these areas, seamlessly weaving together contemporary breakthroughs in the field. Particularly, how it shares an exploration of the future trajectory for generative AI. In conclusion, the paper ends with a discussion of Responsible AI principles, and the necessary ethical considerations for the sustainability and growth of these generative models.",
    "citationCount": 189,
    "pdf_filename": "2024_Generative_artificial_intelligence__a_sy_5b8b9941.pdf"
  },
  "7bba1b6bbdc065ec6617cfe420f46fbf3d7bd397": {
    "paperId": "7bba1b6bbdc065ec6617cfe420f46fbf3d7bd397",
    "title": "The current state of artificial intelligence generative language models is more creative than humans on divergent thinking tasks",
    "year": 2024,
    "authors": "Kent F. Hubert, Kim N. Awa, Darya L. Zabelina",
    "abstract": "The emergence of publicly accessible artificial intelligence (AI) large language models such as ChatGPT has given rise to global conversations on the implications of AI capabilities. Emergent research on AI has challenged the assumption that creative potential is a uniquely human trait thus, there seems to be a disconnect between human perception versus what AI is objectively capable of creating. Here, we aimed to assess the creative potential of humans in comparison to AI. In the present study, human participants (N = 151) and GPT-4 provided responses for the Alternative Uses Task, Consequences Task, and Divergent Associations Task. We found that AI was robustly more creative along each divergent thinking measurement in comparison to the human counterparts. Specifically, when controlling for fluency of responses, AI was more original and elaborate. The present findings suggest that the current state of AI language models demonstrate higher creative potential than human respondents.",
    "citationCount": 116,
    "pdf_filename": "2024_The_current_state_of_artificial_intellig_7bba1b6b.pdf"
  },
  "9be96dfc894b8ad6302f67f47448e19e6cb1dd3c": {
    "paperId": "9be96dfc894b8ad6302f67f47448e19e6cb1dd3c",
    "title": "The ethical implications of using generative chatbots in higher education",
    "year": 2024,
    "authors": "Ryan Thomas Williams",
    "abstract": "Incorporating artificial intelligence (AI) into education, specifically through generative chatbots, can transform teaching and learning for education professionals in both administrative and pedagogical ways. However, the ethical implications of using generative chatbots in education must be carefully considered. Ethical concerns about advanced chatbots have yet to be explored in the education sector. This short article introduces the ethical concerns associated with introducing platforms such as ChatGPT in education. The article outlines how handling sensitive student data by chatbots presents significant privacy challenges, thus requiring adherence to data protection regulations, which may not always be possible. It highlights the risk of algorithmic bias in chatbots, which could perpetuate societal biases, which can be problematic. The article also examines the balance between fostering student autonomy in learning and the potential impact on academic self-efficacy, noting the risk of over-reliance on AI for educational purposes. Plagiarism continues to emerge as a critical ethical concern, with AI-generated content threatening academic integrity. The article advocates for comprehensive measures to address these ethical issues, including clear policies, advanced plagiarism detection techniques, and innovative assessment methods. By addressing these ethical challenges, the article argues that educators, AI developers, policymakers, and students can fully harness the potential of chatbots in education, creating a more inclusive, empowering, and ethically sound educational future.",
    "citationCount": 102,
    "pdf_filename": "2024_The_ethical_implications_of_using_genera_9be96dfc.pdf"
  },
  "b2503e37c3bb9be19ba53268b992e29c81080aad": {
    "paperId": "b2503e37c3bb9be19ba53268b992e29c81080aad",
    "title": "Using artificial intelligence in craft education: crafting with text-to-image generative models",
    "year": 2023,
    "authors": "Henriikka Vartiainen, M. Tedre",
    "abstract": "ABSTRACT Artificial intelligence (AI) and the automation of creative work have received little attention in craft education. This study aimed to address this gap by exploring Finnish pre-service craft teachers’ and teacher educators’ (N = 15) insights into the potential benefits and challenges of AI, particularly text-to-image generative AI. This study implemented a hands-on workshop on creative making with text-to-image generative AI in order to stimulate discourses and capture imaginaries concerning generative AI. The results revealed that making with AI inspired teachers to consider the unique nature of crafts as well as the tensions and tradeoffs of adopting generative AI in craft practices. The teachers identified concerns in data-driven design, including algorithmic bias, copyright violations and black-boxing creativity, as well as in power relationships, hybrid influencing and behaviour engineering. The article concludes with a discussion of the complicated relationships the results uncovered between creative making and generative AI.",
    "citationCount": 179,
    "pdf_filename": "2023_Using_artificial_intelligence_in_craft_e_b2503e37.pdf"
  },
  "5d2f65749187c7369072d7ecbe37784295ac5acd": {
    "paperId": "5d2f65749187c7369072d7ecbe37784295ac5acd",
    "title": "How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey",
    "year": 2024,
    "authors": "Matthew S. Bower, Jodie Torrington, Jennifer W. M. Lai, P. Petocz, Mark Alfano",
    "abstract": "There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an ‘ignorance effect’. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.",
    "citationCount": 105,
    "pdf_filename": "2024_How_should_we_change_teaching_and_assess_5d2f6574.pdf"
  },
  "414ba364b5506c62edd01b64cba9d855c541335f": {
    "paperId": "414ba364b5506c62edd01b64cba9d855c541335f",
    "title": "Enhancing Deep Reinforcement Learning: A Tutorial on Generative Diffusion Models in Network Optimization",
    "year": 2023,
    "authors": "Hongyang Du, Ruichen Zhang, Yinqiu Liu, Jiacheng Wang, Yi-Lan Lin",
    "abstract": "Generative Diffusion Models (GDMs) have emerged as a transformative force in the realm of Generative Artificial Intelligence (GenAI), demonstrating their versatility and efficacy across various applications. The ability to model complex data distributions and generate high-quality samples has made GDMs particularly effective in tasks such as image generation and reinforcement learning. Furthermore, their iterative nature, which involves a series of noise addition and denoising steps, is a powerful and unique approach to learning and generating data. This paper serves as a comprehensive tutorial on applying GDMs in network optimization tasks. We delve into the strengths of GDMs, emphasizing their wide applicability across various domains, such as vision, text, and audio generation. We detail how GDMs can be effectively harnessed to solve complex optimization problems inherent in networks. The paper first provides a basic background of GDMs and their applications in network optimization. This is followed by a series of case studies, showcasing the integration of GDMs with Deep Reinforcement Learning (DRL), incentive mechanism design, Semantic Communications (SemCom), Internet of Vehicles (IoV) networks, etc. These case studies underscore the practicality and efficacy of GDMs in real-world scenarios, offering insights into network design. We conclude with a discussion on potential future directions for GDM research and applications, providing major insights into how they can continue to shape the future of network optimization.",
    "citationCount": 150,
    "pdf_filename": "2023_Enhancing_Deep_Reinforcement_Learning__A_414ba364.pdf"
  },
  "ec1c43ca684732d06716a36271a4cb3066797153": {
    "paperId": "ec1c43ca684732d06716a36271a4cb3066797153",
    "title": "Generative artificial intelligence",
    "year": 2023,
    "authors": "Leonardo Banh, G. Strobel",
    "abstract": "Recent developments in the field of artificial intelligence (AI) have enabled new paradigms of machine processing, shifting from data-driven, discriminative AI tasks toward sophisticated, creative tasks through generative AI. Leveraging deep generative models, generative AI is capable of producing novel and realistic content across a broad spectrum (e.g., texts, images, or programming code) for various domains based on basic user prompts. In this article, we offer a comprehensive overview of the fundamentals of generative AI with its underpinning concepts and prospects. We provide a conceptual introduction to relevant terms and techniques, outline the inherent properties that constitute generative AI, and elaborate on the potentials and challenges. We underline the necessity for researchers and practitioners to comprehend the distinctive characteristics of generative artificial intelligence in order to harness its potential while mitigating its risks and to contribute to a principal understanding.",
    "citationCount": 170,
    "pdf_filename": "2023_Generative_artificial_intelligence_ec1c43ca.pdf"
  },
  "b020cac5955b48c22ac59fa74bc49f6e3260a637": {
    "paperId": "b020cac5955b48c22ac59fa74bc49f6e3260a637",
    "title": "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction",
    "year": 2023,
    "authors": "Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma",
    "abstract": "Recently video generation has achieved substantial progress with realistic results. Nevertheless, existing AI-generated videos are usually very short clips (\"shot-level\") depicting a single scene. To deliver a coherent long video (\"story-level\"), it is desirable to have creative transition and prediction effects across different clips. This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction. The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos. Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions. By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality. Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction. To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment. Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos. Project page: https://vchitect.github.io/SEINE-project/ .",
    "citationCount": 197,
    "pdf_filename": "2023_SEINE__Short_to_Long_Video_Diffusion_Mod_b020cac5.pdf"
  },
  "98d158d4f4c20fc560e8451fd8122cb5ae1cc4fd": {
    "paperId": "98d158d4f4c20fc560e8451fd8122cb5ae1cc4fd",
    "title": "GenAI against humanity: nefarious applications of generative artificial intelligence and large language models",
    "year": 2023,
    "authors": "Emilio Ferrara",
    "abstract": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we’ll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social media platforms to the unnerving potential of AI to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential GenAI’s nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful GenAI applications we might encounter in the near future, and some ways we can prepare for them.",
    "citationCount": 158,
    "pdf_filename": "2023_GenAI_against_humanity__nefarious_applic_98d158d4.pdf"
  },
  "e3fd89a7f6b28973cfc68bfc51caebd8fb93f0bc": {
    "paperId": "e3fd89a7f6b28973cfc68bfc51caebd8fb93f0bc",
    "title": "BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine",
    "year": 2023,
    "authors": "Yi Luo, Jiahuan Zhang, Siqi Fan, Kai Yang, Yushuai Wu",
    "abstract": "Foundation models (FMs) have exhibited remarkable performance across a wide range of downstream tasks in many domains. Nevertheless, general-purpose FMs often face challenges when confronted with domain-specific problems, due to their limited access to the proprietary training data in a particular domain. In biomedicine, there are various biological modalities, such as molecules, proteins, and cells, which are encoded by the language of life and exhibit significant modality gaps with human natural language. In this paper, we introduce BioMedGPT, an open multimodal generative pre-trained transformer (GPT) for biomedicine, to bridge the gap between the language of life and human natural language. BioMedGPT allows users to easily ``communicate'' with diverse biological modalities through free text, which is the first of its kind. BioMedGPT aligns different biological modalities with natural language via a large generative language model, namely, BioMedGPT-LM. We publish BioMedGPT-10B, which unifies the feature spaces of molecules, proteins, and natural language via encoding and alignment. Through fine-tuning, BioMedGPT-10B outperforms or is on par with human and significantly larger general-purpose foundation models on the biomedical QA task. It also demonstrates promising performance in the molecule QA and protein QA tasks, which could greatly accelerate the discovery of new drugs and therapeutic targets. In addition, BioMedGPT-LM-7B is the first large generative language model based on Llama2 in the biomedical domain, therefore is commercial friendly. Both BioMedGPT-10B and BioMedGPT-LM-7B are open-sourced to the research community. In addition, we publish the datasets that are meticulously curated for the alignment of multi-modalities, i.e., PubChemQA and UniProtQA. All the models, codes, and datasets are available at \\url{https://github.com/PharMolix/OpenBioMed}.",
    "citationCount": 109,
    "pdf_filename": "2023_BioMedGPT__Open_Multimodal_Generative_Pr_e3fd89a7.pdf"
  },
  "c68d3127888912ead55096d30165de783fe24216": {
    "paperId": "c68d3127888912ead55096d30165de783fe24216",
    "title": "JourneyDB: A Benchmark for Generative Image Understanding",
    "year": 2023,
    "authors": "Junting Pan, Keqiang Sun, Yuying Ge, Hao Li, Haodong Duan",
    "abstract": "While recent advancements in vision-language models have had a transformative impact on multi-modal comprehension, the extent to which these models possess the ability to comprehend generated images remains uncertain. Synthetic images, in comparison to real data, encompass a higher level of diversity in terms of both content and style, thereby presenting significant challenges for the models to fully grasp. In light of this challenge, we introduce a comprehensive dataset, referred to as JourneyDB, that caters to the domain of generative images within the context of multi-modal visual understanding. Our meticulously curated dataset comprises 4 million distinct and high-quality generated images, each paired with the corresponding text prompts that were employed in their creation. Furthermore, we additionally introduce an external subset with results of another 22 text-to-image generative models, which makes JourneyDB a comprehensive benchmark for evaluating the comprehension of generated images. On our dataset, we have devised four benchmarks to assess the performance of generated image comprehension in relation to both content and style interpretation. These benchmarks encompass prompt inversion, style retrieval, image captioning, and visual question answering. Lastly, we evaluate the performance of state-of-the-art multi-modal models when applied to the JourneyDB dataset, providing a comprehensive analysis of their strengths and limitations in comprehending generated content. We anticipate that the proposed dataset and benchmarks will facilitate further research in the field of generative content understanding. The dataset is publicly available at https://journeydb.github.io.",
    "citationCount": 160,
    "pdf_filename": "2023_JourneyDB__A_Benchmark_for_Generative_Im_c68d3127.pdf"
  },
  "55b7e681e14e775600b341d8cc9bf53f3e9a4567": {
    "paperId": "55b7e681e14e775600b341d8cc9bf53f3e9a4567",
    "title": "Human-AI collaboration patterns in AI-assisted academic writing",
    "year": 2024,
    "authors": "Andy Nguyen, Yvonne Hong, Belle Dang, Xiaoshan Huang",
    "abstract": "ABSTRACT Artificial Intelligence (AI) has increasingly influenced higher education, notably in academic writing where AI-powered assisting tools offer both opportunities and challenges. Recently, the rapid growth of generative AI (GAI) has brought its impacts into sharper focus, yet the dynamics of its utilisation in academic writing remain largely unexplored. This paper focuses on examining the nature of human-AI interactions in academic writing, specifically investigating the strategies doctoral students employ when collaborating with a GAI-powered assisting tool. This study involves 626 recorded activities on how ten doctoral students interact with GAI-powered assisting tool during academic writing. AI-driven learning analytics approach was adopted for three layered analyses: (1) data pre-processing and analysis with quantitative content analysis, (2) sequence analysis with Hidden Markov Model (HMM) and hierarchical sequence clustering, and (3) pattern analysis with process mining. Findings indicate that doctoral students engaging in iterative, highly interactive processes with the GAI-powered assisting tool generally achieve better performance in the writing task. In contrast, those who use GAI merely as a supplementary information source, maintaining a linear writing approach, tend to get lower writing performance. This study points to the need for further investigations into human-AI collaboration in learning in higher education, with implications for tailored educational strategies and solutions.",
    "citationCount": 179,
    "pdf_filename": "2024_Human_AI_collaboration_patterns_in_AI_as_55b7e681.pdf"
  },
  "5c96740dbcc3a50d9280c81ab8128b025cf05879": {
    "paperId": "5c96740dbcc3a50d9280c81ab8128b025cf05879",
    "title": "Exploring AI-mediated informal digital learning of English (AI-IDLE): a mixed-method investigation of Chinese EFL learners’ AI adoption and experiences",
    "year": 2024,
    "authors": "G. Liu, Ron Darvin, Chaojun Ma",
    "abstract": "Abstract Recent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data via an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of perceived ease of use, perceived usefulness, intention to use, and actual use, the quantitative analysis provides statistical accounts for EFL learners’ adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research.",
    "citationCount": 139,
    "pdf_filename": "2024_Exploring_AI_mediated_informal_digital_l_5c96740d.pdf"
  },
  "1a450fcd40aeea64544fad08844de1119c33f03f": {
    "paperId": "1a450fcd40aeea64544fad08844de1119c33f03f",
    "title": "Natural scene reconstruction from fMRI signals using generative latent diffusion",
    "year": 2023,
    "authors": "Furkan Ozcelik, Rufin VanRullen",
    "abstract": "In neural decoding research, one of the most intriguing topics is the reconstruction of perceived natural images based on fMRI signals. Previous studies have succeeded in re-creating different aspects of the visuals, such as low-level properties (shape, texture, layout) or high-level features (category of objects, descriptive semantics of scenes) but have typically failed to reconstruct these properties together for complex scene images. Generative AI has recently made a leap forward with latent diffusion models capable of generating high-complexity images. Here, we investigate how to take advantage of this innovative technology for brain decoding. We present a two-stage scene reconstruction framework called “Brain-Diffuser”. In the first stage, starting from fMRI signals, we reconstruct images that capture low-level properties and overall layout using a VDVAE (Very Deep Variational Autoencoder) model. In the second stage, we use the image-to-image framework of a latent diffusion model (Versatile Diffusion) conditioned on predicted multimodal (text and visual) features, to generate final reconstructed images. On the publicly available Natural Scenes Dataset benchmark, our method outperforms previous models both qualitatively and quantitatively. When applied to synthetic fMRI patterns generated from individual ROI (region-of-interest) masks, our trained model creates compelling “ROI-optimal” scenes consistent with neuroscientific knowledge. Thus, the proposed methodology can have an impact on both applied (e.g. brain–computer interface) and fundamental neuroscience.",
    "citationCount": 136,
    "pdf_filename": "2023_Natural_scene_reconstruction_from_fMRI_s_1a450fcd.pdf"
  },
  "134c7410e1b58aa839de1c10c23a1c4934aad897": {
    "paperId": "134c7410e1b58aa839de1c10c23a1c4934aad897",
    "title": "Generative artificial intelligence as a new context for management theories: analysis of ChatGPT",
    "year": 2023,
    "authors": "P. Korzyński, G. Mazurek, Andreas Altmann, J. Ejdys, Rūta Kazlauskaitė",
    "abstract": "PurposeThe primary purpose of this paper is to examine how generative Artificial Intelligence (AI) such as ChatGPT may serve as a new context for management theories and concepts.Design/methodology/approachThe paper presents the analyses of selected management theories on decision-making, knowledge management, customer service, human resource management and administrative tasks and explains what may change after generative AI adoption.FindingsThe paper indicates that some management theories and concepts need to be studied in the generative AI environment that may influence managerial work at the strategic, functional and administrative levels.Research limitations/implicationsThis paper is an opinion piece article and does not refer to empirical data. It formulates some conclusions to further empirical research studies.Originality/valueThe paper analyzes selected management theories in a new technological setting. The paper also provides information about the functions of generative AI that are useful in understanding and overcoming how new technology may change organizations and management.",
    "citationCount": 192,
    "pdf_filename": "2023_Generative_artificial_intelligence_as_a__134c7410.pdf"
  },
  "b08d575f4d8afab06bb7e6fb89827124ed25da8c": {
    "paperId": "b08d575f4d8afab06bb7e6fb89827124ed25da8c",
    "title": "Mapping out a research agenda for generative artificial intelligence in tertiary education",
    "year": 2023,
    "authors": "J. Lodge, Kate Thompson, L. Corrin",
    "abstract": "Generative artificial intelligence (AI) has taken the world by storm. In this editorial, we outline some of the key areas of tertiary education impacted by large language models and associated applications that will require re-thinking and research to address in the short to medium term. Given how rapidly generative AI developments are currently occurring, this editorial is speculative. Although there is a long history of research on AI in education, the current situation is both unprecedented and seemingly not something that the AI in education community fully predicted. We also outline the editorial position of AJET in regards to generative AI to assist authors using tools such as ChatGPT as any part of the research or writing process. This is a rapidly evolving space. We have attempted to provide some clarity in this editorial while acknowledging that we may need to revisit some or all of what we offer here in the weeks and months ahead.",
    "citationCount": 121,
    "pdf_filename": "2023_Mapping_out_a_research_agenda_for_genera_b08d575f.pdf"
  },
  "64fe5a9abfcde0c7f345ef636bd70547dd212ac3": {
    "paperId": "64fe5a9abfcde0c7f345ef636bd70547dd212ac3",
    "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation",
    "year": 2024,
    "authors": "Orit Shaer, Angel Cooper, O. Mokryn, Andrew L. Kun, Hagit Ben Shoshan",
    "abstract": "The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process – the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implications for HCI education and practice.",
    "citationCount": 108,
    "pdf_filename": "2024_AI_Augmented_Brainwriting__Investigating_64fe5a9a.pdf"
  },
  "ed152e3e47524ef43a9aedc39a96365433384535": {
    "paperId": "ed152e3e47524ef43a9aedc39a96365433384535",
    "title": "Generative artificial intelligence empowers digital twins in drug discovery and clinical trials",
    "year": 2023,
    "authors": "Maria Bordukova, Nikita Makarov, Raul Rodriguez-Esteban, Fabian Schmich, Michael P Menden",
    "abstract": "ABSTRACT Introduction The concept of Digital Twins (DTs) translated to drug development and clinical trials describes virtual representations of systems of various complexities, ranging from individual cells to entire humans, and enables in silico simulations and experiments. DTs increase the efficiency of drug discovery and development by digitalizing processes associated with high economic, ethical, or social burden. The impact is multifaceted: DT models sharpen disease understanding, support biomarker discovery and accelerate drug development, thus advancing precision medicine. One way to realize DTs is by generative artificial intelligence (AI), a cutting-edge technology that enables the creation of novel, realistic and complex data with desired properties. Areas covered The authors provide a brief introduction to generative AI and describe how it facilitates the modeling of DTs. In addition, they compare existing implementations of generative AI for DTs in drug discovery and clinical trials. Finally, they discuss technical and regulatory challenges that should be addressed before DTs can transform drug discovery and clinical trials. Expert opinion The current state of DTs in drug discovery and clinical trials does not exploit the entire power of generative AI yet and is limited to simulation of a small number of characteristics. Nonetheless, generative AI has the potential to transform the field by leveraging recent developments in deep learning and customizing models for the needs of scientists, physicians and patients.",
    "citationCount": 112,
    "pdf_filename": "2023_Generative_artificial_intelligence_empow_ed152e3e.pdf"
  },
  "ca2f5a4599c978a6cb6bc3242faf0037d0d981fc": {
    "paperId": "ca2f5a4599c978a6cb6bc3242faf0037d0d981fc",
    "title": "Effects of Generative Chatbots in Higher Education",
    "year": 2023,
    "authors": "Galina Ilieva, Tania Yankova, Stanislava Klisarova-Belcheva, Angel Dimitrov, Marin Bratkov",
    "abstract": "Learning technologies often do not meet the university requirements for learner engagement via interactivity and real-time feedback. In addition to the challenge of providing personalized learning experiences for students, these technologies can increase the workload of instructors due to the maintenance and updates required to keep the courses up-to-date. Intelligent chatbots based on generative artificial intelligence (AI) technology can help overcome these disadvantages by transforming pedagogical activities and guiding both students and instructors interactively. In this study, we explore and compare the main characteristics of existing educational chatbots. Then, we propose a new theoretical framework for blended learning with intelligent chatbots integration enabling students to interact online and instructors to create and manage their courses using generative AI tools. The advantages of the proposed framework are as follows: (1) it provides a comprehensive understanding of the transformative potential of AI chatbots in education and facilitates their effective implementation; (2) it offers a holistic methodology to enhance the overall educational experience; and (3) it unifies the applications of intelligent chatbots in teaching–learning activities within universities.",
    "citationCount": 116,
    "pdf_filename": "2023_Effects_of_Generative_Chatbots_in_Higher_ca2f5a45.pdf"
  },
  "6159549f986c63e160a678feef2130a2a4b93feb": {
    "paperId": "6159549f986c63e160a678feef2130a2a4b93feb",
    "title": "Generative Recommendation: Towards Next-generation Recommender Paradigm",
    "year": 2023,
    "authors": "Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, Tat-seng Chua",
    "abstract": "Recommender systems typically retrieve items from an item corpus for personalized recommendations. However, such a retrieval-based recommender paradigm faces two limitations: 1) the human-generated items in the corpus might fail to satisfy the users' diverse information needs, and 2) users usually adjust the recommendations via inefficient passive feedback, e.g., clicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success, offering the potential to overcome these limitations: 1) generative AI can produce personalized items to satisfy users' information needs, and 2) the newly emerged large language models significantly reduce the efforts of users to precisely express information needs via natural language instructions. In this light, the boom of AIGC points the way towards the next-generation recommender paradigm with two new objectives: 1) generating personalized content through generative AI, and 2) integrating user instructions to guide content generation. To this end, we propose a novel Generative Recommender paradigm named GeneRec, which adopts an AI generator to personalize content generation and leverages user instructions. Specifically, we pre-process users' instructions and traditional feedback via an instructor to output the generation guidance. Given the guidance, we instantiate the AI generator through an AI editor and an AI creator to repurpose existing items and create new items. Eventually, GeneRec can perform content retrieval, repurposing, and creation to satisfy users' information needs. Besides, to ensure the trustworthiness of the generated items, we emphasize various fidelity checks. Moreover, we provide a roadmap to envision future developments of GeneRec and several domain-specific applications of GeneRec with potential research tasks. Lastly, we study the feasibility of implementing AI editor and AI creator on micro-video generation.",
    "citationCount": 115,
    "pdf_filename": "2023_Generative_Recommendation__Towards_Next__6159549f.pdf"
  },
  "987f733632ee235d770b7229c567f443ad0abb2f": {
    "paperId": "987f733632ee235d770b7229c567f443ad0abb2f",
    "title": "The Advent of Generative Language Models in Medical Education",
    "year": 2023,
    "authors": "Mert Karabacak, B. Ozkara, Konstantinos Margetis, M. Wintermark, S. Bisdas",
    "abstract": "Artificial intelligence (AI) and generative language models (GLMs) present significant opportunities for enhancing medical education, including the provision of realistic simulations, digital patients, personalized feedback, evaluation methods, and the elimination of language barriers. These advanced technologies can facilitate immersive learning environments and enhance medical students' educational outcomes. However, ensuring content quality, addressing biases, and managing ethical and legal concerns present obstacles. To mitigate these challenges, it is necessary to evaluate the accuracy and relevance of AI-generated content, address potential biases, and develop guidelines and policies governing the use of AI-generated content in medical education. Collaboration among educators, researchers, and practitioners is essential for developing best practices, guidelines, and transparent AI models that encourage the ethical and responsible use of GLMs and AI in medical education. By sharing information about the data used for training, obstacles encountered, and evaluation methods, developers can increase their credibility and trustworthiness within the medical community. In order to realize the full potential of AI and GLMs in medical education while mitigating potential risks and obstacles, ongoing research and interdisciplinary collaboration are necessary. By collaborating, medical professionals can ensure that these technologies are effectively and responsibly integrated, contributing to enhanced learning experiences and patient care.",
    "citationCount": 142,
    "pdf_filename": "2023_The_Advent_of_Generative_Language_Models_987f7336.pdf"
  },
  "c583c7aabacb19e9ac14024d812dc4be819b1044": {
    "paperId": "c583c7aabacb19e9ac14024d812dc4be819b1044",
    "title": "How to Bell the Cat? A Theoretical Review of Generative Artificial Intelligence towards Digital Disruption in All Walks of Life",
    "year": 2023,
    "authors": "S. Mondal, Subhankar Das, Vasiliki G. Vrana",
    "abstract": "Generative Artificial Intelligence (GAI) has brought revolutionary changes to the world, enabling businesses to create new experiences by combining virtual and physical worlds. As the use of GAI grows along with the Metaverse, it is explored by academics, researchers, and industry communities for its endless possibilities. From ChatGPT by OpenAI to Bard AI by Google, GAI is a leading technology in physical and virtual business platforms. This paper focuses on GAI’s economic and societal impact and the challenges it poses. Businesses must rethink their operations and strategies to create hybrid physical and virtual experiences using GAI. This study proposes a framework that can help business managers develop effective strategies to enhance their operations. It analyzes the initial applications of GAI in multiple sectors to promote the development of future customer solutions and explores how GAI can help businesses create new value propositions and experiences for their customers, and the possibilities of digital communication and information technology. A research agenda is proposed for developing GAI for business management to enhance organizational efficiency. The results highlight a healthy conversation on the potential of GAI in various business sectors to improve customer experience.",
    "citationCount": 142,
    "pdf_filename": "2023_How_to_Bell_the_Cat__A_Theoretical_Revie_c583c7aa.pdf"
  },
  "bc351e9bf74e2b6ad6e2459e04d8fff43d17dd16": {
    "paperId": "bc351e9bf74e2b6ad6e2459e04d8fff43d17dd16",
    "title": "The influence of AI text generators on critical thinking skills in UK business schools",
    "year": 2024,
    "authors": "Aniekan Essien, O. Bukoye, Christine O’Dea, M. Kremantzis",
    "abstract": "ABSTRACT This study investigates the influence of generative artificial intelligence (GAI), specifically AI text generators (ChatGPT), on critical thinking skills in UK postgraduate business school students. Using Bloom’s taxonomy as theoretical underpinning, we adopt a mixed-method research employing a sample of 107 participants to investigate both the influence and challenges of these technologies in higher education. Our findings reveal that the most significant improvements occurred at the lower levels of Bloom’s taxonomy. We identify concerns relating to reliability, accuracy, and potential ethical implications of its application in higher education. The significance of this paper spans across, pedagogy, policy and practice, offering insights into the complex relationship between AI technologies and critical thinking skills. While highlighting the multifaceted aspects of the impact of AI in education, this article serves as a guide to educators and policymakers, stressing the importance of a comprehensive approach to fostering critical thinking and other transferable skills in the higher education landscape.",
    "citationCount": 116,
    "pdf_filename": "2024_The_influence_of_AI_text_generators_on_c_bc351e9b.pdf"
  },
  "a6f418dfbf52b6ec8cd13ed283e3691728cd00c7": {
    "paperId": "a6f418dfbf52b6ec8cd13ed283e3691728cd00c7",
    "title": "The Multiclass Fault Diagnosis of Wind Turbine Bearing Based on Multisource Signal Fusion and Deep Learning Generative Model",
    "year": 2022,
    "authors": "Liang Zhang, Hao Zhang, G. Cai",
    "abstract": "Low fault diagnosis accuracy in case of insufficient and imbalanced samples is a major problem in the wind turbine fault diagnosis. The imbalance of samples refers to the large difference in the number of samples of different categories or the lack of a certain fault sample, which requires good learning of the characteristics of a small number of samples. Sample generation in the deep learning generation model can effectively solve this problem. In this study, we proposed a novel multiclass wind turbine bearing fault diagnosis strategy based on the conditional variational generative adversarial network (CVAE-GAN) model combining multisource signals fusion. This strategy converts multisource 1-D vibration signals into 2-D signals, and the multisource 2-D signals were fused by using wavelet transform. The CVAE-GAN model was developed by merging the variational autoencoder (VAE) with the generative adversarial network (GAN). The VAE encoder was introduced as the front end of the GAN generator. The sample label was introduced as the model input to improve the model’s training efficiency. Finally, the sample set was used to train encoder, generator, and discriminator in the CVAE-GAN model to supplement the number of the fault samples. In the classifier, the sample set is used to do experimental analysis under various sample circumstances. The results show that the proposed strategy can increase wind turbine bearing fault diagnostic accuracy in complex scenarios.",
    "citationCount": 167,
    "pdf_filename": "2022_The_Multiclass_Fault_Diagnosis_of_Wind_T_a6f418df.pdf"
  },
  "13261129251c9e8891cff02c3aee15c4df6a5630": {
    "paperId": "13261129251c9e8891cff02c3aee15c4df6a5630",
    "title": "Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems",
    "year": 2023,
    "authors": "Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin",
    "abstract": "In the rapidly evolving landscape of artificial intelligence (AI), generative large language models (LLMs) stand at the forefront, revolutionizing how we interact with our data. However, the computational intensity and memory consumption of deploying these models present substantial challenges in terms of serving efficiency, particularly in scenarios demanding low latency and high throughput. This survey addresses the imperative need for efficient LLM serving methodologies from a machine learning system (MLSys) research perspective, standing at the crux of advanced AI innovations and practical system optimizations. We provide in-depth analysis, covering a spectrum of solutions, ranging from cutting-edge algorithmic modifications to groundbreaking changes in system designs. The survey aims to provide a comprehensive understanding of the current state and future directions in efficient LLM serving, offering valuable insights for researchers and practitioners in overcoming the barriers of effective LLM deployment, thereby reshaping the future of AI.",
    "citationCount": 118,
    "pdf_filename": "2023_Towards_Efficient_Generative_Large_Langu_13261129.pdf"
  },
  "696d96c260cd4ce074ff68040e1e5c783234d7bd": {
    "paperId": "696d96c260cd4ce074ff68040e1e5c783234d7bd",
    "title": "Typology of Risks of Generative Text-to-Image Models",
    "year": 2023,
    "authors": "Charlotte M. Bird, Eddie L. Ungless, Atoosa Kasirzadeh",
    "abstract": "This paper investigates the direct risks and harms associated with modern text-to-image generative models, such as DALL-E and Midjourney, through a comprehensive literature review. While these models offer unprecedented capabilities for generating images, their development and use introduce new types of risk that require careful consideration. Our review reveals significant knowledge gaps concerning the understanding and treatment of these risks despite some already being addressed. We offer a taxonomy of risks across six key stakeholder groups, inclusive of unexplored issues, and suggest future research directions. We identify 22 distinct risk types, spanning issues from data bias to malicious use. The investigation presented here is intended to enhance the ongoing discourse on responsible model development and deployment. By highlighting previously overlooked risks and gaps, it aims to shape subsequent research and governance initiatives, guiding them toward the responsible, secure, and ethically conscious evolution of text-to-image models.",
    "citationCount": 109,
    "pdf_filename": "2023_Typology_of_Risks_of_Generative_Text_to__696d96c2.pdf"
  },
  "7f6e9471f4197d2f944660ccaee5be6b15495047": {
    "paperId": "7f6e9471f4197d2f944660ccaee5be6b15495047",
    "title": "A Note on Shumailov et al. (2024): 'AI Models Collapse When Trained on Recursively Generated Data'",
    "year": 2024,
    "authors": "Ali Borji",
    "abstract": "The study conducted by Shumailov et al. (2024) demonstrates that repeatedly training a generative model on synthetic data leads to model collapse. This finding has generated considerable interest and debate, particularly given that current models have nearly exhausted the available data. In this work, we investigate the effects of fitting a distribution (through Kernel Density Estimation, or KDE) or a model to the data, followed by repeated sampling from it. Our objective is to develop a theoretical understanding of the phenomenon observed by Shumailov et al. (2024). Our results indicate that the outcomes reported are a statistical phenomenon and may be unavoidable.",
    "citationCount": 104,
    "pdf_filename": "2024_A_Note_on_Shumailov_et_al___2024____AI_M_7f6e9471.pdf"
  },
  "30c5c481ded2686e21ce108925d4ecf9d0c62d05": {
    "paperId": "30c5c481ded2686e21ce108925d4ecf9d0c62d05",
    "title": "The impact of generative artificial intelligence on socioeconomic inequalities and policy making",
    "year": 2023,
    "authors": "V. Capraro, Austin Lentsch, D. Acemoglu, Selin Akgün, Aisel Akhmedova",
    "abstract": "Abstract Generative artificial intelligence (AI) has the potential to both exacerbate and ameliorate existing socioeconomic inequalities. In this article, we provide a state-of-the-art interdisciplinary overview of the potential impacts of generative AI on (mis)information and three information-intensive domains: work, education, and healthcare. Our goal is to highlight how generative AI could worsen existing inequalities while illuminating how AI may help mitigate pervasive social problems. In the information domain, generative AI can democratize content creation and access but may dramatically expand the production and proliferation of misinformation. In the workplace, it can boost productivity and create new jobs, but the benefits will likely be distributed unevenly. In education, it offers personalized learning, but may widen the digital divide. In healthcare, it might improve diagnostics and accessibility, but could deepen pre-existing inequalities. In each section, we cover a specific topic, evaluate existing research, identify critical gaps, and recommend research directions, including explicit trade-offs that complicate the derivation of a priori hypotheses. We conclude with a section highlighting the role of policymaking to maximize generative AI's potential to reduce inequalities while mitigating its harmful effects. We discuss strengths and weaknesses of existing policy frameworks in the European Union, the United States, and the United Kingdom, observing that each fails to fully confront the socioeconomic challenges we have identified. We propose several concrete policies that could promote shared prosperity through the advancement of generative AI. This article emphasizes the need for interdisciplinary collaborations to understand and address the complex challenges of generative AI.",
    "citationCount": 158,
    "pdf_filename": "2023_The_impact_of_generative_artificial_inte_30c5c481.pdf"
  },
  "22bbfe33c33513492b12052b82f9616451a72517": {
    "paperId": "22bbfe33c33513492b12052b82f9616451a72517",
    "title": "Generative Artificial Intelligence Acceptance Scale: A Validity and Reliability Study",
    "year": 2023,
    "authors": "F. Yilmaz, Ramazan Yılmaz, Mehmet Ceylan",
    "abstract": "Abstract The purpose of this study is to formulate an acceptance scale grounded in the Unified Theory of Acceptance and Use of Technology (UTAUT) model. The scale is designed to scrutinize students’ acceptance of generative artificial intelligence (AI) applications. This tool assesses students’ acceptance levels toward generative AI applications. The scale development study was conducted in three phases, encompassing 627 university students from various faculties who have utilized generative AI tools such as ChatGPT during the 2022–2023 academic year. To evaluate the face and content validity of the scale, input was sought from professionals with expertise in the field. The initial sample group (n = 338) underwent exploratory factor analysis (EFA) to explore the underlying factors, while the subsequent sample group (n = 250) underwent confirmatory factor analysis (CFA) for the verification of factor structure. Later, it was seen that four factors comprising 20 items accounted for 78.349% of total variance due to EFA. CFA results confirmed that structure of the scale, featuring 20 items and four factors (performance expectancy, effort expectancy, facilitating conditions, and social influence), was compatible with the obtained data. Reliability analysis yielded Cronbach’s alpha coefficient of 0.97, and the test–retest method demonstrated a reliability coefficient of 0.95. To evaluate the discriminative power of the items, a comparative analysis was conducted between the lower 27% and upper 27% of participants, with subsequent calculation of corrected item-total correlations. The results demonstrate that the generative AI acceptance scale exhibits robust validity and reliability, thus affirming its effectiveness as a robust measurement instrument.",
    "citationCount": 120,
    "pdf_filename": "2023_Generative_Artificial_Intelligence_Accep_22bbfe33.pdf"
  },
  "229dc7283514bb87340c72615abc73202d1f9489": {
    "paperId": "229dc7283514bb87340c72615abc73202d1f9489",
    "title": "ChatGPT: A Case Study on Copyright Challenges for Generative Artificial Intelligence Systems",
    "year": 2023,
    "authors": "N. Lucchi",
    "abstract": "Abstract This article focuses on copyright issues pertaining to generative artificial intelligence (AI) systems, with particular emphasis on the ChatGPT case study as a primary exemplar. In order to generate high-quality outcomes, generative AI systems require substantial quantities of training data, which may frequently comprise copyright-protected information. This prompts inquiries into the legal principles of fair use, the creation of derivative works and the lawfulness of data gathering and utilisation. The utilisation of input data for the purpose of training and enhancing AI models presents significant concerns regarding potential violations of copyright. This paper offers suggestions for safeguarding the interests of copyright holders and competitors, while simultaneously addressing legal challenges and expediting the advancement of AI technologies. This study analyses the ChatGPT platform as a case example to explore the necessary modifications that copyright regulations must undergo to adequately tackle the intricacies of authorship and ownership in the realm of AI-generated creative content.",
    "citationCount": 111,
    "pdf_filename": "2023_ChatGPT__A_Case_Study_on_Copyright_Chall_229dc728.pdf"
  },
  "a9e273d078b4ee68efcb7b918d23f89720bef028": {
    "paperId": "a9e273d078b4ee68efcb7b918d23f89720bef028",
    "title": "ChatGPT and generative artificial intelligence: an exploratory study of key benefits and challenges in operations and supply chain management",
    "year": 2023,
    "authors": "S. Wamba, Cameron Guthrie, M. Queiroz, Stefan Minner",
    "abstract": "ChatGPT and generative artificial intelligence (Gen-AI) are transforming firms and supply chains. However, the empirical literature reporting the benefits, challenges, and outlook of these nascent technologies in operations and supply chain management (OSCM) is limited. This study surveys current projects and perceptions of these technologies in US (n = 119) and UK (n = 181) supply chains. We found that projects range from proof-of-concept to full implementation, with a main focus on operational gains, such as improved customer satisfaction, cost minimisation, and process efficiencies. The main challenges concern data, technological and organisational issues. Expected benefits are dominated by cost savings and enhanced customer experience, but also include increased automation and sustainability. Industries were found to cluster around six groups according to perceived benefits and implementation challenges. Our findings contribute to the emerging literature on Gen-AI use in OSCM, and to management practice by mapping the benefits, challenges, outlook, and maturity level of Gen-AI projects in supply chains.",
    "citationCount": 123,
    "pdf_filename": "2023_ChatGPT_and_generative_artificial_intell_a9e273d0.pdf"
  },
  "2f16bfd22a1cb747fc15d9598473c2558a2bffb0": {
    "paperId": "2f16bfd22a1cb747fc15d9598473c2558a2bffb0",
    "title": "Will Generative Artificial Intelligence Deliver on Its Promise in Health Care?",
    "year": 2023,
    "authors": "Robert M. Wachter, Erik Brynjolfsson",
    "abstract": "Importance\nSince the introduction of ChatGPT in late 2022, generative artificial intelligence (genAI) has elicited enormous enthusiasm and serious concerns.\n\n\nObservations\nHistory has shown that general purpose technologies often fail to deliver their promised benefits for many years (\"the productivity paradox of information technology\"). Health care has several attributes that make the successful deployment of new technologies even more difficult than in other industries; these have challenged prior efforts to implement AI and electronic health records. However, genAI has unique properties that may shorten the usual lag between implementation and productivity and/or quality gains in health care. Moreover, the health care ecosystem has evolved to make it more receptive to genAI, and many health care organizations are poised to implement the complementary innovations in culture, leadership, workforce, and workflow often needed for digital innovations to flourish.\n\n\nConclusions and Relevance\nThe ability of genAI to rapidly improve and the capacity of organizations to implement complementary innovations that allow IT tools to reach their potential are more advanced than in the past; thus, genAI is capable of delivering meaningful improvements in health care more rapidly than was the case with previous technologies.",
    "citationCount": 108,
    "pdf_filename": "2023_Will_Generative_Artificial_Intelligence__2f16bfd2.pdf"
  },
  "5001630bcc65e8e0e621b19625629a2689724743": {
    "paperId": "5001630bcc65e8e0e621b19625629a2689724743",
    "title": "Generative Judge for Evaluating Alignment",
    "year": 2023,
    "authors": "Junlong Li, Shichao Sun, Weizhe Yuan, Run-Ze Fan, Hai Zhao",
    "abstract": "The rapid development of Large Language Models (LLMs) has substantially expanded the range of tasks they can address. In the field of Natural Language Processing (NLP), researchers have shifted their focus from conventional NLP tasks (e.g., sequence tagging and parsing) towards tasks that revolve around aligning with human needs (e.g., brainstorming and email writing). This shift in task distribution imposes new requirements on evaluating these aligned models regarding generality (i.e., assessing performance across diverse scenarios), flexibility (i.e., examining under different protocols), and interpretability (i.e., scrutinizing models with explanations). In this paper, we propose a generative judge with 13B parameters, Auto-J, designed to address these challenges. Our model is trained on user queries and LLM-generated responses under massive real-world scenarios and accommodates diverse evaluation protocols (e.g., pairwise response comparison and single-response evaluation) with well-structured natural language critiques. To demonstrate the efficacy of our approach, we construct a new testbed covering 58 different scenarios. Experimentally, Auto-J outperforms a series of strong competitors, including both open-source and closed-source models, by a large margin. We also provide detailed analysis and case studies to further reveal the potential of our method and make a variety of resources public at https://github.com/GAIR-NLP/auto-j.",
    "citationCount": 137,
    "pdf_filename": "2023_Generative_Judge_for_Evaluating_Alignmen_5001630b.pdf"
  },
  "c5427eab1a236e4529dc004307e921677fde304b": {
    "paperId": "c5427eab1a236e4529dc004307e921677fde304b",
    "title": "A new generative adversarial network for medical images super resolution",
    "year": 2022,
    "authors": "Waqar Ahmad, Hazrat Ali, Zubair Shah, Shoaib Azmat",
    "abstract": "For medical image analysis, there is always an immense need for rich details in an image. Typically, the diagnosis will be served best if the fine details in the image are retained and the image is available in high resolution. In medical imaging, acquiring high-resolution images is challenging and costly as it requires sophisticated and expensive instruments, trained human resources, and often causes operation delays. Deep learning based super resolution techniques can help us to extract rich details from a low-resolution image acquired using the existing devices. In this paper, we propose a new Generative Adversarial Network (GAN) based architecture for medical images, which maps low-resolution medical images to high-resolution images. The proposed architecture is divided into three steps. In the first step, we use a multi-path architecture to extract shallow features on multiple scales instead of single scale. In the second step, we use a ResNet34 architecture to extract deep features and upscale the features map by a factor of two. In the third step, we extract features of the upscaled version of the image using a residual connection-based mini-CNN and again upscale the feature map by a factor of two. The progressive upscaling overcomes the limitation for previous methods in generating true colors. Finally, we use a reconstruction convolutional layer to map back the upscaled features to a high-resolution image. Our addition of an extra loss term helps in overcoming large errors, thus, generating more realistic and smooth images. We evaluate the proposed architecture on four different medical image modalities: (1) the DRIVE and STARE datasets of retinal fundoscopy images, (2) the BraTS dataset of brain MRI, (3) the ISIC skin cancer dataset of dermoscopy images, and (4) the CAMUS dataset of cardiac ultrasound images. The proposed architecture achieves superior accuracy compared to other state-of-the-art super-resolution architectures.",
    "citationCount": 139,
    "pdf_filename": "2022_A_new_generative_adversarial_network_for_c5427eab.pdf"
  },
  "e4f82c0a13cae6739239ae0c25a554b6daff35af": {
    "paperId": "e4f82c0a13cae6739239ae0c25a554b6daff35af",
    "title": "Compression of Generative Pre-trained Language Models via Quantization",
    "year": 2022,
    "authors": "Chaofan Tao, Lu Hou, Wei Zhang, Lifeng Shang, Xin Jiang",
    "abstract": "The increasing size of generative Pre-trained Language Models (PLMs) have greatly increased the demand for model compression. Despite various methods to compress BERT or its variants, there are few attempts to compress generative PLMs, and the underlying difficulty remains unclear. In this paper, we compress generative PLMs by quantization. We find that previous quantization methods fail on generative tasks due to the homogeneous word embeddings caused by reduced capacity and the varied distribution of weights. Correspondingly, we propose a token-level contrastive distillation to learn distinguishable word embeddings, and a module-wise dynamic scaling to make quantizers adaptive to different modules. Empirical results on various tasks show that our proposed method outperforms the state-of-the-art compression methods on generative PLMs by a clear margin. With comparable performance with the full-precision models, we achieve 14.4x and 13.4x compression rate on GPT-2 and BART, respectively.",
    "citationCount": 112,
    "pdf_filename": "2022_Compression_of_Generative_Pre_trained_La_e4f82c0a.pdf"
  },
  "9c30c6ecb7f8b7950d1ba0b0da7a621d6d991eca": {
    "paperId": "9c30c6ecb7f8b7950d1ba0b0da7a621d6d991eca",
    "title": "AGIQA-3K: An Open Database for AI-Generated Image Quality Assessment",
    "year": 2023,
    "authors": "Chunyi Li, Zicheng Zhang, Haoning Wu, Wei Sun, Xiongkuo Min",
    "abstract": "With the rapid advancements of the text-to-image generative model, AI-generated images (AGIs) have been widely applied to entertainment, education, social media, etc. However, considering the large quality variance among different AGIs, there is an urgent need for quality models that are consistent with human subjective ratings. To address this issue, we extensively consider various popular AGI models, generated AGI through different prompts and model parameters, and collected subjective scores at the perceptual quality and text-to-image alignment, thus building the most comprehensive AGI subjective quality database AGIQA-3K so far. Furthermore, we conduct a benchmark experiment on this database to evaluate the consistency between the current Image Quality Assessment (IQA) model and human perception, while proposing StairReward that significantly improves the assessment performance of subjective text-to-image alignment. We believe that the fine-grained subjective scores in AGIQA-3K will inspire subsequent AGI quality models to fit human subjective perception mechanisms at both perception and alignment levels and to optimize the generation result of future AGI models. The database is released on https://github.com/lcysyzxdxc/AGIQA-3k-Database.",
    "citationCount": 181,
    "pdf_filename": "2023_AGIQA_3K__An_Open_Database_for_AI_Genera_9c30c6ec.pdf"
  },
  "02b86623755c6541a3799c26b31bd8f2918ce3f8": {
    "paperId": "02b86623755c6541a3799c26b31bd8f2918ce3f8",
    "title": "Structure-based de novo drug design using 3D deep generative models",
    "year": 2021,
    "authors": "Yibo Li, Jianfeng Pei, L. Lai",
    "abstract": "Deep generative models are attracting much attention in the field of de novo molecule design. Compared to traditional methods, deep generative models can be trained in a fully data-driven way with little requirement for expert knowledge. Although many models have been developed to generate 1D and 2D molecular structures, 3D molecule generation is less explored, and the direct design of drug-like molecules inside target binding sites remains challenging. In this work, we introduce DeepLigBuilder, a novel deep learning-based method for de novo drug design that generates 3D molecular structures in the binding sites of target proteins. We first developed Ligand Neural Network (L-Net), a novel graph generative model for the end-to-end design of chemically and conformationally valid 3D molecules with high drug-likeness. Then, we combined L-Net with Monte Carlo tree search to perform structure-based de novo drug design tasks. In the case study of inhibitor design for the main protease of SARS-CoV-2, DeepLigBuilder suggested a list of drug-like compounds with novel chemical structures, high predicted affinity, and similar binding features to those of known inhibitors. The current version of L-Net was trained on drug-like compounds from ChEMBL, which could be easily extended to other molecular datasets with desired properties based on users' demands and applied in functional molecule generation. Merging deep generative models with atomic-level interaction evaluation, DeepLigBuilder provides a state-of-the-art model for structure-based de novo drug design and lead optimization.",
    "citationCount": 126,
    "pdf_filename": "2021_Structure_based_de_novo_drug_design_usin_02b86623.pdf"
  },
  "d31b0f55bbe44caf586e3b0e8424129ea8f068cd": {
    "paperId": "d31b0f55bbe44caf586e3b0e8424129ea8f068cd",
    "title": "Ten years of generative adversarial nets (GANs): a survey of the state-of-the-art",
    "year": 2023,
    "authors": "Tanujit Chakraborty, Ujjwal Reddy K S, Shraddha M. Naik, Madhurima Panja, B. Manvitha",
    "abstract": "Generative adversarial networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas, since their inception in 2014. Consisting of a discriminative network and a generative network engaged in a minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the ‘Top Ten Global Breakthrough Technologies List’ issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, cycle-consistent GAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen–Shannon divergence while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as transformers, physics-informed neural networks, large language models, and diffusion models. Finally, we reveal several issues as well as future research outlines in this field.",
    "citationCount": 114,
    "pdf_filename": "2023_Ten_years_of_generative_adversarial_nets_d31b0f55.pdf"
  },
  "1338ea7038614963c6784043c708a91736ea61e7": {
    "paperId": "1338ea7038614963c6784043c708a91736ea61e7",
    "title": "Recent Advances for Quantum Neural Networks in Generative Learning",
    "year": 2022,
    "authors": "Jinkai Tian, Xiaoyun Sun, Yuxuan Du, Shanshan Zhao, Qing Liu",
    "abstract": "Quantum computers are next-generation devices that hold promise to perform calculations beyond the reach of classical computers. A leading method towards achieving this goal is through quantum machine learning, especially quantum generative learning. Due to the intrinsic probabilistic nature of quantum mechanics, it is reasonable to postulate that quantum generative learning models (QGLMs) may surpass their classical counterparts. As such, QGLMs are receiving growing attention from the quantum physics and computer science communities, where various QGLMs that can be efficiently implemented on near-term quantum machines with potential computational advantages are proposed. In this paper, we review the current progress of QGLMs from the perspective of machine learning. Particularly, we interpret these QGLMs, covering quantum circuit Born machines, quantum generative adversarial networks, quantum Boltzmann machines, and quantum variational autoencoders, as the quantum extension of classical generative learning models. In this context, we explore their intrinsic relations and their fundamental differences. We further summarize the potential applications of QGLMs in both conventional machine learning tasks and quantum physics. Last, we discuss the challenges and further research directions for QGLMs.",
    "citationCount": 111,
    "pdf_filename": "2022_Recent_Advances_for_Quantum_Neural_Netwo_1338ea70.pdf"
  },
  "ffe35292dc950ff1e28bf482c586db1bcb176aa3": {
    "paperId": "ffe35292dc950ff1e28bf482c586db1bcb176aa3",
    "title": "Working With AI to Persuade: Examining a Large Language Model's Ability to Generate Pro-Vaccination Messages",
    "year": 2023,
    "authors": "Elise Karinshak, S. Liu, J. Park, Jeffrey T. Hancock",
    "abstract": "Artificial Intelligence (AI) is a transformative force in communication and messaging strategy, with potential to disrupt traditional approaches. Large language models (LLMs), a form of AI, are capable of generating high-quality, humanlike text. We investigate the persuasive quality of AI-generated messages to understand how AI could impact public health messaging. Specifically, through a series of studies designed to characterize and evaluate generative AI in developing public health messages, we analyze COVID-19 pro-vaccination messages generated by GPT-3, a state-of-the-art instantiation of a large language model. Study 1 is a systematic evaluation of GPT-3's ability to generate pro-vaccination messages. Study 2 then observed peoples' perceptions of curated GPT-3-generated messages compared to human-authored messages released by the CDC (Centers for Disease Control and Prevention), finding that GPT-3 messages were perceived as more effective, stronger arguments, and evoked more positive attitudes than CDC messages. Finally, Study 3 assessed the role of source labels on perceived quality, finding that while participants preferred AI-generated messages, they expressed dispreference for messages that were labeled as AI-generated. The results suggest that, with human supervision, AI can be used to create effective public health messages, but that individuals prefer their public health messages to come from human institutions rather than AI sources. We propose best practices for assessing generative outputs of large language models in future social science research and ways health professionals can use AI systems to augment public health messaging.",
    "citationCount": 164,
    "pdf_filename": "2023_Working_With_AI_to_Persuade__Examining_a_ffe35292.pdf"
  },
  "c532f1df90925e5c69789f0cd99248d8a2a2e5bc": {
    "paperId": "c532f1df90925e5c69789f0cd99248d8a2a2e5bc",
    "title": "My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises",
    "year": 2023,
    "authors": "James Finnie-Ansley, Paul Denny, Andrew Luxton-Reilly, E. Santos, J. Prather",
    "abstract": "The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.",
    "citationCount": 164,
    "pdf_filename": "2023_My_AI_Wants_to_Know_if_This_Will_Be_on_t_c532f1df.pdf"
  },
  "c8f2aced926707fba8a0535a6df5b5823d394bac": {
    "paperId": "c8f2aced926707fba8a0535a6df5b5823d394bac",
    "title": "AI-Generated Content (AIGC): A Survey",
    "year": 2023,
    "authors": "Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, Hong Lin",
    "abstract": "To address the challenges of digital intelligence in the digital economy, artificial intelligence-generated content (AIGC) has emerged. AIGC uses artificial intelligence to assist or replace manual content generation by generating content based on user-inputted keywords or requirements. The development of large model algorithms has significantly strengthened the capabilities of AIGC, which makes AIGC products a promising generative tool and adds convenience to our lives. As an upstream technology, AIGC has unlimited potential to support different downstream applications. It is important to analyze AIGC's current capabilities and shortcomings to understand how it can be best utilized in future applications. Therefore, this paper provides an extensive overview of AIGC, covering its definition, essential conditions, cutting-edge capabilities, and advanced features. Moreover, it discusses the benefits of large-scale pre-trained models and the industrial chain of AIGC. Furthermore, the article explores the distinctions between auxiliary generation and automatic generation within AIGC, providing examples of text generation. The paper also examines the potential integration of AIGC with the Metaverse. Lastly, the article highlights existing issues and suggests some future directions for application.",
    "citationCount": 177,
    "pdf_filename": "2023_AI_Generated_Content__AIGC___A_Survey_c8f2aced.pdf"
  },
  "33a575637b17862a9233693141bd69e22763cf83": {
    "paperId": "33a575637b17862a9233693141bd69e22763cf83",
    "title": "Prompting Higher Education Towards AI-Augmented Teaching and Learning Practice",
    "year": 2023,
    "authors": "Bronwyn Eager, Ryan Brunton",
    "abstract": "Large Language Models (LLMs) and conversational-style generative artificial intelligence (AI) are causing major disruption to higher education pedagogy. The emergence of tools like ChatGPT has raised concerns about plagiarism detection but also presents opportunities for educators to leverage AI to build supportive learning environments. In this commentary, we explore the potential of AI-augmented teaching and learning practice in higher education, discussing both the productive affordances and challenges associated with these technologies. We offer instructional advice for writing instructional text to guide the generation of quality outputs from AI models, as well as a case study to illustrate using AI for assessment design. Ultimately, we suggest that AI should be seen as one tool among many that can be used to enhance teaching and learning outcomes in higher education.",
    "citationCount": 180,
    "pdf_filename": "2023_Prompting_Higher_Education_Towards_AI_Au_33a57563.pdf"
  },
  "f0aa94ffe329cd2780aa133bb25a70d68647afae": {
    "paperId": "f0aa94ffe329cd2780aa133bb25a70d68647afae",
    "title": "Holy or Unholy? Interview with Open AI’s ChatGPT",
    "year": 2023,
    "authors": "Ali Iskender",
    "abstract": "In this paper, OpenAI's ChatGPT (Generative Pre-trained Transformer), also known as GPT-3, a machine-learning model that has the ability to generate human-like text, was employed as an interviewee instead of a human subject. The scope of the interview was the impacts of OpenAI's GPT on higher education and academic publishing. Particularly, several questions about the impacts of OpenAI's ChatGPT and other AI-based machine learning models on the hospitality and tourism industry and education were asked. The originality of this paper derives from having the ChatGPT as an interviewee. ChatGPT stated that its use helps instructors delegate monotonous tasks such as grading and focus on more intellectual tasks, and students may utilize ChatGPT to brainstorm ideas. ChatGPT confesses the risk of diminishing critical thinking for students in the case of over-reliance on ChatGPT as well as educational inequalities. For academic work, ChatGPT addressed it cannot be a substitute for human creativity and intellectuality because originality and novelty lack in outputs generated by ChatGPT. The tourism and hospitality industry can benefit from ChatGPT for certain things such as personalized services, content creation, and many more.",
    "citationCount": 183,
    "pdf_filename": "2023_Holy_or_Unholy__Interview_with_Open_AI_s_f0aa94ff.pdf"
  },
  "fe4b9562c542f5df1dea05bf1decca9dc3930e23": {
    "paperId": "fe4b9562c542f5df1dea05bf1decca9dc3930e23",
    "title": "On the use of AI-based tools like ChatGPT to support management research",
    "year": 2023,
    "authors": "Bastian Burger, Dominik K. Kanbach, S. Kraus, M. Breier, Vincenzo Corvello",
    "abstract": "PurposeThe article discusses the current relevance of artificial intelligence (AI) in research and how AI improves various research methods. This article focuses on the practical case study of systematic literature reviews (SLRs) to provide a guideline for employing AI in the process.Design/methodology/approachResearchers no longer require technical skills to use AI in their research. The recent discussion about using Chat Generative Pre-trained Transformer (GPT), a chatbot by OpenAI, has reached the academic world and fueled heated debates about the future of academic research. Nevertheless, as the saying goes, AI will not replace our job; a human being using AI will. This editorial aims to provide an overview of the current state of using AI in research, highlighting recent trends and developments in the field.FindingsThe main result is guidelines for the use of AI in the scientific research process. The guidelines were developed for the literature review case but the authors believe the instructions provided can be adjusted to many fields of research, including but not limited to quantitative research, data qualification, research on unstructured data, qualitative data and even on many support functions and repetitive tasks.Originality/valueAI already has the potential to make researchers’ work faster, more reliable and more convenient. The authors highlight the advantages and limitations of AI in the current time, which should be present in any research utilizing AI. Advantages include objectivity and repeatability in research processes that currently are subject to human error. The most substantial disadvantages lie in the architecture of current general-purpose models, which understanding is essential for using them in research. The authors will describe the most critical shortcomings without going into technical detail and suggest how to work with the shortcomings daily.",
    "citationCount": 170,
    "pdf_filename": "2023_On_the_use_of_AI_based_tools_like_ChatGP_fe4b9562.pdf"
  },
  "9f6655a6e93d9be261a93893fb8469ac8fa4a99d": {
    "paperId": "9f6655a6e93d9be261a93893fb8469ac8fa4a99d",
    "title": "Rapamycin in the context of Pascal’s Wager: generative pre-trained transformer perspective",
    "year": 2022,
    "authors": "A. Zhavoronkov",
    "abstract": "Large language models utilizing transformer neural networks and other deep learning architectures demonstrated unprecedented results in many tasks previously accessible only to human intelligence. In this article, we collaborate with ChatGPT, an AI model developed by OpenAI to speculate on the applications of Rapamycin, in the context of Pascal’s Wager philosophical argument commonly utilized to justify the belief in god. In response to the query “Write an exhaustive research perspective on why taking Rapamycin may be more beneficial than not taking Rapamycin from the perspective of Pascal’s wager” ChatGPT provided the pros and cons for the use of Rapamycin considering the preclinical evidence of potential life extension in animals. This article demonstrates the potential of ChatGPT to produce complex philosophical arguments and should not be used for any off-label use of Rapamycin.",
    "citationCount": 168,
    "pdf_filename": "2022_Rapamycin_in_the_context_of_Pascal_s_Wag_9f6655a6.pdf"
  },
  "1875879c3b85289f8f7da0b9aa4d35343225be8e": {
    "paperId": "1875879c3b85289f8f7da0b9aa4d35343225be8e",
    "title": "The Challenges and Opportunities of AI-Assisted Writing: Developing AI Literacy for the AI Age",
    "year": 2023,
    "authors": "P. Cardon, Carolin Fleischmann, Jolanta Aritz, Minna Logemann, Jeanette Heidewald",
    "abstract": "Generative AI may significantly disrupt the teaching and practice of business communication. This study of 343 communication instructors revealed a collective view that AI-assisted writing will be widely adopted in the workplace and will require significant changes to instruction. Key perceived challenges include less critical thinking and authenticity in writing. Key perceived benefits include more efficiency and better idea generation in writing. Students will need to develop AI literacy—composed of application, authenticity, accountability, and agency—to succeed in the workplace. Recommendations are provided for instructors and administrators to ensure the benefits of AI-assisted writing can outweigh the challenges.",
    "citationCount": 149,
    "pdf_filename": "2023_The_Challenges_and_Opportunities_of_AI_A_1875879c.pdf"
  },
  "5c56849181d2871dedb95f3bda443dc11d29a399": {
    "paperId": "5c56849181d2871dedb95f3bda443dc11d29a399",
    "title": "Generative adversarial networks and synthetic patient data: current challenges and future perspectives",
    "year": 2022,
    "authors": "Anmol Arora, Ananya Arora",
    "abstract": "ABSTRACT Artificial intelligence (AI) has been heralded as one of the key technological innovations of the 21st century. Within healthcare, much attention has been placed upon the ability of deductive AI systems to analyse large datasets to find patterns that would be unfeasible to program. Generative AI, including generative adversarial networks, are a newer type of machine learning that functions to create fake data after learning the properties of real data. Artificially generated patient data has the potential to revolutionise clinical research and protect patient privacy. Using novel techniques, it is increasingly possible to fully anonymise datasets to the point where no datapoint is traceable to any real individual. This can be used to expand and balance datasets as well as to replace the use of real patient data in certain contexts. This paper focuses upon three key uses of synthetic data: clinical research, data privacy and medical education. We also highlight ethical and practical concerns that require consideration.",
    "citationCount": 109,
    "pdf_filename": "2022_Generative_adversarial_networks_and_synt_5c568491.pdf"
  },
  "b6e9a253f36b13ee48ab441f4e7b0937c73982f5": {
    "paperId": "b6e9a253f36b13ee48ab441f4e7b0937c73982f5",
    "title": "Raising the Bar of AI-generated Image Detection with CLIP",
    "year": 2023,
    "authors": "D. Cozzolino, G. Poggi, Riccardo Corvi, Matthias Nießner, L. Verdoliva",
    "abstract": "The aim of this work is to explore the potential of pre-trained vision-language models (VLMs) for universal detection of AI-generated images. We develop a lightweight detection strategy based on CLIP features and study its performance in a wide variety of challenging scenarios. We find that, contrary to previous beliefs, it is neither necessary nor convenient to use a large domain-specific dataset for training. On the contrary, by using only a handful of example images from a single generative model, a CLIP-based detector exhibits surprising generalization ability and high robustness across different architectures, including recent commercial tools such as Dalle-3, Midjourney v5, and Firefly. We match the state-of-the-art (SoTA) on in-distribution data and significantly improve upon it in terms of generalization to out-of-distribution data (+6% AUC) and robustness to impaired/laundered data (+13%). Our project is available at https://grip-unina.github.io/ClipBased-SyntheticImageDetection/",
    "citationCount": 128,
    "pdf_filename": "2023_Raising_the_Bar_of_AI_generated_Image_De_b6e9a253.pdf"
  },
  "a002c252b6437a25d4615ebddc085a8a421ec057": {
    "paperId": "a002c252b6437a25d4615ebddc085a8a421ec057",
    "title": "ZeroNAS: Differentiable Generative Adversarial Networks Search for Zero-Shot Learning",
    "year": 2021,
    "authors": "Caixia Yan, Xiaojun Chang, Zhihui Li, ZongYuan Ge, Weili Guan",
    "abstract": "In recent years, remarkable progress in zero-shot learning (ZSL) has been achieved by generative adversarial networks (GAN). To compensate for the lack of training samples in ZSL, a surge of GAN architectures have been developed by human experts through trial-and-error testing. Despite their efficacy, however, there is still no guarantee that these hand-crafted models can consistently achieve good performance across diversified datasets or scenarios. Accordingly, in this paper, we turn to neural architecture search (NAS) and make the first attempt to bring NAS techniques into the ZSL realm. Specifically, we propose a differentiable GAN architecture search method over a specifically designed search space for zero-shot learning, referred to as ZeroNAS. Considering the relevance and balance of the generator and discriminator, ZeroNAS jointly searches their architectures in a min-max player game via adversarial training. Extensive experiments conducted on four widely used benchmark datasets demonstrate that ZeroNAS is capable of discovering desirable architectures that perform favorably against state-of-the-art ZSL and generalized zero-shot learning (GZSL) approaches. Source code is at https://github.com/caixiay/ZeroNAS.",
    "citationCount": 150,
    "pdf_filename": "2021_ZeroNAS__Differentiable_Generative_Adver_a002c252.pdf"
  },
  "177c49d4d816d359bf92c4782ae6e6c9ddb154ce": {
    "paperId": "177c49d4d816d359bf92c4782ae6e6c9ddb154ce",
    "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
    "year": 2020,
    "authors": "Tero Karras, S. Laine, Timo Aila",
    "abstract": "We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.",
    "citationCount": 187,
    "pdf_filename": "2020_A_Style_Based_Generator_Architecture_for_177c49d4.pdf"
  },
  "dcd2d383eb900dea4e1643963d947a707fbaf6fc": {
    "paperId": "dcd2d383eb900dea4e1643963d947a707fbaf6fc",
    "title": "Diffusion-Based Reinforcement Learning for Edge-Enabled AI-Generated Content Services",
    "year": 2023,
    "authors": "Hongyang Du, Zonghang Li, Dusist Niyato, Jiawen Kang, Zehui Xiong",
    "abstract": "As Metaverse emerges as the next-generation Internet paradigm, the ability to efficiently generate content is paramount. AI-Generated Content (AIGC) emerges as a key solution, yet the resource-intensive nature of large Generative AI (GAI) models presents challenges. To address this issue, we introduce an AIGC-as-a-Service (AaaS) architecture, which deploys AIGC models in wireless edge networks to ensure broad AIGC services accessibility for Metaverse users. Nonetheless, an important aspect of providing personalized user experiences requires carefully selecting AIGC Service Providers (ASPs) capable of effectively executing user tasks, which is complicated by environmental uncertainty and variability. Addressing this gap in current research, we introduce the AI-Generated Optimal Decision (AGOD) algorithm, a diffusion model-based approach for generating the optimal ASP selection decisions. Integrating AGOD with Deep Reinforcement Learning (DRL), we develop the Deep Diffusion Soft Actor-Critic (D2SAC) algorithm, enhancing the efficiency and effectiveness of ASP selection. Our comprehensive experiments demonstrate that D2SAC outperforms seven leading DRL algorithms. Furthermore, the proposed AGOD algorithm has the potential for extension to various optimization problems in wireless networks, positioning it as a promising approach for future research on AIGC-driven services.",
    "citationCount": 123,
    "pdf_filename": "2023_Diffusion_Based_Reinforcement_Learning_f_dcd2d383.pdf"
  },
  "7d2f897255412922f631e60cddeec815edd392b3": {
    "paperId": "7d2f897255412922f631e60cddeec815edd392b3",
    "title": "The Caring Machine: Feeling AI for Customer Care",
    "year": 2023,
    "authors": "Ming-Hui Huang, R. Rust",
    "abstract": "Customer care is important for its role in relationship building. This role has traditionally been performed by human customer agents; however, the emergence of interactive generative AI (GenAI) shows potential for using AI for customer care in emotionally charged interactions. Bridging practice and the academic literatures in marketing and computer science, this article develops an AI-enabled customer care journey, from accurate emotion recognition to empathetic response, emotional management support, and, finally, the establishment of an emotional connection. Marketing requirements for each of the stages are derived from in-depth interviews with top managers and a survey of chief marketing officers. By juxtaposing these requirements against the current feeling capabilities of GenAI, the authors highlight the technological challenges engineers must tackle. The article concludes with a set of marketing tenets for implementing and researching the caring machine. These include verifying emotion recognition accuracy using marketing emotion theories through multiple emotion signals and methods, utilizing prompt engineering to enhance GenAI’s emotion understanding, employing “response engineering” to personalize emotion management recommendations, and strategically deploying GenAI for emotional connection to simultaneously enhance customer emotional well-being and customer lifetime value.",
    "citationCount": 129,
    "pdf_filename": "2023_The_Caring_Machine__Feeling_AI_for_Custo_7d2f8972.pdf"
  },
  "7aead47e2bf590809cb3e235dd26f0de95b6fe92": {
    "paperId": "7aead47e2bf590809cb3e235dd26f0de95b6fe92",
    "title": "Hello GPT! Goodbye home examination? An exploratory study of AI chatbots impact on university teachers’ assessment practices",
    "year": 2023,
    "authors": "Alexandra Farazouli, T. Cerratto Pargman, K. Bolander-Laksov, C. McGrath",
    "abstract": "Abstract AI chatbots have recently fuelled debate regarding education practices in higher education institutions worldwide. Focusing on Generative AI and ChatGPT in particular, our study examines how AI chatbots impact university teachers’ assessment practices, exploring teachers’ perceptions about how ChatGPT performs in response to home examination prompts in undergraduate contexts. University teachers (n = 24) from four different departments in humanities and social sciences participated in Turing Test-inspired experiments, where they blindly assessed student and ChatGPT-written responses to home examination questions. Additionally, we conducted semi-structured interviews in focus groups with the same teachers examining their reflections about the quality of the texts they assessed. Regarding chatbot-generated texts, we found a passing rate range across the cohort (37.5 − 85.7%) and a chatbot-written suspicion range (14–23%). Regarding the student-written texts, we identified patterns of downgrading, suggesting that teachers were more critical when grading student-written texts. Drawing on post-phenomenology and mediation theory, we discuss AI chatbots as a potentially disruptive technology in higher education practices.",
    "citationCount": 128,
    "pdf_filename": "2023_Hello_GPT__Goodbye_home_examination__An__7aead47e.pdf"
  },
  "cc29e49baab11caeb7df80bb220e5f559b709a6c": {
    "paperId": "cc29e49baab11caeb7df80bb220e5f559b709a6c",
    "title": "Why and how to embrace AI such as ChatGPT in your academic life",
    "year": 2023,
    "authors": "Zhicheng Lin",
    "abstract": "Generative artificial intelligence (AI), including large language models (LLMs), is poised to transform scientific research, enabling researchers to elevate their research productivity. This article presents a how-to guide for employing LLMs in academic settings, focusing on their unique strengths, constraints and implications through the lens of philosophy of science and epistemology. Using ChatGPT as a case study, I identify and elaborate on three attributes contributing to its effectiveness—intelligence, versatility and collaboration—accompanied by tips on crafting effective prompts, practical use cases and a living resource online (https://osf.io/8vpwu/). Next, I evaluate the limitations of generative AI and its implications for ethical use, equality and education. Regarding ethical and responsible use, I argue from technical and epistemic standpoints that there is no need to restrict the scope or nature of AI assistance, provided that its use is transparently disclosed. A pressing challenge, however, lies in detecting fake research, which can be mitigated by embracing open science practices, such as transparent peer review and sharing data, code and materials. Addressing equality, I contend that while generative AI may promote equality for some, it may simultaneously exacerbate disparities for others—an issue with potentially significant yet unclear ramifications as it unfolds. Lastly, I consider the implications for education, advocating for active engagement with LLMs and cultivating students' critical thinking and analytical skills. The how-to guide seeks to empower researchers with the knowledge and resources necessary to effectively harness generative AI while navigating the complex ethical dilemmas intrinsic to its application.",
    "citationCount": 126,
    "pdf_filename": "2023_Why_and_how_to_embrace_AI_such_as_ChatGP_cc29e49b.pdf"
  },
  "073a9c27bba15de9f6abe80c94bbdb2e57618175": {
    "paperId": "073a9c27bba15de9f6abe80c94bbdb2e57618175",
    "title": "How AI can distort human beliefs",
    "year": 2023,
    "authors": "Celeste Kidd, Abeba Birhane",
    "abstract": "Models can convey biases and false information to users Individual humans form their beliefs by sampling a small subset of the available data in the world. Once those beliefs are formed with high certainty, they can become stubborn to revise. Fabrication and bias in generative artificial intelligence (AI) models are established phenomena that can occur as part of regular system use, in the absence of any malevolent forces seeking to push bias or disinformation. However, transmission of false information and bias from these models to people has been prominently absent from the discourse. Overhyped, unrealistic, and exaggerated capabilities permeate how generative AI models are presented, which contributes to the popular misconception that these models exceed human-level reasoning and exacerbates the risk of transmission of false information and negative stereotypes to people.",
    "citationCount": 114,
    "pdf_filename": "2023_How_AI_can_distort_human_beliefs_073a9c27.pdf"
  },
  "8094e5c04947eb6722168142548e57a1cebb4ef7": {
    "paperId": "8094e5c04947eb6722168142548e57a1cebb4ef7",
    "title": "Social Dynamics of AI Support in Creative Writing",
    "year": 2023,
    "authors": "K. Gero, Tao Long, Lydia B. Chilton",
    "abstract": "Recently, large language models have made huge advances in generating coherent, creative text. While much research focuses on how users can interact with language models, less work considers the social-technical gap that this technology poses. What are the social nuances that underlie receiving support from a generative AI? In this work we ask when and why a creative writer might turn to a computer versus a peer or mentor for support. We interview 20 creative writers about their writing practice and their attitudes towards both human and computer support. We discover three elements that govern a writer’s interaction with support actors: 1) what writers desire help with, 2) how writers perceive potential support actors, and 3) the values writers hold. We align our results with existing frameworks of writing cognition and creativity support, uncovering the social dynamics which modulate user responses to generative technologies.",
    "citationCount": 118,
    "pdf_filename": "2023_Social_Dynamics_of_AI_Support_in_Creativ_8094e5c0.pdf"
  },
  "4b6216e0fcaf3c50edcb279d9d618f085c057e2f": {
    "paperId": "4b6216e0fcaf3c50edcb279d9d618f085c057e2f",
    "title": "What ChatGPT Tells Us about Gender: A Cautionary Tale about Performativity and Gender Biases in AI",
    "year": 2023,
    "authors": "Nicole Gross",
    "abstract": "Large language models and generative AI, such as ChatGPT, have gained influence over people’s personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper’s central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to ‘undo gender’.",
    "citationCount": 112,
    "pdf_filename": "2023_What_ChatGPT_Tells_Us_about_Gender__A_Ca_4b6216e0.pdf"
  },
  "7aa0ab836f198b9ba040a92534eb89f1d706b66d": {
    "paperId": "7aa0ab836f198b9ba040a92534eb89f1d706b66d",
    "title": "Discovering the Syntax and Strategies of Natural Language Programming with Generative Language Models",
    "year": 2022,
    "authors": "Ellen Jiang, Edwin Toh, A. Molina, Kristen Olson, Claire Kayacik",
    "abstract": "In this paper, we present a natural language code synthesis tool, GenLine, backed by 1) a large generative language model and 2) a set of task-specific prompts that create or change code. To understand the user experience of natural language code synthesis with these new types of models, we conducted a user study in which participants applied GenLine to two programming tasks. Our results indicate that while natural language code synthesis can sometimes provide a magical experience, participants still faced challenges. In particular, participants felt that they needed to learn the model’s “syntax,” despite their input being natural language. Participants also struggled to form an accurate mental model of the types of requests the model can reliably translate and developed a set of strategies to debug model input. From these findings, we discuss design implications for future natural language code synthesis tools built using large generative language models.",
    "citationCount": 101,
    "pdf_filename": "2022_Discovering_the_Syntax_and_Strategies_of_7aa0ab83.pdf"
  },
  "4c55dd37ab4c41565226a3c8194166d7412b0a02": {
    "paperId": "4c55dd37ab4c41565226a3c8194166d7412b0a02",
    "title": "Large Language Models Empowered Autonomous Edge AI for Connected Intelligence",
    "year": 2023,
    "authors": "Yifei Shen, Jiawei Shao, Xinjie Zhang, Zehong Lin, Hao Pan",
    "abstract": "The evolution of wireless networks gravitates toward connected intelligence, a concept that envisions seamless interconnectivity among humans, objects, and intelligence in a hyper-connected cyber-physical world. Edge artificial intelligence (Edge AI) is a promising solution to achieve connected intelligence by delivering high-quality, low-latency, and privacy-preserving AI services at the network edge. This article presents a vision of autonomous edge AI systems that automatically organize, adapt, and optimize themselves to meet users' diverse requirements, leveraging the power of large language models (LLMs), that is, generative pretrained transformer (GPT). By exploiting the powerful abilities of GPT in language understanding, planning, and code generation, as well as incorporating classic wisdom such as task-oriented communication and edge federated learning, we present a versatile framework that efficiently coordinates edge AI models to cater to users' personal demands while automatically generating code to train new models in a privacy-preserving manner. Experimental results demonstrate the system's remarkable ability to accurately comprehend user demands, efficiently execute AI models with minimal cost, and effectively create high-performance AI models at edge servers.",
    "citationCount": 125,
    "pdf_filename": "2023_Large_Language_Models_Empowered_Autonomo_4c55dd37.pdf"
  },
  "add949bdb6beb0dfd7d54efd15db23e79c72e3b8": {
    "paperId": "add949bdb6beb0dfd7d54efd15db23e79c72e3b8",
    "title": "Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation",
    "year": 2023,
    "authors": "Sangho Suh, Meng Chen, Bryan Min, T. Li, Haijun Xia",
    "abstract": "Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 14 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to harness the creative potential of LLMs.",
    "citationCount": 118,
    "pdf_filename": "2023_Luminate__Structured_Generation_and_Expl_add949bd.pdf"
  },
  "ad07d3499faade81e6c33069902c45b13ba90c44": {
    "paperId": "ad07d3499faade81e6c33069902c45b13ba90c44",
    "title": "Broadly applicable and accurate protein design by integrating structure prediction networks and diffusion generative models",
    "year": 2022,
    "authors": "Joseph L. Watson, David Juergens, N. Bennett, Brian L. Trippe, Jason Yim",
    "abstract": "There has been considerable recent progress in designing new proteins using deep learning methods1–9. Despite this progress, a general deep learning framework for protein design that enables solution of a wide range of design challenges, including de novo binder design and design of higher order symmetric architectures, has yet to be described. Diffusion models10,11 have had considerable success in image and language generative modeling but limited success when applied to protein modeling, likely due to the complexity of protein backbone geometry and sequence-structure relationships. Here we show that by fine tuning the RoseTTAFold structure prediction network on protein structure denoising tasks, we obtain a generative model of protein backbones that achieves outstanding performance on unconditional and topology-constrained protein monomer design, protein binder design, symmetric oligomer design, enzyme active site scaffolding, and symmetric motif scaffolding for therapeutic and metal-binding protein design. We demonstrate the power and generality of the method, called RoseTTAFold Diffusion (RFdiffusion), by experimentally characterizing the structures and functions of hundreds of new designs. In a manner analogous to networks which produce images from user-specified inputs, RFdiffusion enables the design of diverse, complex, functional proteins from simple molecular specifications.",
    "citationCount": 191,
    "pdf_filename": "2022_Broadly_applicable_and_accurate_protein__ad07d349.pdf"
  },
  "9927fc0d9d977dae67ddc2dceac13093b6f4689e": {
    "paperId": "9927fc0d9d977dae67ddc2dceac13093b6f4689e",
    "title": "Generative Adversarial Networks-Based Data Augmentation for Brain–Computer Interface",
    "year": 2020,
    "authors": "Fatemeh Fahimi, S. Došen, K. Ang, N. Mrachacz‐Kersting, Cuntai Guan",
    "abstract": "The performance of a classifier in a brain–computer interface (BCI) system is highly dependent on the quality and quantity of training data. Typically, the training data are collected in a laboratory where the users perform tasks in a controlled environment. However, users’ attention may be diverted in real-life BCI applications and this may decrease the performance of the classifier. To improve the robustness of the classifier, additional data can be acquired in such conditions, but it is not practical to record electroencephalogram (EEG) data over several long calibration sessions. A potentially time- and cost-efficient solution is artificial data generation. Hence, in this study, we proposed a framework based on the deep convolutional generative adversarial networks (DCGANs) for generating artificial EEG to augment the training set in order to improve the performance of a BCI classifier. To make a comparative investigation, we designed a motor task experiment with diverted and focused attention conditions. We used an end-to-end deep convolutional neural network for classification between movement intention and rest using the data from 14 subjects. The results from the leave-one subject-out (LOO) classification yielded baseline accuracies of 73.04% for diverted attention and 80.09% for focused attention without data augmentation. Using the proposed DCGANs-based framework for augmentation, the results yielded a significant improvement of 7.32% for diverted attention ( $p < 0.01$ ) and 5.45% for focused attention ( $p < 0.01$ ). In addition, we implemented the method on the data set IVa from BCI competition III to distinguish different motor imagery tasks. The proposed method increased the accuracy by 3.57% ( $p < 0.02$ ). This study shows that using GANs for EEG augmentation can significantly improve BCI performance, especially in real-life applications, whereby users’ attention may be diverted.",
    "citationCount": 172,
    "pdf_filename": "2020_Generative_Adversarial_Networks_Based_Da_9927fc0d.pdf"
  },
  "79c5f79827c643c1e9464c2a5ff4d1326db16f20": {
    "paperId": "79c5f79827c643c1e9464c2a5ff4d1326db16f20",
    "title": "AI chatbots not yet ready for clinical use",
    "year": 2023,
    "authors": "Joshua Au Yeung, Zeljko Kraljevic, Akish Luintel, Alfred Balston, Esther Idowu",
    "abstract": "As large language models (LLMs) expand and become more advanced, so do the natural language processing capabilities of conversational AI, or “chatbots”. OpenAI's recent release, ChatGPT, uses a transformer-based model to enable human-like text generation and question-answering on general domain knowledge, while a healthcare-specific Large Language Model (LLM) such as GatorTron has focused on the real-world healthcare domain knowledge. As LLMs advance to achieve near human-level performances on medical question and answering benchmarks, it is probable that Conversational AI will soon be developed for use in healthcare. In this article we discuss the potential and compare the performance of two different approaches to generative pretrained transformers—ChatGPT, the most widely used general conversational LLM, and Foresight, a GPT (generative pretrained transformer) based model focused on modelling patients and disorders. The comparison is conducted on the task of forecasting relevant diagnoses based on clinical vignettes. We also discuss important considerations and limitations of transformer-based chatbots for clinical use.",
    "citationCount": 129,
    "pdf_filename": "2023_AI_chatbots_not_yet_ready_for_clinical_u_79c5f798.pdf"
  },
  "d066bc10a8df107fb1f65518711df59cdc3c41fd": {
    "paperId": "d066bc10a8df107fb1f65518711df59cdc3c41fd",
    "title": "CrackGAN: Pavement Crack Detection Using Partially Accurate Ground Truths Based on Generative Adversarial Learning",
    "year": 2020,
    "authors": "Kaige Zhang, Yingtao Zhang, Heng-Da Cheng",
    "abstract": "Fully convolutional network is a powerful tool for per-pixel semantic segmentation/detection. However, it is problematic when coping with crack detection using partially accurate ground truths (GTs): the network may easily converge to the status that treats all the pixels as background (BG) and still achieves a very good loss, named “All Black” phenomenon, due to the unavailability of accurate GTs and the data imbalance. To tackle this problem, we propose crack-patch-only (CPO) supervised generative adversarial learning for end-to-end training, which forces the network to always produce crack-GT images while reserves both crack and BG-image translation abilities by feeding a larger-size crack image into an asymmetric U-shape generator to overcome the “All Black” issue. The proposed approach is validated using four crack datasets; and achieves state-of-the-art performance comparing with that of the recently published works in efficiency and accuracy.",
    "citationCount": 165,
    "pdf_filename": "2020_CrackGAN__Pavement_Crack_Detection_Using_d066bc10.pdf"
  },
  "3676e5c74effe6674bd00a8283ef410045cf600a": {
    "paperId": "3676e5c74effe6674bd00a8283ef410045cf600a",
    "title": "Generative Models for De Novo Drug Design.",
    "year": 2021,
    "authors": "X. Tong, Xiaohong Liu, Xiaoqin Tan, Xutong Li, Jiaxin Jiang",
    "abstract": "Artificial intelligence (AI) is booming. Among various AI approaches, generative models have received much attention in recent years. Inspired by these successes, researchers are now applying generative model techniques to de novo drug design, which has been considered as the \"holy grail\" of drug discovery. In this Perspective, we first focus on describing models such as recurrent neural network, autoencoder, generative adversarial network, transformer, and hybrid models with reinforcement learning. Next, we summarize the applications of generative models to drug design, including generating various compounds to expand the compound library and designing compounds with specific properties, and we also list a few publicly available molecular design tools based on generative models which can be used directly to generate molecules. In addition, we also introduce current benchmarks and metrics frequently used for generative models. Finally, we discuss the challenges and prospects of using generative models to aid drug design.",
    "citationCount": 160,
    "pdf_filename": "2021_Generative_Models_for_De_Novo_Drug_Desig_3676e5c7.pdf"
  },
  "77d2794d3765b75b39d7acb1192dc4cf3774890a": {
    "paperId": "77d2794d3765b75b39d7acb1192dc4cf3774890a",
    "title": "Diabetic Retinopathy Diagnosis Using Multichannel Generative Adversarial Network With Semisupervision",
    "year": 2020,
    "authors": "Shuqiang Wang, Xiangyu Wang, Yong Hu, Yanyan Shen, Zhile Yang",
    "abstract": "Diabetic retinopathy (DR) is one of the major causes of blindness. It is of great significance to apply deep-learning techniques for DR recognition. However, deep-learning algorithms often depend on large amounts of labeled data, which is expensive and time-consuming to obtain in the medical imaging area. In addition, the DR features are inconspicuous and spread out over high-resolution fundus images. Therefore, it is a big challenge to learn the distribution of such DR features. This article proposes a multichannel-based generative adversarial network (MGAN) with semisupervision to grade DR. The multichannel generative model is developed to generate a series of subfundus images corresponding to the scattering DR features. By minimizing the dependence on labeled data, the proposed semisupervised MGAN can identify the inconspicuous lesion features by using high-resolution fundus images without compression. Experimental results on the public Messidor data set show that the proposed model can grade DR effectively. Note to Practitioners—This article is motivated by the challenging problem due to the inadequacy of labeled data in medical image analysis and the dispersion of efficient features in high-resolution medical images. As for the inadequacy of labeled data in medical image analysis, the reasons mainly include the followings: 1) the high-quality annotation of medical imaging sample depends heavily on scarce medical expertise which is very expensive and 2) comparing with natural issues, it is more difficult to collect medical images because of privacy issues. It is of great significance to apply deep-learning techniques for diabetic retinopathy (DR) recognition. In this article, the multichannel generative adversarial network (GAN) with semisupervision is developed for DR-aided diagnosis. The proposed model can deal with DR classification problem with inadequacy of labeled data in the following ways: 1) the multichannel generative scheme is proposed to generate a series of subfundus images corresponding to the scattering DR features and 2) the proposed multichannel-based GAN (MGAN) model with semisupervision can make full use of both labeled data and unlabeled data. The experimental results demonstrate that the proposed model outperforms the other representative models in terms of accuracy, area under ROC curve (AUC), sensitivity, and specificity.",
    "citationCount": 119,
    "pdf_filename": "2020_Diabetic_Retinopathy_Diagnosis_Using_Mul_77d2794d.pdf"
  },
  "767b5e373facf6c1ddd30e0b45b3720beb83cb9c": {
    "paperId": "767b5e373facf6c1ddd30e0b45b3720beb83cb9c",
    "title": "Generative Adversarial Networks–Enabled Human–Artificial Intelligence Collaborative Applications for Creative and Design Industries: A Systematic Review of Current Approaches and Trends",
    "year": 2021,
    "authors": "Rowan T. Hughes, Liming Zhu, T. Bednarz",
    "abstract": "The future of work and workplace is very much in flux. A vast amount has been written about artificial intelligence (AI) and its impact on work, with much of it focused on automation and its impact in terms of potential job losses. This review will address one area where AI is being added to creative and design practitioners’ toolbox to enhance their creativity, productivity, and design horizons. A designer’s primary purpose is to create, or generate, the most optimal artifact or prototype, given a set of constraints. We have seen AI encroaching into this space with the advent of generative networks and generative adversarial networks (GANs) in particular. This area has become one of the most active research fields in machine learning over the past number of years, and a number of these techniques, particularly those around plausible image generation, have garnered considerable media attention. We will look beyond automatic techniques and solutions and see how GANs are being incorporated into user pipelines for design practitioners. A systematic review of publications indexed on ScienceDirect, SpringerLink, Web of Science, Scopus, IEEExplore, and ACM DigitalLibrary was conducted from 2015 to 2020. Results are reported according to PRISMA statement. From 317 search results, 34 studies (including two snowball sampled) are reviewed, highlighting key trends in this area. The studies’ limitations are presented, particularly a lack of user studies and the prevalence of toy-examples or implementations that are unlikely to scale. Areas for future study are also identified.",
    "citationCount": 113,
    "pdf_filename": "2021_Generative_Adversarial_Networks_Enabled__767b5e37.pdf"
  },
  "a6d8d04962f84ae6225e72723869a002b9fc8036": {
    "paperId": "a6d8d04962f84ae6225e72723869a002b9fc8036",
    "title": "What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers",
    "year": 2021,
    "authors": "Boseop Kim, Hyoungseok Kim, Sang-Woo Lee, Gichang Lee, Donghyun Kwak",
    "abstract": "GPT-3 shows remarkable in-context learning ability of large-scale language models (LMs) trained on hundreds of billion scale data. Here we address some remaining issues less reported by the GPT-3 paper, such as a non-English LM, the performances of different sized models, and the effect of recently introduced prompt optimization on in-context learning. To achieve this, we introduce HyperCLOVA, a Korean variant of 82B GPT-3 trained on a Korean-centric corpus of 560B tokens. Enhanced by our Korean-specific tokenization, HyperCLOVA with our training configuration shows state-of-the-art in-context zero-shot and few-shot learning performances on various downstream tasks in Korean. Also, we show the performance benefits of prompt-based learning and demonstrate how it can be integrated into the prompt engineering pipeline. Then we discuss the possibility of materializing the No Code AI paradigm by providing AI prototyping capabilities to non-experts of ML by introducing HyperCLOVA studio, an interactive prompt engineering interface. Lastly, we demonstrate the potential of our methods with three successful in-house applications.",
    "citationCount": 128,
    "pdf_filename": "2021_What_Changes_Can_Large_scale_Language_Mo_a6d8d049.pdf"
  },
  "42592de0c8580ad4f443722e531487ba4f6ad181": {
    "paperId": "42592de0c8580ad4f443722e531487ba4f6ad181",
    "title": "Expanding functional protein sequence spaces using generative adversarial networks",
    "year": 2021,
    "authors": "Donatas Repecka, Vykintas Jauniškis, Laurynas Karpus, Elzbieta Rembeza, Irmantas Rokaitis",
    "abstract": "De novo protein design for catalysis of any desired chemical reaction is a long-standing goal in protein engineering because of the broad spectrum of technological, scientific and medical applications. However, mapping protein sequence to protein function is currently neither computationally nor experimentally tangible. Here, we develop ProteinGAN, a self-attention-based variant of the generative adversarial network that is able to ‘learn’ natural protein sequence diversity and enables the generation of functional protein sequences. ProteinGAN learns the evolutionary relationships of protein sequences directly from the complex multidimensional amino-acid sequence space and creates new, highly diverse sequence variants with natural-like physical properties. Using malate dehydrogenase (MDH) as a template enzyme, we show that 24% (13 out of 55 tested) of the ProteinGAN-generated and experimentally tested sequences are soluble and display MDH catalytic activity in the tested conditions in vitro, including a highly mutated variant of 106 amino-acid substitutions. ProteinGAN therefore demonstrates the potential of artificial intelligence to rapidly generate highly diverse functional proteins within the allowed biological constraints of the sequence space. A protein’s three-dimensional structure and properties are defined by its amino-acid sequence, but mapping protein sequence to protein function is a computationally highly intensive task. A new generative adversarial network approach learns from natural protein sequences and generates new, diverse protein sequence variations, which are experimentally tested.",
    "citationCount": 184,
    "pdf_filename": "2021_Expanding_functional_protein_sequence_sp_42592de0.pdf"
  },
  "d15f6cf2d4d691cc4b3e04ec22db8f856fd25e2a": {
    "paperId": "d15f6cf2d4d691cc4b3e04ec22db8f856fd25e2a",
    "title": "FEM Simulation-Based Generative Adversarial Networks to Detect Bearing Faults",
    "year": 2020,
    "authors": "Yun Gao, Xiao-Yang Liu, J. Xiang",
    "abstract": "Complete fault sample is essential to activate artificial intelligent (AI) models. A novel fault detection scheme is proposed to build a bridge between AI and real-world running mechanical systems. First, the finite element method simulation is used to simulate samples with different faults to overcome the shortcoming of missing fault samples. Second, to enlarge datasets, new samples similar to the simulation and measurement fault samples are generated by generative adversarial networks and further combined with the original simulation and measurement samples to obtain synthetic samples. Finally, the synthetic and unknown fault samples are severed as the training and test samples, respectively, to the classifiers of AI models, and the unknown fault types will be finally determined. A public datasets of bearings have been used to verify the effectiveness of the proposed scheme. It is expected that the proposed scheme can be extended to complex mechanical systems.",
    "citationCount": 168,
    "pdf_filename": "2020_FEM_Simulation_Based_Generative_Adversar_d15f6cf2.pdf"
  },
  "5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b": {
    "paperId": "5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b",
    "title": "Video Generative Adversarial Networks: A Review",
    "year": 2020,
    "authors": "Nuha Aldausari, A. Sowmya, Nadine Marcus, Gelareh Mohammadi",
    "abstract": "With the increasing interest in the content creation field in multiple sectors such as media, education, and entertainment, there is an increased trend in the papers that use AI algorithms to generate content such as images, videos, audio, and text. Generative Adversarial Networks (GANs) is one of the promising models that synthesizes data samples that are similar to real data samples. While the variations of GANs models in general have been covered to some extent in several survey papers, to the best of our knowledge, this is the first paper that reviews the state-of-the-art video GANs models. This paper first categorizes GANs review papers into general GANs review papers, image GANs review papers, and special field GANs review papers such as anomaly detection, medical imaging, or cybersecurity. The paper then summarizes the main improvements in GANs that are not necessarily applied in the video domain in the first run but have been adopted in multiple video GANs variations. Then, a comprehensive review of video GANs models are provided under two main divisions based on existence of a condition. The conditional models are then further classified according to the provided condition into audio, text, video, and image. The paper concludes with the main challenges and limitations of the current video GANs models.",
    "citationCount": 136,
    "pdf_filename": "2020_Video_Generative_Adversarial_Networks__A_5c1b1ab7.pdf"
  },
  "bd4fee2eee2ab9c4c73cc3e1ab277cda8e645413": {
    "paperId": "bd4fee2eee2ab9c4c73cc3e1ab277cda8e645413",
    "title": "Integrating deep learning into CAD/CAE system: generative design and evaluation of 3D conceptual wheel",
    "year": 2020,
    "authors": "Soyoung Yoo, Sunghee Lee, Seongsin Kim, Kwang Hyeon Hwang, Jong Ho Park",
    "abstract": "Engineering design research integrating artificial intelligence (AI) into computer-aided design (CAD) and computer-aided engineering (CAE) is actively being conducted. This study proposes a deep learning-based CAD/CAE framework in the conceptual design phase that automatically generates 3D CAD designs and evaluates their engineering performance. The proposed framework comprises seven stages: (1) 2D generative design, (2) dimensionality reduction, (3) design of experiment in latent space, (4) CAD automation, (5) CAE automation, (6) transfer learning, and (7) visualization and analysis. The proposed framework is demonstrated through a road wheel design case study and indicates that AI can be practically incorporated into an end-use product design project. Engineers and industrial designers can jointly review a large number of generated 3D CAD models by using this framework along with the engineering performance results estimated by AI and find conceptual design candidates for the subsequent detailed design stage.",
    "citationCount": 129,
    "pdf_filename": "2020_Integrating_deep_learning_into_CAD_CAE_s_bd4fee2e.pdf"
  },
  "82f766d3c572b4c690b439edab5d32b3ba72852e": {
    "paperId": "82f766d3c572b4c690b439edab5d32b3ba72852e",
    "title": "G-IDS: Generative Adversarial Networks Assisted Intrusion Detection System",
    "year": 2020,
    "authors": "Md Hasan Shahriar, Nur Imtiazul Haque, M. Rahman, M. Alonso",
    "abstract": "The boundaries of cyber-physical systems (CPS) and the Internet of Things (IoT) are converging together day by day to introduce a common platform on hybrid systems. Moreover, the combination of artificial intelligence (AI) with CPS creates a new dimension of technological advancement. All these connectivity and dependability are creating massive space for the attackers to launch cyber attacks. To defend against these attacks, intrusion detection system (IDS) has been widely used. However, emerging CPS fields suffer from imbalanced and missing sample data, which makes the training of IDS difficult. In this paper, we propose a generative adversarial network (GAN) based intrusion detection system (G-IDS), where GAN generates synthetic samples, and IDS gets trained on them along with the original ones. G-IDS also fixes the difficulties of imbalanced or missing data problems. We model a network security dataset for an emerging CPS using NSL KDD-99 dataset and evaluate our proposed model's performance using different metrics. We find that our proposed G-IDS model performs much better in attack detection and model stabilization during the training process than a standalone IDS.",
    "citationCount": 119,
    "pdf_filename": "2020_G_IDS__Generative_Adversarial_Networks_A_82f766d3.pdf"
  },
  "004847141139c57bbe59956dfd03dea772d9579a": {
    "paperId": "004847141139c57bbe59956dfd03dea772d9579a",
    "title": "3DALL-E: Integrating Text-to-Image AI in 3D Design Workflows",
    "year": 2022,
    "authors": "Vivian Liu, Jo Vermeulen, G. Fitzmaurice, Justin Matejka",
    "abstract": "Text-to-image AI are capable of generating novel images for inspiration, but their applications for 3D design workflows and how designers can build 3D models using AI-provided inspiration have not yet been explored. To investigate this, we integrated DALL-E, GPT-3, and CLIP within a CAD software in 3DALL-E, a plugin that generates 2D image inspiration for 3D design. 3DALL-E allows users to construct text and image prompts based on what they are modeling. In a study with 13 designers, we found that designers saw great potential in 3DALL-E within their workflows and could use text-to-image AI to produce reference images, prevent design fixation, and inspire design considerations. We elaborate on prompting patterns observed across 3D modeling tasks and provide measures of prompt complexity observed across participants. From our findings, we discuss how 3DALL-E can merge with existing generative design workflows and propose prompt bibliographies as a form of human-AI design history.",
    "citationCount": 151,
    "pdf_filename": "2022_3DALL_E__Integrating_Text_to_Image_AI_in_00484714.pdf"
  },
  "5b819b32dcb6dfaeeb1ce3f2996e77ed615e7782": {
    "paperId": "5b819b32dcb6dfaeeb1ce3f2996e77ed615e7782",
    "title": "Antibody design using LSTM based deep generative model from phage display library for affinity maturation",
    "year": 2021,
    "authors": "K. Saka, Taro Kakuzaki, S. Metsugi, Daiki Kashiwagi, Kenji Yoshida",
    "abstract": "Molecular evolution is an important step in the development of therapeutic antibodies. However, the current method of affinity maturation is overly costly and labor-intensive because of the repetitive mutation experiments needed to adequately explore sequence space. Here, we employed a long short term memory network (LSTM)—a widely used deep generative model—based sequence generation and prioritization procedure to efficiently discover antibody sequences with higher affinity. We applied our method to the affinity maturation of antibodies against kynurenine, which is a metabolite related to the niacin synthesis pathway. Kynurenine binding sequences were enriched through phage display panning using a kynurenine-binding oriented human synthetic Fab library. We defined binding antibodies using a sequence repertoire from the NGS data to train the LSTM model. We confirmed that likelihood of generated sequences from a trained LSTM correlated well with binding affinity. The affinity of generated sequences are over 1800-fold higher than that of the parental clone. Moreover, compared to frequency based screening using the same dataset, our machine learning approach generated sequences with greater affinity.",
    "citationCount": 151,
    "pdf_filename": "2021_Antibody_design_using_LSTM_based_deep_ge_5b819b32.pdf"
  },
  "8bd619903329f28ede9dabeaeeac3caa3a276caa": {
    "paperId": "8bd619903329f28ede9dabeaeeac3caa3a276caa",
    "title": "The Advent of Generative Chemistry.",
    "year": 2020,
    "authors": "Q. Vanhaelen, Yen-Chu Lin, A. Zhavoronkov",
    "abstract": "Generative adversarial networks (GANs), first published in 2014, are among the most important concepts in modern artificial intelligence (AI). Bridging deep learning and game theory, GANs are used to generate or \"imagine\" new objects with desired properties. Since 2016, multiple GANs with reinforcement learning (RL) have been successfully applied in pharmacology for de novo molecular design. Those techniques aim at a more efficient use of the data and a better exploration of the chemical space. We review recent advances for the generation of novel molecules with desired properties with a focus on the applications of GANs, RL, and related techniques. We also discuss the current limitations and challenges in the new growing field of generative chemistry.",
    "citationCount": 109,
    "pdf_filename": "2020_The_Advent_of_Generative_Chemistry__8bd61990.pdf"
  },
  "29c4e190bfc8fc328b1fb93322716600acfc68a6": {
    "paperId": "29c4e190bfc8fc328b1fb93322716600acfc68a6",
    "title": "The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues",
    "year": 2022,
    "authors": "Anaïs Tack, C. Piech",
    "abstract": "How can we test whether state-of-the-art generative models, such as Blender and GPT-3, are good AI teachers, capable of replying to a student in an educational dialogue? Designing an AI teacher test is challenging: although evaluation methods are much-needed, there is no off-the-shelf solution to measuring pedagogical ability. This paper reports on a first attempt at an AI teacher test. We built a solution around the insight that you can run conversational agents in parallel to human teachers in real-world dialogues, simulate how different agents would respond to a student, and compare these counterpart responses in terms of three abilities: speak like a teacher, understand a student, help a student. Our method builds on the reliability of comparative judgments in education and uses a probabilistic model and Bayesian sampling to infer estimates of pedagogical ability. We find that, even though conversational agents (Blender in particular) perform well on conversational uptake, they are quantifiably worse than real teachers on several pedagogical dimensions, especially with regard to helpfulness (Blender: {\\Delta} ability = -0.75; GPT-3: {\\Delta} ability = -0.93).",
    "citationCount": 114,
    "pdf_filename": "2022_The_AI_Teacher_Test__Measuring_the_Pedag_29c4e190.pdf"
  },
  "1a1a1ef120e48f7d635cf856f0ab0dba88b102db": {
    "paperId": "1a1a1ef120e48f7d635cf856f0ab0dba88b102db",
    "title": "Bidirectional Mapping Generative Adversarial Networks for Brain MR to PET Synthesis",
    "year": 2020,
    "authors": "Shengye Hu, Baiying Lei, Shuqiang Wang, Yong Wang, Zhiguang Feng",
    "abstract": "Fusing multi-modality medical images, such as magnetic resonance (MR) imaging and positron emission tomography (PET), can provide various anatomical and functional information about the human body. However, PET data is not always available for several reasons, such as high cost, radiation hazard, and other limitations. This paper proposes a 3D end-to-end synthesis network called Bidirectional Mapping Generative Adversarial Networks (BMGAN). Image contexts and latent vectors are effectively used for brain MR-to-PET synthesis. Specifically, a bidirectional mapping mechanism is designed to embed the semantic information of PET images into the high-dimensional latent space. Moreover, the 3D Dense-UNet generator architecture and the hybrid loss functions are further constructed to improve the visual quality of cross-modality synthetic images. The most appealing part is that the proposed method can synthesize perceptually realistic PET images while preserving the diverse brain structures of different subjects. Experimental results demonstrate that the performance of the proposed method outperforms other competitive methods in terms of quantitative measures, qualitative displays, and evaluation metrics for classification.",
    "citationCount": 161,
    "pdf_filename": "2020_Bidirectional_Mapping_Generative_Adversa_1a1a1ef1.pdf"
  },
  "1af720143c6a7026c7c830914a34b3dc6be6730f": {
    "paperId": "1af720143c6a7026c7c830914a34b3dc6be6730f",
    "title": "House-GAN++: Generative Adversarial Layout Refinement Network towards Intelligent Computational Agent for Professional Architects",
    "year": 2021,
    "authors": "Nelson Nauata, Sepidehsadat Hosseini, Kai-Hung Chang, Hang Chu, Chin-Yi Cheng",
    "abstract": "This paper proposes a generative adversarial layout refinement network for automated floorplan generation. Our architecture is an integration of a graph-constrained relational GAN and a conditional GAN, where a previously generated layout becomes the next input constraint, enabling iterative refinement. A surprising discovery of our research is that a simple non-iterative training process, dubbed component-wise GT-conditioning, is effective in learning such a generator. The iterative generator further allows us to improve a metric of choice via meta-optimization techniques by controlling when to pass which input constraints during iterative refinement. Our qualitative and quantitative evaluation based on the three standard metrics demonstrate that the proposed system makes significant improvements over the current state-of-the-art, even competitive against the ground-truth floorplans, designed by professional architects. Code, model, and data are available at https://ennauata.github.io/houseganpp/page.html.",
    "citationCount": 133,
    "pdf_filename": "2021_House_GAN____Generative_Adversarial_Layo_1af72014.pdf"
  },
  "8a8e2c23fd7179d981cbefbbc4844494e7255c53": {
    "paperId": "8a8e2c23fd7179d981cbefbbc4844494e7255c53",
    "title": "GPT-3 and InstructGPT: technological dystopianism, utopianism, and “Contextual” perspectives in AI ethics and industry",
    "year": 2022,
    "authors": "Anastasia Chan",
    "abstract": "This paper examines the ethical solutions raised in response to OpenAI’s language model Generative Pre-trained Transformer-3 (GPT-3) a year and a half from its release. I argue that hype and fear about GPT-3, even within the Natural Language Processing (NLP) industry and AI ethics, have often been underpinned by technologically deterministic perspectives. These perspectives emphasise the autonomy of the language model rather than the autonomy of human actors in AI systems. I highlight the existence of deterministic perspectives in the current AI discourse (which range from technological utopianism to dystopianism), with a specific focus on the two issues of: (1) GPT-3’s potential intentional misuse for manipulation and (2) unintentional harm caused by bias. In response, I find that a contextual approach to GPT-3, which is centred upon wider ecologies of societal harm and benefit, human autonomy, and human values, illuminates practical solutions to concerns about manipulation and bias. Additionally, although OpenAI’s newest 2022 language model InstructGPT represents a small step in reducing toxic language and aligning GPT-3 with user intent, it does not provide any compelling solutions to manipulation or bias. Therefore, I argue that solutions to address these issues must focus on organisational settings as a precondition for ethical decision-making in AI, and high-quality curated datasets as a precondition for less harmful language model outputs.",
    "citationCount": 110,
    "pdf_filename": "2022_GPT_3_and_InstructGPT__technological_dys_8a8e2c23.pdf"
  },
  "d1baf8975aaf887716cbcb774b4d087a55ca2acc": {
    "paperId": "d1baf8975aaf887716cbcb774b4d087a55ca2acc",
    "title": "Synthetic promoter design in Escherichia coli based on a deep generative network",
    "year": 2020,
    "authors": "Ye Wang, Haochen Wang, Lei Wei, Shuailin Li, Liyang Liu",
    "abstract": "Abstract Promoter design remains one of the most important considerations in metabolic engineering and synthetic biology applications. Theoretically, there are 450 possible sequences for a 50-nt promoter, of which naturally occurring promoters make up only a small subset. To explore the vast number of potential sequences, we report a novel AI-based framework for de novo promoter design in Escherichia coli. The model, which was guided by sequence features learned from natural promoters, could capture interactions between nucleotides at different positions and design novel synthetic promoters in silico. We combined a deep generative model that guides the search for artificial sequences with a predictive model to preselect the most promising promoters. The AI-designed promoters were optimized based on the promoter activity in E. coli and the predictive model. After two rounds of optimization, up to 70.8% of the AI-designed promoters were experimentally demonstrated to be functional, and few of them shared significant sequence similarity with the E. coli genome. Our work provided an end-to-end approach to the de novo design of novel promoter elements, indicating the potential to apply deep learning methods to de novo genetic element design.",
    "citationCount": 153,
    "pdf_filename": "2020_Synthetic_promoter_design_in_Escherichia_d1baf897.pdf"
  },
  "2730ce41b89d1b2d245ddc86adccf77a2eb0bd46": {
    "paperId": "2730ce41b89d1b2d245ddc86adccf77a2eb0bd46",
    "title": "Preparing for an Era of Deepfakes and AI-Generated Ads: A Framework for Understanding Responses to Manipulated Advertising",
    "year": 2021,
    "authors": "Colin Campbell, Kirk Plangger, S. Sands, Jan H. Kietzmann",
    "abstract": "Abstract Traditionally, the production and distribution of advertising material has relied on human effort and analog tools. However, technological innovations have given the advertising industry digital and automatic tools that enable advertisers to automate many advertising processes and produce “synthetic ads,” or ads comprising content based on the artificial and automatic production and modification of data. The emerging practice of synthetic advertising, to date the most sophisticated form of ad manipulation, relies on various artificial intelligence (AI) techniques, such as deepfakes and generative adversarial networks (GANs), to automatically create content that depicts an unreal, albeit convincing, artificial version of reality. In this article, a general framework is constructed to better understand how consumers respond to all forms of ad manipulation. It is anticipated that this article will help explain how consumers respond to the more sophisticated forms of synthetic ads—such as deepfakes—that are emerging at an accelerating rate. To guide research in this area, a research agenda is developed focusing on three manipulated advertising areas: ad falsity, consumer response, and originality. Furthermore, the implications for theory and industry are considered.",
    "citationCount": 191,
    "pdf_filename": "2021_Preparing_for_an_Era_of_Deepfakes_and_AI_2730ce41.pdf"
  },
  "2a36402451c4fcab33c9e7f59fc027167c070aa6": {
    "paperId": "2a36402451c4fcab33c9e7f59fc027167c070aa6",
    "title": "Perfection Not Required? Human-AI Partnerships in Code Translation",
    "year": 2021,
    "authors": "Justin D. Weisz, Michael J. Muller, Stephanie Houde, John T. Richards, Steven I. Ross",
    "abstract": "Generative models have become adept at producing artifacts such as images, videos, and prose at human-like levels of proficiency. New generative techniques, such as unsupervised neural machine translation (NMT), have recently been applied to the task of generating source code, translating it from one programming language to another. The artifacts produced in this way may contain imperfections, such as compilation or logical errors. We examine the extent to which software engineers would tolerate such imperfections and explore ways to aid the detection and correction of those errors. Using a design scenario approach, we interviewed 11 software engineers to understand their reactions to the use of an NMT model in the context of application modernization, focusing on the task of translating source code from one language to another. Our three-stage scenario sparked discussions about the utility and desirability of working with an imperfect AI system, how acceptance of that system’s outputs would be established, and future opportunities for generative AI in application modernization. Our study highlights how UI features such as confidence highlighting and alternate translations help software engineers work with and better understand generative NMT models.",
    "citationCount": 150,
    "pdf_filename": "2021_Perfection_Not_Required__Human_AI_Partne_2a364024.pdf"
  },
  "b20f13ddf177b09a0a81fe05ab5a9bf29fb576b5": {
    "paperId": "b20f13ddf177b09a0a81fe05ab5a9bf29fb576b5",
    "title": "REINVENT 2.0 – an AI Tool for De Novo Drug Design",
    "year": 2020,
    "authors": "T. Blaschke, Josep Arús‐Pous, Hongming Chen, Christian Margreitter, C. Tyrchan",
    "abstract": "With this application note we aim to offer the community a production-ready tool for de novo design. It can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space. By releasing the code we are aiming to facilitate the research on using generative methods on drug discovery problems and to promote the collaborative efforts in this area so that it can be used as an interaction point for future scientific collaborations.",
    "citationCount": 173,
    "pdf_filename": "2020_REINVENT_2_0___an_AI_Tool_for_De_Novo_Dr_b20f13dd.pdf"
  },
  "bb2e4307ed82ee937bdf25474322f805735deec9": {
    "paperId": "bb2e4307ed82ee937bdf25474322f805735deec9",
    "title": "AI-generated vs. Human Artworks. A Perception Bias Towards Artificial Intelligence?",
    "year": 2020,
    "authors": "Martin Ragot, Nicolas Martin, Salomé Cojean",
    "abstract": "Via generative adversarial networks (GANs), artificial intelligence (AI) has influenced many areas, especially the artistic field, as symbol of a human task. In human-computer interaction (HCI) studies, perception biases against AI, machines, or computers are generally cited. However, experimental evidence is still lacking. This paper presents a wide-scale experiment in which 565 participants are asked to evaluate paintings (which were created by humans or AI) on four dimensions: liking, perceived beauty, novelty, and meaning. A priming effect is evaluated using two between-subject conditions: Artworks presented as created by an AI, and artworks presented as created by a human artist. Finally, the paintings perceived as being drawn by human are evaluated significantly more highly than those perceived as being made by AI. Thus, using such a methodology and sample in an unprecedented way, the results show a negative bias of perception towards AI and a preference bias towards human systems.",
    "citationCount": 158,
    "pdf_filename": "2020_AI_generated_vs__Human_Artworks__A_Perce_bb2e4307.pdf"
  },
  "7b0e8efb4d582aec215c4a60d85201144009574c": {
    "paperId": "7b0e8efb4d582aec215c4a60d85201144009574c",
    "title": "Retrosynthetic accessibility score (RAscore) – rapid machine learned synthesizability classification from AI driven retrosynthetic planning†",
    "year": 2020,
    "authors": "Amol Thakkar, Veronika Chadimová, E. Bjerrum, O. Engkvist, J. Reymond",
    "abstract": "Computer aided synthesis planning (CASP) is part of a suite of artificial intelligence (AI) based tools that are able to propose synthesis routes to a wide range of compounds. However, at present they are too slow to be used to screen the synthetic feasibility of millions of generated or enumerated compounds before identification of potential bioactivity by virtual screening (VS) workflows. Herein we report a machine learning (ML) based method capable of classifying whether a synthetic route can be identified for a particular compound or not by the CASP tool AiZynthFinder. The resulting ML models return a retrosynthetic accessibility score (RAscore) of any molecule of interest, and computes at least 4500 times faster than retrosynthetic analysis performed by the underlying CASP tool. The RAscore should be useful for pre-screening millions of virtual molecules from enumerated databases or generative models for synthetic accessibility and produce higher quality databases for virtual screening of biological activity.",
    "citationCount": 101,
    "pdf_filename": "2020_Retrosynthetic_accessibility_score__RAsc_7b0e8efb.pdf"
  },
  "f8544e496bdb933bbf1bbad66c7343928922311b": {
    "paperId": "f8544e496bdb933bbf1bbad66c7343928922311b",
    "title": "The Jazz Transformer on the Front Line: Exploring the Shortcomings of AI-composed Music through Quantitative Measures",
    "year": 2020,
    "authors": "Shih-Lun Wu, Yi-Hsuan Yang",
    "abstract": "This paper presents the Jazz Transformer, a generative model that utilizes a neural sequence model called the Transformer-XL for modeling lead sheets of Jazz music. Moreover, the model endeavors to incorporate structural events present in the Weimar Jazz Database (WJazzD) for inducing structures in the generated music. While we are able to reduce the training loss to a low value, our listening test suggests however a clear gap between the average ratings of the generated and real compositions. We therefore go one step further and conduct a series of computational analysis of the generated compositions from different perspectives. This includes analyzing the statistics of the pitch class, grooving, and chord progression, assessing the structureness of the music with the help of the fitness scape plot, and evaluating the model's understanding of Jazz music through a MIREX-like continuation prediction task. Our work presents in an analytical manner why machine-generated music to date still falls short of the artwork of humanity, and sets some goals for future work on automatic composition to further pursue.",
    "citationCount": 107,
    "pdf_filename": "2020_The_Jazz_Transformer_on_the_Front_Line___f8544e49.pdf"
  },
  "d7b1ad0149ac0f29f16335069b9e12869f6aa109": {
    "paperId": "d7b1ad0149ac0f29f16335069b9e12869f6aa109",
    "title": "Human-AI Co-Creation in Songwriting",
    "year": 2020,
    "authors": "Cheng-Zhi Anna Huang, Hendrik Vincent Koops, Ed Newton-Rex, Monica Dinculescu, Carrie J. Cai",
    "abstract": "Machine learning is challenging the way we make music. Although research in deep generative models has dramatically improved the capability and fluency of music models, recent work has shown that it can be challenging for humans to partner with this new class of algorithms. In this paper, we present findings on what 13 musician/developer teams, a total of 61 users, needed when co-creating a song with AI, the challenges they faced, and how they leveraged and repurposed existing characteristics of AI to overcome some of these challenges. Many teams adopted modular approaches, such as independently running multiple smaller models that align with the musical building blocks of a song, before re-combining their results. As ML models are not easily steerable, teams also generated massive numbers of samples and curated them post-hoc, or used a range of strategies to direct the generation, or algorithmically ranked the samples. Ultimately, teams not only had to manage the \"flare and focus\" aspects of the creative process, but also juggle them with a parallel process of exploring and curating multiple ML models and outputs. These findings reflect a need to design machine learning-powered music interfaces that are more decomposable, steerable, interpretable, and adaptive, which in return will enable artists to more effectively explore how AI can extend their personal expression.",
    "citationCount": 101,
    "pdf_filename": "2020_Human_AI_Co_Creation_in_Songwriting_d7b1ad01.pdf"
  },
  "f773ceb43ffc7f9cd685250c4919924ec0bc85c7": {
    "paperId": "f773ceb43ffc7f9cd685250c4919924ec0bc85c7",
    "title": "RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots",
    "year": 2024,
    "authors": "Soroush Nasiriany, Abhiram Maddukuri, Lance Zhang, Adeet Parikh, Aaron Lo",
    "abstract": "Recent advancements in Artificial Intelligence (AI) have largely been propelled by scaling. In Robotics, scaling is hindered by the lack of access to massive robot datasets. We advocate using realistic physical simulation as a means to scale environments, tasks, and datasets for robot learning methods. We present RoboCasa, a large-scale simulation framework for training generalist robots in everyday environments. RoboCasa features realistic and diverse scenes focusing on kitchen environments. We provide thousands of 3D assets across over 150 object categories and dozens of interactable furniture and appliances. We enrich the realism and diversity of our simulation with generative AI tools, such as object assets from text-to-3D models and environment textures from text-to-image models. We design a set of 100 tasks for systematic evaluation, including composite tasks generated by the guidance of large language models. To facilitate learning, we provide high-quality human demonstrations and integrate automated trajectory generation methods to substantially enlarge our datasets with minimal human burden. Our experiments show a clear scaling trend in using synthetically generated robot data for large-scale imitation learning and show great promise in harnessing simulation data in real-world tasks. Videos and open-source code are available at https://robocasa.ai/",
    "citationCount": 176,
    "pdf_filename": "2024_RoboCasa__Large_Scale_Simulation_of_Ever_f773ceb4.pdf"
  },
  "ebf0a3812d8c02b333bb0890a9387c60b7b5589f": {
    "paperId": "ebf0a3812d8c02b333bb0890a9387c60b7b5589f",
    "title": "A critical review of GenAI policies in higher education assessment: a call to reconsider the “originality” of students’ work",
    "year": 2024,
    "authors": "Jiahui Luo (Jess)",
    "abstract": "Abstract This study offers a critical examination of university policies developed to address recent challenges presented by generative AI (GenAI) to higher education assessment. Drawing on Bacchi’s ‘What’s the problem represented to be’ (WPR) framework, we analysed the GenAI policies of 20 world-leading universities to explore what are considered problems in this AI-mediated assessment landscape and how these problems are represented in policies. Although miscellaneous GenAI-related problems were mentioned in these policies (e.g. reliability of AI-generated outputs, equal access to GenAI), the primary problem represented is that students may not submit original work for assessment. In the current framing, GenAI is often viewed as a type of external assistance separate from the student’s independent efforts and intellectual contribution, thereby undermining the originality of their work. We argue that such problem representation fails to acknowledge how the rise of GenAI further complicates the process of producing original work and what it means by originality in a time when knowledge production becomes increasingly distributed, collaborative and mediated by technology. Therefore, a critical silence in higher education policies concerns the evolving notion of originality in the digital age and a more inclusive approach to address the originality of students’ work is required.",
    "citationCount": 161,
    "pdf_filename": "2024_A_critical_review_of_GenAI_policies_in_h_ebf0a381.pdf"
  },
  "49fff1d586f5e05ba81bddf5caf528c67ea535cb": {
    "paperId": "49fff1d586f5e05ba81bddf5caf528c67ea535cb",
    "title": "Empowering student self-regulated learning and science education through ChatGPT: A pioneering pilot study",
    "year": 2024,
    "authors": "D. Ng, Chee-Wei Tan, J. Leung",
    "abstract": "In recent years, AI technologies have been developed to promote students' self‐regulated learning (SRL) and proactive learning in digital learning environments. This paper discusses a comparative study between generative AI‐based (SRLbot) and rule‐based AI chatbots (Nemobot) in a 3‐week science learning experience with 74 Secondary 4 students in Hong Kong. The experimental group used SRLbot to maintain a regular study habit and facilitate their SRL, while the control group utilized rule‐based AI chatbots. Results showed that SRLbot effectively enhanced students' science knowledge, behavioural engagement and motivation. Quantile regression analysis indicated that the number of interactions significantly predicted variations in SRL. Students appreciated the personalized recommendations and flexibility of SRLbot, which adjusted responses based on their specific learning and SRL scenarios. The ChatGPT‐enhanced instructional design reduced learning anxiety and promoted learning performance, motivation and sustained learning habits. Students' feedback on learning challenges, psychological support and self‐regulation behaviours provided insights into their progress and experience with this technology. SRLbot's adaptability and personalized approach distinguished it from rule‐based chatbots. The findings offer valuable evidence for AI developers and educators to consider generative AI settings and chatbot design, facilitating greater success in online science learning.\nWhat is already known about this topic\n\nAI technologies have been used to support student self‐regulated learning (SRL) across subjects.\nSRL has been identified as an important aspect of student learning that can be developed through technological support.\nGenerative AI technologies like ChatGPT have shown potential for enhancing student learning by providing personalized guidance and feedback.\nWhat this paper adds\n\nThis paper reports on a case study that specifically examines the effectiveness of ChatGPT in promoting SRL among secondary students.\nThe study provides evidence that ChatGPT can enhance students' science knowledge, motivation and SRL compared to a rule‐based AI chatbot.\nThe study offers insights into how ChatGPT can be used as a tool to facilitate SRL and promote sustained learning habits.\nImplications for practice and/or policy\n\nThe findings of this study suggest that educators should consider the potential of ChatGPT and other generative AI technologies to support student learning and SRL.\nEducators and students should be aware of the limitations of AI technologies and ensure that they are used appropriately to generate desired responses.\nIt is also important to equip teachers and students with AI competencies to enable them to use AI for learning and teaching.\n\n",
    "citationCount": 148,
    "pdf_filename": "2024_Empowering_student_self_regulated_learni_49fff1d5.pdf"
  },
  "32566efe68955837f5d677cde1cddff09dbad381": {
    "paperId": "32566efe68955837f5d677cde1cddff09dbad381",
    "title": "DanceGRPO: Unleashing GRPO on Visual Generation",
    "year": 2025,
    "authors": "Zeyue Xue, Jie Wu, Yu Gao, Fangyuan Kong, Lingting Zhu",
    "abstract": "Recent advances in generative AI have revolutionized visual content creation, yet aligning model outputs with human preferences remains a critical challenge. While Reinforcement Learning (RL) has emerged as a promising approach for fine-tuning generative models, existing methods like DDPO and DPOK face fundamental limitations - particularly their inability to maintain stable optimization when scaling to large and diverse prompt sets, severely restricting their practical utility. This paper presents DanceGRPO, a framework that addresses these limitations through an innovative adaptation of Group Relative Policy Optimization (GRPO) for visual generation tasks. Our key insight is that GRPO's inherent stability mechanisms uniquely position it to overcome the optimization challenges that plague prior RL-based approaches on visual generation. DanceGRPO establishes several significant advances: First, it demonstrates consistent and stable policy optimization across multiple modern generative paradigms, including both diffusion models and rectified flows. Second, it maintains robust performance when scaling to complex, real-world scenarios encompassing three key tasks and four foundation models. Third, it shows remarkable versatility in optimizing for diverse human preferences as captured by five distinct reward models assessing image/video aesthetics, text-image alignment, video motion quality, and binary feedback. Our comprehensive experiments reveal that DanceGRPO outperforms baseline methods by up to 181\\% across multiple established benchmarks, including HPS-v2.1, CLIP Score, VideoAlign, and GenEval. Our results establish DanceGRPO as a robust and versatile solution for scaling Reinforcement Learning from Human Feedback (RLHF) tasks in visual generation, offering new insights into harmonizing reinforcement learning and visual synthesis.",
    "citationCount": 108,
    "pdf_filename": "2025_DanceGRPO__Unleashing_GRPO_on_Visual_Gen_32566efe.pdf"
  },
  "96159eea50588975893787d2f13e21e38ed4615a": {
    "paperId": "96159eea50588975893787d2f13e21e38ed4615a",
    "title": "Artificial intelligence in neuro-oncology: advances and challenges in brain tumor diagnosis, prognosis, and precision treatment",
    "year": 2024,
    "authors": "S. Khalighi, Kartik Reddy, Abhishek Midya, K. Pandav, A. Madabhushi",
    "abstract": "This review delves into the most recent advancements in applying artificial intelligence (AI) within neuro-oncology, specifically emphasizing work on gliomas, a class of brain tumors that represent a significant global health issue. AI has brought transformative innovations to brain tumor management, utilizing imaging, histopathological, and genomic tools for efficient detection, categorization, outcome prediction, and treatment planning. Assessing its influence across all facets of malignant brain tumor management- diagnosis, prognosis, and therapy- AI models outperform human evaluations in terms of accuracy and specificity. Their ability to discern molecular aspects from imaging may reduce reliance on invasive diagnostics and may accelerate the time to molecular diagnoses. The review covers AI techniques, from classical machine learning to deep learning, highlighting current applications and challenges. Promising directions for future research include multimodal data integration, generative AI, large medical language models, precise tumor delineation and characterization, and addressing racial and gender disparities. Adaptive personalized treatment strategies are also emphasized for optimizing clinical outcomes. Ethical, legal, and social implications are discussed, advocating for transparency and fairness in AI integration for neuro-oncology and providing a holistic understanding of its transformative impact on patient care.",
    "citationCount": 141,
    "pdf_filename": "2024_Artificial_intelligence_in_neuro_oncolog_96159eea.pdf"
  },
  "c6e2837894bb545fc62ef41d7dadcd6e1bb51dc5": {
    "paperId": "c6e2837894bb545fc62ef41d7dadcd6e1bb51dc5",
    "title": "PromptCharm: Text-to-Image Generation through Multi-modal Prompting and Refinement",
    "year": 2024,
    "authors": "Zhijie Wang, Yuheng Huang, Da Song, Lei Ma, Tianyi Zhang",
    "abstract": "The recent advancements in Generative AI have significantly advanced the field of text-to-image generation. The state-of-the-art text-to-image model, Stable Diffusion, is now capable of synthesizing high-quality images with a strong sense of aesthetics. Crafting text prompts that align with the model’s interpretation and the user’s intent thus becomes crucial. However, prompting remains challenging for novice users due to the complexity of the stable diffusion model and the non-trivial efforts required for iteratively editing and refining the text prompts. To address these challenges, we propose PromptCharm, a mixed-initiative system that facilitates text-to-image creation through multi-modal prompt engineering and refinement. To assist novice users in prompting, PromptCharm first automatically refines and optimizes the user’s initial prompt. Furthermore, PromptCharm supports the user in exploring and selecting different image styles within a large database. To assist users in effectively refining their prompts and images, PromptCharm renders model explanations by visualizing the model’s attention values. If the user notices any unsatisfactory areas in the generated images, they can further refine the images through model attention adjustment or image inpainting within the rich feedback loop of PromptCharm. To evaluate the effectiveness and usability of PromptCharm, we conducted a controlled user study with 12 participants and an exploratory user study with another 12 participants. These two studies show that participants using PromptCharm were able to create images with higher quality and better aligned with the user’s expectations compared with using two variants of PromptCharm that lacked interaction or visualization support.",
    "citationCount": 107,
    "pdf_filename": "2024_PromptCharm__Text_to_Image_Generation_th_c6e28378.pdf"
  },
  "2986b2b06173e065c94bae49c7a9a3718dad486c": {
    "paperId": "2986b2b06173e065c94bae49c7a9a3718dad486c",
    "title": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
    "year": 2024,
    "authors": "Patrice Bechard, Orlando Marquez Ayala",
    "abstract": "A common and fundamental limitation of Generative AI (GenAI) is its propensity to hallucinate. While large language models (LLM) have taken the world by storm, without eliminating or at least reducing hallucinations, real-world GenAI systems may face challenges in user adoption. In the process of deploying an enterprise application that produces workflows based on natural language requirements, we devised a system leveraging Retrieval Augmented Generation (RAG) to greatly improve the quality of the structured output that represents such workflows. Thanks to our implementation of RAG, our proposed system significantly reduces hallucinations in the output and improves the generalization of our LLM in out-of-domain settings. In addition, we show that using a small, well-trained retriever encoder can reduce the size of the accompanying LLM, thereby making deployments of LLM-based systems less resource-intensive.",
    "citationCount": 108,
    "pdf_filename": "2024_Reducing_hallucination_in_structured_out_2986b2b0.pdf"
  },
  "8fd282cf9dfd3c9a7483a6b8b69c8259b53aaee8": {
    "paperId": "8fd282cf9dfd3c9a7483a6b8b69c8259b53aaee8",
    "title": "Deep Multimodal Data Fusion",
    "year": 2024,
    "authors": "Fei Zhao, Chengcui Zhang, Baocheng Geng",
    "abstract": "Multimodal Artificial Intelligence (Multimodal AI), in general, involves various types of data (e.g., images, texts, or data collected from different sensors), feature engineering (e.g., extraction, combination/fusion), and decision-making (e.g., majority vote). As architectures become more and more sophisticated, multimodal neural networks can integrate feature extraction, feature fusion, and decision-making processes into one single model. The boundaries between those processes are increasingly blurred. The conventional multimodal data fusion taxonomy (e.g., early/late fusion), based on which the fusion occurs in, is no longer suitable for the modern deep learning era. Therefore, based on the main-stream techniques used, we propose a new fine-grained taxonomy grouping the state-of-the-art (SOTA) models into five classes: Encoder-Decoder methods, Attention Mechanism methods, Graph Neural Network methods, Generative Neural Network methods, and other Constraint-based methods. Most existing surveys on multimodal data fusion are only focused on one specific task with a combination of two specific modalities. Unlike those, this survey covers a broader combination of modalities, including Vision + Language (e.g., videos, texts), Vision + Sensors (e.g., images, LiDAR), and so on, and their corresponding tasks (e.g., video captioning, object detection). Moreover, a comparison among these methods is provided, as well as challenges and future directions in this area.",
    "citationCount": 184,
    "pdf_filename": "2024_Deep_Multimodal_Data_Fusion_8fd282cf.pdf"
  },
  "620791117f9af0b58c778f6583357388436317d6": {
    "paperId": "620791117f9af0b58c778f6583357388436317d6",
    "title": "Exploring User Adoption of ChatGPT: A Technology Acceptance Model Perspective",
    "year": 2024,
    "authors": "Jiaojiao Ma, Pengcheng Wang, Benqian Li, Tian Wang, Xiang Shan Pang",
    "abstract": "Abstract In the rapidly evolving landscape of technology, the emergence of Chat Generative Pre-trained Transformer (ChatGPT) marks a pivotal milestone in the realm of Artificial Intelligence (AI). However, little research has reported the predictors of people’s intentions to use ChatGPT. This pioneering study empirically examines user adoption through the lens of the Technology Acceptance Model (TAM) using a convenience sampling method. The study surveyed 784 ChatGPT users in China, of whom 58.93% were males. The results have revealed several key findings: (1) perceived usefulness, perceived ease of use, behavioral intention, and use behavior were positively correlated with each other; (2) behavioral intention acted as a mediating factor in the relationship between perceived usefulness and use behavior, as well as the relationship between perceived ease of use and use behavior; (3) perceived usefulness and behavioral intention played a chain-mediated role between perceived ease of use and use behavior; (4) the relationship between behavioral intention and use behavior exhibited greater strength among females compared to males; (5) the association between behavioral intention and use behavior was found to be stronger among urban users in comparison to their rural counterparts; (6) the connections between perceived ease of use and perceived usefulness, perceived ease of use and behavioral intention, and behavioral intention and use behavior were observed to be stronger among individuals with higher educational backgrounds relative to those with lower educational backgrounds. These findings provide crucial nuanced insights to advance the practical application of ChatGPT, emphasizing the need for enhanced usability and ease of use. However, this study exclusively captured usage behaviors within the Chinese user base. Future investigations could encompass diverse demographics across multiple countries, enabling cross-cultural comparisons.",
    "citationCount": 106,
    "pdf_filename": "2024_Exploring_User_Adoption_of_ChatGPT__A_Te_62079111.pdf"
  },
  "3edfc47bb4e37a031636ad82b5c4a8f27a2eee1f": {
    "paperId": "3edfc47bb4e37a031636ad82b5c4a8f27a2eee1f",
    "title": "Three Epochs of Artificial Intelligence in Health Care.",
    "year": 2024,
    "authors": "Michael D Howell, G. Corrado, Karen B. DeSalvo",
    "abstract": "Importance\nInterest in artificial intelligence (AI) has reached an all-time high, and health care leaders across the ecosystem are faced with questions about where, when, and how to deploy AI and how to understand its risks, problems, and possibilities.\n\n\nObservations\nWhile AI as a concept has existed since the 1950s, all AI is not the same. Capabilities and risks of various kinds of AI differ markedly, and on examination 3 epochs of AI emerge. AI 1.0 includes symbolic AI, which attempts to encode human knowledge into computational rules, as well as probabilistic models. The era of AI 2.0 began with deep learning, in which models learn from examples labeled with ground truth. This era brought about many advances both in people's daily lives and in health care. Deep learning models are task-specific, meaning they do one thing at a time, and they primarily focus on classification and prediction. AI 3.0 is the era of foundation models and generative AI. Models in AI 3.0 have fundamentally new (and potentially transformative) capabilities, as well as new kinds of risks, such as hallucinations. These models can do many different kinds of tasks without being retrained on a new dataset. For example, a simple text instruction will change the model's behavior. Prompts such as \"Write this note for a specialist consultant\" and \"Write this note for the patient's mother\" will produce markedly different content.\n\n\nConclusions and Relevance\nFoundation models and generative AI represent a major revolution in AI's capabilities, ffering tremendous potential to improve care. Health care leaders are making decisions about AI today. While any heuristic omits details and loses nuance, the framework of AI 1.0, 2.0, and 3.0 may be helpful to decision-makers because each epoch has fundamentally different capabilities and risks.",
    "citationCount": 101,
    "pdf_filename": "2024_Three_Epochs_of_Artificial_Intelligence__3edfc47b.pdf"
  },
  "9ebf258c59b8c1ed7d1564afea2e785de9aee1c3": {
    "paperId": "9ebf258c59b8c1ed7d1564afea2e785de9aee1c3",
    "title": "A Comprehensive Review of Deep Learning: Architectures, Recent Advances, and Applications",
    "year": 2024,
    "authors": "Ibomoiye Domor Mienye, Theo G. Swart",
    "abstract": "Deep learning (DL) has become a core component of modern artificial intelligence (AI), driving significant advancements across diverse fields by facilitating the analysis of complex systems, from protein folding in biology to molecular discovery in chemistry and particle interactions in physics. However, the field of deep learning is constantly evolving, with recent innovations in both architectures and applications. Therefore, this paper provides a comprehensive review of recent DL advances, covering the evolution and applications of foundational models like convolutional neural networks (CNNs) and Recurrent Neural Networks (RNNs), as well as recent architectures such as transformers, generative adversarial networks (GANs), capsule networks, and graph neural networks (GNNs). Additionally, the paper discusses novel training techniques, including self-supervised learning, federated learning, and deep reinforcement learning, which further enhance the capabilities of deep learning models. By synthesizing recent developments and identifying current challenges, this paper provides insights into the state of the art and future directions of DL research, offering valuable guidance for both researchers and industry experts.",
    "citationCount": 105,
    "pdf_filename": "2024_A_Comprehensive_Review_of_Deep_Learning__9ebf258c.pdf"
  },
  "b4f0059c9a706f963e0ab6d82163a7762dafb176": {
    "paperId": "b4f0059c9a706f963e0ab6d82163a7762dafb176",
    "title": "Aci-bench: a Novel Ambient Clinical Intelligence Dataset for Benchmarking Automatic Visit Note Generation",
    "year": 2023,
    "authors": "Wen-wai Yim, Yujuan Velvin Fu, Asma Ben Abacha, Neal Snider, Thomas Lin",
    "abstract": "Recent immense breakthroughs in generative models such as in GPT4 have precipitated re-imagined ubiquitous usage of these models in all applications. One area that can benefit by improvements in artificial intelligence (AI) is healthcare. The note generation task from doctor-patient encounters, and its associated electronic medical record documentation, is one of the most arduous time-consuming tasks for physicians. It is also a natural prime potential beneficiary to advances in generative models. However with such advances, benchmarking is more critical than ever. Whether studying model weaknesses or developing new evaluation metrics, shared open datasets are an imperative part of understanding the current state-of-the-art. Unfortunately as clinic encounter conversations are not routinely recorded and are difficult to ethically share due to patient confidentiality, there are no sufficiently large clinic dialogue-note datasets to benchmark this task. Here we present the Ambient Clinical Intelligence Benchmark ( aci-bench ) corpus, the largest dataset to date tackling the problem of AI-assisted note generation from visit dialogue. We also present the benchmark performances of several common state-of-the-art approaches.",
    "citationCount": 125,
    "pdf_filename": "2023_Aci_bench__a_Novel_Ambient_Clinical_Inte_b4f0059c.pdf"
  },
  "1460d33f547ee40c560174dc0f6898f4802f4cf8": {
    "paperId": "1460d33f547ee40c560174dc0f6898f4802f4cf8",
    "title": "Calibrated Language Models Must Hallucinate",
    "year": 2023,
    "authors": "A. Kalai, S. Vempala",
    "abstract": "Recent language models generate false but plausible-sounding text with surprising frequency. Such “hallucinations” are an obstacle to the usability of language-based AI systems and can harm people who rely upon their outputs. This work shows that there is an inherent statistical lower-bound on the rate that pretrained language models hallucinate certain types of facts, having nothing to do with the transformer LM architecture or data quality. For “arbitrary” facts whose veracity cannot be determined from the training data, we show that hallucinations must occur at a certain rate for language models that satisfy a statistical calibration condition appropriate for generative language models. Specifically, if the maximum probability of any fact is bounded, we show that the probability of generating a hallucination is close to the fraction of facts that occur exactly once in the training data (a “Good-Turing” estimate), even assuming ideal training data without errors. One conclusion is that models pretrained to be sufficiently good predictors (i.e., calibrated) may require post-training to mitigate hallucinations on the type of arbitrary facts that tend to appear once in the training set. However, our analysis also suggests that there is no statistical reason that pretraining will lead to hallucination on facts that tend to appear more than once in the training data (like references to publications such as articles and books, whose hallucinations have been particularly notable and problematic) or on systematic facts (like arithmetic calculations). Therefore, different architectures and learning algorithms may mitigate these latter types of hallucinations.",
    "citationCount": 125,
    "pdf_filename": "2023_Calibrated_Language_Models_Must_Hallucin_1460d33f.pdf"
  },
  "f653569b131176dfed8842694b5ad2ead5e4b923": {
    "paperId": "f653569b131176dfed8842694b5ad2ead5e4b923",
    "title": "Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust",
    "year": 2023,
    "authors": "Yuxin Wen, John Kirchenbauer, Jonas Geiping, T. Goldstein",
    "abstract": "Watermarking the outputs of generative models is a crucial technique for tracing copyright and preventing potential harm from AI-generated content. In this paper, we introduce a novel technique called Tree-Ring Watermarking that robustly fingerprints diffusion model outputs. Unlike existing methods that perform post-hoc modifications to images after sampling, Tree-Ring Watermarking subtly influences the entire sampling process, resulting in a model fingerprint that is invisible to humans. The watermark embeds a pattern into the initial noise vector used for sampling. These patterns are structured in Fourier space so that they are invariant to convolutions, crops, dilations, flips, and rotations. After image generation, the watermark signal is detected by inverting the diffusion process to retrieve the noise vector, which is then checked for the embedded signal. We demonstrate that this technique can be easily applied to arbitrary diffusion models, including text-conditioned Stable Diffusion, as a plug-in with negligible loss in FID. Our watermark is semantically hidden in the image space and is far more robust than watermarking alternatives that are currently deployed. Code is available at https://github.com/YuxinWenRick/tree-ring-watermark.",
    "citationCount": 153,
    "pdf_filename": "2023_Tree_Ring_Watermarks__Fingerprints_for_D_f653569b.pdf"
  },
  "90a1843a2c1259708a6b11df7f6701ec0643e6ae": {
    "paperId": "90a1843a2c1259708a6b11df7f6701ec0643e6ae",
    "title": "Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness",
    "year": 2023,
    "authors": "Felix Friedrich, P. Schramowski, Manuel Brack, Lukas Struppek, Dominik Hintersdorf",
    "abstract": "Generative AI models have recently achieved astonishing results in quality and are consequently employed in a fast-growing number of applications. However, since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer from degenerated and biased human behavior, as we demonstrate. In fact, they may even reinforce such biases. To not only uncover but also combat these undesired effects, we present a novel strategy, called Fair Diffusion, to attenuate biases after the deployment of generative text-to-image models. Specifically, we demonstrate shifting a bias, based on human instructions, in any direction yielding arbitrarily new proportions for, e.g., identity groups. As our empirical evaluation demonstrates, this introduced control enables instructing generative image models on fairness, with no data filtering and additional training required.",
    "citationCount": 167,
    "pdf_filename": "2023_Fair_Diffusion__Instructing_Text_to_Imag_90a1843a.pdf"
  },
  "86312ea272f7a6f5e3b067c9aaa355a4f559f95e": {
    "paperId": "86312ea272f7a6f5e3b067c9aaa355a4f559f95e",
    "title": "Best humans still outperform artificial intelligence in a creative divergent thinking task",
    "year": 2023,
    "authors": "Mika Koivisto, Simone Grassini",
    "abstract": "Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n = 256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI.",
    "citationCount": 163,
    "pdf_filename": "2023_Best_humans_still_outperform_artificial__86312ea2.pdf"
  },
  "4973b3f6289b55548a9d65b30ae490fc4eae4811": {
    "paperId": "4973b3f6289b55548a9d65b30ae490fc4eae4811",
    "title": "Economics of ChatGPT: A Labor Market View on the Occupational Impact of Artificial Intelligence",
    "year": 2023,
    "authors": "Ali Zarifhonarvar",
    "abstract": "PurposeThe study investigates the influence of ChatGPT on the labor market dynamics, aiming to provide a structured understanding of the changes induced by generative AI technologies.Design/methodology/approachAn analysis of existing literature serves as the foundation for understanding the impact, while the supply and demand model helps assess the effects of ChatGPT. A text-mining approach is utilized to analyze the International Standard Occupation Classification, identifying occupations most susceptible to disruption by ChatGPT.FindingsThe study reveals that 32.8% of occupations could be fully impacted by ChatGPT, while 36.5% might experience a partial impact and 30.7% are likely to remain unaffected.Research limitations/implicationsWhile this study offers insights into the potential influence of ChatGPT and other generative AI services on the labor market, it is essential to note that these findings represent potential implications rather than realized labor market effects. Further research is needed to track actual changes in employment patterns and job market dynamics where these AI services are widely adopted.Originality/valueThis paper contributes to the field by systematically categorizing the level of impact on different occupations, providing a nuanced perspective on the short- and long-term implications of ChatGPT and similar generative AI services on the labor market.",
    "citationCount": 158,
    "pdf_filename": "2023_Economics_of_ChatGPT__A_Labor_Market_Vie_4973b3f6.pdf"
  },
  "5f8bf881c80125452e4a73ad51fdb2c72c65c551": {
    "paperId": "5f8bf881c80125452e4a73ad51fdb2c72c65c551",
    "title": "Cultural bias and cultural alignment of large language models",
    "year": 2023,
    "authors": "Yan Tao, Olga Viberg, Ryan S. Baker, René F. Kizilcec",
    "abstract": "Abstract Culture fundamentally shapes people’s reasoning, behavior, and communication. As people increasingly use generative artificial intelligence (AI) to expedite and automate personal and professional tasks, cultural values embedded in AI models may bias people’s authentic expression and contribute to the dominance of certain cultures. We conduct a disaggregated evaluation of cultural bias for five widely used large language models (OpenAI’s GPT-4o/4-turbo/4/3.5-turbo/3) by comparing the models’ responses to nationally representative survey data. All models exhibit cultural values resembling English-speaking and Protestant European countries. We test cultural prompting as a control strategy to increase cultural alignment for each country/territory. For later models (GPT-4, 4-turbo, 4o), this improves the cultural alignment of the models’ output for 71–81% of countries and territories. We suggest using cultural prompting and ongoing evaluation to reduce cultural bias in the output of generative AI.",
    "citationCount": 185,
    "pdf_filename": "2023_Cultural_bias_and_cultural_alignment_of__5f8bf881.pdf"
  },
  "39121b1ef28b731e5bf43fe6dd6c07dd33040f68": {
    "paperId": "39121b1ef28b731e5bf43fe6dd6c07dd33040f68",
    "title": "What drives students toward ChatGPT? An investigation of the factors influencing adoption and usage of ChatGPT",
    "year": 2023,
    "authors": "Chandan Kumar Tiwari, Mohd. Abass Bhat, S. Khan, Rajaswaminathan Subramaniam, Mohammad Atif Irshad Khan",
    "abstract": "\nPurpose\nThe purpose of this paper is to identify the factors determining students’ attitude toward using newly emerged artificial intelligence (AI) tool, Chat Generative Pre-Trained Transformer (ChatGPT), for educational and learning purpose based on technology acceptance model.\n\n\nDesign/methodology/approach\nThe recommended model was empirically tested with partial least squares structural equation modeling using 375 student survey responses.\n\n\nFindings\nThe study revealed that students have a favorable view of the instructional use of ChatGPT. Usefulness, social presence and legitimacy of the tool, as well as enjoyment and motivation, contribute to a favorable attitude toward using this tool in a learning environment. However, perceived ease of use was not found to be a significant determinant in the adoption and utilization of ChatGPT by the students.\n\n\nPractical implications\nThis research is intended to benefit enterprises, academic institutions and the global community by offering light on how students perceive the ChatGPT service in an educational setting. Furthermore, the application enhances confidence and interest among learners, leading to improved literacy and general awareness. Eventually, the outcome of this research will help AI developers to improve their product and service delivery, as well as benefit regulators in regulating the usage of AI-based bots.\n\n\nOriginality/value\nDue to its novelty, the current research on AI-based ChatGPT usage in the education sector is rather restricted. This study provides the adoption aspects of ChatGPT, a new AI-based technology for students, thereby contributing significantly to the existing research on the adoption of advanced education technologies. In addition, the literature lacks research on the adoption of ChatGPT by students for educational purposes; this study addresses this gap by identifying adoption determinants of ChatGPT in education.\n",
    "citationCount": 171,
    "pdf_filename": "2023_What_drives_students_toward_ChatGPT__An__39121b1e.pdf"
  },
  "39444c55f07839ac6a0d1839472a982f8fb447bb": {
    "paperId": "39444c55f07839ac6a0d1839472a982f8fb447bb",
    "title": "Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?",
    "year": 2023,
    "authors": "I. Alberts, L. Mercolli, T. Pyka, G. Prenosil, Kuangyu Shi",
    "abstract": "There has been substantial press recently regarding the impressive performance of large language models (LLM), particularly the OpenAI tool “Chat Generative Pre-Trained Transformer,” commonly known as “ChatGPT” [1]. LLM represent artificial intelligence (AI) tools based on multilayer recurrent neural networks that are trained on vast amounts of data to generate human-like text (https:// ai. googl eblog. com/ 2017/ 08/ trans formernovelneuralnetwo rk. html). Whereas traditional language models are programmed to use statistical techniques to predict the next word in a sentence, ChatGPT uses transformer-based models that allow for the processing of vast amounts of data in parallel. The result is a revolution in the ability of these models to understand and generate text. Their performance is remarkable, e.g., ChatGPT is capable of writing lines of code, producing plays, stories, poetry as well as simulated scientific content such as abstracts. While there has been much fanfare in the media regarding this undoubtedly impressive performance, there is much less information available about how this might affect the nuclear medicine community, or its reliability in producing nuclear medicine and molecular imaging-related content. It is currently unclear to what extent ChatGPT might help as a collaborative tool, for example correcting or helping to improve upon a researcher’s writing or as a tool for summarising nuclear medicine literature. Within seconds, ChatGPT is capable of producing convincing and grammatically fluent prose that is indistinguishable from content produced by human researchers. The threat that this poses to academic publishing models is already apparent [2]. Controversially, ChatGPT has (at the time of writing) already been listed as a co-author on four academic publications [3]. Anecdotally, students are already using the tool as a writing assistant, raising issues of academic integrity and plagiarism [4]. There are already 25 PubMed entries for “ChatGPT”, this will likely grow rapidly in the coming weeks and months. In response, a number of journals are already implementing editorial policies about the acceptability of AI-assisted writing or clarifying issues around authorship [3, 5]. Some internet fora have already banned ChatGPT-generated answers owing to their unreliability (https:// meta. stack overfl ow. com/ quest ions/ 421831/ tempo rarypolicychatg ptisbanned). Recent experience has shown that AI tools can be harnessed to mass-produce questionable content on social media networks or social media bots that can deliberately amplify misinformation [6]. This experience might portend the future of ChatGPT-generated academic content. A report from the Copenhagen-based Institute for Future Studies estimates that 99% of the internet could be produced by generative AI by 2025 (https:// cifs. dk/ news/ whatif99ofthemetav erseismadebyai). At present, ChatGPT is not capable of producing an entire research paper sua sponte, although it is predicted and indeed conceivable that this might soon be the case [7]. Nevertheless, it can already, even in the currently available beta version, produce a very convincing abstract [8]. We wonder whether conferences might soon be flooded with AI-generated abstracts or whether predatory publishers [9] might be catalysed by the ability of ChatGPT to churn out convincing but ultimately unreliable content. Even the review process could be influenced: there are already proposals to harness the ability of LLM to summarise text as a tool for the sifting out of low-quality studies submitted to a journal. Once can imagine a not-too distant future where AI might generate and review research [10], This article is part of the Topical Collection on Advanced Image Analyses (Radiomics and Artificial Intelligence)",
    "citationCount": 181,
    "pdf_filename": "2023_Large_language_models__LLM__and_ChatGPT__39444c55.pdf"
  },
  "3159478fbc81e562c812b9d5dc1891271b21f0c4": {
    "paperId": "3159478fbc81e562c812b9d5dc1891271b21f0c4",
    "title": "Prompt Engineering in Medical Education",
    "year": 2023,
    "authors": "Thomas F. Heston, Charya Khun",
    "abstract": "Artificial intelligence-powered generative language models (GLMs), such as ChatGPT, Perplexity AI, and Google Bard, have the potential to provide personalized learning, unlimited practice opportunities, and interactive engagement 24/7, with immediate feedback. However, to fully utilize GLMs, properly formulated instructions are essential. Prompt engineering is a systematic approach to effectively communicating with GLMs to achieve the desired results. Well-crafted prompts yield good responses from the GLM, while poorly constructed prompts will lead to unsatisfactory responses. Besides the challenges of prompt engineering, significant concerns are associated with using GLMs in medical education, including ensuring accuracy, mitigating bias, maintaining privacy, and avoiding excessive reliance on technology. Future directions involve developing more sophisticated prompt engineering techniques, integrating GLMs with other technologies, creating personalized learning pathways, and researching the effectiveness of GLMs in medical education.",
    "citationCount": 166,
    "pdf_filename": "2023_Prompt_Engineering_in_Medical_Education_3159478f.pdf"
  },
  "6487ec82f6d8082a5b402a5416ea03009acb1679": {
    "paperId": "6487ec82f6d8082a5b402a5416ea03009acb1679",
    "title": "State of the Art on Diffusion Models for Visual Computing",
    "year": 2023,
    "authors": "Ryan Po, Wang Yifan, Vladislav Golyanik, Kfir Aberman, J. Barron",
    "abstract": "The field of visual computing is rapidly advancing due to the emergence of generative artificial intelligence (AI), which unlocks unprecedented capabilities for the generation, editing, and reconstruction of images, videos, and 3D scenes. In these domains, diffusion models are the generative AI architecture of choice. Within the last year alone, the literature on diffusion‐based tools and applications has seen exponential growth and relevant papers are published across the computer graphics, computer vision, and AI communities with new works appearing daily on arXiv. This rapid growth of the field makes it difficult to keep up with all recent developments. The goal of this state‐of‐the‐art report (STAR) is to introduce the basic mathematical concepts of diffusion models, implementation details and design choices of the popular Stable Diffusion model, as well as overview important aspects of these generative AI tools, including personalization, conditioning, inversion, among others. Moreover, we give a comprehensive overview of the rapidly growing literature on diffusion‐based generation and editing, categorized by the type of generated medium, including 2D images, videos, 3D objects, locomotion, and 4D scenes. Finally, we discuss available datasets, metrics, open challenges, and social implications. This STAR provides an intuitive starting point to explore this exciting topic for researchers, artists, and practitioners alike.",
    "citationCount": 148,
    "pdf_filename": "2023_State_of_the_Art_on_Diffusion_Models_for_6487ec82.pdf"
  },
  "996be611b62c9bb9ef7d02e364f62660425d49a1": {
    "paperId": "996be611b62c9bb9ef7d02e364f62660425d49a1",
    "title": "The Impact of Multimodal Large Language Models on Health Care’s Future",
    "year": 2023,
    "authors": "B. Meskó",
    "abstract": "When large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode—text. As medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality—meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents—can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care’s future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care—empathy, understanding, and the doctor-patient relationship—when deploying AI.",
    "citationCount": 137,
    "pdf_filename": "2023_The_Impact_of_Multimodal_Large_Language__996be611.pdf"
  },
  "e64d60855db9691caea22e0ec21f35d060933801": {
    "paperId": "e64d60855db9691caea22e0ec21f35d060933801",
    "title": "Artificial intelligence in healthcare: Complementing, not replacing, doctors and healthcare providers",
    "year": 2023,
    "authors": "Emre Sezgin",
    "abstract": "The utilization of artificial intelligence (AI) in clinical practice has increased and is evidently contributing to improved diagnostic accuracy, optimized treatment planning, and improved patient outcomes. The rapid evolution of AI, especially generative AI and large language models (LLMs), have reignited the discussions about their potential impact on the healthcare industry, particularly regarding the role of healthcare providers. Concerning questions, “can AI replace doctors?” and “will doctors who are using AI replace those who are not using it?” have been echoed. To shed light on this debate, this article focuses on emphasizing the augmentative role of AI in healthcare, underlining that AI is aimed to complement, rather than replace, doctors and healthcare providers. The fundamental solution emerges with the human–AI collaboration, which combines the cognitive strengths of healthcare providers with the analytical capabilities of AI. A human-in-the-loop (HITL) approach ensures that the AI systems are guided, communicated, and supervised by human expertise, thereby maintaining safety and quality in healthcare services. Finally, the adoption can be forged further by the organizational process informed by the HITL approach to improve multidisciplinary teams in the loop. AI can create a paradigm shift in healthcare by complementing and enhancing the skills of healthcare providers, ultimately leading to improved service quality, patient outcomes, and a more efficient healthcare system.",
    "citationCount": 151,
    "pdf_filename": "2023_Artificial_intelligence_in_healthcare__C_e64d6085.pdf"
  },
  "f4b88a1a6a877cbeb9faaf99eccc5e1ed9f2ea6b": {
    "paperId": "f4b88a1a6a877cbeb9faaf99eccc5e1ed9f2ea6b",
    "title": "Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts",
    "year": 2023,
    "authors": "Zhi-Yi Chin, Chieh-Ming Jiang, Ching-Chun Huang, Pin-Yu Chen, Wei-Chen Chiu",
    "abstract": "Text-to-image diffusion models, e.g. Stable Diffusion (SD), lately have shown remarkable ability in high-quality content generation, and become one of the representatives for the recent wave of transformative AI. Nevertheless, such advance comes with an intensifying concern about the misuse of this generative technology, especially for producing copyrighted or NSFW (i.e. not safe for work) images. Although efforts have been made to filter inappropriate images/prompts or remove undesirable concepts/styles via model fine-tuning, the reliability of these safety mechanisms against diversified problematic prompts remains largely unexplored. In this work, we propose Prompting4Debugging (P4D) as a debugging and red-teaming tool that automatically finds problematic prompts for diffusion models to test the reliability of a deployed safety mechanism. We demonstrate the efficacy of our P4D tool in uncovering new vulnerabilities of SD models with safety mechanisms. Particularly, our result shows that around half of prompts in existing safe prompting benchmarks which were originally considered\"safe\"can actually be manipulated to bypass many deployed safety mechanisms, including concept removal, negative prompt, and safety guidance. Our findings suggest that, without comprehensive testing, the evaluations on limited safe prompting benchmarks can lead to a false sense of safety for text-to-image models.",
    "citationCount": 113,
    "pdf_filename": "2023_Prompting4Debugging__Red_Teaming_Text_to_f4b88a1a.pdf"
  },
  "1a61b1f46ef6afb58ee2ecb689c757f8ad2f84d0": {
    "paperId": "1a61b1f46ef6afb58ee2ecb689c757f8ad2f84d0",
    "title": "Disco: Disentangled Control for Realistic Human Dance Generation",
    "year": 2023,
    "authors": "Tan Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zhengyuan Yang",
    "abstract": "Generative AI has made significant strides in computer vision, particularly in text-driven image/video synthesis (T2I/T2V). Despite the notable advancements, it remains challenging in human-centric content synthesis such as realistic dance generation. Current methodologies, primarily tailored for human motion transfer, encounter difficulties when confronted with real-world dance scenarios (e.g., social media dance), which require to generalize across a wide spectrum of poses and intricate human details. In this paper, we depart from the traditional paradigm of human motion transfer and emphasize two additional critical attributes for the synthesis of human dance content in social media contexts: (i) Generalizability: the model should be able to generalize beyond generic human viewpoints as well as unseen human subjects, backgrounds, and poses; (ii) Compositionality: it should allow for the seamless composition of seen/unseen subjects, backgrounds, and poses from different sources. To address these challenges, we introduce Disco, which includes a novel model architecture with disentangled control to improve the compositionality of dance synthesis, and an effective human attribute pre-training for better generalizability to unseen humans. Extensive qualitative and quantitative results demonstrate that DISCO can generate high-quality human dance images and videos with diverse appearances and flexible motions. Code is available at https://disco-dance.github.io/.",
    "citationCount": 125,
    "pdf_filename": "2023_Disco__Disentangled_Control_for_Realisti_1a61b1f4.pdf"
  },
  "dc38ab7034c173027340a474977531a9ccfff2ec": {
    "paperId": "dc38ab7034c173027340a474977531a9ccfff2ec",
    "title": "Unveiling the ChatGPT phenomenon: Evaluating the consistency and accuracy of endodontic question answers.",
    "year": 2023,
    "authors": "Ana Suárez, Víctor Díaz-Flores García, Juan Algar, Margarita Gómez Sánchez, María Llorente de Pedro",
    "abstract": "AIM\nChatbot Generative Pre-trained Transformer (ChatGPT) is a generative artificial intelligence (AI) software based on large language models (LLMs), designed to simulate human conversations and generate novel content based on the training data it has been exposed to. The aim of this study was to evaluate the consistency and accuracy of ChatGPT-generated answers to clinical questions in endodontics, compared to answers provided by human experts.\n\n\nMETHODOLOGY\nNinety-one dichotomous (yes/no) questions were designed and categorized into three levels of difficulty. Twenty questions were randomly selected from each difficulty level. Sixty answers were generated by ChatGPT for each question. Two endodontic experts independently answered the 60 questions. Statistical analysis was performed using the SPSS program to calculate the consistency and accuracy of the answers generated by ChatGPT compared to the experts. Confidence intervals (95%) and standard deviations were used to estimate variability.\n\n\nRESULTS\nThe answers generated by ChatGPT showed high consistency (85.44%). No significant differences in consistency were found based on question difficulty. In terms of answer accuracy, ChatGPT achieved an average accuracy of 57.33%. However, significant differences in accuracy were observed based on question difficulty, with lower accuracy for easier questions.\n\n\nCONCLUSIONS\nCurrently, ChatGPT is not capable of replacing dentists in clinical decision-making. As ChatGPT's performance improves through deep learning, it is expected to become more useful and effective in the field of endodontics. However, careful attention and ongoing evaluation are needed to ensure its accuracy, reliability and safety in endodontics.",
    "citationCount": 131,
    "pdf_filename": "2023_Unveiling_the_ChatGPT_phenomenon__Evalua_dc38ab70.pdf"
  },
  "1c2a38413583c6836f11b88edebf65577e1450bd": {
    "paperId": "1c2a38413583c6836f11b88edebf65577e1450bd",
    "title": "Exploring the role of ChatGPT in patient care (diagnosis and treatment) and medical research: A systematic review",
    "year": 2023,
    "authors": "R. Garg, V. L. Urs, Akshya Anand Agrawal, S. Chaudhary, V. Paliwal",
    "abstract": "Background ChatGPT(Chat Generative Pre-trained Transformer) is an artificial intelligence (AI) based on a natural language processing tool developed by OpenAI (California, USA). This systematic review examines the potential of Chat GPT in diagnosing and treating patients and its contributions to medical research. Methods In order to locate articles on ChatGPT's use in clinical practise and medical research, this systematic review used PRISMA standards and conducted database searches across several sources. Selected records were analysed using ChatGPT, which also produced a summary for each article. The resultant word document was transformed to a PDF and handled using ChatPDF. The review looked at topics pertaining to scholarly publishing, clinical practise, and medical research. Results We reviewed 118 publications. There are difficulties and moral conundrums associated with using ChatGPT in therapeutic settings and medical research. Patient inquiries, note writing, decision-making, trial enrolment, data management, decision support, research support, and patient education are all things that ChatGPT can help with. However, the solutions it provides are frequently inadequate and inconsistent, presenting issues with its originality, privacy, accuracy, bias, and legality. When utilising ChatGPT for academic writings, there are issues with prejudice and plagiarism, and because it lacks human-like characteristics, its authority as an author is called into question. Conclusions ChatGPT has limitations when used in research and healthcare. Even while it aids in patient treatment, concerns regarding accuracy, authorship, and bias arise. Currently, ChatGPT can serve as a \"clinical assistant\" and be a huge assistance with research and scholarly writing.",
    "citationCount": 154,
    "pdf_filename": "2023_Exploring_the_role_of_ChatGPT_in_patient_1c2a3841.pdf"
  },
  "d92538d0c93daf4e642d951bdfdd5a5455d7cf6a": {
    "paperId": "d92538d0c93daf4e642d951bdfdd5a5455d7cf6a",
    "title": "ChatGPT: these are not hallucinations – they’re fabrications and falsifications",
    "year": 2023,
    "authors": "R. Emsley",
    "abstract": "The artificial intelligence (AI) system, Chat Generative Pre-trained Transformer (ChatGPT), is considered a promising, even revolutionary tool and its widespread use in health care education, research, and practice is predicted to be inevitable. Like so many others I was keen to test the capabilities of ChatGPT as an aid to scientific writing. An opportunity arose with a study I was planning on an existing dataset (structural MRI brain changes associated with antipsychotic treatment). After registering with OpenAI online, I provided basic information on the dataset and planned study and requested suggestions for the study methodology. These were promptly provided as broad stroke proposals about identifying a research question, hypotheses, suitable outcomes etc. The interaction felt eerily interpersonal and the chatbot’s demeanour was cordial and helpful, even eager. My questions relating to overall methodology produced mostly sensible suggestions, although largely predictable and somewhat mundane. I had difficulty in getting beyond the general responses that were provided for the statistical analysis plan. Specific questions were deflected with generalisations and recommendations to consult a statistician. At that stage I was unimpressed, but there were no concerns. However, after that the problems emerged. I asked which brain regions would be of particular interest in relation to antipsychotic treatment. The thalamus was an unexpected suggestion, so I requested supportive literature. Five references were duly supplied, including publications by established researchers in reputable journals. (These references are provided as Supplement 1). By this time my level of enthusiasm had risen considerably as new possibilities for the analysis emerged based on these heretofore undiscovered studies. My next step was to source these publications via PubMed. The first reference was to a well-known longitudinal study reporting brain changes over time but it was inappropriate, as it was not focussed on the thalamus. I was unable to trace three of the four remaining references, whether I searched by author names, manuscript title or journal details. Similarly, with Google Scholar I was not able to identify the articles. Entering the Digital Object Identifier (DOI) number in my searches took me to totally unrelated publications. Becoming increasingly uneasy, I questioned ChatGPT about previous studies whose content I was familiar with, including my own, as a test of accuracy. Some of the answers provided were patently incorrect. The problem therefore goes beyond just creating false references. It includes falsely reporting the content of genuine publications. Thus, while most attention to date has focussed on the production of false references as these are the easiest to detect, the veracity of any content inputs provided by ChatGPT cannot be trusted. The cause of these falsifications has been linked to a disturbance in language production, with probabilistic outputs based on estimates of semantic similarity. This allows informed guesses, with bits of false information being mixed with factual information. Alarmed, I assumed I had done something wrong. I instructed ChatGPT to check one of the incorrect references. I received an apology for the mistake and was provided with the “correct” reference. However, this one was also incorrect. And so too with the third attempt. On chatting to colleagues and checking the online literature it became apparent that my experience wasn’t unique and that the problem is widespread. One study investigating the frequency of so-called AI hallucinations in research proposals generated by ChatGPT found that out of 178 references cited, 69 did not have a DOI, 28 of which were found not to exist. Another study investigating the authenticity and accuracy of references in medical articles generated by ChatGPT found that of 115 references that were generated, 47% were fabricated, 46% were authentic but inaccurate, and only 7% were authentic and accurate. A further study assessing whether ChatGPT can reliably produce accurate references to supplement manual literature searches reported that of 35 generated citations, only two were real, 12 were similar to actual manuscripts and the remaining 21 were seemingly plausible but in fact a mix of multiple actual manuscripts. This is outrageous. While concerns and cautions have been expressed in the rapidly emerging literature, I would have expected a stronger response. How could the use of such a profoundly defective tool as this be permitted without public outcry and calls for prohibition of its further use in the research environment? The phenomenon has been charitably referred to as hallucinations. This is a misnomer. Hallucinations are false perceptions. What I experienced were fabrications and falsifications. The Office of Research Integrity of the United States Department of Health and Human Services defines fabrication as the making up data or results and falsification as the manipulation, changing or omitting of data or results such that the research is not accurately represented (https://ori.hhs.gov/definition-research-misconduct). Or, if the absence of malicious intent is assumed, confabulations would be a better description, as has been proposed. In any event, the potential consequences are dire. The risk is compounded firstly by the believability of the falsifications, even deceiving established scientists, and secondly by its tendency to “double down” convincingly when confronted with these inaccuracies. My sobering experience spurred me to write this editorial, to alert others to the dangers. And of course, who better to assist than ChatGPT? My request was: “Write an editorial of 2000 words with references for a scientific journal on schizophrenia about using ChatGPT in research. It should be interesting and controversial, highlighting the pros and cons of its use.” The first response ignored my request for references, so I asked: “Include up to 6 references.” A list of 6 references was provided but not cited in the text. I asked: “Cite these references in the text” The references were again provided but not the citations in the text. I asked: “re-write the editorial citing the references in the appropriate places in the text”. This was provided, but this time the reference list was incomplete. There seemed to be a decided reluctance to perform the task, perhaps because of our previous interaction regarding false references. I asked: “Why did you not complete the reference list?” the response: “I apologize for the incomplete reference list in the previous response. Here is the complete reference list for the editorial.” And again, “I apologize for any inconvenience caused by the initial incomplete reference list.” The ChatGPT generated editorial, together with citations and references are provided as Supplement 2. Predictably, fact",
    "citationCount": 151,
    "pdf_filename": "2023_ChatGPT__these_are_not_hallucinations____d92538d0.pdf"
  },
  "5dcd4581c979bc97b165a1e2d55cc434d9136351": {
    "paperId": "5dcd4581c979bc97b165a1e2d55cc434d9136351",
    "title": "Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses",
    "year": 2023,
    "authors": "Jaromir Savelka, Arav Agarwal, Marshall An, C. Bogart, M. Sakr",
    "abstract": "This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.",
    "citationCount": 128,
    "pdf_filename": "2023_Thrilled_by_Your_Progress__Large_Languag_5dcd4581.pdf"
  },
  "cf3522700d89af9dabfbad44c509a0fed2bde517": {
    "paperId": "cf3522700d89af9dabfbad44c509a0fed2bde517",
    "title": "Human-like problem-solving abilities in large language models using ChatGPT",
    "year": 2023,
    "authors": "G. Orrú, Andrea Piarulli, C. Conversano, A. Gemignani",
    "abstract": "Backgrounds The field of Artificial Intelligence (AI) has seen a major shift in recent years due to the development of new Machine Learning (ML) models such as Generative Pre-trained Transformer (GPT). GPT has achieved previously unheard-of levels of accuracy in most computerized language processing tasks and their chat-based variations. Aim The aim of this study was to investigate the problem-solving abilities of ChatGPT using two sets of verbal insight problems, with a known performance level established by a sample of human participants. Materials and methods A total of 30 problems labeled as “practice problems” and “transfer problems” were administered to ChatGPT. ChatGPT's answers received a score of “0” for each incorrectly answered problem and a score of “1” for each correct response. The highest possible score for both the practice and transfer problems was 15 out of 15. The solution rate for each problem (based on a sample of 20 subjects) was used to assess and compare the performance of ChatGPT with that of human subjects. Results The study highlighted that ChatGPT can be trained in out-of-the-box thinking and demonstrated potential in solving verbal insight problems. The global performance of ChatGPT equalled the most probable outcome for the human sample in both practice problems and transfer problems as well as upon their combination. Additionally, ChatGPT answer combinations were among the 5% of most probable outcomes for the human sample both when considering practice problems and pooled problem sets. These findings demonstrate that ChatGPT performance on both set of problems was in line with the mean rate of success of human subjects, indicating that it performed reasonably well. Conclusions The use of transformer architecture and self-attention in ChatGPT may have helped to prioritize inputs while predicting, contributing to its potential in verbal insight problem-solving. ChatGPT has shown potential in solving insight problems, thus highlighting the importance of incorporating AI into psychological research. However, it is acknowledged that there are still open challenges. Indeed, further research is required to fully understand AI's capabilities and limitations in verbal problem-solving.",
    "citationCount": 137,
    "pdf_filename": "2023_Human_like_problem_solving_abilities_in__cf352270.pdf"
  },
  "cf0431d680b75301506fce8e00aa872034bf0dd6": {
    "paperId": "cf0431d680b75301506fce8e00aa872034bf0dd6",
    "title": "Artificial Intelligence & Creativity: A Manifesto for Collaboration",
    "year": 2023,
    "authors": "Florent Vinchon, T. Lubart, S. Bartolotta, Valentin Gironnay, Marion Botella",
    "abstract": "With the advent of artiﬁcial intelligence (AI), the ﬁeld of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human – machine collaboration on creative tasks and proposes “fundamental laws of generative AI” to reinforce the responsible and ethical use of AI in the creativity ﬁeld. Four scenarios are proposed and discussed: “Co-Cre-AI-tion,” “Organic,” “Plagiarism 3.0,” and “Shut down,” each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI-generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlighted to ensure responsible use of AIs. The positive future of creativity and AI lies in a harmonious collaboration that can beneﬁt everyone, potentially leading to a new level of creative productivity respecting ethical considerations and human values during the creative process.",
    "citationCount": 128,
    "pdf_filename": "2023_Artificial_Intelligence___Creativity__A__cf0431d6.pdf"
  },
  "505a9c24e58b4510bd6e553c87179b9b5953e82f": {
    "paperId": "505a9c24e58b4510bd6e553c87179b9b5953e82f",
    "title": "Let's have a chat! A Conversation with ChatGPT: Technology, Applications, and Limitations",
    "year": 2023,
    "authors": "Sakib Shahriar, Kadhim Hayawi",
    "abstract": "The advent of AI-empowered chatbots capable of constructing human-like sentences and articulating cohesive essays has captivated global interest. This paper provides a historical perspective on chatbots, focusing on the technology underpinning the Chat Generative Pre-trained Transformer, better known as ChatGPT. We underscore the potential utility of ChatGPT across a multitude of fields, including healthcare, education, and research. To the best of our knowledge, this is the first review that not only highlights the applications of ChatGPT in multiple domains, but also analyzes its performance on examinations across various disciplines. Despite its promising capabilities, ChatGPT raises numerous ethical and privacy concerns that are meticulously explored in this paper. Acknowledging the current limitations of ChatGPT is crucial in understanding its potential for growth. We also ask ChatGPT to provide its point of view and present its responses to several questions we attempt to answer.",
    "citationCount": 128,
    "pdf_filename": "2023_Let_s_have_a_chat__A_Conversation_with_C_505a9c24.pdf"
  },
  "7fe4667dbe9edd488c8ae88842044ba27c93e654": {
    "paperId": "7fe4667dbe9edd488c8ae88842044ba27c93e654",
    "title": "Artificial intelligence and increasing misinformation",
    "year": 2023,
    "authors": "S. Monteith, T. Glenn, John R. Geddes, P. Whybrow, Eric Achtyes",
    "abstract": "Summary With the recent advances in artificial intelligence (AI), patients are increasingly exposed to misleading medical information. Generative AI models, including large language models such as ChatGPT, create and modify text, images, audio and video information based on training data. Commercial use of generative AI is expanding rapidly and the public will routinely receive messages created by generative AI. However, generative AI models may be unreliable, routinely make errors and widely spread misinformation. Misinformation created by generative AI about mental illness may include factual errors, nonsense, fabricated sources and dangerous advice. Psychiatrists need to recognise that patients may receive misinformation online, including about medicine and psychiatry.",
    "citationCount": 128,
    "pdf_filename": "2023_Artificial_intelligence_and_increasing_m_7fe4667d.pdf"
  },
  "80c44fab16852ea9599411da14de7079c4514172": {
    "paperId": "80c44fab16852ea9599411da14de7079c4514172",
    "title": "Vision-Language Models in Remote Sensing: Current progress and future trends",
    "year": 2023,
    "authors": "Congcong Wen, Yuan Hu, Xiang Li, Zhenghang Yuan, Xiao Xiang Zhu",
    "abstract": "The remarkable achievements of ChatGPT and Generative Pre-trained Transformer 4 (GPT-4) have sparked a wave of interest and research in the field of large language models (LLMs) for artificial general intelligence (AGI). These models provide intelligent solutions that are closer to human thinking, enabling us to use general artificial intelligence (AI) to solve problems in various applications. However, in the field of remote sensing (RS), the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research in RS focuses primarily on visual-understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-LMs (VLMs) excel as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. VLMs can go beyond visual recognition of RS images and can model semantic relationships as well as generate natural language descriptions of the image. This makes them better suited for tasks that require both visual and textual understanding, such as image captioning and visual question answering (VQA). This article provides a comprehensive review of the research on VLMs in RS, summarizing the latest progress, highlighting current challenges, and identifying potential research opportunities. Specifically, we review the application of VLMs in mainstream RS tasks, including image captioning, text-based image generation, text-based image retrieval (TBIR), VQA, scene classification, semantic segmentation, and object detection. For each task, we analyze representative works and discuss research progress. Finally, we summarize the limitations of existing works and provide possible directions for future development. This review aims to provide a comprehensive overview of the current research progress of VLMs in RS (see Figure 1), and to inspire further research in this exciting and promising field.",
    "citationCount": 139,
    "pdf_filename": "2023_Vision_Language_Models_in_Remote_Sensing_80c44fab.pdf"
  },
  "2b7bd0491c31407342aa85c82163ede304d0e850": {
    "paperId": "2b7bd0491c31407342aa85c82163ede304d0e850",
    "title": "“HOT” ChatGPT: The Promise of ChatGPT in Detecting and Discriminating Hateful, Offensive, and Toxic Comments on Social Media",
    "year": 2023,
    "authors": "Lingyao Li, Lizhou Fan, Shubham Atreja, Libby Hemphill",
    "abstract": "Harmful textual content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to this issue is developing detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful textual content. We used ChatGPT to investigate this potential and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful textual content on social media: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared to human annotations. Our findings also suggest that ChatGPT classifications align with the provided HOT definitions. However, ChatGPT classifies “hateful” and “offensive” as subsets of “toxic.” Moreover, the choice of prompts used to interact with ChatGPT impacts its performance. Based on these insights, our study provides several meaningful implications for employing ChatGPT to detect HOT content, particularly regarding the reliability and consistency of its performance, its understanding and reasoning of the HOT concept, and the impact of prompts on its performance. Overall, our study provides guidance on the potential of using generative AI models for moderating large volumes of user-generated textual content on social media.",
    "citationCount": 122,
    "pdf_filename": "2023__HOT__ChatGPT__The_Promise_of_ChatGPT_in_2b7bd049.pdf"
  },
  "c206c5d82aaf3636e9d2820c62d27154a76d0519": {
    "paperId": "c206c5d82aaf3636e9d2820c62d27154a76d0519",
    "title": "Comparison of ChatGPT–3.5, ChatGPT-4, and Orthopaedic Resident Performance on Orthopaedic Assessment Examinations",
    "year": 2023,
    "authors": "P. Massey, Carver Montgomery, Andrew S Zhang",
    "abstract": "Introduction: Artificial intelligence (AI) programs have the ability to answer complex queries including medical profession examination questions. The purpose of this study was to compare the performance of orthopaedic residents (ortho residents) against Chat Generative Pretrained Transformer (ChatGPT)-3.5 and GPT-4 on orthopaedic assessment examinations. A secondary objective was to perform a subgroup analysis comparing the performance of each group on questions that included image interpretation versus text-only questions. Methods: The ResStudy orthopaedic examination question bank was used as the primary source of questions. One hundred eighty questions and answer choices from nine different orthopaedic subspecialties were directly input into ChatGPT-3.5 and then GPT-4. ChatGPT did not have consistently available image interpretation, so no images were directly provided to either AI format. Answers were recorded as correct versus incorrect by the chatbot, and resident performance was recorded based on user data provided by ResStudy. Results: Overall, ChatGPT-3.5, GPT-4, and ortho residents scored 29.4%, 47.2%, and 74.2%, respectively. There was a difference among the three groups in testing success, with ortho residents scoring higher than ChatGPT-3.5 and GPT-4 (P < 0.001 and P < 0.001). GPT-4 scored higher than ChatGPT-3.5 (P = 0.002). A subgroup analysis was performed by dividing questions into question stems without images and question stems with images. ChatGPT-3.5 was more correct (37.8% vs. 22.4%, respectively, OR = 2.1, P = 0.033) and ChatGPT-4 was also more correct (61.0% vs. 35.7%, OR = 2.8, P < 0.001), when comparing text-only questions versus questions with images. Residents were 72.6% versus 75.5% correct with text-only questions versus questions with images, with no significant difference (P = 0.302). Conclusion: Orthopaedic residents were able to answer more questions accurately than ChatGPT-3.5 and GPT-4 on orthopaedic assessment examinations. GPT-4 is superior to ChatGPT-3.5 for answering orthopaedic resident assessment examination questions. Both ChatGPT-3.5 and GPT-4 performed better on text-only questions than questions with images. It is unlikely that GPT-4 or ChatGPT-3.5 would pass the American Board of Orthopaedic Surgery written examination.",
    "citationCount": 122,
    "pdf_filename": "2023_Comparison_of_ChatGPT_3_5__ChatGPT_4__an_c206c5d8.pdf"
  },
  "3c2c924b788ef620b9e4a0fdf789a12a5bde5129": {
    "paperId": "3c2c924b788ef620b9e4a0fdf789a12a5bde5129",
    "title": "ChatGPT in education: a discourse analysis of worries and concerns on social media",
    "year": 2023,
    "authors": "Lingyao Li, Zihui Ma, Lizhou Fan, Sanggyu Lee, Huizi Yu",
    "abstract": "The rapid advancements in generative AI models present new opportunities in the education sector. However, it is imperative to acknowledge and address the potential risks and concerns that may arise with their use. We analyzed Twitter data to identify critical concerns related to the use of ChatGPT in education. We employed BERT-based topic modeling to conduct a discourse analysis and social network analysis to identify influential users in the conversation. While Twitter users generally expressed a positive attitude toward using ChatGPT, their concerns converged into five categories: academic integrity, impact on learning outcomes and skill development, limitation of capabilities, policy and social concerns, and workforce challenges. We also found that users from the tech, education, and media fields were often implicated in the conversation, while education and tech individual users led the discussion of concerns. Based on these findings, the study provides several implications for policymakers, tech companies and individuals, educators, and media agencies. In summary, our study underscores the importance of responsible and ethical use of AI in education and highlights the need for collaboration among stakeholders to regulate AI policy.",
    "citationCount": 115,
    "pdf_filename": "2023_ChatGPT_in_education__a_discourse_analys_3c2c924b.pdf"
  },
  "f6d60ef6317a9f6de13e03b38c5c9bb8e6717d49": {
    "paperId": "f6d60ef6317a9f6de13e03b38c5c9bb8e6717d49",
    "title": "ChatGPT: More Than a “Weapon of Mass Deception” Ethical Challenges and Responses from the Human-Centered Artificial Intelligence (HCAI) Perspective",
    "year": 2023,
    "authors": "A. Sison, Marco Tulio Daza, Roberto Gozalo-Brizuela, E.C. Garrido-Merchán",
    "abstract": "Abstract This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a “grand challenge,” thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a “weapon of mass deception” (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparency, educator considerations, HITL) to mitigate ChatGPT misuse or abuse and recommend best uses (creative writing, non-creative writing, teaching and learning). We conclude with considerations regarding the role of hu mans in ensuring the proper use of ChatGPT for individual and social wellbeing.",
    "citationCount": 119,
    "pdf_filename": "2023_ChatGPT__More_Than_a__Weapon_of_Mass_Dec_f6d60ef6.pdf"
  },
  "c886d0e3bffa478bf5e01f2b9f4231d1d5e3fbd0": {
    "paperId": "c886d0e3bffa478bf5e01f2b9f4231d1d5e3fbd0",
    "title": "How ChatGPT Will Change Software Engineering Education",
    "year": 2023,
    "authors": "Marian Daun, Jennifer Brings",
    "abstract": "This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.",
    "citationCount": 114,
    "pdf_filename": "2023_How_ChatGPT_Will_Change_Software_Enginee_c886d0e3.pdf"
  },
  "9d78505dd333b4bc77b75b65313ab9f96bcfe198": {
    "paperId": "9d78505dd333b4bc77b75b65313ab9f96bcfe198",
    "title": "Microscaling Data Formats for Deep Learning",
    "year": 2023,
    "authors": "B. Rouhani, Ritchie Zhao, Ankit More, Mathew Hall, Alireza Khodamoradi",
    "abstract": "Narrow bit-width data formats are key to reducing the computational and storage costs of modern deep learning applications. This paper evaluates Microscaling (MX) data formats that combine a per-block scaling factor with narrow floating-point and integer types for individual elements. MX formats balance the competing needs of hardware efficiency, model accuracy, and user friction. Empirical results on over two dozen benchmarks demonstrate practicality of MX data formats as a drop-in replacement for baseline FP32 for AI inference and training with low user friction. We also show the first instance of training generative language models at sub-8-bit weights, activations, and gradients with minimal accuracy loss and no modifications to the training recipe.",
    "citationCount": 107,
    "pdf_filename": "2023_Microscaling_Data_Formats_for_Deep_Learn_9d78505d.pdf"
  },
  "ac1788e9a168a6455beb6316f316950842297c11": {
    "paperId": "ac1788e9a168a6455beb6316f316950842297c11",
    "title": "Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities",
    "year": 2023,
    "authors": "Maximilian Mozes, Xuanli He, Bennett Kleinberg, L. D. Griffin",
    "abstract": "Spurred by the recent rapid increase in the development and distribution of large language models (LLMs) across industry and academia, much recent work has drawn attention to safety- and security-related threats and vulnerabilities of LLMs, including in the context of potentially criminal activities. Specifically, it has been shown that LLMs can be misused for fraud, impersonation, and the generation of malware; while other authors have considered the more general problem of AI alignment. It is important that developers and practitioners alike are aware of security-related problems with such models. In this paper, we provide an overview of existing - predominantly scientific - efforts on identifying and mitigating threats and vulnerabilities arising from LLMs. We present a taxonomy describing the relationship between threats caused by the generative capabilities of LLMs, prevention measures intended to address such threats, and vulnerabilities arising from imperfect prevention measures. With our work, we hope to raise awareness of the limitations of LLMs in light of such security concerns, among both experienced developers and novel users of such technologies.",
    "citationCount": 103,
    "pdf_filename": "2023_Use_of_LLMs_for_Illicit_Purposes__Threat_ac1788e9.pdf"
  },
  "c95447af60932779604bb7315c4cef3cbb8bd732": {
    "paperId": "c95447af60932779604bb7315c4cef3cbb8bd732",
    "title": "Can Artificial Intelligence Pass the American Board of Orthopaedic Surgery Examination? Orthopaedic Residents Versus ChatGPT",
    "year": 2023,
    "authors": "Zachary C Lum",
    "abstract": "Abstract Background Advances in neural networks, deep learning, and artificial intelligence (AI) have progressed recently. Previous deep learning AI has been structured around domain-specific areas that are trained on dataset-specific areas of interest that yield high accuracy and precision. A new AI model using large language models (LLM) and nonspecific domain areas, ChatGPT (OpenAI), has gained attention. Although AI has demonstrated proficiency in managing vast amounts of data, implementation of that knowledge remains a challenge. Questions/purposes (1) What percentage of Orthopaedic In-Training Examination questions can a generative, pretrained transformer chatbot (ChatGPT) answer correctly? (2) How does that percentage compare with results achieved by orthopaedic residents of different levels, and if scoring lower than the 10th percentile relative to 5th-year residents is likely to correspond to a failing American Board of Orthopaedic Surgery score, is this LLM likely to pass the orthopaedic surgery written boards? (3) Does increasing question taxonomy affect the LLM’s ability to select the correct answer choices? Methods This study randomly selected 400 of 3840 publicly available questions based on the Orthopaedic In-Training Examination and compared the mean score with that of residents who took the test over a 5-year period. Questions with figures, diagrams, or charts were excluded, including five questions the LLM could not provide an answer for, resulting in 207 questions administered with raw score recorded. The LLM’s answer results were compared with the Orthopaedic In-Training Examination ranking of orthopaedic surgery residents. Based on the findings of an earlier study, a pass-fail cutoff was set at the 10th percentile. Questions answered were then categorized based on the Buckwalter taxonomy of recall, which deals with increasingly complex levels of interpretation and application of knowledge; comparison was made of the LLM’s performance across taxonomic levels and was analyzed using a chi-square test. Results ChatGPT selected the correct answer 47% (97 of 207) of the time, and 53% (110 of 207) of the time it answered incorrectly. Based on prior Orthopaedic In-Training Examination testing, the LLM scored in the 40th percentile for postgraduate year (PGY) 1s, the eighth percentile for PGY2s, and the first percentile for PGY3s, PGY4s, and PGY5s; based on the latter finding (and using a predefined cutoff of the 10th percentile of PGY5s as the threshold for a passing score), it seems unlikely that the LLM would pass the written board examination. The LLM’s performance decreased as question taxonomy level increased (it answered 54% [54 of 101] of Tax 1 questions correctly, 51% [18 of 35] of Tax 2 questions correctly, and 34% [24 of 71] of Tax 3 questions correctly; p = 0.034). Conclusion Although this general-domain LLM has a low likelihood of passing the orthopaedic surgery board examination, testing performance and knowledge are comparable to that of a first-year orthopaedic surgery resident. The LLM's ability to provide accurate answers declines with increasing question taxonomy and complexity, indicating a deficiency in implementing knowledge. Clinical Relevance Current AI appears to perform better at knowledge and interpretation-based inquires, and based on this study and other areas of opportunity, it may become an additional tool for orthopaedic learning and education.",
    "citationCount": 103,
    "pdf_filename": "2023_Can_Artificial_Intelligence_Pass_the_Ame_c95447af.pdf"
  },
  "e191380320f6514e1a1e065d967455670c187c06": {
    "paperId": "e191380320f6514e1a1e065d967455670c187c06",
    "title": "Artificial Intelligence in Ophthalmology: A Comparative Analysis of GPT-3.5, GPT-4, and Human Expertise in Answering StatPearls Questions",
    "year": 2023,
    "authors": "M. Moshirfar, Amal W Altaf, Isabella M. Stoakes, Jared J Tuttle, P. Hoopes",
    "abstract": "Importance Chat Generative Pre-Trained Transformer (ChatGPT) has shown promising performance in various fields, including medicine, business, and law, but its accuracy in specialty-specific medical questions, particularly in ophthalmology, is still uncertain. Purpose This study evaluates the performance of two ChatGPT models (GPT-3.5 and GPT-4) and human professionals in answering ophthalmology questions from the StatPearls question bank, assessing their outcomes, and providing insights into the integration of artificial intelligence (AI) technology in ophthalmology. Methods ChatGPT's performance was evaluated using 467 ophthalmology questions from the StatPearls question bank. These questions were stratified into 11 subcategories, four difficulty levels, and three generalized anatomical categories. The answer accuracy of GPT-3.5, GPT-4, and human participants was assessed. Statistical analysis was conducted via the Kolmogorov-Smirnov test for normality, one-way analysis of variance (ANOVA) for the statistical significance of GPT-3 versus GPT-4 versus human performance, and repeated unpaired two-sample t-tests to compare the means of two groups. Results GPT-4 outperformed both GPT-3.5 and human professionals on ophthalmology StatPearls questions, except in the \"Lens and Cataract\" category. The performance differences were statistically significant overall, with GPT-4 achieving higher accuracy (73.2%) compared to GPT-3.5 (55.5%, p-value < 0.001) and humans (58.3%, p-value < 0.001). There were variations in performance across difficulty levels (rated one to four), but GPT-4 consistently performed better than both GPT-3.5 and humans on level-two, -three, and -four questions. On questions of level-four difficulty, human performance significantly exceeded that of GPT-3.5 (p = 0.008). Conclusion The study's findings demonstrate GPT-4's significant performance improvements over GPT-3.5 and human professionals on StatPearls ophthalmology questions. Our results highlight the potential of advanced conversational AI systems to be utilized as important tools in the education and practice of medicine.",
    "citationCount": 110,
    "pdf_filename": "2023_Artificial_Intelligence_in_Ophthalmology_e1913803.pdf"
  },
  "0900126a594d07ac519299b559b21b73d2e4ee5a": {
    "paperId": "0900126a594d07ac519299b559b21b73d2e4ee5a",
    "title": "Artificial Intelligence for Drug Discovery: Are We There Yet?",
    "year": 2023,
    "authors": "C. Hasselgren, Tudor I. Oprea",
    "abstract": "Drug discovery is adapting to novel technologies such as data science, informatics, and artificial intelligence (AI) to accelerate effective treatment development while reducing costs and animal experiments. AI is transforming drug discovery, as indicated by increasing interest from investors, industrial and academic scientists, and legislators. Successful drug discovery requires optimizing properties related to pharmacodynamics, pharmacokinetics, and clinical outcomes. This review discusses the use of AI in the three pillars of drug discovery: diseases, targets, and therapeutic modalities, with a focus on small-molecule drugs. AI technologies, such as generative chemistry, machine learning, and multiproperty optimization, have enabled several compounds to enter clinical trials. The scientific community must carefully vet known information to address the reproducibility crisis. The full potential of AI in drug discovery can only be realized with sufficient ground truth and appropriate human intervention at later pipeline stages. Expected final online publication date for the Annual Review of Pharmacology and Toxicology, Volume 64 is January 2024. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",
    "citationCount": 113,
    "pdf_filename": "2023_Artificial_Intelligence_for_Drug_Discove_0900126a.pdf"
  },
  "b155b933ab9b62b0f3da3018e545decbe546273f": {
    "paperId": "b155b933ab9b62b0f3da3018e545decbe546273f",
    "title": "The impact of ChatGPT on blended learning: Current trends and future research directions",
    "year": 2023,
    "authors": "Ali Alshahrani",
    "abstract": "Designing sustainable and scalable educational systems is a challenge. Artificial Intelligence (AI) offers promising solutions to enhance the effectiveness and sustainability of blended learning systems. This research paper focuses on the integration of the Chat Generative Pre-trained Transformer (ChatGPT), with a blended learning system. The objectives of this study are to investigate the potential of AI techniques in enhancing the sustainability of educational systems, explore the use of ChatGPT to personalize the learning experience and improve engagement, and propose a model for sustainable learning that incorporates AI. The study aims to contribute to the body of knowledge on AI applications for sustainable education, identify best practices for integrating AI in education, and provide insights for policymakers and educators on the benefits of AI in education delivery. The study emphasizes the significance of AI in sustainable education by addressing personalized learning and educational accessibility. By automating administrative tasks and optimizing content delivery, AI can enhance educational accessibility and promote inclusive and equitable education. The study’s findings highlight the potential benefits of integrating AI chatbots like ChatGPT into education. Such benefits include promoting student engagement, motivation, and self-directed learning through immediate feedback and assistance. The research provides valuable guidance for educators, policymakers, and instructional designers who seek to effectively leverage AI technology in education. In conclusion, the study recommends directions for future research in order to maximize the benefits of integrating ChatGPT into learning systems. Positive results have been observed, including improved learning outcomes, enhanced student engagement, and personalized learning experiences. Through advancing the utilization of AI tools like ChatGPT, blended learning systems can be made more sustainable, efficient, and accessible for learners worldwide.",
    "citationCount": 106,
    "pdf_filename": "2023_The_impact_of_ChatGPT_on_blended_learnin_b155b933.pdf"
  },
  "f5d9175a8ea7eecb2622b254714f33e5eed0ad17": {
    "paperId": "f5d9175a8ea7eecb2622b254714f33e5eed0ad17",
    "title": "Artificial Intelligence and Ten Societal Megatrends: An Exploratory Study Using GPT-3",
    "year": 2023,
    "authors": "D. Haluza, David Jungwirth",
    "abstract": "This paper examines the potential of artificial intelligence (AI) to address societal megatrends, with a specific focus on OpenAI’s Generative Pre-Trained Transformer 3 (GPT-3). To do this, we conducted an analysis using GPT-3 in order to explore the benefits of AI for digitalization, urbanization, globalization, climate change, automation and mobility, global health issues, and the aging population. We also looked at emerging markets as well as sustainability in this study. Interaction with GPT-3 was conducted solely through prompt questions, and generated responses were analyzed. Our results indicate that AI can significantly improve our understanding of these megatrends by providing insights into how they develop over time and which solutions could be implemented. Further research is needed to determine how effective AI will be in addressing them successfully, but initial findings are encouraging. Our discussion focuses on the implications of our findings for society going forward and suggests that further investigation should be conducted into how best to utilize new technologies such as GPT-3 when tackling these challenges. Lastly, we conclude that, while there is still much work left to do before any tangible effects can be seen from utilizing AI tools such as GPT-3 on societal megatrends, early indications suggest it may have a positive impact if used correctly.",
    "citationCount": 111,
    "pdf_filename": "2023_Artificial_Intelligence_and_Ten_Societal_f5d9175a.pdf"
  },
  "0207eb299dd3a872bea886609278a742e9f5571d": {
    "paperId": "0207eb299dd3a872bea886609278a742e9f5571d",
    "title": "Synthetic Data for Face Recognition: Current State and Future Prospects",
    "year": 2023,
    "authors": "Fadi Boutros, V. Štruc, Julian Fierrez, Naser Damer",
    "abstract": "Over the past years, deep learning capabilities and the availability of large-scale training datasets advanced rapidly, leading to breakthroughs in face recognition accuracy. However, these technologies are foreseen to face a major challenge in the next years due to the legal and ethical concerns about using authentic biometric data in AI model training and evaluation along with increasingly utilizing data-hungry state-of-the-art deep learning models. With the recent advances in deep generative models and their success in generating realistic and high-resolution synthetic image data, privacy-friendly synthetic data has been recently proposed as an alternative to privacy-sensitive authentic data to overcome the challenges of using authentic data in face recognition development. This work aims at providing a clear and structured picture of the use-cases taxonomy of synthetic face data in face recognition along with the recent emerging advances of face recognition models developed on the bases of synthetic data. We also discuss the challenges facing the use of synthetic data in face recognition development and several future prospects of synthetic data in the domain of face recognition.",
    "citationCount": 108,
    "pdf_filename": "2023_Synthetic_Data_for_Face_Recognition__Cur_0207eb29.pdf"
  },
  "77fa06b12aea62f13c91d8dc666c7ef2b26662ff": {
    "paperId": "77fa06b12aea62f13c91d8dc666c7ef2b26662ff",
    "title": "A Recipe for Watermarking Diffusion Models",
    "year": 2023,
    "authors": "Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Ngai-Man Cheung",
    "abstract": "Diffusion models (DMs) have demonstrated advantageous potential on generative tasks. Widespread interest exists in incorporating DMs into downstream applications, such as producing or editing photorealistic images. However, practical deployment and unprecedented power of DMs raise legal issues, including copyright protection and monitoring of generated content. In this regard, watermarking has been a proven solution for copyright protection and content monitoring, but it is underexplored in the DMs literature. Specifically, DMs generate samples from longer tracks and may have newly designed multimodal structures, necessitating the modification of conventional watermarking pipelines. To this end, we conduct comprehensive analyses and derive a recipe for efficiently watermarking state-of-the-art DMs (e.g., Stable Diffusion), via training from scratch or finetuning. Our recipe is straightforward but involves empirically ablated implementation details, providing a foundation for future research on watermarking DMs. The code is available at https://github.com/yunqing-me/WatermarkDM.",
    "citationCount": 144,
    "pdf_filename": "2023_A_Recipe_for_Watermarking_Diffusion_Mode_77fa06b1.pdf"
  },
  "afe4ee7ba225d8965cd96056b3e1e76a31451a75": {
    "paperId": "afe4ee7ba225d8965cd96056b3e1e76a31451a75",
    "title": "PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation",
    "year": 2023,
    "authors": "Yingchaojie Feng, Xingbo Wang, Kamkwai Wong, Sijia Wang, Yuhong Lu",
    "abstract": "Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model.",
    "citationCount": 123,
    "pdf_filename": "2023_PromptMagician__Interactive_Prompt_Engin_afe4ee7b.pdf"
  },
  "4d20147c8d20538d977f693e4974a0a9c91f5879": {
    "paperId": "4d20147c8d20538d977f693e4974a0a9c91f5879",
    "title": "Adversarial Texture for Fooling Person Detectors in the Physical World",
    "year": 2022,
    "authors": "Zhan Hu, Siyuan Huang, Xiaopei Zhu, Xiaolin Hu, Fuchun Sun",
    "abstract": "Nowadays, cameras equipped with AI systems can capture and analyze images to detect people automatically. However, the AI system can make mistakes when receiving deliberately designed patterns in the real world, i.e., physical adversarial examples. Prior works have shown that it is possible to print adversarial patches on clothes to evade DNN-based person detectors. However, these adversarial examples could have catastrophic drops in the attack success rate when the viewing angle (i.e., the camera's angle towards the object) changes. To perform a multi-angle attack, we propose Adversarial Texture (AdvTexture). AdvTexture can cover clothes with arbitrary shapes so that people wearing such clothes can hide from person detectors from different viewing angles. We propose a generative method, named Toroidal-Cropping-based Expandable Generative Attack (TC-EGA), to craft AdvTexture with repetitive structures. We printed several pieces of cloth with AdvTexure and then made T-shirts, skirts, and dresses in the physical world. Experiments showed that these clothes could fool person detectors in the physical world.",
    "citationCount": 142,
    "pdf_filename": "2022_Adversarial_Texture_for_Fooling_Person_D_4d20147c.pdf"
  },
  "0ef76368047bd5a80204a1a319d85f6df0c16b4e": {
    "paperId": "0ef76368047bd5a80204a1a319d85f6df0c16b4e",
    "title": "Diffusion-based Molecule Generation with Informative Prior Bridges",
    "year": 2022,
    "authors": "Lemeng Wu, Chengyue Gong, Xingchao Liu, Mao Ye, Qiang Liu",
    "abstract": "AI-based molecule generation provides a promising approach to a large area of biomedical sciences and engineering, such as antibody design, hydrolase engineering, or vaccine development. Because the molecules are governed by physical laws, a key challenge is to incorporate prior information into the training procedure to generate high-quality and realistic molecules. We propose a simple and novel approach to steer the training of diffusion-based generative models with physical and statistics prior information. This is achieved by constructing physically informed diffusion bridges, stochastic processes that guarantee to yield a given observation at the fixed terminal time. We develop a Lyapunov function based method to construct and determine bridges, and propose a number of proposals of informative prior bridges for both high-quality molecule generation and uniformity-promoted 3D point cloud generation. With comprehensive experiments, we show that our method provides a powerful approach to the 3D generation task, yielding molecule structures with better quality and stability scores and more uniformly distributed point clouds of high qualities.",
    "citationCount": 139,
    "pdf_filename": "2022_Diffusion_based_Molecule_Generation_with_0ef76368.pdf"
  },
  "e5d30a65cb267dc185770c40cce732f9770cbd27": {
    "paperId": "e5d30a65cb267dc185770c40cce732f9770cbd27",
    "title": "A taxonomy of prompt modifiers for text-to-image generation",
    "year": 2022,
    "authors": "J. Oppenlaender",
    "abstract": "ABSTRACT Text-guided synthesis of images has become enormously popular and online communities dedicated to text-to-image generation and art generated with Artificial Intelligence (AI) have emerged. While deep generative models can synthesise high-quality images and artworks from simple descriptive text prompts, practitioners of text-to-image generation typically seek to control the generative model’s output by adding short key phrases (‘modifiers’) to the prompt. This paper identifies six types of prompt modifiers used by practitioners in the online text-to-image community based on a 3-month ethnographic study. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practice of text-to-image generation, but may also help practitioners of AI generated art improve their images. We further outline how prompt modifiers are applied in the practice of ‘prompt engineering.’ and discuss research opportunities of this novel creative practice in the field of Human–Computer Interaction (HCI). The paper concludes with a discussion of broader implications of prompt engineering from the perspective of Human-AI Interaction (HAI) in future applications beyond the use case of text-to-image generation and AI generated art.",
    "citationCount": 139,
    "pdf_filename": "2022_A_taxonomy_of_prompt_modifiers_for_text__e5d30a65.pdf"
  },
  "6a9d8a449b8326084786d81c92cdefd6beb5df10": {
    "paperId": "6a9d8a449b8326084786d81c92cdefd6beb5df10",
    "title": "Putting GPT-3's Creativity to the (Alternative Uses) Test",
    "year": 2022,
    "authors": "C. Stevenson, I. Smal, M. Baas, R. Grasman, H. Maas",
    "abstract": "AI large language models have (co-)produced amazing written works from newspaper articles to novels and poetry. These works meet the standards of the standard definition of creativity: being original and useful, and sometimes even the additional element of surprise. But can a large language model designed to predict the next text fragment provide creative, out-of-the-box, responses that still solve the problem at hand? We put Open AI's generative natural language model, GPT-3, to the test. Can it provide creative solutions to one of the most commonly used tests in creativity research? We assessed GPT-3's creativity on Guilford's Alternative Uses Test and compared its performance to previously collected human responses on expert ratings of originality, usefulness and surprise of responses, flexibility of each set of ideas as well as an automated method to measure creativity based on the semantic distance between a response and the AUT object in question. Our results show that -- on the whole -- humans currently outperform GPT-3 when it comes to creative output. But, we believe it is only a matter of time before GPT-3 catches up on this particular task. We discuss what this work reveals about human and AI creativity, creativity testing and our definition of creativity.",
    "citationCount": 110,
    "pdf_filename": "2022_Putting_GPT_3_s_Creativity_to_the__Alter_6a9d8a44.pdf"
  },
  "bdaf49ffbcabefad6132f24e167477114d7f551d": {
    "paperId": "bdaf49ffbcabefad6132f24e167477114d7f551d",
    "title": "Transforming Drug Therapy with Deep Learning: The Future of Personalized Medicine",
    "year": 2025,
    "authors": "A. Mulani, Minal Deshmukh, V. Jadhav, Kalyani Chaudhari, Ammu Anna Mathew",
    "abstract": "Abstract Personalized medicine represents a paradigm shift in healthcare, aiming to tailor treatment strategies to the unique genetic, environmental, and lifestyle characteristics of individual patients. This approach holds immense potential for improving therapeutic efficacy and minimizing adverse drug reactions. With the rapid advancement of artificial intelligence, deep learning has emerged as a transformative tool in pharmacology, enabling precise modeling of complex biological data and uncovering hidden patterns in patient-specific information. This study investigates the application of deep learning techniques – such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Transformer architectures, and Generative Adversarial Networks (GANs) – in optimizing personalized treatment strategies. Using a diverse dataset comprising electronic health records (EHRs), genomic sequences, and clinical indicators, we developed and trained deep learning models for tasks including drug response prediction, biomarker identification, and adverse drug reaction (ADR) forecasting. Among the models evaluated, Transformer-based architectures demonstrated superior performance, achieving an accuracy of 91.2% and an AUC-ROC of 0.92 in drug response prediction tasks. Moreover, the integration of deep learning models into the treatment pipeline resulted in a 20–30% improvement in drug-patient matching efficiency compared to traditional statistical methods. The findings underscore the potential of AI-powered systems to enhance clinical decision-making and enable precision pharmacotherapy. However, challenges such as data privacy, model interpretability, and regulatory compliance remain critical barriers to widespread adoption. The study also explores future directions, including the implementation of explainable AI (XAI) and federated learning, to address these limitations and facilitate the integration of deep learning into routine clinical practice.",
    "citationCount": 123,
    "pdf_filename": "2025_Transforming_Drug_Therapy_with_Deep_Lear_bdaf49ff.pdf"
  },
  "b19d6e45380449d4f08b3d38ddfe5923be820c03": {
    "paperId": "b19d6e45380449d4f08b3d38ddfe5923be820c03",
    "title": "TrafficGen: Learning to Generate Diverse and Realistic Traffic Scenarios",
    "year": 2022,
    "authors": "Lan Feng, Quanyi Li, Zhenghao Peng, Shuhan Tan, Bolei Zhou",
    "abstract": "Diverse and realistic traffic scenarios are crucial for evaluating the AI safety of autonomous driving systems in simulation. This work introduces a data-driven method called TrafficGen for traffic scenario generation. It learns from the fragmented human driving data collected in the real world and then generates realistic traffic scenarios. TrafficGen is an autoregressive neural generative model with an encoder-decoder architecture. In each autoregressive iteration, it first encodes the current traffic context with the attention mechanism and then decodes a vehicle's initial state followed by generating its long trajectory. We evaluate the trained model in terms of vehicle placement and trajectories, and the experimental result shows our method has substantial improvements over baselines for generating traffic scenarios. After training, TrafficGen can also augment existing traffic scenarios, by adding new vehicles and extending the fragmented trajectories. We further demonstrate that importing the generated scenarios into a simulator as an interactive training environment improves the performance and safety of a driving agent learned from reinforcement learning. Model and data are available at https://metadriverse.github.io/trafficgen.",
    "citationCount": 121,
    "pdf_filename": "2022_TrafficGen__Learning_to_Generate_Diverse_b19d6e45.pdf"
  },
  "e030bc12101fad1824faf931f318a089c1c14aaf": {
    "paperId": "e030bc12101fad1824faf931f318a089c1c14aaf",
    "title": "Machinery Fault Diagnosis Based on Domain Adaptation to Bridge the Gap Between Simulation and Measured Signals",
    "year": 2022,
    "authors": "Yunxia Lou, Ajay Kumar, J. Xiang",
    "abstract": "In intelligent fault diagnosis, the success of artificial intelligence (AI) models is highly dependent on labeled training samples, which may not be obtained in real-world applications. Recently, a finite element method (FEM) simulation-based personalized diagnosis method was developed to overcome the problems of insufficient and incomplete labeled training samples. However, the simulation signals obtained using the FEM and measured signals actually have a certain deviation. To supplement the FEM simulation-based personalized diagnosis method, a fault diagnosis method using domain adaptation (DA) is proposed to bridge the gap between simulation signals and measured signals. First, the FEM is adopted to obtain sufficient and complete simulation samples of all the fault categories as the original fault samples in the source domain. Second, the original simulation fault samples are adjusted using a generative adversarial network (GAN)-based DA network to make them similar to the measured samples through the adversarial training of the refiner and domain discriminator. Last, credible adjustment fault samples and measured fault samples obtained in machinery are applied to a convolutional neural network (CNN) for training and testing to complete the fault classification. The data obtained from rolling element bearing and gear test rigs are utilized to explore the feasibility of the proposed method, and the classification accuracies reach 99.44% and 99.58%, respectively. The comparison investigations using experimental data of gears and bearings indicate that the present method can accurately classify faults in machinery.",
    "citationCount": 128,
    "pdf_filename": "2022_Machinery_Fault_Diagnosis_Based_on_Domai_e030bc12.pdf"
  },
  "313cb2cfec8d36aac197681cf500128b8c2e8b19": {
    "paperId": "313cb2cfec8d36aac197681cf500128b8c2e8b19",
    "title": "A dual diffusion model enables 3D molecule generation and lead optimization based on target pockets",
    "year": 2024,
    "authors": "Lei Huang, Tingyang Xu, Yang Yu, Peilin Zhao, Xingjian Chen",
    "abstract": "Structure-based generative chemistry is essential in computer-aided drug discovery by exploring a vast chemical space to design ligands with high binding affinity for targets. However, traditional in silico methods are limited by computational inefficiency, while machine learning approaches face bottlenecks due to auto-regressive sampling. To address these concerns, we have developed a conditional deep generative model, PMDM, for 3D molecule generation fitting specified targets. PMDM consists of a conditional equivariant diffusion model with both local and global molecular dynamics, enabling PMDM to consider the conditioned protein information to generate molecules efficiently. The comprehensive experiments indicate that PMDM outperforms baseline models across multiple evaluation metrics. To evaluate the applications of PMDM under real drug design scenarios, we conduct lead compound optimization for SARS-CoV-2 main protease (Mpro) and Cyclin-dependent Kinase 2 (CDK2), respectively. The selected lead optimization molecules are synthesized and evaluated for their in-vitro activities against CDK2, displaying improved CDK2 activity. Structure-based generative chemistry is crucial in computer-aided drug discovery. Here, authors propose PMDM, a conditional generative model for 3D molecule generation tailored to specific targets. Extensive experiments demonstrate that PMDM can effectively generate rational bioactive molecules",
    "citationCount": 105,
    "pdf_filename": "2024_A_dual_diffusion_model_enables_3D_molecu_313cb2cf.pdf"
  },
  "581ac1e3568b8d632c2cdbef3bf91acb803b78f2": {
    "paperId": "581ac1e3568b8d632c2cdbef3bf91acb803b78f2",
    "title": "RAVE: A variational autoencoder for fast and high-quality neural audio synthesis",
    "year": 2021,
    "authors": "Antoine Caillon, P. Esling",
    "abstract": "Deep generative models applied to audio have improved by a large margin the state-of-the-art in many speech and music related tasks. However, as raw waveform modelling remains an inherently difficult task, audio generative models are either computationally intensive, rely on low sampling rates, are complicated to control or restrict the nature of possible signals. Among those models, Variational AutoEncoders (VAE) give control over the generation by exposing latent variables, although they usually suffer from low synthesis quality. In this paper, we introduce a Realtime Audio Variational autoEncoder (RAVE) allowing both fast and high-quality audio waveform synthesis. We introduce a novel two-stage training procedure, namely representation learning and adversarial fine-tuning. We show that using a post-training analysis of the latent space allows a direct control between the reconstruction fidelity and the representation compactness. By leveraging a multi-band decomposition of the raw waveform, we show that our model is the first able to generate 48kHz audio signals, while simultaneously running 20 times faster than real-time on a standard laptop CPU. We evaluate synthesis quality using both quantitative and qualitative subjective experiments and show the superiority of our approach compared to existing models. Finally, we present applications of our model for timbre transfer and signal compression. All of our source code and audio examples are publicly available.",
    "citationCount": 149,
    "pdf_filename": "2021_RAVE__A_variational_autoencoder_for_fast_581ac1e3.pdf"
  },
  "85376095b9e1a6763192c288747b203996b8d427": {
    "paperId": "85376095b9e1a6763192c288747b203996b8d427",
    "title": "Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing",
    "year": 2021,
    "authors": "Hyunsu Kim, Yunjey Choi, Junho Kim, Sungjoo Yoo, Youngjung Uh",
    "abstract": "Generative adversarial networks (GANs) synthesize realistic images from random latent vectors. Although manipulating the latent vectors controls the synthesized outputs, editing real images with GANs suffers from i) time-consuming optimization for projecting real images to the latent vectors, ii) or inaccurate embedding through an encoder. We propose StyleMapGAN: the intermediate latent space has spatial dimensions, and a spatially variant modulation replaces AdaIN. It makes the embedding through an encoder more accurate than existing optimization-based methods while maintaining the properties of GANs. Experimental results demonstrate that our method significantly outperforms state-of-the-art models in various image manipulation tasks such as local editing and image interpolation. Last but not least, conventional editing methods on GANs are still valid on our StyleMapGAN. Source code is available at https://github.com/naver-ai/StyleMapGAN.",
    "citationCount": 162,
    "pdf_filename": "2021_Exploiting_Spatial_Dimensions_of_Latent__85376095.pdf"
  },
  "a8b08fa108868561bbbe51a3b7d28033b1bc6042": {
    "paperId": "a8b08fa108868561bbbe51a3b7d28033b1bc6042",
    "title": "Embeddings",
    "year": 2021,
    "authors": "Jason Potts",
    "abstract": "Abstract I argue here that the concept of embedding (understood in the mathematical and computer science sense) provides a general way of understanding the relation between generative AI, written language and semiotics, and animal cognition when understood recursively. I propose this framing as an application of cultural science and suggest that this offers a new way to understand the alignment problem between humans and increasingly intelligent machines.",
    "citationCount": 168,
    "pdf_filename": "2021_Embeddings_a8b08fa1.pdf"
  },
  "f6fdac9b5e771394d22bfd5fbaf8147a52b6e792": {
    "paperId": "f6fdac9b5e771394d22bfd5fbaf8147a52b6e792",
    "title": "UniControl: A Unified Diffusion Model for Controllable Visual Generation In the Wild",
    "year": 2023,
    "authors": "Can Qin, Shu Zhang, Ning Yu, Yihao Feng, Xinyi Yang",
    "abstract": "Achieving machine autonomy and human control often represent divergent objectives in the design of interactive AI systems. Visual generative foundation models such as Stable Diffusion show promise in navigating these goals, especially when prompted with arbitrary languages. However, they often fall short in generating images with spatial, structural, or geometric controls. The integration of such controls, which can accommodate various visual conditions in a single unified model, remains an unaddressed challenge. In response, we introduce UniControl, a new generative foundation model that consolidates a wide array of controllable condition-to-image (C2I) tasks within a singular framework, while still allowing for arbitrary language prompts. UniControl enables pixel-level-precise image generation, where visual conditions primarily influence the generated structures and language prompts guide the style and context. To equip UniControl with the capacity to handle diverse visual conditions, we augment pretrained text-to-image diffusion models and introduce a task-aware HyperNet to modulate the diffusion models, enabling the adaptation to different C2I tasks simultaneously. Trained on nine unique C2I tasks, UniControl demonstrates impressive zero-shot generation abilities with unseen visual conditions. Experimental results show that UniControl often surpasses the performance of single-task-controlled methods of comparable model sizes. This control versatility positions UniControl as a significant advancement in the realm of controllable visual generation.",
    "citationCount": 187,
    "pdf_filename": "2023_UniControl__A_Unified_Diffusion_Model_fo_f6fdac9b.pdf"
  },
  "db20a10ef5641a0d0e60584e4cc8430a9763d437": {
    "paperId": "db20a10ef5641a0d0e60584e4cc8430a9763d437",
    "title": "PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support",
    "year": 2021,
    "authors": "Hao Sun, Zhenru Lin, Chujie Zheng, Siyang Liu, Minlie Huang",
    "abstract": "Great research interests have been attracted to devise AI services that are able to provide mental health support. However, the lack of corpora is a main obstacle to this research, particularly in Chinese language. In this paper, we propose PsyQA, a Chinese dataset of psychological health support in the form of question and answer pair. PsyQA is crawled from a Chinese mental health service platform, and contains 22K questions and 56K long and well-structured answers. Based on the psychological counseling theories, we annotate a portion of answer texts with typical strategies for providing support, and further present in-depth analysis of both lexical features and strategy patterns in the counseling answers. We also evaluate the performance of generating counseling answers with the generative pretrained models. Results show that utilizing strategies enhances the fluency and helpfulness of generated answers, but there is still a large space for future research.",
    "citationCount": 105,
    "pdf_filename": "2021_PsyQA__A_Chinese_Dataset_for_Generating__db20a10e.pdf"
  },
  "ed4a59cbb9ae22587d4d0a2bc9b400cd089437a4": {
    "paperId": "ed4a59cbb9ae22587d4d0a2bc9b400cd089437a4",
    "title": "Physics-based Deep Learning",
    "year": 2021,
    "authors": "Nils Thuerey, Philipp Holl, Maximilian Mueller, Patrick Schnell, Felix Trost",
    "abstract": "This document is a hands-on, comprehensive guide to deep learning in the realm of physical simulations. Rather than just theory, we emphasize practical application: every concept is paired with interactive Jupyter notebooks to get you up and running quickly. Beyond traditional supervised learning, we dive into physical loss-constraints, differentiable simulations, diffusion-based approaches for probabilistic generative AI, as well as reinforcement learning and advanced neural network architectures. These foundations are paving the way for the next generation of scientific foundation models. We are living in an era of rapid transformation. These methods have the potential to redefine what's possible in computational science.",
    "citationCount": 113,
    "pdf_filename": "2021_Physics_based_Deep_Learning_ed4a59cb.pdf"
  },
  "02fde8bfd9259a4f53316579eb0bf97213559e5c": {
    "paperId": "02fde8bfd9259a4f53316579eb0bf97213559e5c",
    "title": "The Radicalization Risks of GPT-3 and Advanced Neural Language Models",
    "year": 2020,
    "authors": "Kris McGuffie, Alex Newhouse",
    "abstract": "In this paper, we expand on our previous research of the potential for abuse of generative language models by assessing GPT-3. Experimenting with prompts representative of different types of extremist narrative, structures of social interaction, and radical ideologies, we find that GPT-3 demonstrates significant improvement over its predecessor, GPT-2, in generating extremist texts. We also show GPT-3's strength in generating text that accurately emulates interactive, informational, and influential content that could be utilized for radicalizing individuals into violent far-right extremist ideologies and behaviors. While OpenAI's preventative measures are strong, the possibility of unregulated copycat technology represents significant risk for large-scale online radicalization and recruitment; thus, in the absence of safeguards, successful and efficient weaponization that requires little experimentation is likely. AI stakeholders, the policymaking community, and governments should begin investing as soon as possible in building social norms, public policy, and educational initiatives to preempt an influx of machine-generated disinformation and propaganda. Mitigation will require effective policy and partnerships across industry, government, and civil society.",
    "citationCount": 162,
    "pdf_filename": "2020_The_Radicalization_Risks_of_GPT_3_and_Ad_02fde8bf.pdf"
  },
  "0f026c4f88ea47b5e9485a62491cc411c3eed107": {
    "paperId": "0f026c4f88ea47b5e9485a62491cc411c3eed107",
    "title": "Addressing Artificial Intelligence Bias in Retinal Diagnostics",
    "year": 2021,
    "authors": "P. Burlina, Neil J. Joshi, W. Paul, Katia D. Pacheco, N. Bressler",
    "abstract": "Purpose This study evaluated generative methods to potentially mitigate artificial intelligence (AI) bias when diagnosing diabetic retinopathy (DR) resulting from training data imbalance or domain generalization, which occurs when deep learning systems (DLSs) face concepts at test/inference time they were not initially trained on. Methods The public domain Kaggle EyePACS dataset (88,692 fundi and 44,346 individuals, originally diverse for ethnicity) was modified by adding clinician-annotated labels and constructing an artificial scenario of data imbalance and domain generalization by disallowing training (but not testing) exemplars for images of retinas with DR warranting referral (DR-referable) from darker-skin individuals, who presumably have greater concentration of melanin within uveal melanocytes, on average, contributing to retinal image pigmentation. A traditional/baseline diagnostic DLS was compared against new DLSs that would use training data augmented via generative models for debiasing. Results Accuracy (95% confidence intervals [CIs]) of the baseline diagnostics DLS for fundus images of lighter-skin individuals was 73.0% (66.9% to 79.2%) versus darker-skin of 60.5% (53.5% to 67.3%), demonstrating bias/disparity (delta = 12.5%; Welch t-test t = 2.670, P = 0.008) in AI performance across protected subpopulations. Using novel generative methods for addressing missing subpopulation training data (DR-referable darker-skin) achieved instead accuracy, for lighter-skin, of 72.0% (65.8% to 78.2%), and for darker-skin, of 71.5% (65.2% to 77.8%), demonstrating closer parity (delta = 0.5%) in accuracy across subpopulations (Welch t-test t = 0.111, P = 0.912). Conclusions Findings illustrate how data imbalance and domain generalization can lead to disparity of accuracy across subpopulations, and show that novel generative methods of synthetic fundus images may play a role for debiasing AI. Translational Relevance New AI methods have possible applications to address potential AI bias in DR diagnostics from fundus pigmentation, and potentially other ophthalmic DLSs too.",
    "citationCount": 112,
    "pdf_filename": "2021_Addressing_Artificial_Intelligence_Bias__0f026c4f.pdf"
  },
  "4c35e7cb5731c6f281e98b524d4e922c9fb88b3b": {
    "paperId": "4c35e7cb5731c6f281e98b524d4e922c9fb88b3b",
    "title": "Shapley explainability on the data manifold",
    "year": 2020,
    "authors": "Christopher Frye, Damien de Mijolla, T. Begley, Laurence Cowton, Megan Stanley",
    "abstract": "Explainability in AI is crucial for model development, compliance with regulation, and providing operational nuance to predictions. The Shapley framework for explainability attributes a model's predictions to its input features in a mathematically principled and model-agnostic way. However, general implementations of Shapley explainability make an untenable assumption: that the model's features are uncorrelated. In this work, we demonstrate unambiguous drawbacks of this assumption and develop two solutions to Shapley explainability that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other directly learns the Shapley value-function, providing performance and stability at the cost of flexibility. While \"off-manifold\" Shapley values can (i) give rise to incorrect explanations, (ii) hide implicit model dependence on sensitive attributes, and (iii) lead to unintelligible explanations in higher-dimensional data, on-manifold explainability overcomes these problems.",
    "citationCount": 113,
    "pdf_filename": "2020_Shapley_explainability_on_the_data_manif_4c35e7cb.pdf"
  },
  "47e799f83b0850f3d036a2e3a66bb337661b7e68": {
    "paperId": "47e799f83b0850f3d036a2e3a66bb337661b7e68",
    "title": "Thinking Like a Skeptic: Defeasible Inference in Natural Language",
    "year": 2020,
    "authors": "Rachel Rudinger, Vered Shwartz, Jena D. Hwang, Chandra Bhagavatula, Maxwell Forbes",
    "abstract": "Defeasible inference is a mode of reasoning in which an inference (X is a bird, therefore X flies) may be weakened or overturned in light of new evidence (X is a penguin). Though long recognized in classical AI and philosophy, defeasible inference has not been extensively studied in the context of contemporary data-driven research on natural language inference and commonsense reasoning. We introduce Defeasible NLI (abbreviated \\delta-NLI), a dataset for defeasible inference in natural language. Defeasible NLI contains extensions to three existing inference datasets covering diverse modes of reasoning: common sense, natural language inference, and social norms. From Defeasible NLI, we develop both a classification and generation task for defeasible inference, and demonstrate that the generation task is much more challenging. Despite lagging human performance, however, generative models trained on this data are capable of writing sentences that weaken or strengthen a specified inference up to 68% of the time.",
    "citationCount": 111,
    "pdf_filename": "2020_Thinking_Like_a_Skeptic__Defeasible_Infe_47e799f8.pdf"
  },
  "5e3bcd2347efdc11ef67e3e2eb82715f63892275": {
    "paperId": "5e3bcd2347efdc11ef67e3e2eb82715f63892275",
    "title": "A Comparison of Artificial Intelligence and Human Doctors for the Purpose of Triage and Diagnosis",
    "year": 2020,
    "authors": "Adam Baker, Yura N. Perov, Katherine Middleton, J. Baxter, D. Mullarkey",
    "abstract": "AI virtual assistants have significant potential to alleviate the pressure on overly burdened healthcare systems by enabling patients to self-assess their symptoms and to seek further care when appropriate. For these systems to make a meaningful contribution to healthcare globally, they must be trusted by patients and healthcare professionals alike, and service the needs of patients in diverse regions and segments of the population. We developed an AI virtual assistant which provides patients with triage and diagnostic information. Crucially, the system is based on a generative model, which allows for relatively straightforward re-parameterization to reflect local disease and risk factor burden in diverse regions and population segments. This is an appealing property, particularly when considering the potential of AI systems to improve the provision of healthcare on a global scale in many regions and for both developing and developed countries. We performed a prospective validation study of the accuracy and safety of the AI system and human doctors. Importantly, we assessed the accuracy and safety of both the AI and human doctors independently against identical clinical cases and, unlike previous studies, also accounted for the information gathering process of both agents. Overall, we found that the AI system is able to provide patients with triage and diagnostic information with a level of clinical accuracy and safety comparable to that of human doctors. Through this approach and study, we hope to start building trust in AI-powered systems by directly comparing their performance to human doctors, who do not always agree with each other on the cause of patients’ symptoms or the most appropriate triage recommendation.",
    "citationCount": 110,
    "pdf_filename": "2020_A_Comparison_of_Artificial_Intelligence__5e3bcd23.pdf"
  },
  "cac5b71e255e9ee325955b03a7f0333489b449f9": {
    "paperId": "cac5b71e255e9ee325955b03a7f0333489b449f9",
    "title": "3-D Inorganic Crystal Structure Generation and Property Prediction via Representation Learning",
    "year": 2020,
    "authors": "Callum J Court, Batuhan Yildirim, Apoorv Jain, J. Cole",
    "abstract": "Generative models have been successfully used to synthesize completely novel images, text, music, and speech. As such, they present an exciting opportunity for the design of new materials for functional applications. So far, generative deep-learning methods applied to molecular and drug discovery have yet to produce stable and novel 3-D crystal structures across multiple material classes. To that end, we, herein, present an autoencoder-based generative deep-representation learning pipeline for geometrically optimized 3-D crystal structures that simultaneously predicts the values of eight target properties. The system is highly general, as demonstrated through creation of novel materials from three separate material classes: binary alloys, ternary perovskites, and Heusler compounds. Comparison of these generated structures to those optimized via electronic-structure calculations shows that our generated materials are valid and geometrically optimized.",
    "citationCount": 131,
    "pdf_filename": "2020_3_D_Inorganic_Crystal_Structure_Generati_cac5b71e.pdf"
  },
  "207d4a0a19fae91f131e59a6f6bcd36245b6057b": {
    "paperId": "207d4a0a19fae91f131e59a6f6bcd36245b6057b",
    "title": "Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet Domain",
    "year": 2020,
    "authors": "Senrong You, Yong Liu, Baiying Lei, Shuqiang Wang",
    "abstract": "Magnetic resonance imaging plays an important role in computer-aided diagnosis and brain exploration. However, limited by hardware, scanning time and cost, it's challenging to acquire high-resolution (HR) magnetic resonance (MR) image clinically. In this paper, fine perceptive generative adversarial networks (FP-GANs) is proposed to produce HR MR images from low-resolution counterparts. It can cope with the detail insensitive problem of the existing super-resolution model in a divide-and-conquer manner. Specifically, FP-GANs firstly divides an MR image into low-frequency global approximation and high-frequency anatomical texture in wavelet domain. Then each sub-band generative adversarial network (sub-band GAN) conquers the super-resolution procedure of each single sub-band image. Meanwhile, sub-band attention is deployed to tune focus between global and texture information. It can focus on sub-band images instead of feature maps to further enhance the anatomical reconstruction ability of FP-GANs. In addition, inverse discrete wavelet transformation (IDWT) is integrated into model for taking the reconstruction of whole image into account. Experiments on MultiRes_7T dataset demonstrate that FP-GANs outperforms the competing methods quantitatively and qualitatively.",
    "citationCount": 109,
    "pdf_filename": "2020_Fine_Perceptive_GANs_for_Brain_MR_Image__207d4a0a.pdf"
  },
  "5543a3694eb874c3a559b6c483d5227858e7b49a": {
    "paperId": "5543a3694eb874c3a559b6c483d5227858e7b49a",
    "title": "RFAL: Adversarial Learning for RF Transmitter Identification and Classification",
    "year": 2020,
    "authors": "Debashri Roy, Tathagata Mukherjee, M. Chatterjee, Erik Blasch, E. Pasiliao",
    "abstract": "Recent advances in wireless technologies have led to several autonomous deployments of such networks. As nodes across distributed networks must co-exist, it is important that all transmitters and receivers are aware of their radio frequency (RF) surroundings so that they can adapt their transmission and reception parameters to best suit their needs. To this end, machine learning techniques have become popular as they can learn, analyze and predict the RF signals and associated parameters that characterize the RF environment. However, in the presence of adversaries, malicious activities such as jamming and spoofing are inevitable, making most machine learning techniques ineffective in such environments. In this paper we propose the Radio Frequency Adversarial Learning (RFAL) framework for building a robust system to identify rogue RF transmitters by designing and implementing a generative adversarial net (GAN). We hope to exploit transmitter specific “signatures” like the in-phase (I) and quadrature (Q) imbalance (i.e., the I/Q imbalance) present in all transmitters for this task, by learning feature representations using a deep neural network that uses the I/Q data from received signals as input. After detection and elimination of the adversarial transmitters RFAL further uses this learned feature embedding as “fingerprints” for categorizing the trusted transmitters. More specifically, we implement a generative model that learns the sample space of the I/Q values of known transmitters and uses the learned representation to generate signals that imitate the transmissions of these transmitters. We program 8 universal software radio peripheral (USRP) software defined radios (SDRs) as trusted transmitters and collect “over-the-air” raw I/Q data from them using a Realtek Software Defined Radio (RTL-SDR), in a laboratory setting. We also implement a discriminator model that discriminates between the trusted transmitters and the counterfeit ones with 99.9% accuracy and is trained in the GAN framework using data from the generator. Finally, after elimination of the adversarial transmitters, the trusted transmitters are classified using a convolutional neural network (CNN), a fully connected deep neural network (DNN) and a recurrent neural network (RNN) to demonstrate building of an end-to-end robust transmitter identification system with RFAL. Experimental results reveal that the CNN, DNN, and RNN are able to correctly distinguish between the 8 trusted transmitters with 81.6%, 94.6% and 97% accuracy respectively. We also show that better “trusted transmission” classification accuracy is achieved for all three types of neural networks when data from two different types of transmitters (different manufacturers) are used rather than when using the same type of transmitter (same manufacturer).",
    "citationCount": 157,
    "pdf_filename": "2020_RFAL__Adversarial_Learning_for_RF_Transm_5543a369.pdf"
  },
  "e310707f28c60e1f56820ab12272affe71818d17": {
    "paperId": "e310707f28c60e1f56820ab12272affe71818d17",
    "title": "Generative Representational Instruction Tuning",
    "year": 2024,
    "authors": "Niklas Muennighoff, Hongjin Su, Liang Wang, Nan Yang, Furu Wei",
    "abstract": "All text-based language problems can be reduced to either generation or embedding. Current models only perform well at one or the other. We introduce generative representational instruction tuning (GRIT) whereby a large language model is trained to handle both generative and embedding tasks by distinguishing between them through instructions. Compared to other open models, our resulting GritLM 7B sets a new state of the art on the Massive Text Embedding Benchmark (MTEB) and outperforms all models up to its size on a range of generative tasks. By scaling up further, GritLM 8x7B outperforms all open generative language models that we tried while still being among the best embedding models. Notably, we find that GRIT matches training on only generative or embedding data, thus we can unify both at no performance loss. Among other benefits, the unification via GRIT speeds up Retrieval-Augmented Generation (RAG) by>60% for long documents, by no longer requiring separate retrieval and generation models. Models, code, etc. are freely available at https://github.com/ContextualAI/gritlm.",
    "citationCount": 198,
    "pdf_filename": "2024_Generative_Representational_Instruction__e310707f.pdf"
  },
  "3c10800ee7c707bbf5e9fdb371e1451f9d92e26d": {
    "paperId": "3c10800ee7c707bbf5e9fdb371e1451f9d92e26d",
    "title": "Student perspectives on the use of generative artificial intelligence technologies in higher education",
    "year": 2024,
    "authors": "Heather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, Bryony N. Parsons",
    "abstract": "The aim of this project was to understand student perspectives on generative artificial intelligence (GAI) technologies such as Chat generative Pre-Trained Transformer (ChatGPT), in order to inform changes to the University of Liverpool Academic Integrity code of practice. The survey for this study was created by a library student team and vetted through focus groups. A total of 2555 students participated in the survey. Results showed that only 7% of students who responded had not heard of any GAI technologies, whilst over half had used or considered using these for academic purposes. The majority of students (54.1%) were supportive or somewhat supportive of using tools such as Grammarly, but 70.4% were unsupportive or somewhat unsupportive towards students using tools such as ChatGPT to write their whole essay. Students who had higher levels of confidence in their academic writing were less likely to use or consider using them for academic purposes, and were also less likely to be supportive of other students using them. Most students (41.1%) also thought there should be a university wide policy on when these technologies are or are not appropriate to use. The results of this research suggest that students require clear policies on the use of GAI and that these technologies should not be banned from university, but consideration must be made to ensure different groups of students have equal access to the technologies.",
    "citationCount": 154,
    "pdf_filename": "2024_Student_perspectives_on_the_use_of_gener_3c10800e.pdf"
  },
  "2fbd84851d1133c30575e1b08f276dae843c4c81": {
    "paperId": "2fbd84851d1133c30575e1b08f276dae843c4c81",
    "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
    "year": 2024,
    "authors": "Yuancheng Wang, Haoyue Zhan, Liwei Liu, Ruihong Zeng, Haotian Guo",
    "abstract": "The recent large-scale text-to-speech (TTS) systems are usually grouped as autoregressive and non-autoregressive systems. The autoregressive systems implicitly model duration but exhibit certain deficiencies in robustness and lack of duration controllability. Non-autoregressive systems require explicit alignment information between text and speech during training and predict durations for linguistic units (e.g. phone), which may compromise their naturalness. In this paper, we introduce Masked Generative Codec Transformer (MaskGCT), a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision, as well as phone-level duration prediction. MaskGCT is a two-stage model: in the first stage, the model uses text to predict semantic tokens extracted from a speech self-supervised learning (SSL) model, and in the second stage, the model predicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows the mask-and-predict learning paradigm. During training, MaskGCT learns to predict masked semantic or acoustic tokens based on given conditions and prompts. During inference, the model generates tokens of a specified length in a parallel manner. Experiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality, similarity, and intelligibility. Audio samples are available at https://maskgct.github.io/. We release our code and model checkpoints at https://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct.",
    "citationCount": 135,
    "pdf_filename": "2024_MaskGCT__Zero_Shot_Text_to_Speech_with_M_2fbd8485.pdf"
  },
  "01fd2da3cbb93d1435b50ca78f71b13e8930585b": {
    "paperId": "01fd2da3cbb93d1435b50ca78f71b13e8930585b",
    "title": "GenAD: Generative End-to-End Autonomous Driving",
    "year": 2024,
    "authors": "Wenzhao Zheng, Ruiqi Song, Xianda Guo, Long Chen",
    "abstract": "Directly producing planning results from raw sensors has been a long-desired solution for autonomous driving and has attracted increasing attention recently. Most existing end-to-end autonomous driving methods factorize this problem into perception, motion prediction, and planning. However, we argue that the conventional progressive pipeline still cannot comprehensively model the entire traffic evolution process, e.g., the future interaction between the ego car and other traffic participants and the structural trajectory prior. In this paper, we explore a new paradigm for end-to-end autonomous driving, where the key is to predict how the ego car and the surroundings evolve given past scenes. We propose GenAD, a generative framework that casts autonomous driving into a generative modeling problem. We propose an instance-centric scene tokenizer that first transforms the surrounding scenes into map-aware instance tokens. We then employ a variational autoencoder to learn the future trajectory distribution in a structural latent space for trajectory prior modeling. We further adopt a temporal model to capture the agent and ego movements in the latent space to generate more effective future trajectories. GenAD finally simultaneously performs motion prediction and planning by sampling distributions in the learned structural latent space conditioned on the instance tokens and using the learned temporal model to generate futures. Extensive experiments on the widely used nuScenes benchmark show that the proposed GenAD achieves state-of-the-art performance on vision-centric end-to-end autonomous driving with high efficiency. Code: https://github.com/wzzheng/GenAD.",
    "citationCount": 129,
    "pdf_filename": "2024_GenAD__Generative_End_to_End_Autonomous__01fd2da3.pdf"
  },
  "676b1c74535efca92fbb79a26ea66df9ea07e7e7": {
    "paperId": "676b1c74535efca92fbb79a26ea66df9ea07e7e7",
    "title": "Publishers’ and journals’ instructions to authors on use of generative artificial intelligence in academic and scientific publishing: bibliometric analysis",
    "year": 2024,
    "authors": "Conner Ganjavi, M. Eppler, Asli Pekcan, Brett Biedermann, Andre Abreu",
    "abstract": "Abstract Objectives To determine the extent and content of academic publishers’ and scientific journals’ guidance for authors on the use of generative artificial intelligence (GAI). Design Cross sectional, bibliometric study. Setting Websites of academic publishers and scientific journals, screened on 19-20 May 2023, with the search updated on 8-9 October 2023. Participants Top 100 largest academic publishers and top 100 highly ranked scientific journals, regardless of subject, language, or country of origin. Publishers were identified by the total number of journals in their portfolio, and journals were identified through the Scimago journal rank using the Hirsch index (H index) as an indicator of journal productivity and impact. Main outcome measures The primary outcomes were the content of GAI guidelines listed on the websites of the top 100 academic publishers and scientific journals, and the consistency of guidance between the publishers and their affiliated journals. Results Among the top 100 largest publishers, 24% provided guidance on the use of GAI, of which 15 (63%) were among the top 25 publishers. Among the top 100 highly ranked journals, 87% provided guidance on GAI. Of the publishers and journals with guidelines, the inclusion of GAI as an author was prohibited in 96% and 98%, respectively. Only one journal (1%) explicitly prohibited the use of GAI in the generation of a manuscript, and two (8%) publishers and 19 (22%) journals indicated that their guidelines exclusively applied to the writing process. When disclosing the use of GAI, 75% of publishers and 43% of journals included specific disclosure criteria. Where to disclose the use of GAI varied, including in the methods or acknowledgments, in the cover letter, or in a new section. Variability was also found in how to access GAI guidelines shared between journals and publishers. GAI guidelines in 12 journals directly conflicted with those developed by the publishers. The guidelines developed by top medical journals were broadly similar to those of academic journals. Conclusions Guidelines by some top publishers and journals on the use of GAI by authors are lacking. Among those that provided guidelines, the allowable uses of GAI and how it should be disclosed varied substantially, with this heterogeneity persisting in some instances among affiliated publishers and journals. Lack of standardization places a burden on authors and could limit the effectiveness of the regulations. As GAI continues to grow in popularity, standardized guidelines to protect the integrity of scientific output are needed.",
    "citationCount": 138,
    "pdf_filename": "2024_Publishers__and_journals__instructions_t_676b1c74.pdf"
  },
  "95b4be099405394d936281413d5d83e9e3dde837": {
    "paperId": "95b4be099405394d936281413d5d83e9e3dde837",
    "title": "A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)",
    "year": 2024,
    "authors": "Yashar Deldjoo, Zhankui He, Julian McAuley, A. Korikov, Scott Sanner",
    "abstract": "Traditional recommender systems typically use user-item rating histories as their main data source. However, deep generative models now have the capability to model and sample from complex data distributions, including user-item interactions, text, images, and videos, enabling novel recommendation tasks. This comprehensive, multidisciplinary survey connects key advancements in RS using Generative Models (Gen-RecSys), covering: interaction-driven generative models; the use of large language models (LLM) and textual data for natural language recommendation; and the integration of multimodal models for generating and processing images/videos in RS. Our work highlights necessary paradigms for evaluating the impact and harm of Gen-RecSys and identifies open challenges. This survey accompanies a \"tutorial\" presented at ACM KDD'24, with supporting materials provided at: https://encr.pw/vDhLq.",
    "citationCount": 107,
    "pdf_filename": "2024_A_Review_of_Modern_Recommender_Systems_U_95b4be09.pdf"
  },
  "4fdf88a4b0677360c333d122699547d8485090f4": {
    "paperId": "4fdf88a4b0677360c333d122699547d8485090f4",
    "title": "From Matching to Generation: A Survey on Generative Information Retrieval",
    "year": 2024,
    "authors": "Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yuyao Zhang, Peitian Zhang",
    "abstract": "Information Retrieval (IR) systems are crucial tools for users to access information, which have long been dominated by traditional methods relying on similarity matching. With the advancement of pre-trained language models, Generative Information Retrieval (GenIR) emerges as a novel paradigm, attracting increasing attention. Based on the form of information provided to users, current research in GenIR can be categorized into two aspects: (1) Generative Retrieval (GR) leverages the generative model’s parameters for memorizing documents, enabling retrieval by directly generating relevant document identifiers without explicit indexing. (2) Reliable Response Generation employs language models to directly generate information users seek, breaking the limitations of traditional IR in terms of document granularity and relevance matching while offering flexibility, efficiency, and creativity to meet practical needs. This article aims to systematically review the latest research progress in GenIR. We will summarize the advancements in GR regarding model training and structure, document identifier, incremental learning, and so on, as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, and so on. We also review the evaluation, challenges, and future developments in GenIR systems. This review aims to offer a comprehensive reference for researchers, encouraging further development in the GenIR field (Github Repository: https://github.com/RUC-NLPIR/GenIR-Survey).",
    "citationCount": 123,
    "pdf_filename": "2024_From_Matching_to_Generation__A_Survey_on_4fdf88a4.pdf"
  },
  "88241c65981eaf814108a57b5bc22ea9573da969": {
    "paperId": "88241c65981eaf814108a57b5bc22ea9573da969",
    "title": "Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format",
    "year": 2024,
    "authors": "J. Zaretsky, Jeong Min Kim, Samuel Baskharoun, Yunan Zhao, Jonathan S. Austrian",
    "abstract": "Key Points Question Can a large language model transform discharge summaries into a format that is more readable and understandable for patients? Findings In this cross-sectional study of 50 discharge summaries, understandability scores were significantly higher for patient-friendly discharge summaries. Summaries were rated entirely complete in 56 of 100 reviews, but 18 reviews noted safety concerns involving omissions and inaccuracies. Meaning These findings suggest that a large language model could be used to translate discharge summaries into patient-friendly language and format, but implementation will require improvements in accuracy, completeness, and safety.",
    "citationCount": 151,
    "pdf_filename": "2024_Generative_Artificial_Intelligence_to_Tr_88241c65.pdf"
  },
  "a289100678e7d94af836d91cd48d7821ebc5b83d": {
    "paperId": "a289100678e7d94af836d91cd48d7821ebc5b83d",
    "title": "Recommender Systems with Generative Retrieval",
    "year": 2023,
    "authors": "Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan H. Keshavan, T. Vu",
    "abstract": "Modern recommender systems perform large-scale retrieval by first embedding queries and item candidates in the same unified space, followed by approximate nearest neighbor search to select top candidates given a query embedding. In this paper, we propose a novel generative retrieval approach, where the retrieval model autoregressively decodes the identifiers of the target candidates. To that end, we create semantically meaningful tuple of codewords to serve as a Semantic ID for each item. Given Semantic IDs for items in a user session, a Transformer-based sequence-to-sequence model is trained to predict the Semantic ID of the next item that the user will interact with. To the best of our knowledge, this is the first Semantic ID-based generative model for recommendation tasks. We show that recommender systems trained with the proposed paradigm significantly outperform the current SOTA models on various datasets. In addition, we show that incorporating Semantic IDs into the sequence-to-sequence model enhances its ability to generalize, as evidenced by the improved retrieval performance observed for items with no prior interaction history.",
    "citationCount": 165,
    "pdf_filename": "2023_Recommender_Systems_with_Generative_Retr_a2891006.pdf"
  },
  "e95c26a32223ee5a0bd2e6621dec0197f9d544af": {
    "paperId": "e95c26a32223ee5a0bd2e6621dec0197f9d544af",
    "title": "Generative Models as an Emerging Paradigm in the Chemical Sciences",
    "year": 2023,
    "authors": "Dylan M. Anstine, O. Isayev",
    "abstract": "Traditional computational approaches to design chemical species are limited by the need to compute properties for a vast number of candidates, e.g., by discriminative modeling. Therefore, inverse design methods aim to start from the desired property and optimize a corresponding chemical structure. From a machine learning viewpoint, the inverse design problem can be addressed through so-called generative modeling. Mathematically, discriminative models are defined by learning the probability distribution function of properties given the molecular or material structure. In contrast, a generative model seeks to exploit the joint probability of a chemical species with target characteristics. The overarching idea of generative modeling is to implement a system that produces novel compounds that are expected to have a desired set of chemical features, effectively sidestepping issues found in the forward design process. In this contribution, we overview and critically analyze popular generative algorithms like generative adversarial networks, variational autoencoders, flow, and diffusion models. We highlight key differences between each of the models, provide insights into recent success stories, and discuss outstanding challenges for realizing generative modeling discovered solutions in chemical applications.",
    "citationCount": 198,
    "pdf_filename": "2023_Generative_Models_as_an_Emerging_Paradig_e95c26a3.pdf"
  },
  "c62711f6b5d8620ba36bc2c378ec6ab53f6e197c": {
    "paperId": "c62711f6b5d8620ba36bc2c378ec6ab53f6e197c",
    "title": "RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation",
    "year": 2023,
    "authors": "Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang",
    "abstract": "We present RoboGen, a generative robotic agent that automatically learns diverse robotic skills at scale via generative simulation. RoboGen leverages the latest advancements in foundation and generative models. Instead of directly using or adapting these models to produce policies or low-level actions, we advocate for a generative scheme, which uses these models to automatically generate diversified tasks, scenes, and training supervisions, thereby scaling up robotic skill learning with minimal human supervision. Our approach equips a robotic agent with a self-guided propose-generate-learn cycle: the agent first proposes interesting tasks and skills to develop, and then generates corresponding simulation environments by populating pertinent objects and assets with proper spatial configurations. Afterwards, the agent decomposes the proposed high-level task into sub-tasks, selects the optimal learning approach (reinforcement learning, motion planning, or trajectory optimization), generates required training supervision, and then learns policies to acquire the proposed skill. Our work attempts to extract the extensive and versatile knowledge embedded in large-scale models and transfer them to the field of robotics. Our fully generative pipeline can be queried repeatedly, producing an endless stream of skill demonstrations associated with diverse tasks and environments.",
    "citationCount": 163,
    "pdf_filename": "2023_RoboGen__Towards_Unleashing_Infinite_Dat_c62711f6.pdf"
  },
  "fdb57e034b2eea19550412cd3c4d9a4d25fb3d15": {
    "paperId": "fdb57e034b2eea19550412cd3c4d9a4d25fb3d15",
    "title": "Future of education in the era of generative artificial intelligence: Consensus among Chinese scholars on applications of ChatGPT in schools",
    "year": 2023,
    "authors": "Ming Liu, Yiling Ren, Lucy Michael Nyagoga, Francis Stonier, Zhongming Wu",
    "abstract": "ChatGPT is an artificial intelligence chatbot that utilizes advanced natural language processing technologies, including large language models, to produce human‐like responses to user queries spanning a wide range of topics from programming to mathematics. As an emerging generative artificial intelligence (GAI) tool, it presents novel opportunities and challenges to the ongoing digital transformation of education. This article employs a systematic review approach to summarize the viewpoints of Chinese scholars and experts regarding the implementation of GAI in education. The research findings indicate that a majority of Chinese scholars support the cautious integration of GAI into education as it serves as a learning tool that offers personalized educational experiences for students. However, it also raises concerns related to academic integrity and the potential hindrance to students' critical thinking skills. Consequently, a framework called DATS, which outlines an optimization path for future GAI applications in schools, is proposed. The framework takes into account the perspectives of four key stakeholders: developers, administrators, teachers, and students.",
    "citationCount": 158,
    "pdf_filename": "2023_Future_of_education_in_the_era_of_genera_fdb57e03.pdf"
  },
  "cb005eddc00d2ac59d1629ba1559e772c3268478": {
    "paperId": "cb005eddc00d2ac59d1629ba1559e772c3268478",
    "title": "Generative Artificial Intelligence in the Hospitality and Tourism Industry: Developing a Framework for Future Research",
    "year": 2023,
    "authors": "T. Dogru, Nathaniel D. Line, M. Mody, Lydia Hanks, Je’Anna Abbott",
    "abstract": "Generative artificial intelligence (GAI) offers important opportunities for the hospitality and tourism (HT) industry in the context of operations, design, marketing, destination management, human resources, revenue management, accounting and finance, strategic management, and beyond. However, the implementation of GAI in HT contexts comes with ethical, legal, social, and economic considerations that require careful reflection by HT firms. The purpose of this study is to offer a critical examination of the effects of GAI applications across a broad spectrum of stakeholders in the HT industry, in an effort to integrate practical and academic insights and foresights and drive academic research forward. Through the contributions of a purposeful selection of scholars, educators, and industry-practitioners, along the tenets of the stakeholder theory of the firm, this study highlights the potential challenges and opportunities of GAI and considers how academics can navigate the (research) complexities of this rapidly evolving technological phenomenon.",
    "citationCount": 160,
    "pdf_filename": "2023_Generative_Artificial_Intelligence_in_th_cb005edd.pdf"
  },
  "9867456c81f262162c2fdf9c8498218a8936c84d": {
    "paperId": "9867456c81f262162c2fdf9c8498218a8936c84d",
    "title": "SneakyPrompt: Jailbreaking Text-to-image Generative Models",
    "year": 2023,
    "authors": "Yuchen Yang, Bo Hui, Haolin Yuan, N. Gong, Yinzhi Cao",
    "abstract": "Text-to-image generative models such as Stable Diffusion and DALL•E raise many ethical concerns due to the generation of harmful images such as Not-Safe-for-Work (NSFW) ones. To address these ethical concerns, safety filters are often adopted to prevent the generation of NSFW images. In this work, we propose SneakyPrompt, the first automated attack framework, to jailbreak text-to-image generative models such that they generate NSFW images even if safety filters are adopted. Given a prompt that is blocked by a safety filter, SneakyPrompt repeatedly queries the text-to-image generative model and strategically perturbs tokens in the prompt based on the query results to bypass the safety filter. Specifically, SneakyPrompt utilizes reinforcement learning to guide the perturbation of tokens. Our evaluation shows that SneakyPrompt successfully jailbreaks DALL•E 2 with closed-box safety filters to generate NSFW images. Moreover, we also deploy several state-of-the-art, open-source safety filters on a Stable Diffusion model. Our evaluation shows that SneakyPrompt not only successfully generates NSFW images, but also outperforms existing text adversarial attacks when extended to jailbreak text-to-image generative models, in terms of both the number of queries and qualities of the generated NSFW images. SneakyPrompt is open-source and available at this repository: https://github.com/Yuchen413/text2image_safety.",
    "citationCount": 141,
    "pdf_filename": "2023_SneakyPrompt__Jailbreaking_Text_to_image_9867456c.pdf"
  },
  "d8c71ea4595cda618d5e3e2eb1671413b228a173": {
    "paperId": "d8c71ea4595cda618d5e3e2eb1671413b228a173",
    "title": "ChatGPT versus engineering education assessment: a multidisciplinary and multi-institutional benchmarking and analysis of this generative artificial intelligence tool to investigate assessment integrity",
    "year": 2023,
    "authors": "Sasha Nikolic, S. Daniel, Rezwanul Haque, M. Belkina, G. Hassan",
    "abstract": "ABSTRACT ChatGPT, a sophisticated online chatbot, sent shockwaves through many sectors once reports filtered through that it could pass exams. In higher education, it has raised many questions about the authenticity of assessment and challenges in detecting plagiarism. Amongst the resulting frenetic hubbub, hints of potential opportunities in how ChatGPT could support learning and the development of critical thinking have also emerged. In this paper, we examine how ChatGPT may affect assessment in engineering education by exploring ChatGPT responses to existing assessment prompts from ten subjects across seven Australian universities. We explore the strengths and weaknesses of current assessment practice and discuss opportunities on how ChatGPT can be used to facilitate learning. As artificial intelligence is rapidly improving, this analysis sets a benchmark for ChatGPT’s performance as of early 2023 in responding to engineering education assessment prompts. ChatGPT did pass some subjects and excelled with some assessment types. Findings suggest that changes in current practice are needed, as typically with little modification to the input prompts, ChatGPT could generate passable responses to many of the assessments, and it is only going to get better as future versions are trained on larger data sets.",
    "citationCount": 192,
    "pdf_filename": "2023_ChatGPT_versus_engineering_education_ass_d8c71ea4.pdf"
  },
  "26f7785ef8da35820599799549152b9ef695dae2": {
    "paperId": "26f7785ef8da35820599799549152b9ef695dae2",
    "title": "GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation",
    "year": 2023,
    "authors": "Jinming Li, Wentao Zhang, Tiantian Wang, Guanglei Xiong, Alan Lu",
    "abstract": "Recent advancements in Natural Language Processing (NLP) have led to the development of NLP-based recommender systems that have shown superior performance. However, current models commonly treat items as mere IDs and adopt discriminative modeling, resulting in limitations of (1) fully leveraging the content information of items and the language modeling capabilities of NLP models; (2) interpreting user interests to improve relevance and diversity; and (3) adapting practical circumstances such as growing item inventories. To address these limitations, we present GPT4Rec, a novel and flexible generative framework inspired by search engines. It first generates hypothetical\"search queries\"given item titles in a user's history, and then retrieves items for recommendation by searching these queries. The framework overcomes previous limitations by learning both user and item embeddings in the language space. To well-capture user interests with different aspects and granularity for improving relevance and diversity, we propose a multi-query generation technique with beam search. The generated queries naturally serve as interpretable representations of user interests and can be searched to recommend cold-start items. With GPT-2 language model and BM25 search engine, our framework outperforms state-of-the-art methods by $75.7\\%$ and $22.2\\%$ in Recall@K on two public datasets. Experiments further revealed that multi-query generation with beam search improves both the diversity of retrieved items and the coverage of a user's multi-interests. The adaptiveness and interpretability of generated queries are discussed with qualitative case studies.",
    "citationCount": 140,
    "pdf_filename": "2023_GPT4Rec__A_Generative_Framework_for_Pers_26f7785e.pdf"
  },
  "fa1db49fec0cfde794a9499efd1186b6f1108124": {
    "paperId": "fa1db49fec0cfde794a9499efd1186b6f1108124",
    "title": "Intriguing properties of synthetic images: from generative adversarial networks to diffusion models",
    "year": 2023,
    "authors": "Riccardo Corvi, D. Cozzolino, G. Poggi, Koki Nagano, L. Verdoliva",
    "abstract": "Detecting fake images is becoming a major goal of computer vision. This need is becoming more and more pressing with the continuous improvement of synthesis methods based on Generative Adversarial Networks (GAN), and even more with the appearance of powerful methods based on Diffusion Models (DM). Towards this end, it is important to gain insight into which image features better discriminate fake images from real ones. In this paper we report on our systematic study of a large number of image generators of different families, aimed at discovering the most forensically relevant characteristics of real and generated images. Our experiments provide a number of interesting observations and shed light on some intriguing properties of synthetic images: (1) not only the GAN models but also the DM and VQ-GAN (Vector Quantized Generative Adversarial Networks) models give rise to visible artifacts in the Fourier domain and exhibit anomalous regular patterns in the autocorrelation; (2) when the dataset used to train the model lacks sufficient variety, its biases can be transferred to the generated images; (3) synthetic and real images exhibit significant differences in the mid-high frequency signal content, observable in their radial and angular spectral power distributions.",
    "citationCount": 137,
    "pdf_filename": "2023_Intriguing_properties_of_synthetic_image_fa1db49f.pdf"
  },
  "6f121e4188d1635568c0b73627c0acf6b251554a": {
    "paperId": "6f121e4188d1635568c0b73627c0acf6b251554a",
    "title": "MatterGen: a generative model for inorganic materials design",
    "year": 2023,
    "authors": "Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton",
    "abstract": "The design of functional materials with desired properties is essential in driving technological advances in areas like energy storage, catalysis, and carbon capture. Generative models provide a new paradigm for materials design by directly generating entirely novel materials given desired property constraints. Despite recent progress, current generative models have low success rate in proposing stable crystals, or can only satisfy a very limited set of property constraints. Here, we present MatterGen, a model that generates stable, diverse inorganic materials across the periodic table and can further be fine-tuned to steer the generation towards a broad range of property constraints. To enable this, we introduce a new diffusion-based generative process that produces crystalline structures by gradually refining atom types, coordinates, and the periodic lattice. We further introduce adapter modules to enable fine-tuning towards any given property constraints with a labeled dataset. Compared to prior generative models, structures produced by MatterGen are more than twice as likely to be novel and stable, and more than 15 times closer to the local energy minimum. After fine-tuning, MatterGen successfully generates stable, novel materials with desired chemistry, symmetry, as well as mechanical, electronic and magnetic properties. Finally, we demonstrate multi-property materials design capabilities by proposing structures that have both high magnetic density and a chemical composition with low supply-chain risk. We believe that the quality of generated materials and the breadth of MatterGen's capabilities represent a major advancement towards creating a universal generative model for materials design.",
    "citationCount": 133,
    "pdf_filename": "2023_MatterGen__a_generative_model_for_inorga_6f121e41.pdf"
  },
  "8f2a8d67ae617fefe396ff62de715f150f756312": {
    "paperId": "8f2a8d67ae617fefe396ff62de715f150f756312",
    "title": "Score-based generative modeling for de novo protein design",
    "year": 2023,
    "authors": "Jin Sub Lee, Jisun Kim, Philip M. Kim",
    "abstract": "The generation of de novo protein structures with predefined functions and properties remains a challenging problem in protein design. Diffusion models, also known as score-based generative models (SGMs), have recently exhibited astounding empirical performance in image synthesis. Here we use image-based representations of protein structure to develop ProteinSGM, a score-based generative model that produces realistic de novo proteins. Through unconditional generation, we show that ProteinSGM can generate native-like protein structures, surpassing the performance of previously reported generative models. We experimentally validate some de novo designs and observe secondary structure compositions consistent with generated backbones. Finally, we apply conditional generation to de novo protein design by formulating it as an image inpainting problem, allowing precise and modular design of protein structure. This study proposes a diffusion model, ProteinSGM, for the design of novel protein folds. The designed proteins are diverse, experimentally stable and structurally consistent with predicted models",
    "citationCount": 132,
    "pdf_filename": "2023_Score_based_generative_modeling_for_de_n_8f2a8d67.pdf"
  },
  "513fc9d2500a0e532ddf17ed7f8ed4d1cfb727af": {
    "paperId": "513fc9d2500a0e532ddf17ed7f8ed4d1cfb727af",
    "title": "Generative models improve fairness of medical classifiers under distribution shifts",
    "year": 2023,
    "authors": "Ira Ktena, Olivia Wiles, Isabela Albuquerque, Sylvestre-Alvise Rebuffi, Ryutaro Tanno",
    "abstract": "Domain generalization is a ubiquitous challenge for machine learning in healthcare. Model performance in real-world conditions might be lower than expected because of discrepancies between the data encountered during deployment and development. Underrepresentation of some groups or conditions during model development is a common cause of this phenomenon. This challenge is often not readily addressed by targeted data acquisition and ‘labeling’ by expert clinicians, which can be prohibitively expensive or practically impossible because of the rarity of conditions or the available clinical expertise. We hypothesize that advances in generative artificial intelligence can help mitigate this unmet need in a steerable fashion, enriching our training dataset with synthetic examples that address shortfalls of underrepresented conditions or subgroups. We show that diffusion models can automatically learn realistic augmentations from data in a label-efficient manner. We demonstrate that learned augmentations make models more robust and statistically fair in-distribution and out of distribution. To evaluate the generality of our approach, we studied three distinct medical imaging contexts of varying difficulty: (1) histopathology, (2) chest X-ray and (3) dermatology images. Complementing real samples with synthetic ones improved the robustness of models in all three medical tasks and increased fairness by improving the accuracy of clinical diagnosis within underrepresented groups, especially out of distribution. By generating synthetic image samples specific to underrepresented groups, diffusion models help medical image classifiers to achieve greater fairness metrics across a variety of medical disciplines and demographic attributes.",
    "citationCount": 133,
    "pdf_filename": "2023_Generative_models_improve_fairness_of_me_513fc9d2.pdf"
  },
  "4e1e6e82c7c4c652a37e0d07d726178e56a87e54": {
    "paperId": "4e1e6e82c7c4c652a37e0d07d726178e56a87e54",
    "title": "GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis",
    "year": 2023,
    "authors": "Ming Tao, Bingkun Bao, Hao Tang, Changsheng Xu",
    "abstract": "Synthesizing high-fidelity complex images from text is challenging. Based on large pretraining, the autoregressive and diffusion models can synthesize photo-realistic images. Although these large models have shown notable progress, there remain three flaws. 1) These models require tremendous training data and parameters to achieve good performance. 2) The multi-step generation design slows the image synthesis process heavily. 3) The synthesized visual features are challenging to control and require delicately designed prompts. To enable high-quality, efficient, fast, and controllable text-to-image synthesis, we propose Generative Adversarial CLIPs, namely GALIP. GALIP leverages the powerful pretrained CLIP model both in the discriminator and generator. Specifically, we propose a CLIP-based discriminator. The complex scene understanding ability of CLIP enables the discriminator to accurately assess the image quality. Furthermore, we propose a CLIP-empowered generator that induces the visual concepts from CLIP through bridge features and prompts. The CLIP-integrated generator and discriminator boost training efficiency, and as a result, our model only requires about 3% training data and 6% learnable parameters, achieving comparable results to large pretrained autoregressive and diffusion models. Moreover, our model achieves ~120×faster synthesis speed and inherits the smooth latent space from GAN. The extensive experimental results demonstrate the excellent performance of our GALIP. Code is available at https://github.com/tobran/GALIP.",
    "citationCount": 133,
    "pdf_filename": "2023_GALIP__Generative_Adversarial_CLIPs_for__4e1e6e82.pdf"
  },
  "468992bf970c37bd1fef58b78a6c2fcd8c018868": {
    "paperId": "468992bf970c37bd1fef58b78a6c2fcd8c018868",
    "title": "Scaling Laws for Generative Mixed-Modal Language Models",
    "year": 2023,
    "authors": "Armen Aghajanyan, L. Yu, Alexis Conneau, Wei-Ning Hsu, Karen Hambardzumyan",
    "abstract": "Generative language models define distributions over sequences of tokens that can represent essentially any combination of data modalities (e.g., any permutation of image tokens from VQ-VAEs, speech tokens from HuBERT, BPE tokens for language or code, and so on). To better understand the scaling properties of such mixed-modal models, we conducted over 250 experiments using seven different modalities and model sizes ranging from 8 million to 30 billion, trained on 5-100 billion tokens. We report new mixed-modal scaling laws that unify the contributions of individual modalities and the interactions between them. Specifically, we explicitly model the optimal synergy and competition due to data and model size as an additive term to previous uni-modal scaling laws. We also find four empirical phenomena observed during the training, such as emergent coordinate-ascent style training that naturally alternates between modalities, guidelines for selecting critical hyper-parameters, and connections between mixed-modal competition and training stability. Finally, we test our scaling law by training a 30B speech-text model, which significantly outperforms the corresponding unimodal models. Overall, our research provides valuable insights into the design and training of mixed-modal generative models, an important new class of unified models that have unique distributional properties.",
    "citationCount": 135,
    "pdf_filename": "2023_Scaling_Laws_for_Generative_Mixed_Modal__468992bf.pdf"
  },
  "8e2212b7fa9ef3d9cd49cec1a6a6329fc36791af": {
    "paperId": "8e2212b7fa9ef3d9cd49cec1a6a6329fc36791af",
    "title": "Unifying the design space and optimizing linear and nonlinear truss metamaterials by generative modeling",
    "year": 2023,
    "authors": "Li Zheng, K. Karapiperis, Siddhant Kumar, D. Kochmann",
    "abstract": "The rise of machine learning has fueled the discovery of new materials and, especially, metamaterials—truss lattices being their most prominent class. While their tailorable properties have been explored extensively, the design of truss-based metamaterials has remained highly limited and often heuristic, due to the vast, discrete design space and the lack of a comprehensive parameterization. We here present a graph-based deep learning generative framework, which combines a variational autoencoder and a property predictor, to construct a reduced, continuous latent representation covering an enormous range of trusses. This unified latent space allows for the fast generation of new designs through simple operations (e.g., traversing the latent space or interpolating between structures). We further demonstrate an optimization framework for the inverse design of trusses with customized mechanical properties in both the linear and nonlinear regimes, including designs exhibiting exceptionally stiff, auxetic, pentamode-like, and tailored nonlinear behaviors. This generative model can predict manufacturable (and counter-intuitive) designs with extreme target properties beyond the training domain.",
    "citationCount": 128,
    "pdf_filename": "2023_Unifying_the_design_space_and_optimizing_8e2212b7.pdf"
  },
  "02aec976011a7d595d61db9639209968f4b93177": {
    "paperId": "02aec976011a7d595d61db9639209968f4b93177",
    "title": "When combinations of humans and AI are useful: A systematic review and meta-analysis",
    "year": 2024,
    "authors": "Michelle Vaccaro, Abdullah Almaatouq, Thomas W. Malone",
    "abstract": "Inspired by the increasing use of artificial intelligence (AI) to augment humans, researchers have studied human–AI systems involving different tasks, systems and populations. Despite such a large body of work, we lack a broad conceptual understanding of when combinations of humans and AI are better than either alone. Here we addressed this question by conducting a preregistered systematic review and meta-analysis of 106 experimental studies reporting 370 effect sizes. We searched an interdisciplinary set of databases (the Association for Computing Machinery Digital Library, the Web of Science and the Association for Information Systems eLibrary) for studies published between 1 January 2020 and 30 June 2023. Each study was required to include an original human-participants experiment that evaluated the performance of humans alone, AI alone and human–AI combinations. First, we found that, on average, human–AI combinations performed significantly worse than the best of humans or AI alone (Hedges’ g = −0.23; 95% confidence interval, −0.39 to −0.07). Second, we found performance losses in tasks that involved making decisions and significantly greater gains in tasks that involved creating content. Finally, when humans outperformed AI alone, we found performance gains in the combination, but when AI outperformed humans alone, we found losses. Limitations of the evidence assessed here include possible publication bias and variations in the study designs analysed. Overall, these findings highlight the heterogeneity of the effects of human–AI collaboration and point to promising avenues for improving human–AI systems. Vaccaro et al. present a systematic review and meta-analysis of the performance of human–AI combinations, finding that on average, human–AI combinations performed significantly worse than the best of humans or AI alone. They also found performance losses in decision-making tasks and significantly greater gains in content creation tasks.",
    "citationCount": 156,
    "pdf_filename": "2024_When_combinations_of_humans_and_AI_are_u_02aec976.pdf"
  },
  "36e21d8093361027088c1977ebaa2acf105c2b28": {
    "paperId": "36e21d8093361027088c1977ebaa2acf105c2b28",
    "title": "On Provable Copyright Protection for Generative Models",
    "year": 2023,
    "authors": "Nikhil Vyas, S. Kakade, B. Barak",
    "abstract": "There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data $C$ that was in their training set. We give a formal definition of $\\textit{near access-freeness (NAF)}$ and prove bounds on the probability that a model satisfying this definition outputs a sample similar to $C$, even if $C$ is included in its training set. Roughly speaking, a generative model $p$ is $\\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of $p$ diverges by at most $k$-bits from the output of a model $q$ that $\\textit{did not access $C$ at all}$. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models, showing minimal degradation in output quality while ensuring strong protections against sampling protected content.",
    "citationCount": 109,
    "pdf_filename": "2023_On_Provable_Copyright_Protection_for_Gen_36e21d80.pdf"
  },
  "32ae407d2e5002c54d31a94d8aed7fb5a1a455fe": {
    "paperId": "32ae407d2e5002c54d31a94d8aed7fb5a1a455fe",
    "title": "Distribution Bias Aware Collaborative Generative Adversarial Network for Imbalanced Deep Learning in Industrial IoT",
    "year": 2023,
    "authors": "Xiaokang Zhou, Yiyong Hu, Jiayi Wu, Wei Liang, Jianhua Ma",
    "abstract": "The impact of Internet of Things (IoT) has become increasingly significant in smart manufacturing, while deep generative model (DGM) is viewed as a promising learning technique to work with large amount of continuously generated industrial Big Data in facilitating modern industrial applications. However, it is still challenging to handle the imbalanced data when using conventional Generative Adversarial Network (GAN) based learning strategies. In this article, we propose a distribution bias aware collaborative GAN (DB-CGAN) model for imbalanced deep learning in industrial IoT, especially to solve limitations caused by distribution bias issue between the generated data and original data, via a more robust data augmentation. An integrated data augmentation framework is constructed by introducing a complementary classifier into the basic GAN model. Specifically, a conditional generator with random labels is designed and trained adversarially with the classifier to effectively enhance augmentation of the number of data samples in minority classes, while a weight sharing scheme is newly designed between two separated feature extractors, enabling the collaborative adversarial training among generator, discriminator, and classifier. An augmentation algorithm is then developed for intelligent anomaly detection in imbalanced learning, which can significantly improve the classification accuracy based on the correction of distribution bias using the rebalanced data. Compared with five baseline methods, experiment evaluations based on two real-world imbalanced datasets demonstrate the outstanding performance of our proposed model in tackling the distribution bias issue for multiclass classification in imbalanced learning for industrial IoT applications.",
    "citationCount": 115,
    "pdf_filename": "2023_Distribution_Bias_Aware_Collaborative_Ge_32ae407d.pdf"
  },
  "9b1367167e45bac5e039ba0407cb3329125e9ff2": {
    "paperId": "9b1367167e45bac5e039ba0407cb3329125e9ff2",
    "title": "Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?",
    "year": 2023,
    "authors": "Jaromir Savelka, Arav Agarwal, C. Bogart, Yifan Song, M. Sakr",
    "abstract": "We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (<70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (>55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.",
    "citationCount": 113,
    "pdf_filename": "2023_Can_Generative_Pre_trained_Transformers__9b136716.pdf"
  },
  "9f52317ea9c5a6804b978987ff2a6557f98b5b2c": {
    "paperId": "9f52317ea9c5a6804b978987ff2a6557f98b5b2c",
    "title": "SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks",
    "year": 2023,
    "authors": "Rui Zhu, Qihang Zhao, J. Eshraghian",
    "abstract": "As the size of large language models continue to scale, so does the computational resources required to run it. Spiking Neural Networks (SNNs) have emerged as an energy-efficient approach to deep learning that leverage sparse and event-driven activations to reduce the computational overhead associated with model inference. While they have become competitive with non-spiking models on many computer vision tasks, SNNs have also proven to be more challenging to train. As a result, their performance lags behind modern deep learning, and we are yet to see the effectiveness of SNNs in language generation. In this paper, inspired by the Receptance Weighted Key Value (RWKV) language model, we successfully implement `SpikeGPT', a generative language model with binary, event-driven spiking activation units. We train the proposed model on two model variants: 45M and 216M parameters. To the best of our knowledge, SpikeGPT is the largest backpropagation-trained SNN model to date, rendering it suitable for both the generation and comprehension of natural language. We achieve this by modifying the transformer block to replace multi-head self attention to reduce quadratic computational complexity O(N^2) to linear complexity O(N) with increasing sequence length. Input tokens are instead streamed in sequentially to our attention mechanism (as with typical SNNs). Our preliminary experiments show that SpikeGPT remains competitive with non-spiking models on tested benchmarks, while maintaining 20x fewer operations when processed on neuromorphic hardware that can leverage sparse, event-driven activations. Our code implementation is available at https://github.com/ridgerchu/SpikeGPT.",
    "citationCount": 111,
    "pdf_filename": "2023_SpikeGPT__Generative_Pre_trained_Languag_9f52317e.pdf"
  },
  "d9ff3db7a9e37fe0363bb87aa47acd6b6b67977e": {
    "paperId": "d9ff3db7a9e37fe0363bb87aa47acd6b6b67977e",
    "title": "GenRec: Large Language Model for Generative Recommendation",
    "year": 2023,
    "authors": "Jianchao Ji, Zelong Li, Shuyuan Xu, Wenyue Hua, Yingqiang Ge",
    "abstract": "In recent years, large language models (LLM) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommendation systems using large language models (LLMs) based on text data. In this paper, we present a novel LLM for generative recommendation (GenRec) that utilized the expressive power of LLM to directly generate the target item to recommend, rather than calculating ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendation. Our proposed approach leverages the vast knowledge encoded in large language models to accomplish recommendation tasks. We first we formulate specialized prompts to enhance the ability of LLM to comprehend recommendation tasks. Subsequently, we use these prompts to fine-tune the LLaMA backbone LLM on a dataset of user-item interactions, represented by textual data, to capture user preferences and item characteristics. Our research underscores the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems and offers a foundational framework for future explorations in this field. We conduct extensive experiments on benchmark datasets, and the experiments shows that our GenRec has significant better results on large dataset.",
    "citationCount": 101,
    "pdf_filename": "2023_GenRec__Large_Language_Model_for_Generat_d9ff3db7.pdf"
  },
  "f7e747c74705a42176c2cf196d4128a421e6f6b0": {
    "paperId": "f7e747c74705a42176c2cf196d4128a421e6f6b0",
    "title": "Chat Generative Pretrained Transformer Fails the Multiple-Choice American College of Gastroenterology Self-Assessment Test",
    "year": 2023,
    "authors": "Kelly Suchman, Shashank Garg, A. Trindade",
    "abstract": "INTRODUCTION: Chat Generative Pretrained Transformer (ChatGPT) is a natural language processing model that generates human-like text. METHODS: ChatGPT-3 and ChatGPT-4 were used to answer the 2022 and 2021 American College of Gastroenterology self-assessment tests. The exact questions were inputted in both versions of ChatGPT. A score of 70% or higher was required to pass the assessment. RESULTS: Overall, ChatGPT-3 scored 65.1% on 455 included questions and GPT-4 scored 62.4%. DISCUSSION: ChatGPT did not pass the American College of Gastroenterology self-assessment test. We do not recommend its use for medical education in gastroenterology in its current form.",
    "citationCount": 104,
    "pdf_filename": "2023_Chat_Generative_Pretrained_Transformer_F_f7e747c7.pdf"
  },
  "f8b90da7b61d9917a68e96c6faef51b4fe3d28f4": {
    "paperId": "f8b90da7b61d9917a68e96c6faef51b4fe3d28f4",
    "title": "The limits of fair medical imaging AI in real-world generalization",
    "year": 2024,
    "authors": "Yuzhe Yang, Haoran Zhang, J. Gichoya, Dina Katabi, Marzyeh Ghassemi",
    "abstract": "As artificial intelligence (AI) rapidly approaches human-level performance in medical imaging, it is crucial that it does not exacerbate or propagate healthcare disparities. Previous research established AI’s capacity to infer demographic data from chest X-rays, leading to a key concern: do models using demographic shortcuts have unfair predictions across subpopulations? In this study, we conducted a thorough investigation into the extent to which medical AI uses demographic encodings, focusing on potential fairness discrepancies within both in-distribution training sets and external test sets. Our analysis covers three key medical imaging disciplines—radiology, dermatology and ophthalmology—and incorporates data from six global chest X-ray datasets. We confirm that medical imaging AI leverages demographic shortcuts in disease classification. Although correcting shortcuts algorithmically effectively addresses fairness gaps to create ‘locally optimal’ models within the original data distribution, this optimality is not true in new test settings. Surprisingly, we found that models with less encoding of demographic attributes are often most ‘globally optimal’, exhibiting better fairness during model evaluation in new test environments. Our work establishes best practices for medical imaging models that maintain their performance and fairness in deployments beyond their initial training contexts, underscoring critical considerations for AI clinical deployments across populations and sites. When tested across tasks, diseases and imaging modalities, the performance of AI models depends on encoding of demographic shortcuts, and correcting for them decreases their ability to generalize in new populations.",
    "citationCount": 134,
    "pdf_filename": "2024_The_limits_of_fair_medical_imaging_AI_in_f8b90da7.pdf"
  },
  "0f41c28f58f929383079b4fd1258e1759fe765be": {
    "paperId": "0f41c28f58f929383079b4fd1258e1759fe765be",
    "title": "Teachers’ AI-TPACK: Exploring the Relationship between Knowledge Elements",
    "year": 2024,
    "authors": "Yimin Ning, Cheng Zhang, Binyan Xu, Ying Zhou, Tommy Tanu Wijaya",
    "abstract": "The profound impact of artificial intelligence (AI) on the modes of teaching and learning necessitates a reexamination of the interrelationships among technology, pedagogy, and subject matter. Given this context, we endeavor to construct a framework for integrating the Technological Pedagogical Content Knowledge of Artificial Intelligence Technology (Artificial Intelligence—Technological Pedagogical Content Knowledge, AI-TPACK) aimed at elucidating the complex interrelations and synergistic effects of AI technology, pedagogical methods, and subject-specific content in the field of education. The AI-TPACK framework comprises seven components: Pedagogical Knowledge (PK), Content Knowledge (CK), AI-Technological Knowledge (AI-TK), Pedagogical Content Knowledge (PCK), AI-Technological Pedagogical Knowledge (AI-TCK), AI-Technological Content Knowledge (AI-TPK), and AI-TPACK itself. We developed an effective structural equation modeling (SEM) approach to explore the relationships among teachers’ AI-TPACK knowledge elements through the utilization of exploratory factor analysis (EFA) and confirmatory factor analysis (CFA). The result showed that six knowledge elements all serve as predictive factors for AI-TPACK variables. However, different knowledge elements showed varying levels of explanatory power in relation to teachers’ AI-TPACK. The influence of core knowledge elements (PK, CK, and AI-TK) on AI-TPACK is indirect, mediated by composite knowledge elements (PCK, AI-TCK, and AI-TPK), each playing unique roles. Non-technical knowledge elements have significantly lower explanatory power for teachers of AI-TPACK compared to knowledge elements related to technology. Notably, content knowledge (C) diminishes the explanatory power of PCK and AI-TCK. This study investigates the relationships within the AI-TPACK framework and its constituent knowledge elements. The framework serves as a comprehensive guide for the large-scale assessment of teachers’ AI-TPACK, and a nuanced comprehension of the interplay among AI-TPACK elements contributes to a deeper understanding of the generative mechanisms underlying teachers’ AI-TPACK. Such insights bear significant implications for the sustainable development of teachers in the era of artificial intelligence.",
    "citationCount": 126,
    "pdf_filename": "2024_Teachers__AI_TPACK__Exploring_the_Relati_0f41c28f.pdf"
  },
  "a1081c6fc6921d6b76d9ebda4d712333fd7bbbf5": {
    "paperId": "a1081c6fc6921d6b76d9ebda4d712333fd7bbbf5",
    "title": "Large Language Models for Generative Recommendation: A Survey and Visionary Discussions",
    "year": 2023,
    "authors": "Lei Li, Yongfeng Zhang, Dugang Liu, L. Chen",
    "abstract": "Large language models (LLM) not only have revolutionized the field of natural language processing (NLP) but also have the potential to reshape many other fields, e.g., recommender systems (RS). However, most of the related work treats an LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor), which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages, such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods, and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS tasks. We hope that this survey can provide the context and guidance needed to explore this interesting and emerging topic.",
    "citationCount": 110,
    "pdf_filename": "2023_Large_Language_Models_for_Generative_Rec_a1081c6f.pdf"
  },
  "354ae953df2b8ecb364904ffa4fb59ec6e861d1f": {
    "paperId": "354ae953df2b8ecb364904ffa4fb59ec6e861d1f",
    "title": "Integrated Generative Model for Industrial Anomaly Detection via Bidirectional LSTM and Attention Mechanism",
    "year": 2023,
    "authors": "Fanhui Kong, Jianqiang Li, Bin Jiang, Huihui Wang, H. Song",
    "abstract": "For emerging industrial Internet of Things (IIoT), intelligent anomaly detection is a key step to build smart industry. Especially, explosive time-series data pose enormous challenges to the information mining and processing for modern industry. How to identify and detect the multidimensional industrial time-series anomaly is an important issue. However, most of the existing studies fail to handle with large amounts of unlabeled data, thus generating the undesirable results. In this article, we propose a novel integrated deep generative model, which is built by generative adversarial networks based on bidirectional long short-term memory and attention mechanism (AMBi-GAN). The structure for the generator and the discriminator is the bidirectional long short-term memory with attention mechanism, which can capture time-series dependence. Reconstruction loss and generation loss test the input of sample training space and random latent space. Experimental results show that the detection performance of our proposed AMBi-GAN has the potential to improve the detection accuracy of industrial multidimensional time-series anomaly toward IIoT in the era of artificial intelligence.",
    "citationCount": 102,
    "pdf_filename": "2023_Integrated_Generative_Model_for_Industri_354ae953.pdf"
  },
  "568a93409f91e959b075ffee9435204b4f15569c": {
    "paperId": "568a93409f91e959b075ffee9435204b4f15569c",
    "title": "Generative Cooperative Learning for Unsupervised Video Anomaly Detection",
    "year": 2022,
    "authors": "M. Zaheer, Arif Mahmood, M. H. Khan, Mattia Segu, F. Yu",
    "abstract": "Video anomaly detection is well investigated in weakly-supervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach.",
    "citationCount": 179,
    "pdf_filename": "2022_Generative_Cooperative_Learning_for_Unsu_568a9340.pdf"
  },
  "8fa4f6b5232868c2e400670716540f6877068439": {
    "paperId": "8fa4f6b5232868c2e400670716540f6877068439",
    "title": "Scalable emulation of protein equilibrium ensembles with generative deep learning",
    "year": 2025,
    "authors": "Sarah Lewis, Tim Hempel, José Jiménez-Luna, Michael Gastegger, Yu Xie",
    "abstract": "Following the sequence and structure revolutions, predicting the dynamical mechanisms of proteins that implement biological function remains an outstanding scientific challenge. Several experimental techniques and molecular dynamics (MD) simulations can, in principle, determine conformational states, binding configurations and their probabilities, but suffer from low throughput. Here we develop a Biomolecular Emulator (BioEmu), a generative deep learning system that can generate thousands of statistically independent samples from the protein structure ensemble per hour on a single graphical processing unit. By leveraging novel training methods and vast data of protein structures, over 200 milliseconds of MD simulation, and experimental protein stabilities, BioEmu’s protein ensembles represent equilibrium in a range of challenging and practically relevant metrics. Qualitatively, BioEmu samples many functionally relevant conformational changes, ranging from formation of cryptic pockets, over unfolding of specific protein regions, to large-scale domain rearrangements. Quantitatively, BioEmu samples protein conformations with relative free energy errors around 1 kcal/mol, as validated against millisecond-timescale MD simulation and experimentally-measured protein stabilities. By simultaneously emulating structural ensembles and thermodynamic properties, BioEmu reveals mechanistic insights, such as the causes for fold destabilization of mutants, and can efficiently provide experimentally-testable hypotheses.",
    "citationCount": 125,
    "pdf_filename": "2025_Scalable_emulation_of_protein_equilibriu_8fa4f6b5.pdf"
  },
  "14e5357df60cb2200881085f60bac6f99026ed15": {
    "paperId": "14e5357df60cb2200881085f60bac6f99026ed15",
    "title": "Generative",
    "year": 2025,
    "authors": "Lea Bishop",
    "abstract": ". This article is an edited transcription of two conversations at Birkbeck College, London, in February 1987. Its primary concern is a transdisciplinary consciousness that refuses to comply with the tendency toward reductionism and simplification. Some of the problems the dialogue explores are (1) the notion of order (with particular reference to Bohm’s recent reflections on the concept of the generative order), (2) the limits of knowledge and the concept of the Absolute, (3) the nature of perceptive or intuitive reason, (4) the relation between matter and mind",
    "citationCount": 123,
    "pdf_filename": "2025_Generative_14e5357d.pdf"
  },
  "e8a72d29771d1a33b4a0e43c74adcee6c73d74c7": {
    "paperId": "e8a72d29771d1a33b4a0e43c74adcee6c73d74c7",
    "title": "End-to-end Generative Pretraining for Multimodal Video Captioning",
    "year": 2022,
    "authors": "P. H. Seo, Arsha Nagrani, Anurag Arnab, C. Schmid",
    "abstract": "Recent video and language pretraining frameworks lack the ability to generate sentences. We present Multimodal Video Generative Pretraining (MV-GPT), a new pretraining framework for learning from unlabelled videos which can be effectively used for generative tasks such as multimodal video captioning. Unlike recent video-language pretraining frameworks, our framework trains both a multimodal video encoder and a sentence decoder jointly. To overcome the lack of captions in unlabelled videos, we leverage the future utterance as an additional text source and propose a bidirectional generation objective - we generate future utterances given the present mulitmodal context, and also the present utterance given future observations. With this objective, we train an encoder-decoder model end-to-end to generate a caption from raw pixels and transcribed speech directly. Our model achieves state-of the-art performance for multimodal video captioning on four standard benchmarks, as well as for other video understanding tasks such as VideoQA, video retrieval and action classification.",
    "citationCount": 184,
    "pdf_filename": "2022_End_to_end_Generative_Pretraining_for_Mu_e8a72d29.pdf"
  },
  "dae32f073c218bc0c2f20a442848d00f3e049ad0": {
    "paperId": "dae32f073c218bc0c2f20a442848d00f3e049ad0",
    "title": "Convergence of score-based generative modeling for general data distributions",
    "year": 2022,
    "authors": "Holden Lee, Jianfeng Lu, Yixin Tan",
    "abstract": "Score-based generative modeling (SGM) has grown to be a hugely successful method for learning to generate samples from complex data distributions such as that of images and audio. It is based on evolving an SDE that transforms white noise into a sample from the learned distribution, using estimates of the score function, or gradient log-pdf. Previous convergence analyses for these methods have suffered either from strong assumptions on the data distribution or exponential dependencies, and hence fail to give efficient guarantees for the multimodal and non-smooth distributions that arise in practice and for which good empirical performance is observed. We consider a popular kind of SGM -- denoising diffusion models -- and give polynomial convergence guarantees for general data distributions, with no assumptions related to functional inequalities or smoothness. Assuming $L^2$-accurate score estimates, we obtain Wasserstein distance guarantees for any distribution of bounded support or sufficiently decaying tails, as well as TV guarantees for distributions with further smoothness assumptions.",
    "citationCount": 165,
    "pdf_filename": "2022_Convergence_of_score_based_generative_mo_dae32f07.pdf"
  },
  "594a35bf04aab5ed95528e88ced5ec683d7d560a": {
    "paperId": "594a35bf04aab5ed95528e88ced5ec683d7d560a",
    "title": "Diffusion-SDF: Conditional Generative Modeling of Signed Distance Functions",
    "year": 2022,
    "authors": "Gene Chou, Yuval Bahat, Felix Heide",
    "abstract": "Probabilistic diffusion models have achieved state-of-the-art results for image synthesis, inpainting, and text-to-image tasks. However, they are still in the early stages of generating complex 3D shapes. This work proposes Diffusion-SDF, a generative model for shape completion, single-view reconstruction, and reconstruction of real-scanned point clouds. We use neural signed distance functions (SDFs) as our 3D representation to parameterize the geometry of various signals (e.g., point clouds, 2D images) through neural networks. Neural SDFs are implicit functions and diffusing them amounts to learning the reversal of their neural network weights, which we solve using a custom modulation module. Extensive experiments show that our method is capable of both realistic unconditional generation and conditional generation from partial inputs. This work expands the domain of diffusion models from learning 2D, explicit representations, to 3D, implicit representations. Code is released at https://github.com/princeton-computational-imaging/Diffusion-SDF.",
    "citationCount": 147,
    "pdf_filename": "2022_Diffusion_SDF__Conditional_Generative_Mo_594a35bf.pdf"
  },
  "2a43f920e4f1f869a9db402a50135f9f8df06f32": {
    "paperId": "2a43f920e4f1f869a9db402a50135f9f8df06f32",
    "title": "A multimodal comparison of latent denoising diffusion probabilistic models and generative adversarial networks for medical image synthesis",
    "year": 2022,
    "authors": "Gustav Müller-Franzes, J. Niehues, Firas Khader, Soroosh Tayebi Arasteh, Christoph Haarburger",
    "abstract": "Although generative adversarial networks (GANs) can produce large datasets, their limited diversity and fidelity have been recently addressed by denoising diffusion probabilistic models, which have demonstrated superiority in natural image synthesis. In this study, we introduce Medfusion, a conditional latent DDPM designed for medical image generation, and evaluate its performance against GANs, which currently represent the state-of-the-art. Medfusion was trained and compared with StyleGAN-3 using fundoscopy images from the AIROGS dataset, radiographs from the CheXpert dataset, and histopathology images from the CRCDX dataset. Based on previous studies, Progressively Growing GAN (ProGAN) and Conditional GAN (cGAN) were used as additional baselines on the CheXpert and CRCDX datasets, respectively. Medfusion exceeded GANs in terms of diversity (recall), achieving better scores of 0.40 compared to 0.19 in the AIROGS dataset, 0.41 compared to 0.02 (cGAN) and 0.24 (StyleGAN-3) in the CRMDX dataset, and 0.32 compared to 0.17 (ProGAN) and 0.08 (StyleGAN-3) in the CheXpert dataset. Furthermore, Medfusion exhibited equal or higher fidelity (precision) across all three datasets. Our study shows that Medfusion constitutes a promising alternative to GAN-based models for generating high-quality medical images, leading to improved diversity and less artifacts in the generated images.",
    "citationCount": 153,
    "pdf_filename": "2022_A_multimodal_comparison_of_latent_denois_2a43f920.pdf"
  },
  "d877831e4c8e8c775f8e642fdfc53e93a7ec4cde": {
    "paperId": "d877831e4c8e8c775f8e642fdfc53e93a7ec4cde",
    "title": "Application of generative adversarial networks (GAN) for ophthalmology image domains: a survey",
    "year": 2022,
    "authors": "Aram You, Jin Kuk Kim, I. Ryu, T. Yoo",
    "abstract": "Background Recent advances in deep learning techniques have led to improved diagnostic abilities in ophthalmology. A generative adversarial network (GAN), which consists of two competing types of deep neural networks, including a generator and a discriminator, has demonstrated remarkable performance in image synthesis and image-to-image translation. The adoption of GAN for medical imaging is increasing for image generation and translation, but it is not familiar to researchers in the field of ophthalmology. In this work, we present a literature review on the application of GAN in ophthalmology image domains to discuss important contributions and to identify potential future research directions. Methods We performed a survey on studies using GAN published before June 2021 only, and we introduced various applications of GAN in ophthalmology image domains. The search identified 48 peer-reviewed papers in the final review. The type of GAN used in the analysis, task, imaging domain, and the outcome were collected to verify the usefulness of the GAN. Results In ophthalmology image domains, GAN can perform segmentation, data augmentation, denoising, domain transfer, super-resolution, post-intervention prediction, and feature extraction. GAN techniques have established an extension of datasets and modalities in ophthalmology. GAN has several limitations, such as mode collapse, spatial deformities, unintended changes, and the generation of high-frequency noises and artifacts of checkerboard patterns. Conclusions The use of GAN has benefited the various tasks in ophthalmology image domains. Based on our observations, the adoption of GAN in ophthalmology is still in a very early stage of clinical validation compared with deep learning classification techniques because several problems need to be overcome for practical use. However, the proper selection of the GAN technique and statistical modeling of ocular imaging will greatly improve the performance of each image analysis. Finally, this survey would enable researchers to access the appropriate GAN technique to maximize the potential of ophthalmology datasets for deep learning research.",
    "citationCount": 162,
    "pdf_filename": "2022_Application_of_generative_adversarial_ne_d877831e.pdf"
  },
  "c9561b15c25ca781ccf1a384e978e28341bac0e4": {
    "paperId": "c9561b15c25ca781ccf1a384e978e28341bac0e4",
    "title": "State-specific protein–ligand complex structure prediction with a multiscale deep generative model",
    "year": 2022,
    "authors": "Zhuoran Qiao, Weili Nie, Arash Vahdat, Thomas F. Miller, Anima Anandkumar",
    "abstract": "The binding complexes formed by proteins and small molecule ligands are ubiquitous and critical to life. Despite recent advancements in protein structure prediction, existing algorithms are so far unable to systematically predict the binding ligand structures along with their regulatory effects on protein folding. To address this discrepancy, we present NeuralPLexer, a computational approach that can directly predict protein–ligand complex structures solely using protein sequence and ligand molecular graph inputs. NeuralPLexer adopts a deep generative model to sample the three-dimensional structures of the binding complex and their conformational changes at an atomistic resolution. The model is based on a diffusion process that incorporates essential biophysical constraints and a multiscale geometric deep learning system to iteratively sample residue-level contact maps and all heavy-atom coordinates in a hierarchical manner. NeuralPLexer achieves state-of-the-art performance compared with all existing methods on benchmarks for both protein–ligand blind docking and flexible binding-site structure recovery. Moreover, owing to its specificity in sampling both ligand-free-state and ligand-bound-state ensembles, NeuralPLexer consistently outperforms AlphaFold2 in terms of global protein structure accuracy on both representative structure pairs with large conformational changes and recently determined ligand-binding proteins. NeuralPLexer predictions align with structure determination experiments for important targets in enzyme engineering and drug discovery, suggesting its potential for accelerating the design of functional proteins and small molecules at the proteome scale. Great advances in protein structure prediction have been made with recent deep learning-based methods, but proteins interact with their environment and can change shape drastically when binding to ligand molecules. To predict the 3D structure of these combined protein–ligand complexes, Qiao et al. developed a generative diffusion model with biophysical constraints and geometric deep learning.",
    "citationCount": 131,
    "pdf_filename": "2022_State_specific_protein_ligand_complex_st_c9561b15.pdf"
  },
  "33b1dbf1ad913047b919cd090907ffc4199b4178": {
    "paperId": "33b1dbf1ad913047b919cd090907ffc4199b4178",
    "title": "GRiT: A Generative Region-to-text Transformer for Object Understanding",
    "year": 2022,
    "authors": "Jialian Wu, Jianfeng Wang, Zhengyuan Yang, Zhe Gan, Zicheng Liu",
    "abstract": "This paper presents a Generative RegIon-to-Text transformer, GRiT, for object understanding. The spirit of GRiT is to formulate object understanding aspairs, where region locates objects and text describes objects. For example, the text in object detection denotes class names while that in dense captioning refers to descriptive sentences. Specifically, GRiT consists of a visual encoder to extract image features, a foreground object extractor to localize objects, and a text decoder to generate open-set object descriptions. With the same model architecture, GRiT can understand objects via not only simple nouns, but also rich descriptive sentences including object attributes or actions. Experimentally, we apply GRiT to object detection and dense captioning tasks. GRiT achieves 60.4 AP on COCO 2017 test-dev for object detection and 15.5 mAP on Visual Genome for dense captioning. Code is available at https://github.com/JialianW/GRiT",
    "citationCount": 144,
    "pdf_filename": "2022_GRiT__A_Generative_Region_to_text_Transf_33b1dbf1.pdf"
  },
  "2808b8bf0508dc0890a4f765afb95496b45d758a": {
    "paperId": "2808b8bf0508dc0890a4f765afb95496b45d758a",
    "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars",
    "year": 2022,
    "authors": "Jingxiang Sun, Xuanxia Wang, Lizhen Wang, Xiaoyu Li, Yong Zhang",
    "abstract": "3D-aware generative adversarial networks (GANs) synthesize high-fidelity and multi-view-consistent facial images using only collections of single-view 2D imagery. Towards fine-grained control over facial attributes, recent efforts incorporate 3D Morphable Face Model (3DMM) to describe deformation in generative radiance fields either explicitly or implicitly. Explicit methods provide fine-grained expression control but cannot handle topological changes caused by hair and accessories, while implicit ones can model varied topologies but have limited generalization caused by the unconstrained deformation fields. We propose a novel 3D GAN framework for unsupervised learning of generative, high-quality and 3D-consistent facial avatars from unstructured 2D images. To achieve both deformation accuracy and topological flexibility, we propose a 3D representation called Generative Texture-Rasterized Tri-planes. The proposed representation learns Generative Neural Textures on top of parametric mesh templates and then projects them into three orthogonal-viewed feature planes through rasterization, forming a tri-plane feature representation for volume rendering. In this way, we combine both fine-grained expression control of mesh-guided explicit deformation and the flexibility of implicit volumetric representation. We further propose specific modules for modeling mouth interior which is not taken into account by 3DMM. Our method demonstrates state-of-the-art 3D-aware synthesis quality and animation ability through extensive experiments. Furthermore, serving as 3D prior, our animatable 3D representation boosts multiple applications including one-shot facial avatars and 3D-aware stylization. Project page: https://mrtornado24.github.io/Next3D/. Code: https://github.com/MrTornado24/Next3D.",
    "citationCount": 141,
    "pdf_filename": "2022_Next3D__Generative_Neural_Texture_Raster_2808b8bf.pdf"
  },
  "2f8bb30ba639cb1ca5349fbcbd86b09aea20b082": {
    "paperId": "2f8bb30ba639cb1ca5349fbcbd86b09aea20b082",
    "title": "TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network",
    "year": 2022,
    "authors": "Xiaomin Li, V. Metsis, Huan Wang, Anne H. H. Ngu",
    "abstract": "Signal measurements appearing in the form of time series are one of the most common types of data used in medical machine learning applications. However, such datasets are often small, making the training of deep neural network architectures ineffective. For time-series, the suite of data augmentation tricks we can use to expand the size of the dataset is limited by the need to maintain the basic properties of the signal. Data generated by a Generative Adversarial Network (GAN) can be utilized as another data augmentation tool. RNN-based GANs suffer from the fact that they cannot effectively model long sequences of data points with irregular temporal relations. To tackle these problems, we introduce TTS-GAN, a transformer-based GAN which can successfully generate realistic synthetic time-series data sequences of arbitrary length, similar to the real ones. Both the generator and discriminator networks of the GAN model are built using a pure transformer encoder architecture. We use visualizations and dimensionality reduction techniques to demonstrate the similarity of real and generated time-series data. We also compare the quality of our generated data with the best existing alternative, which is an RNN-based time-series GAN.",
    "citationCount": 132,
    "pdf_filename": "2022_TTS_GAN__A_Transformer_based_Time_Series_2f8bb30b.pdf"
  },
  "1446c8483411ca5654cd6fb0bc584f43e032a425": {
    "paperId": "1446c8483411ca5654cd6fb0bc584f43e032a425",
    "title": "A survey on deep learning applied to medical images: from simple artificial neural networks to generative models",
    "year": 2022,
    "authors": "P. Celard, E. L. Iglesias, José Manuel Sorribes-Fdez, R. Romero, A. S. Vieira",
    "abstract": "Deep learning techniques, in particular generative models, have taken on great importance in medical image analysis. This paper surveys fundamental deep learning concepts related to medical image generation. It provides concise overviews of studies which use some of the latest state-of-the-art models from last years applied to medical images of different injured body areas or organs that have a disease associated with (e.g., brain tumor and COVID-19 lungs pneumonia). The motivation for this study is to offer a comprehensive overview of artificial neural networks (NNs) and deep generative models in medical imaging, so more groups and authors that are not familiar with deep learning take into consideration its use in medicine works. We review the use of generative models, such as generative adversarial networks and variational autoencoders, as techniques to achieve semantic segmentation, data augmentation, and better classification algorithms, among other purposes. In addition, a collection of widely used public medical datasets containing magnetic resonance (MR) images, computed tomography (CT) scans, and common pictures is presented. Finally, we feature a summary of the current state of generative models in medical image including key features, current challenges, and future research paths.",
    "citationCount": 132,
    "pdf_filename": "2022_A_survey_on_deep_learning_applied_to_med_1446c848.pdf"
  },
  "f52b9bc98ba8327ccf90802bb02d1a06acaabd59": {
    "paperId": "f52b9bc98ba8327ccf90802bb02d1a06acaabd59",
    "title": "Generative Joint Source-Channel Coding for Semantic Image Transmission",
    "year": 2022,
    "authors": "Ece Naz Erdemir, Tze-Yang Tung, P. Dragotti, Deniz Gunduz",
    "abstract": "Recent works have shown that joint source-channel coding (JSCC) schemes using deep neural networks (DNNs), called DeepJSCC, provide promising results in wireless image transmission. However, these methods mostly focus on the distortion of the reconstructed signals with respect to the input image, rather than their perception by humans. However, focusing on traditional distortion metrics alone does not necessarily result in high perceptual quality, especially in extreme physical conditions, such as very low bandwidth compression ratio (BCR) and low signal-to-noise ratio (SNR) regimes. In this work, we propose two novel JSCC schemes that leverage the perceptual quality of deep generative models (DGMs) for wireless image transmission, namely InverseJSCC and GenerativeJSCC. While the former is an inverse problem approach to DeepJSCC, the latter is an end-to-end optimized JSCC scheme. In both, we optimize a weighted sum of mean squared error (MSE) and learned perceptual image patch similarity (LPIPS) losses, which capture more semantic similarities than other distortion metrics. InverseJSCC performs denoising on the distorted reconstructions of a DeepJSCC model by solving an inverse optimization problem using the pre-trained style-based generative adversarial network (StyleGAN). Our simulation results show that InverseJSCC significantly improves the state-of-the-art DeepJSCC in terms of perceptual quality in edge cases. In GenerativeJSCC, we carry out end-to-end training of an encoder and a StyleGAN-based decoder, and show that GenerativeJSCC significantly outperforms DeepJSCC both in terms of distortion and perceptual quality.",
    "citationCount": 123,
    "pdf_filename": "2022_Generative_Joint_Source_Channel_Coding_f_f52b9bc9.pdf"
  },
  "0ec562656013a6f4b7d9c20bdc558e21740d3e7e": {
    "paperId": "0ec562656013a6f4b7d9c20bdc558e21740d3e7e",
    "title": "Self-Supervised Attentive Generative Adversarial Networks for Video Anomaly Detection",
    "year": 2022,
    "authors": "Chao Huang, Jie Wen, Yong Xu, Qiuping Jiang, Jian Yang",
    "abstract": "Video anomaly detection (VAD) refers to the discrimination of unexpected events in videos. The deep generative model (DGM)-based method learns the regular patterns on normal videos and expects the learned model to yield larger generative errors for abnormal frames. However, DGM cannot always do so, since it usually captures the shared patterns between normal and abnormal events, which results in similar generative errors for them. In this article, we propose a novel self-supervised framework for unsupervised VAD to tackle the above-mentioned problem. To this end, we design a novel self-supervised attentive generative adversarial network (SSAGAN), which is composed of the self-attentive predictor, the vanilla discriminator, and the self-supervised discriminator. On the one hand, the self-attentive predictor can capture the long-term dependences for improving the prediction qualities of normal frames. On the other hand, the predicted frames are fed to the vanilla discriminator and self-supervised discriminator for performing true–false discrimination and self-supervised rotation detection, respectively. Essentially, the role of the self-supervised task is to enable the predictor to encode semantic information into the predicted normal frames via adversarial training, in order for the angles of rotated normal frames can be detected. As a result, our self-supervised framework lessens the generalization ability of the model to abnormal frames, resulting in larger detection errors for abnormal frames. Extensive experimental results indicate that SSAGAN outperforms other state-of-the-art methods, which demonstrates the validity and advancement of SSAGAN.",
    "citationCount": 120,
    "pdf_filename": "2022_Self_Supervised_Attentive_Generative_Adv_0ec56265.pdf"
  },
  "4b245fa98da7cbb173c6495a0c038f8b8e41d158": {
    "paperId": "4b245fa98da7cbb173c6495a0c038f8b8e41d158",
    "title": "Poisson Flow Generative Models",
    "year": 2022,
    "authors": "Yilun Xu, Ziming Liu, M. Tegmark, T. Jaakkola",
    "abstract": "We propose a new\"Poisson flow\"generative model (PFGM) that maps a uniform distribution on a high-dimensional hemisphere into any data distribution. We interpret the data points as electrical charges on the $z=0$ hyperplane in a space augmented with an additional dimension $z$, generating a high-dimensional electric field (the gradient of the solution to Poisson equation). We prove that if these charges flow upward along electric field lines, their initial distribution in the $z=0$ plane transforms into a distribution on the hemisphere of radius $r$ that becomes uniform in the $r \\to\\infty$ limit. To learn the bijective transformation, we estimate the normalized field in the augmented space. For sampling, we devise a backward ODE that is anchored by the physically meaningful additional dimension: the samples hit the unaugmented data manifold when the $z$ reaches zero. Experimentally, PFGM achieves current state-of-the-art performance among the normalizing flow models on CIFAR-10, with an Inception score of $9.68$ and a FID score of $2.35$. It also performs on par with the state-of-the-art SDE approaches while offering $10\\times $ to $20 \\times$ acceleration on image generation tasks. Additionally, PFGM appears more tolerant of estimation errors on a weaker network architecture and robust to the step size in the Euler method. The code is available at https://github.com/Newbeeer/poisson_flow .",
    "citationCount": 106,
    "pdf_filename": "2022_Poisson_Flow_Generative_Models_4b245fa9.pdf"
  },
  "2d056d6ee49382059f44439906003e1ec72b42f5": {
    "paperId": "2d056d6ee49382059f44439906003e1ec72b42f5",
    "title": "Score-Based Generative Models Detect Manifolds",
    "year": 2022,
    "authors": "Jakiw Pidstrigach",
    "abstract": "Score-based generative models (SGMs) need to approximate the scores $\\nabla \\log p_t$ of the intermediate distributions as well as the final distribution $p_T$ of the forward process. The theoretical underpinnings of the effects of these approximations are still lacking. We find precise conditions under which SGMs are able to produce samples from an underlying (low-dimensional) data manifold $\\mathcal{M}$. This assures us that SGMs are able to generate the\"right kind of samples\". For example, taking $\\mathcal{M}$ to be the subset of images of faces, we find conditions under which the SGM robustly produces an image of a face, even though the relative frequencies of these images might not accurately represent the true data generating distribution. Moreover, this analysis is a first step towards understanding the generalization properties of SGMs: Taking $\\mathcal{M}$ to be the set of all training samples, our results provide a precise description of when the SGM memorizes its training data.",
    "citationCount": 106,
    "pdf_filename": "2022_Score_Based_Generative_Models_Detect_Man_2d056d6e.pdf"
  },
  "6fca4e69d8d7fec0b1fe118e769017b3610d1bd5": {
    "paperId": "6fca4e69d8d7fec0b1fe118e769017b3610d1bd5",
    "title": "A survey of multimodal deep generative models",
    "year": 2022,
    "authors": "Masahiro Suzuki, Y. Matsuo",
    "abstract": "Multimodal learning is a framework for building models that make predictions based on different types of modalities. Important challenges in multimodal learning are the inference of shared representations from arbitrary modalities and cross-modal generation via these representations; however, achieving this requires taking the heterogeneous nature of multimodal data into account. In recent years, deep generative models, i.e. generative models in which distributions are parameterized by deep neural networks, have attracted much attention, especially variational autoencoders, which are suitable for accomplishing the above challenges because they can consider heterogeneity and infer good representations of data. Therefore, various multimodal generative models based on variational autoencoders, called multimodal deep generative models, have been proposed in recent years. In this paper, we provide a categorized survey of studies on multimodal deep generative models. GRAPHICAL ABSTRACT",
    "citationCount": 104,
    "pdf_filename": "2022_A_survey_of_multimodal_deep_generative_m_6fca4e69.pdf"
  },
  "332921119e9f8d038c5047d4be6ad564da630eea": {
    "paperId": "332921119e9f8d038c5047d4be6ad564da630eea",
    "title": "Federated Learning of Generative Image Priors for MRI Reconstruction",
    "year": 2022,
    "authors": "Gokberk Elmas, S. Dar, Yilmaz Korkmaz, Emir Ceyani, Burak Susam",
    "abstract": "Multi-institutional efforts can facilitate training of deep MRI reconstruction models, albeit privacy risks arise during cross-site sharing of imaging data. Federated learning (FL) has recently been introduced to address privacy concerns by enabling distributed training without transfer of imaging data. Existing FL methods employ conditional reconstruction models to map from undersampled to fully-sampled acquisitions via explicit knowledge of the accelerated imaging operator. Since conditional models generalize poorly across different acceleration rates or sampling densities, imaging operators must be fixed between training and testing, and they are typically matched across sites. To improve patient privacy, performance and flexibility in multi-site collaborations, here we introduce Federated learning of Generative IMage Priors (FedGIMP) for MRI reconstruction. FedGIMP leverages a two-stage approach: cross-site learning of a generative MRI prior, and prior adaptation following injection of the imaging operator. The global MRI prior is learned via an unconditional adversarial model that synthesizes high-quality MR images based on latent variables. A novel mapper subnetwork produces site-specific latents to maintain specificity in the prior. During inference, the prior is first combined with subject-specific imaging operators to enable reconstruction, and it is then adapted to individual cross-sections by minimizing a data-consistency loss. Comprehensive experiments on multi-institutional datasets clearly demonstrate enhanced performance of FedGIMP against both centralized and FL methods based on conditional models.",
    "citationCount": 109,
    "pdf_filename": "2022_Federated_Learning_of_Generative_Image_P_33292111.pdf"
  },
  "381cd9310de773a8f77c5bd51b8d40d45a8a2742": {
    "paperId": "381cd9310de773a8f77c5bd51b8d40d45a8a2742",
    "title": "Fault Detection in Gears Using Fault Samples Enlarged by a Combination of Numerical Simulation and a Generative Adversarial Network",
    "year": 2022,
    "authors": "Yun Gao, Xiao-Yang Liu, J. Xiang",
    "abstract": "It is inevitable for gear to become damaged, which has a profound effect on the performance of gear transmission systems. Solving the problem of gear fault detection using artificial intelligence models depends on sufficient fault samples, though they might not always exist. A new method using numerical simulation and a generative adversarial network (GAN) is proposed to enlarge fault samples for detecting faults in gears. First, to supplement the missing fault samples, numerical simulation is employed to obtain simulation fault samples. Then, simulation and measurement fault samples are input into the GAN to generate synthetic fault samples to enlarge the training samples. Finally, the simulation, measurement and related synthetic fault samples serve as typical classifiers, including convolutional neural network, recurrent neural network, and stacked autoencoder, while the test samples of unknown faults are finally detected. Three experimental groups are designed to classify gear faults. The average classification accuracy is 100, 98.83, and 97.64%, which confirms the feasibility and effectiveness of the method for detecting gear faults using incomplete fault samples. The idea presented herein is expected to apply in any type of mechanical system that has the corresponding well-constructed numerical simulation model.",
    "citationCount": 103,
    "pdf_filename": "2022_Fault_Detection_in_Gears_Using_Fault_Sam_381cd931.pdf"
  },
  "3c054fadd359e3cf20e16e8fb5852cbc9c8721ce": {
    "paperId": "3c054fadd359e3cf20e16e8fb5852cbc9c8721ce",
    "title": "A comprehensive literature review of the applications of AI techniques through the lifecycle of industrial equipment",
    "year": 2023,
    "authors": "M. Elahi, Samuel Olaiya Afolaranmi, J. L. M. Lastra, J. A. P. García",
    "abstract": "Driven by the ongoing migration towards Industry 4.0, the increasing adoption of artificial intelligence (AI) has empowered smart manufacturing and digital transformation. AI enhances the migration towards industry 4.0 through AI-based decision-making by analyzing real-time data to optimize different processes such as production planning, predictive maintenance, quality control etc., thus guaranteeing reduced costs, high precision, efficiency and accuracy. This paper explores AI-driven smart manufacturing, revolutionizing traditional approaches and unlocking new possibilities throughout the major phases of the industrial equipment lifecycle. Through a comprehensive review, we delve into a wide range of AI techniques employed to tackle challenges such as optimizing process control, machining parameters, facilitating decision-making, and elevating maintenance strategies within the major phases of an industrial equipment lifecycle. These phases encompass design, manufacturing, maintenance, and recycling/retrofitting. As reported in the 2022 McKinsey Global Survey (https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review), the adoption of AI has witnessed more than a two-fold increase since 2017. This has contributed to an increase in AI research within the last six years. Therefore, from a meticulous search of relevant electronic databases, we carefully selected and synthesized 42 articles spanning from 01 January 2017 to 20 May 2023 to highlight and review the most recent research, adhering to specific inclusion and exclusion criteria, and shedding light on the latest trends and popular AI techniques adopted by researchers. This includes AI techniques such as Convolutional Neural Networks (CNN), Generative Adversarial Networks (GAN), Bayesian Networks, Support Vector Machines (SVM) etc., which are extensively discussed in this paper. Additionally, we provide insights into the advantages (e.g., enhanced decision making) and challenges (e.g., AI integration with legacy systems due to technical complexities and compatibilities) of integrating AI across the major stages of industrial equipment operations. Strategically implementing AI techniques in each phase enables industries to achieve enhanced productivity, improved product quality, cost-effectiveness, and sustainability. This exploration of the potential of AI in smart manufacturing fosters agile and resilient processes, keeping industries at the forefront of technological advancements and harnessing the full potential of AI-driven solutions to improve manufacturing processes and products.",
    "citationCount": 169,
    "pdf_filename": "2023_A_comprehensive_literature_review_of_the_3c054fad.pdf"
  },
  "5ba33ee9858ce38ccd89171dfe2d1025d392f24e": {
    "paperId": "5ba33ee9858ce38ccd89171dfe2d1025d392f24e",
    "title": "Intelligent structural design of shear wall residence using physics‐enhanced generative adversarial networks",
    "year": 2022,
    "authors": "Xinzheng Lu, Wenjie Liao, Yu Zhang, Yuli Huang",
    "abstract": "Intelligent structural design using generative adversarial networks (GANs) is a revolutionary design approach for building structures. Despite its far‐reaching capability, the data quantity and quality may have limited the performance of such a data‐driven network. This study proposes to enhance the objectiveness of training processes by innovatively introducing a surrogate model, Physics Estimator, that informs the generator by appraising the physical behavior of the generated design. Dual loss functions evaluated by a traditional data‐driven discriminator and the Physics Estimator collaboratively foster the physics‐enhanced GAN architecture. We further develop a structural mechanics model to train and optimize the inherent accuracy of the Physics Estimator. The comparative study suggests that the proposed physics‐enhanced GAN can generate structural designs from architectural drawings and specified design conditions 44% better than a data‐driven design method and 90 times faster than a competent engineer.",
    "citationCount": 109,
    "pdf_filename": "2022_Intelligent_structural_design_of_shear_w_5ba33ee9.pdf"
  },
  "9b71083d7fba168e250b47b54a17e91b387a73e1": {
    "paperId": "9b71083d7fba168e250b47b54a17e91b387a73e1",
    "title": "Artificial intelligence in innovation management: A review of innovation capabilities and a taxonomy of AI applications",
    "year": 2023,
    "authors": "Fábio Gama, S. Magistretti",
    "abstract": "Artificial intelligence (AI) is a promising generation of digital technologies. Recent applications and research suggest that AI can not only influence but also accelerate innovation in organizations. However, as the field is rapidly growing, a common understanding of the underlying theoretical capabilities has become increasingly vague and fraught with ambiguity. In view of the centrality of innovation capabilities in making innovation happen, we bring together these scattered perspectives in a systematic and multidisciplinary literature review. The aim of this literature review is to summarize the role of AI in influencing innovation capabilities and provide a taxonomy of AI applications based on empirical studies. Drawing on the technological–organizational–environmental (TOE) framework, our review condenses the research findings of 62 studies. The results of our study are twofold. First, we identify a dichotomous view of innovation capabilities triggered by AI adoption: enabling and enhancing. The enabling capabilities are those that research identifies as enablers of AI adoption, underscoring the competencies and routines needed to implement AI. The enhancing capabilities denote the role that AI adoption has in transforming or creating innovation capabilities in organizations. Second, we propose a taxonomy of AI applications that reflects the practical adoption of AI in relation to three underlying reasons: replace, reinforce, and reveal. Our study makes three main contributions. First, we identify the innovation capabilities that are either required for or generated by AI adoption. Second, we propose a taxonomy of AI applications. Third, we use the TOE framework to track trends in the theoretical contributions of recent articles and propose a research agenda.",
    "citationCount": 154,
    "pdf_filename": "2023_Artificial_intelligence_in_innovation_ma_9b71083d.pdf"
  },
  "a45bde4fafe66475cd542477d6bb034e273aa8dc": {
    "paperId": "a45bde4fafe66475cd542477d6bb034e273aa8dc",
    "title": "ChatGPT in education: global reactions to AI innovations",
    "year": 2023,
    "authors": "Tim Fütterer, Christian Fischer, Anastasiia Alekseeva, Xiaobin Chen, Tamara P. Tate",
    "abstract": "The release and rapid diffusion of ChatGPT have caught the attention of educators worldwide. Some educators are enthusiastic about its potential to support learning. Others are concerned about how it might circumvent learning opportunities or contribute to misinformation. To better understand reactions about ChatGPT concerning education, we analyzed Twitter data (16,830,997 tweets from 5,541,457 users). Based on topic modeling and sentiment analysis, we provide an overview of global perceptions and reactions to ChatGPT regarding education. ChatGPT triggered a massive response on Twitter, with education being the most tweeted content topic. Topics ranged from specific (e.g., cheating) to broad (e.g., opportunities), which were discussed with mixed sentiment. We traced that authority decisions may influence public opinions. We discussed that the average reaction on Twitter (e.g., using ChatGPT to cheat in exams) differs from discussions in which education and teaching–learning researchers are likely to be more interested (e.g., ChatGPT as an intelligent learning partner). This study provides insights into people's reactions when new groundbreaking technology is released and implications for scientific and policy communication in rapidly changing circumstances.",
    "citationCount": 154,
    "pdf_filename": "2023_ChatGPT_in_education__global_reactions_t_a45bde4f.pdf"
  },
  "53c259d967556e95c1b6e02727021ffab395738a": {
    "paperId": "53c259d967556e95c1b6e02727021ffab395738a",
    "title": "Artificial Intelligence in studies—use of ChatGPT and AI-based tools among students in Germany",
    "year": 2023,
    "authors": "Jörg von Garrel, Jana Mayer",
    "abstract": "AI-based tools such as ChatGPT and GPT-4 are currently changing the university landscape and in many places, the consequences for future forms of teaching and examination are already being discussed. In order to create an empirical basis for this, a nationwide survey of students was carried out in order to analyse the use and possible characteristics of AI-based tools that are important to students. The aim of the quantitative study is to be able to draw conclusions about how students use such AI tools. A total of more than 6300 students across Germany took part in the anonymous survey. The results of this quantitative analysis make it clear that almost two-thirds of the students surveyed use or have used AI-based tools as part of their studies. In this context, almost half of the students explicitly mention ChatGPT or GPT-4 as a tool they use. Students of engineering sciences, mathematics and natural sciences use AI-based tools most frequently. A differentiated examination of the usage behaviour makes it clear that students use AI-based tools in a variety of ways. Clarifying questions of understanding and explaining subject-specific concepts are the most relevant reasons for use in this context.",
    "citationCount": 146,
    "pdf_filename": "2023_Artificial_Intelligence_in_studies_use_o_53c259d9.pdf"
  },
  "2e414cd64b85ed3361f516e605a12d01132ed1e7": {
    "paperId": "2e414cd64b85ed3361f516e605a12d01132ed1e7",
    "title": "Using AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including Prompts",
    "year": 2023,
    "authors": "Ethan Mollick, Lilach Mollick",
    "abstract": ": This paper provides guidance for using AI to quickly and easily implement evidence-based teaching strategies that instructors can integrate into their teaching. We discuss five teaching strategies that have proven value but are hard to implement in practice due to time and effort constraints. We show how AI can help instructors create material that supports these strategies and improve student learning. The strategies include providing multiple examples and explanations; uncovering and addressing student misconceptions; frequent low-stakes testing; assessing student learning; and distributed practice. The paper provides guidelines for how AI can support each strategy, and discusses both the promises and perils of this approach, arguing that AI may act as a “force multiplier” for instructors if implemented cautiously and thoughtfully in service of evidence-based teaching practices.",
    "citationCount": 147,
    "pdf_filename": "2023_Using_AI_to_Implement_Effective_Teaching_2e414cd6.pdf"
  },
  "1bc9974780230573bfe9f89789115cb4fbf8bfc6": {
    "paperId": "1bc9974780230573bfe9f89789115cb4fbf8bfc6",
    "title": "Prompting AI Art: An Investigation into the Creative Skill of Prompt Engineering",
    "year": 2023,
    "authors": "J. Oppenlaender, Rhema Linder, Johanna M. Silvennoinen",
    "abstract": "Abstract We are witnessing a novel era of creativity where anyone can create digital content via prompt-based learning (known as prompt engineering). This article investigates prompt engineering as a novel creative skill for creating AI art with text-to-image generation. In three consecutive studies, we explore whether crowdsourced participants can (1) discern prompt quality, (2) write prompts, and (3) refine prompts. We find that participants could evaluate prompt quality and crafted descriptive prompts, but they lacked style-specific vocabulary necessary for effective prompting. This is in line with our hypothesis that prompt engineering is a new type of skill that is non-intuitive and must first be acquired (e.g., through means of practice and learning) before it can be used at a level of high quality. Our studies deepen our understanding of prompt engineering and chart future research directions. We conclude by envisioning four potential futures for prompt engineering.",
    "citationCount": 138,
    "pdf_filename": "2023_Prompting_AI_Art__An_Investigation_into__1bc99747.pdf"
  },
  "c427b655b3aca580d636583dd7efbe621b7b001c": {
    "paperId": "c427b655b3aca580d636583dd7efbe621b7b001c",
    "title": "From ethical AI frameworks to tools: a review of approaches",
    "year": 2023,
    "authors": "E. Prem",
    "abstract": "In reaction to concerns about a broad range of potential ethical issues, dozens of proposals for addressing ethical aspects of artificial intelligence (AI) have been published. However, many of them are too abstract for being easily translated into concrete designs for AI systems. The various proposed ethical frameworks can be considered an instance of principlism that is similar to that found in medical ethics. Given their general nature, principles do not say how they should be applied in a particular context. Hence, a broad range of approaches, methods, and tools have been proposed for addressing ethical concerns of AI systems. This paper presents a systematic analysis of more than 100 frameworks, process models, and proposed remedies and tools for helping to make the necessary shift from principles to implementation, expanding on the work of Morley and colleagues. This analysis confirms a strong focus of proposed approaches on only a few ethical issues such as explicability, fairness, privacy, and accountability. These issues are often addressed with proposals for software and algorithms. Other, more general ethical issues are mainly addressed with conceptual frameworks, guidelines, or process models. This paper develops a structured list and definitions of approaches, presents a refined segmentation of the AI development process, and suggests areas that will require more attention from researchers and developers.",
    "citationCount": 134,
    "pdf_filename": "2023_From_ethical_AI_frameworks_to_tools__a_r_c427b655.pdf"
  },
  "6aa1e50aff42da67933e549ba7c7c46ace652ec2": {
    "paperId": "6aa1e50aff42da67933e549ba7c7c46ace652ec2",
    "title": "Assigning AI: Seven Approaches for Students, with Prompts",
    "year": 2023,
    "authors": "Ethan Mollick, Lilach Mollick",
    "abstract": "This paper examines the transformative role of Large Language Models (LLMs) in education and their potential as learning tools, despite their inherent risks and limitations. The authors propose seven approaches for utilizing AI in classrooms: AI-tutor, AI-coach, AI-mentor, AI-teammate, AI-tool, AI-simulator, and AI-student, each with distinct pedagogical benefits and risks. The aim is to help students learn with and about AI, with practical strategies designed to mitigate risks such as complacency about the AI's output, errors, and biases. These strategies promote active oversight, critical assessment of AI outputs, and complementarity of AI's capabilities with the students' unique insights. By challenging students to remain the\"human in the loop,\"the authors aim to enhance learning outcomes while ensuring that AI serves as a supportive tool rather than a replacement. The proposed framework offers a guide for educators navigating the integration of AI-assisted learning in classrooms",
    "citationCount": 126,
    "pdf_filename": "2023_Assigning_AI__Seven_Approaches_for_Stude_6aa1e50a.pdf"
  },
  "e27be0d4f964713229f665a0a335efed8fbd42c9": {
    "paperId": "e27be0d4f964713229f665a0a335efed8fbd42c9",
    "title": "Gradient Inversion with Generative Image Prior",
    "year": 2021,
    "authors": "Jinwoo Jeon, Jaechang Kim, Kangwook Lee, Sewoong Oh, Jungseul Ok",
    "abstract": "Federated Learning (FL) is a distributed learning framework, in which the local data never leaves clients devices to preserve privacy, and the server trains models on the data via accessing only the gradients of those local data. Without further privacy mechanisms such as differential privacy, this leaves the system vulnerable against an attacker who inverts those gradients to reveal clients sensitive data. However, a gradient is often insufficient to reconstruct the user data without any prior knowledge. By exploiting a generative model pretrained on the data distribution, we demonstrate that data privacy can be easily breached. Further, when such prior knowledge is unavailable, we investigate the possibility of learning the prior from a sequence of gradients seen in the process of FL training. We experimentally show that the prior in a form of generative model is learnable from iterative interactions in FL. Our findings strongly suggest that additional mechanisms are necessary to prevent privacy leakage in FL.",
    "citationCount": 182,
    "pdf_filename": "2021_Gradient_Inversion_with_Generative_Image_e27be0d4.pdf"
  },
  "8cff9612111ed99b909c151d312e68639345eefa": {
    "paperId": "8cff9612111ed99b909c151d312e68639345eefa",
    "title": "Chemistry42: An AI-Driven Platform for Molecular Design and Optimization",
    "year": 2023,
    "authors": "Y. Ivanenkov, Daniil Polykovskiy, Dmitry Bezrukov, B. Zagribelnyy, V. Aladinskiy",
    "abstract": "Chemistry42 is a software platform for de novo small molecule design and optimization that integrates Artificial Intelligence (AI) techniques with computational and medicinal chemistry methodologies. Chemistry42 efficiently generates novel molecular structures with optimized properties validated in both in vitro and in vivo studies and is available through licensing or collaboration. Chemistry42 is the core component of Insilico Medicine’s Pharma.ai drug discovery suite. Pharma.ai also includes PandaOmics for target discovery and multiomics data analysis, and inClinico—a data-driven multimodal forecast of a clinical trial’s probability of success (PoS). In this paper, we demonstrate how the platform can be used to efficiently find novel molecular structures against DDR1 and CDK20.",
    "citationCount": 125,
    "pdf_filename": "2023_Chemistry42__An_AI_Driven_Platform_for_M_8cff9612.pdf"
  },
  "ca5dfab165f0f080350f02d4eea451a55c2aa8ce": {
    "paperId": "ca5dfab165f0f080350f02d4eea451a55c2aa8ce",
    "title": "A Call to Address AI “Hallucinations” and How Healthcare Professionals Can Mitigate Their Risks",
    "year": 2023,
    "authors": "Rami Hatem, Brianna Simmons, Joseph E Thornton",
    "abstract": "Artificial intelligence (AI) has transformed society in many ways. AI in medicine has the potential to improve medical care and reduce healthcare professional burnout but we must be cautious of a phenomenon termed \"AI hallucinations\"and how this term can lead to the stigmatization of AI systems and persons who experience hallucinations. We believe the term \"AI misinformation\" to be more appropriate and avoids contributing to stigmatization. Healthcare professionals can play an important role in AI’s integration into medicine, especially regarding mental health services, so it is important that we continue to critically evaluate AI systems as they emerge.",
    "citationCount": 109,
    "pdf_filename": "2023_A_Call_to_Address_AI__Hallucinations__an_ca5dfab1.pdf"
  },
  "31ec1a15c74c6f7c81267fee25c4687431bbb34d": {
    "paperId": "31ec1a15c74c6f7c81267fee25c4687431bbb34d",
    "title": "AI and the quest for diversity and inclusion: a systematic literature review",
    "year": 2023,
    "authors": "R. Shams, Didar Zowghi, Muneera Bano",
    "abstract": "The pervasive presence and wide-ranging variety of artificial intelligence (AI) systems underscore the necessity for inclusivity and diversity in their design and implementation, to effectively address critical issues of fairness, trust, bias, and transparency. However, diversity and inclusion (D&I) considerations are significantly neglected in AI systems design, development, and deployment. Ignoring D&I in AI systems can cause digital redlining, discrimination, and algorithmic oppression, leading to AI systems being perceived as untrustworthy and unfair. Therefore, we conducted a systematic literature review (SLR) to identify the challenges and their corresponding solutions (guidelines/ strategies/ approaches/ practices) about D&I in AI and about the applications of AI for D&I practices. Through a rigorous search and selection, 48 relevant academic papers published from 2017 to 2022 were identified. By applying open coding on the extracted data from the selected papers, we identified 55 unique challenges and 33 unique solutions in addressing D&I in AI. We also identified 24 unique challenges and 23 unique solutions for enhancing D&I practices by AI. The result of our analysis and synthesis of the selected studies contributes to a deeper understanding of diversity and inclusion issues and considerations in the design, development and deployment of the AI ecosystem. The findings would play an important role in enhancing awareness and attracting the attention of researchers and practitioners in their quest to embed D&I principles and practices in future AI systems. This study also identifies important gaps in the research literature that will inspire future direction for researchers.",
    "citationCount": 100,
    "pdf_filename": "2023_AI_and_the_quest_for_diversity_and_inclu_31ec1a15.pdf"
  },
  "54e1278d65513b124fd58379529efbc3deae6414": {
    "paperId": "54e1278d65513b124fd58379529efbc3deae6414",
    "title": "AI Chatbots, Health Privacy, and Challenges to HIPAA Compliance.",
    "year": 2023,
    "authors": "Mason Marks, C. E. Haupt",
    "abstract": "\n        This Viewpoint examines the privacy concerns raised by medical uses of large language models, such as chatbots.\n      ",
    "citationCount": 109,
    "pdf_filename": "2023_AI_Chatbots__Health_Privacy__and_Challen_54e1278d.pdf"
  },
  "e0ff5f0a1cfe6c66d903f8b6afb46a673b4f97ad": {
    "paperId": "e0ff5f0a1cfe6c66d903f8b6afb46a673b4f97ad",
    "title": "A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education",
    "year": 2023,
    "authors": "J. Doughty, Zipiao Wan, Anishka Bompelli, Jubahed Qayum, Taozhi Wang",
    "abstract": "There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models (LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.",
    "citationCount": 101,
    "pdf_filename": "2023_A_Comparative_Study_of_AI_Generated__GPT_e0ff5f0a.pdf"
  },
  "57c4e8877bde057f50601d1bf7ddd24364d5e048": {
    "paperId": "57c4e8877bde057f50601d1bf7ddd24364d5e048",
    "title": "Towards Vivid and Diverse Image Colorization with Generative Color Prior",
    "year": 2021,
    "authors": "Yanze Wu, Xintao Wang, Yu Li, Honglun Zhang, Xun Zhao",
    "abstract": "Colorization has attracted increasing interest in recent years. Classic reference-based methods usually rely on external color images for plausible results. A large image database or online search engine is inevitably required for retrieving such exemplars. Recent deep-learning-based methods could automatically colorize images at a low cost. However, unsatisfactory artifacts and incoherent colors are always accompanied. In this work, we aim at recovering vivid colors by leveraging the rich and diverse color priors encapsulated in a pretrained Generative Adversarial Networks (GAN). Specifically, we first \"retrieve\" matched features (similar to exemplars) via a GAN encoder and then incorporate these features into the colorization process with feature modulations. Thanks to the powerful generative color prior and delicate designs, our method could produce vivid colors with a single forward pass. Moreover, it is highly convenient to obtain diverse results by modifying GAN latent codes. Our method also inherits the merit of interpretable controls of GANs and could attain controllable and smooth transitions by walking through GAN latent space. Extensive experiments and user studies demonstrate that our method achieves superior performance than previous works.",
    "citationCount": 117,
    "pdf_filename": "2021_Towards_Vivid_and_Diverse_Image_Coloriza_57c4e887.pdf"
  },
  "011fbfe79c738b84c1bfcdabcd752977524b1363": {
    "paperId": "011fbfe79c738b84c1bfcdabcd752977524b1363",
    "title": "Counterfactual Generative Networks",
    "year": 2021,
    "authors": "Axel Sauer, Andreas Geiger",
    "abstract": "Neural networks are prone to learning shortcuts -- they often model simple correlations, ignoring more complex ones that potentially generalize better. Prior works on image classification show that instead of learning a connection to object shape, deep classifiers tend to exploit spurious correlations with low-level texture or the background for solving the classification task. In this work, we take a step towards more robust and interpretable classifiers that explicitly expose the task's causal structure. Building on current advances in deep generative modeling, we propose to decompose the image generation process into independent causal mechanisms that we train without direct supervision. By exploiting appropriate inductive biases, these mechanisms disentangle object shape, object texture, and background; hence, they allow for generating counterfactual images. We demonstrate the ability of our model to generate such images on MNIST and ImageNet. Further, we show that the counterfactual images can improve out-of-distribution robustness with a marginal drop in performance on the original classification task, despite being synthetic. Lastly, our generative model can be trained efficiently on a single GPU, exploiting common pre-trained models as inductive biases.",
    "citationCount": 140,
    "pdf_filename": "2021_Counterfactual_Generative_Networks_011fbfe7.pdf"
  },
  "fc0b21675cc7ec8d9cd39c3ca5257008bbcec4df": {
    "paperId": "fc0b21675cc7ec8d9cd39c3ca5257008bbcec4df",
    "title": "Generative Models as a Data Source for Multiview Representation Learning",
    "year": 2021,
    "authors": "Ali Jahanian, Xavier Puig, Yonglong Tian, Phillip Isola",
    "abstract": "Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple\"views\"of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We find that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more\"model zoos\"proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.",
    "citationCount": 140,
    "pdf_filename": "2021_Generative_Models_as_a_Data_Source_for_M_fc0b2167.pdf"
  },
  "65b20b3e6f81f6567e41e353a47a2380c6cc4b77": {
    "paperId": "65b20b3e6f81f6567e41e353a47a2380c6cc4b77",
    "title": "Text-Free Prosody-Aware Generative Spoken Language Modeling",
    "year": 2021,
    "authors": "E. Kharitonov, Ann Lee, Adam Polyak, Yossi Adi, Jade Copet",
    "abstract": "Speech pre-training has primarily demonstrated efficacy on classification tasks, while its capability of generating novel speech, similar to how GPT-2 can generate coherent paragraphs, has barely been explored. Generative Spoken Language Modeling (GSLM) (CITATION) is the only prior work addressing the generative aspect of speech pre-training, which builds a text-free language model using discovered units. Unfortunately, because the units used in GSLM discard most prosodic information, GSLM fails to leverage prosody for better comprehension and does not generate expressive speech. In this work, we present a prosody-aware generative spoken language model (pGSLM). It is composed of a multi-stream transformer language model (MS-TLM) of speech, represented as discovered unit and prosodic feature streams, and an adapted HiFi-GAN model converting MS-TLM outputs to waveforms. Experimental results show that the pGSLM can utilize prosody to improve both prosody and content modeling, and also generate natural, meaningful, and coherent speech given a spoken prompt. Audio samples can be found at https://speechbot.github.io/pgslm. Codes and models are available at https://github.com/pytorch/fairseq/tree/main/examples/textless_nlp/pgslm.",
    "citationCount": 136,
    "pdf_filename": "2021_Text_Free_Prosody_Aware_Generative_Spoke_65b20b3e.pdf"
  },
  "0b5c5c0e5172d3e5c09c23240d083b99c01a2fc9": {
    "paperId": "0b5c5c0e5172d3e5c09c23240d083b99c01a2fc9",
    "title": "Understanding Failures in Out-of-Distribution Detection with Deep Generative Models",
    "year": 2021,
    "authors": "Lily H. Zhang, Mark Goldstein, R. Ranganath",
    "abstract": "Deep generative models (dgms) seem a natural fit for detecting out-of-distribution (ood) inputs, but such models have been shown to assign higher probabilities or densities to ood images than images from the training distribution. In this work, we explain why this behavior should be attributed to model misestimation. We first prove that no method can guarantee performance beyond random chance without assumptions on which out-distributions are relevant. We then interrogate the typical set hypothesis, the claim that relevant out-distributions can lie in high likelihood regions of the data distribution, and that ood detection should be defined based on the data distribution's typical set. We highlight the consequences implied by assuming support overlap between in- and out-distributions, as well as the arbitrariness of the typical set for ood detection. Our results suggest that estimation error is a more plausible explanation than the misalignment between likelihood-based ood detection and out-distributions of interest, and we illustrate how even minimal estimation error can lead to ood detection failures, yielding implications for future work in deep generative modeling and ood detection.",
    "citationCount": 116,
    "pdf_filename": "2021_Understanding_Failures_in_Out_of_Distrib_0b5c5c0e.pdf"
  },
  "16ada2930cf765df96781125e2ad9b679ba00f23": {
    "paperId": "16ada2930cf765df96781125e2ad9b679ba00f23",
    "title": "GRNN: Generative Regression Neural Network—A Data Leakage Attack for Federated Learning",
    "year": 2021,
    "authors": "Hanchi Ren, Jingjing Deng, Xianghua Xie",
    "abstract": "Data privacy has become an increasingly important issue in Machine Learning (ML), where many approaches have been developed to tackle this challenge, e.g., cryptography (Homomorphic Encryption (HE), Differential Privacy (DP)) and collaborative training (Secure Multi-Party Computation (MPC), Distributed Learning, and Federated Learning (FL)). These techniques have a particular focus on data encryption or secure local computation. They transfer the intermediate information to the third party to compute the final result. Gradient exchanging is commonly considered to be a secure way of training a robust model collaboratively in Deep Learning (DL). However, recent researches have demonstrated that sensitive information can be recovered from the shared gradient. Generative Adversarial Network (GAN), in particular, has shown to be effective in recovering such information. However, GAN based techniques require additional information, such as class labels that are generally unavailable for privacy-preserved learning. In this article, we show that, in the FL system, image-based privacy data can be easily recovered in full from the shared gradient only via our proposed Generative Regression Neural Network (GRNN). We formulate the attack to be a regression problem and optimize two branches of the generative model by minimizing the distance between gradients. We evaluate our method on several image classification tasks. The results illustrate that our proposed GRNN outperforms state-of-the-art methods with better stability, stronger robustness, and higher accuracy. It also has no convergence requirement to the global FL model. Moreover, we demonstrate information leakage using face re-identification. Some defense strategies are also discussed in this work.",
    "citationCount": 119,
    "pdf_filename": "2021_GRNN__Generative_Regression_Neural_Netwo_16ada293.pdf"
  },
  "1d41857ba8e0e8286268989036cd138a1f8ca372": {
    "paperId": "1d41857ba8e0e8286268989036cd138a1f8ca372",
    "title": "Generative Models as Distributions of Functions",
    "year": 2021,
    "authors": "Emilien Dupont, Y. Teh, A. Doucet",
    "abstract": "Generative models are typically trained on grid-like data such as images. As a result, the size of these models usually scales directly with the underlying grid resolution. In this paper, we abandon discretized grids and instead parameterize individual data points by continuous functions. We then build generative models by learning distributions over such functions. By treating data points as functions, we can abstract away from the specific type of data we train on and construct models that are agnostic to discretization. To train our model, we use an adversarial approach with a discriminator that acts on continuous signals. Through experiments on a wide variety of data modalities including images, 3D shapes and climate data, we demonstrate that our model can learn rich distributions of functions independently of data type and resolution.",
    "citationCount": 112,
    "pdf_filename": "2021_Generative_Models_as_Distributions_of_Fu_1d41857b.pdf"
  },
  "8406e7ef77277a79468badc37549eb7df1030d1a": {
    "paperId": "8406e7ef77277a79468badc37549eb7df1030d1a",
    "title": "A Review of Generative Adversarial Networks (GANs) and Its Applications in a Wide Variety of Disciplines: From Medical to Remote Sensing",
    "year": 2021,
    "authors": "Ankan Dash, J. Ye, Guiling Wang",
    "abstract": "We look into Generative Adversarial Network (GAN), its prevalent variants and applications in a number of sectors. GANs combine two neural networks that compete against one another using zero-sum game theory, allowing them to create much crisper and discrete outputs. GANs can be used to perform image processing, video generation and prediction, among other computer vision applications. GANs can also be utilised for a variety of science-related activities, including protein engineering, astronomical data processing, remote sensing image dehazing, and crystal structure synthesis. Other notable fields where GANs have made gains include finance, marketing, fashion design, sports, and music. Therefore in this article we provide a comprehensive overview of the applications of GANs in a wide variety of disciplines. We first cover the theory supporting GAN, GAN variants, and the metrics to evaluate GANs. Then we present how GAN and its variants can be applied in twelve domains, ranging from STEM fields, such as astronomy and biology, to business fields, such as marketing and finance, and to arts, such as music. As a result, researchers from other fields may grasp how GANs work and apply them to their own study. To the best of our knowledge, this article provides the most comprehensive survey of GAN’s applications in different field.",
    "citationCount": 132,
    "pdf_filename": "2021_A_Review_of_Generative_Adversarial_Netwo_8406e7ef.pdf"
  },
  "7f4c17cde1da6f7af2d8596f51a6e3e5041a3312": {
    "paperId": "7f4c17cde1da6f7af2d8596f51a6e3e5041a3312",
    "title": "Molecular design in drug discovery: a comprehensive review of deep generative models",
    "year": 2021,
    "authors": "Yu Cheng, Yongshun Gong, Yuansheng Liu, Bosheng Song, Q. Zou",
    "abstract": "Deep generative models have been an upsurge in the deep learning community since they were proposed. These models are designed for generating new synthetic data including images, videos and texts by fitting the data approximate distributions. In the last few years, deep generative models have shown superior performance in drug discovery especially de novo molecular design. In this study, deep generative models are reviewed to witness the recent advances of de novo molecular design for drug discovery. In addition, we divide those models into two categories based on molecular representations in silico. Then these two classical types of models are reported in detail and discussed about both pros and cons. We also indicate the current challenges in deep generative models for de novo molecular design. De novo molecular design automatically is promising but a long road to be explored.",
    "citationCount": 127,
    "pdf_filename": "2021_Molecular_design_in_drug_discovery__a_co_7f4c17cd.pdf"
  },
  "b57555b882c8ad14371fa7b41ed87e711ecd570d": {
    "paperId": "b57555b882c8ad14371fa7b41ed87e711ecd570d",
    "title": "Generative Deep Learning for Targeted Compound Design",
    "year": 2021,
    "authors": "Tiago Sousa, João Correia, Vítor Pereira, Miguel Rocha",
    "abstract": "In the past few years, de novo molecular design has increasingly been using generative models from the emergent field of Deep Learning, proposing novel compounds that are likely to possess desired properties or activities. De novo molecular design finds applications in different fields ranging from drug discovery and materials sciences to biotechnology. A panoply of deep generative models, including architectures as Recurrent Neural Networks, Autoencoders, and Generative Adversarial Networks, can be trained on existing data sets and provide for the generation of novel compounds. Typically, the new compounds follow the same underlying statistical distributions of properties exhibited on the training data set Additionally, different optimization strategies, including transfer learning, Bayesian optimization, reinforcement learning, and conditional generation, can direct the generation process toward desired aims, regarding their biological activities, synthesis processes or chemical features. Given the recent emergence of these technologies and their relevance, this work presents a systematic and critical review on deep generative models and related optimization methods for targeted compound design, and their applications.",
    "citationCount": 125,
    "pdf_filename": "2021_Generative_Deep_Learning_for_Targeted_Co_b57555b8.pdf"
  },
  "bd2474ed458a3dbb32d68a6dd08293b47b759e95": {
    "paperId": "bd2474ed458a3dbb32d68a6dd08293b47b759e95",
    "title": "Creating artificial human genomes using generative neural networks",
    "year": 2021,
    "authors": "Burak Yelmen, A. Decelle, L. Ongaro, Davide Marnetto, Corentin Tallec",
    "abstract": "Generative models have shown breakthroughs in a wide spectrum of domains due to recent advancements in machine learning algorithms and increased computational power. Despite these impressive achievements, the ability of generative models to create realistic synthetic data is still under-exploited in genetics and absent from population genetics. Yet a known limitation in the field is the reduced access to many genetic databases due to concerns about violations of individual privacy, although they would provide a rich resource for data mining and integration towards advancing genetic studies. In this study, we demonstrated that deep generative adversarial networks (GANs) and restricted Boltzmann machines (RBMs) can be trained to learn the complex distributions of real genomic datasets and generate novel high-quality artificial genomes (AGs) with none to little privacy loss. We show that our generated AGs replicate characteristics of the source dataset such as allele frequencies, linkage disequilibrium, pairwise haplotype distances and population structure. Moreover, they can also inherit complex features such as signals of selection. To illustrate the promising outcomes of our method, we showed that imputation quality for low frequency alleles can be improved by data augmentation to reference panels with AGs and that the RBM latent space provides a relevant encoding of the data, hence allowing further exploration of the reference dataset and features for solving supervised tasks. Generative models and AGs have the potential to become valuable assets in genetic studies by providing a rich yet compact representation of existing genomes and high-quality, easy-access and anonymous alternatives for private databases.",
    "citationCount": 112,
    "pdf_filename": "2021_Creating_artificial_human_genomes_using__bd2474ed.pdf"
  },
  "8173a29c18d5a71ec48338af50c268781dd82d8f": {
    "paperId": "8173a29c18d5a71ec48338af50c268781dd82d8f",
    "title": "Continuous missing data imputation with incomplete dataset by generative adversarial networks–based unsupervised learning for long-term bridge health monitoring",
    "year": 2021,
    "authors": "Huachen Jiang, C. Wan, Kangzhen Yang, You-liang Ding, Songtao Xue",
    "abstract": "Wireless sensors are the key components of structural health monitoring systems. During the signal transmission, sensor failure is inevitable, among which, data loss is the most common type. Missing data problem poses a huge challenge to the consequent damage detection and condition assessment, and therefore, great importance should be attached. Conventional missing data imputation basically adopts the correlation-based method, especially for strain monitoring data. However, such methods often require delicate model selection, and the correlations for vehicle-induced strains are much harder to be captured compared with temperature-induced strains. In this article, a novel data-driven generative adversarial network (GAN) for imputing missing strain response is proposed. As opposed to traditional ways where correlations for inter-strains are explicitly modeled, the proposed method directly imputes the missing data considering the spatial–temporal relationships with other strain sensors based on the remaining observed data. Furthermore, the intact and complete dataset is not even necessary during the training process, which shows another great superiority over the model-based imputation method. The proposed method is implemented and verified on a real concrete bridge. In order to demonstrate the applicability and robustness of the GAN, imputation for single and multiple sensors is studied. Results show the proposed method provides an excellent performance of imputation accuracy and efficiency.",
    "citationCount": 105,
    "pdf_filename": "2021_Continuous_missing_data_imputation_with__8173a29c.pdf"
  },
  "2ee460b329c0987b52793b84f7ac35cb4a547475": {
    "paperId": "2ee460b329c0987b52793b84f7ac35cb4a547475",
    "title": "Operationalizing and Implementing Pretrained, Large Artificial Intelligence Linguistic Models in the US Health Care System: Outlook of Generative Pretrained Transformer 3 (GPT-3) as a Service Model",
    "year": 2021,
    "authors": "Emre Sezgin, J. Sirrianni, S. Linwood",
    "abstract": "Generative pretrained transformer models have been popular recently due to their enhanced capabilities and performance. In contrast to many existing artificial intelligence models, generative pretrained transformer models can perform with very limited training data. Generative pretrained transformer 3 (GPT-3) is one of the latest releases in this pipeline, demonstrating human-like logical and intellectual responses to prompts. Some examples include writing essays, answering complex questions, matching pronouns to their nouns, and conducting sentiment analyses. However, questions remain with regard to its implementation in health care, specifically in terms of operationalization and its use in clinical practice and research. In this viewpoint paper, we briefly introduce GPT-3 and its capabilities and outline considerations for its implementation and operationalization in clinical practice through a use case. The implementation considerations include (1) processing needs and information systems infrastructure, (2) operating costs, (3) model biases, and (4) evaluation metrics. In addition, we outline the following three major operational factors that drive the adoption of GPT-3 in the US health care system: (1) ensuring Health Insurance Portability and Accountability Act compliance, (2) building trust with health care providers, and (3) establishing broader access to the GPT-3 tools. This viewpoint can inform health care practitioners, developers, clinicians, and decision makers toward understanding the use of the powerful artificial intelligence tools integrated into hospital systems and health care.",
    "citationCount": 101,
    "pdf_filename": "2021_Operationalizing_and_Implementing_Pretra_2ee460b3.pdf"
  },
  "ba960d5b53f3795be5d9600da2adea63754bfc9f": {
    "paperId": "ba960d5b53f3795be5d9600da2adea63754bfc9f",
    "title": "Few-Shot Generative Conversational Query Rewriting",
    "year": 2020,
    "authors": "S. Yu, Jiahua Liu, Jingqin Yang, Chenyan Xiong, Paul N. Bennett",
    "abstract": "Conversational query rewriting aims to reformulate a concise conversational query to a fully specified, context-independent query that can be effectively handled by existing information retrieval systems. This paper presents a few-shot generative approach to conversational query rewriting. We develop two methods, based on rules and self-supervised learning, to generate weak supervision data using large amounts of ad hoc search sessions, and to fine-tune GPT-2 to rewrite conversational queries. On the TREC Conversational Assistance Track, our weakly supervised GPT-2 rewriter improves the state-of-the-art ranking accuracy by 12%, only using very limited amounts of manual query rewrites. In the zero-shot learning setting, the rewriter still gives a comparable result to previous state-of-the-art systems. Our analyses reveal that GPT-2 effectively picks up the task syntax and learns to capture context dependencies, even for hard cases that involve group references and long-turn dependencies.",
    "citationCount": 171,
    "pdf_filename": "2020_Few_Shot_Generative_Conversational_Query_ba960d5b.pdf"
  },
  "2c5dba61816bc607a91fa44da7407620561cd985": {
    "paperId": "2c5dba61816bc607a91fa44da7407620561cd985",
    "title": "DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation",
    "year": 2020,
    "authors": "Alexandre Carlier, Martin Danelljan, Alexandre Alahi, Radu Timofte",
    "abstract": "Scalable Vector Graphics (SVG) are ubiquitous in modern 2D interfaces due to their ability to scale to different resolutions. However, despite the success of deep learning-based models applied to rasterized images, the problem of vector graphics representation learning and generation remains largely unexplored. In this work, we propose a novel hierarchical generative network, called DeepSVG, for complex SVG icons generation and interpolation. Our architecture effectively disentangles high-level shapes from the low-level commands that encode the shape itself. The network directly predicts a set of shapes in a non-autoregressive fashion. We introduce the task of complex SVG icons generation by releasing a new large-scale dataset along with an open-source library for SVG manipulation. We demonstrate that our network learns to accurately reconstruct diverse vector graphics, and can serve as a powerful animation tool by performing interpolations and other latent space operations. Our code is available at this https URL.",
    "citationCount": 174,
    "pdf_filename": "2020_DeepSVG__A_Hierarchical_Generative_Netwo_2c5dba61.pdf"
  },
  "77313b88c3d2f7cfa7fcba764103878e32332b2b": {
    "paperId": "77313b88c3d2f7cfa7fcba764103878e32332b2b",
    "title": "TopologyGAN: Topology Optimization Using Generative Adversarial Networks Based on Physical Fields Over the Initial Domain",
    "year": 2020,
    "authors": "Zhenguo Nie, Tong Lin, Haoliang Jiang, L. Kara",
    "abstract": "\n In topology optimization using deep learning, the load and boundary conditions represented as vectors or sparse matrices often miss the opportunity to encode a rich view of the design problem, leading to less than ideal generalization results. We propose a new data-driven topology optimization model called TopologyGAN that takes advantage of various physical fields computed on the original, unoptimized material domain, as inputs to the generator of a conditional generative adversarial network (cGAN). Compared to a baseline cGAN, TopologyGAN achieves a nearly 3 × reduction in the mean squared error and a 2.5 × reduction in the mean absolute error on test problems involving previously unseen boundary conditions. Built on several existing network models, we also introduce a hybrid network called U-SE(Squeeze-and-Excitation)-ResNet for the generator that further increases the overall accuracy. We publicly share our full implementation and trained network.",
    "citationCount": 192,
    "pdf_filename": "2020_TopologyGAN__Topology_Optimization_Using_77313b88.pdf"
  },
  "87cdc6392bcab62cebe605b74966aabd616b6571": {
    "paperId": "87cdc6392bcab62cebe605b74966aabd616b6571",
    "title": "Realistic in silico generation and augmentation of single-cell RNA-seq data using generative adversarial networks",
    "year": 2020,
    "authors": "M. Marouf, Pierre Machart, V. Bansal, Christoph Kilian, D. S. Magruder",
    "abstract": "A fundamental problem in biomedical research is the low number of observations available, mostly due to a lack of available biosamples, prohibitive costs, or ethical reasons. Augmenting few real observations with generated in silico samples could lead to more robust analysis results and a higher reproducibility rate. Here, we propose the use of conditional single-cell generative adversarial neural networks (cscGAN) for the realistic generation of single-cell RNA-seq data. cscGAN learns non-linear gene–gene dependencies from complex, multiple cell type samples and uses this information to generate realistic cells of defined types. Augmenting sparse cell populations with cscGAN generated cells improves downstream analyses such as the detection of marker genes, the robustness and reliability of classifiers, the assessment of novel analysis algorithms, and might reduce the number of animal experiments and costs in consequence. cscGAN outperforms existing methods for single-cell RNA-seq data generation in quality and hold great promise for the realistic generation and augmentation of other biomedical data types. Low sample numbers often limit the robustness of analyses in biomedical research. Here, the authors introduce a method to generate realistic scRNA-seq data using GANs that learn gene expression dependencies from complex samples, and show that augmenting spare cell populations improves downstream analyses.",
    "citationCount": 183,
    "pdf_filename": "2020_Realistic_in_silico_generation_and_augme_87cdc639.pdf"
  },
  "51bf7a3aee6b1f61b902625f6badffedf200d31a": {
    "paperId": "51bf7a3aee6b1f61b902625f6badffedf200d31a",
    "title": "Rewriting a Deep Generative Model",
    "year": 2020,
    "authors": "David Bau, Steven Liu, Tongzhou Wang, Jun-Yan Zhu, A. Torralba",
    "abstract": "A deep generative model such as a GAN learns to model a rich set of semantic and physical rules about the target distribution, but up to now, it has been obscure how such rules are encoded in the network, or how a rule could be changed. In this paper, we introduce a new problem setting: manipulation of specific rules encoded by a deep generative model. To address the problem, we propose a formulation in which the desired rule is changed by manipulating a layer of a deep network as a linear associative memory. We derive an algorithm for modifying one entry of the associative memory, and we demonstrate that several interesting structural rules can be located and modified within the layers of state-of-the-art generative models. We present a user interface to enable users to interactively change the rules of a generative model to achieve desired effects, and we show several proof-of-concept applications. Finally, results on multiple datasets demonstrate the advantage of our method against standard fine-tuning methods and edit transfer algorithms.",
    "citationCount": 148,
    "pdf_filename": "2020_Rewriting_a_Deep_Generative_Model_51bf7a3a.pdf"
  },
  "32095de948f289ba4bc40c730a5f2a90a5cb09b7": {
    "paperId": "32095de948f289ba4bc40c730a5f2a90a5cb09b7",
    "title": "COVID-19 CT Image Synthesis With a Conditional Generative Adversarial Network",
    "year": 2020,
    "authors": "Yifan Jiang, Han Chen, M. Loew, Hanseok Ko",
    "abstract": "Coronavirus disease 2019 (COVID-19) is an ongoing global pandemic that has spread rapidly since December 2019. Real-time reverse transcription polymerase chain reaction (rRT-PCR) and chest computed tomography (CT) imaging both play an important role in COVID-19 diagnosis. Chest CT imaging offers the benefits of quick reporting, a low cost, and high sensitivity for the detection of pulmonary infection. Recently, deep-learning-based computer vision methods have demonstrated great promise for use in medical imaging applications, including X-rays, magnetic resonance imaging, and CT imaging. However, training a deep-learning model requires large volumes of data, and medical staff faces a high risk when collecting COVID-19 CT data due to the high infectivity of the disease. Another issue is the lack of experts available for data labeling. In order to meet the data requirements for COVID-19 CT imaging, we propose a CT image synthesis approach based on a conditional generative adversarial network that can effectively generate high-quality and realistic COVID-19 CT images for use in deep-learning-based medical imaging tasks. Experimental results show that the proposed method outperforms other state-of-the-art image synthesis methods with the generated COVID-19 CT images and indicates promising for various machine learning applications including semantic segmentation and classification.",
    "citationCount": 148,
    "pdf_filename": "2020_COVID_19_CT_Image_Synthesis_With_a_Condi_32095de9.pdf"
  },
  "b501bc13f3a5166a5e622b5fafe084396c77df13": {
    "paperId": "b501bc13f3a5166a5e622b5fafe084396c77df13",
    "title": "Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric Fields With a Generative Adversarial Network",
    "year": 2020,
    "authors": "J. Leinonen, D. Nerini, A. Berne",
    "abstract": "Generative adversarial networks (GANs) have been recently adopted for super-resolution, an application closely related to what is referred to as “downscaling” in the atmospheric sciences: improving the spatial resolution of low-resolution images. The ability of conditional GANs to generate an ensemble of solutions for a given input lends itself naturally to stochastic downscaling, but the stochastic nature of GANs is not usually considered in super-resolution applications. Here, we introduce a recurrent, stochastic super-resolution GAN that can generate ensembles of time-evolving high-resolution atmospheric fields for an input consisting of a low-resolution sequence of images of the same field. We test the GAN using two data sets: one consisting of radar-measured precipitation from Switzerland; the other of cloud optical thickness derived from the Geostationary Earth Observing Satellite 16 (GOES-16). We find that the GAN can generate realistic, temporally consistent super-resolution sequences for both data sets. The statistical properties of the generated ensemble are analyzed using rank statistics, a method adapted from ensemble weather forecasting; these analyses indicate that the GAN produces close to the correct amount of variability in its outputs. As the GAN generator is fully convolutional, it can be applied after training to input images larger than the images used to train it. It is also able to generate time series much longer than the training sequences, as demonstrated by applying the generator to a three-month data set of the precipitation radar data. The source code to our GAN is available at https://github.com/jleinonen/downscaling-rnn-gan.",
    "citationCount": 165,
    "pdf_filename": "2020_Stochastic_Super_Resolution_for_Downscal_b501bc13.pdf"
  },
  "1425ecba05cded19a9c78d90c348efcbd8668b24": {
    "paperId": "1425ecba05cded19a9c78d90c348efcbd8668b24",
    "title": "Generative Art",
    "year": 2020,
    "authors": "H. Dehlinger",
    "abstract": "As an artist, I have the freedom to subject myself to restrictive rules that may run close to what is understood by a ‘program’ in computer science. Sentences like: ‘use only vertical strokes of roughly the same length’, ‘go to and fro along a given contour’, ‘draw a tree with short, violent strokes’, etc., are examples for such ‘programs’. In Generative Art (for a definition see, for example, Galanter, 2003), explicit use is made of such rules. I describe my attempts as ‘an art practice where the artist follows a self-designed system of formal rules’ (Dehlinger, 2007). Working manually on a physical piece in statu nascendi, artists have an immediate feedback on the impact of any stroke or action they perform. Not so in Generative Art. Here an idea or a concept is in the focus for which a specific production system is designed that will turn out an aesthetic event. The artist, the inventor of the generative system, then judges it. The strictness of the rules and the precision in their execution performed by the computer are unparalleled. But, in my eyes the machine does not conceive the art. The artistic intelligence/creativity is seated facing the computer and not within it. Accepting the computer as part of the art making equation, artists are granted the privilege to explore totally new and hitherto unknown domains. Generative Art has a strong relation to design. But contrary to design proper, where usually one (in the eyes of the designer the optimal) instance for implementation is searched for, the emphasis in Generative Art is on the plural. The generating system – and this is a wanted effect – is in principle able to supply an endless sequence of differing results, all within the constraining rules set out – a fantastic playground for art. The problematic issues on programming for art related themes in architecture, design and art have engaged me since I started with programming with Algol 68 in the early 60ies as a student of architecture at the University of Stuttgart, Germany. As students of architecture we also were part of a multidisciplinary Studium generale listening to the lectures on aesthetics of the philosopher Max Bense. It was in this context where I first encountered the computer art pioneer Frieder Nake, working on a Zuse-Graphomat. In 1969, I entered the UC Berkeley as a graduate student thanks to a scholarship by DAAD. And, an unforgettable experience shortly after my arrival was an extensive visit of the Cybernetic Serendipidy exhibition at the San Francisco Exploratorium (Reichardt, 1968).",
    "citationCount": 153,
    "pdf_filename": "2020_Generative_Art_1425ecba.pdf"
  },
  "c336a90aab87970d84cf07f43d7e96e480867df1": {
    "paperId": "c336a90aab87970d84cf07f43d7e96e480867df1",
    "title": "Potential COVID-2019 3C-like Protease Inhibitors Designed Using Generative Deep Learning Approaches",
    "year": 2020,
    "authors": "Z. Alex, A. Vladimir, Z. Alexander, Zagribelnyy Bogdan, Terentiev Victor",
    "abstract": "\n \n The emergence of the 2019 novel coronavirus (COVID-19), for which there is no vaccine or any known effective treatment created a sense of urgency for novel drug discovery approaches. One of the most important COVID-19 protein targets is the 3C-like protease for which the crystal structure is known. Most of the immediate efforts are focused on drug repurposing of known clinically-approved drugs and virtual screening for the molecules available from chemical libraries that may not work well. For example, the IC50 of lopinavir, an HIV protease inhibitor, against the 3C-like protease is approximately 50 micromolar, which is far from ideal. In an attempt to address this challenge, on January 28th, 2020 Insilico Medicine decided to utilize a part of its generative chemistry pipeline to design novel drug-like inhibitors of COVID-19 and started generation on January 30th. It utilized three of its previously validated generative chemistry approaches: crystal-derived pocked-based generator, homology modelling-based generation, and ligand-based generation. Novel druglike compounds generated using these approaches were published at www.insilico.com/ncov-sprint/. Several molecules will be synthesized and tested using the internal resources; however, the team is seeking collaborations to synthesize, test, and, if needed, optimize the published molecules. \n \n",
    "citationCount": 148,
    "pdf_filename": "2020_Potential_COVID_2019_3C_like_Protease_In_c336a90a.pdf"
  },
  "2a71fb5e47141d86458a5a034a3d152c8e0bffb6": {
    "paperId": "2a71fb5e47141d86458a5a034a3d152c8e0bffb6",
    "title": "Discriminative Reconstruction Constrained Generative Adversarial Network for Hyperspectral Anomaly Detection",
    "year": 2020,
    "authors": "T. Jiang, Yunsong Li, Weiying Xie, Q. Du",
    "abstract": "The rich and distinguishable spectral information in hyperspectral images (HSIs) makes it possible to capture anomalous samples [i.e., anomaly detection (AD)] that deviate from background samples. However, hyperspectral anomaly detection (HAD) faces various challenges due to high dimensionality, redundant information, and unlabeled and limited samples. To address these problems, this article proposes an unsupervised discriminative reconstruction constrained generative adversarial network for HAD (HADGAN). Our solution is mainly based on the assumption that the number of normal samples is much larger than the number of abnormal ones. The key contribution of this article is to learn a discriminative background reconstruction with anomaly targets being suppressed, which produces the initial detection image (i.e., the residual image between the original image and reconstructed image) with anomaly targets being highlighted and background samples being suppressed. To accomplish this goal, first, by using an autoencoder (AE) network and an adversarial latent discriminator, the latent feature layer learns normal background distribution and AE learns a background reconstruction as much as possible. Second, consistency enhanced representation and shrink constraints are added to the latent feature layer to ensure that anomaly samples are projected to similar positions as normal samples in the latent feature layer. Third, using an adversarial image feature corrector in the input space can guarantee the reliability of the generated samples. Finally, an energy-based spatial and distance-based spectral joint anomaly detector is applied in the residual map to generate the final detection map. Experiments conducted on several data sets over different scenes demonstrate its state-of-the-art performance.",
    "citationCount": 156,
    "pdf_filename": "2020_Discriminative_Reconstruction_Constraine_2a71fb5e.pdf"
  },
  "67e3e88548b531df704715cb50d6c376d8ff62a2": {
    "paperId": "67e3e88548b531df704715cb50d6c376d8ff62a2",
    "title": "Prior-Guided Image Reconstruction for Accelerated Multi-Contrast MRI via Generative Adversarial Networks",
    "year": 2020,
    "authors": "S. Dar, Mahmut Yurt, M. Shahdloo, M. E. Ildiz, Berk Tınaz",
    "abstract": "Multi-contrast MRI acquisitions of an anatomy enrich the magnitude of information available for diagnosis. Yet, excessive scan times associated with additional contrasts may be a limiting factor. Two mainstream frameworks for enhanced scan efficiency are reconstruction of undersampled acquisitions and synthesis of missing acquisitions. Recently, deep learning methods have enabled significant performance improvements in both frameworks. Yet, reconstruction performance decreases towards higher acceleration factors with diminished sampling density at high-spatial-frequencies, whereas synthesis can manifest artefactual sensitivity or insensitivity to image features due to the absence of data samples from the target contrast. In this article, we propose a new approach for synergistic recovery of undersampled multi-contrast acquisitions based on conditional generative adversarial networks. The proposed method mitigates the limitations of pure learning-based reconstruction or synthesis by utilizing three priors: shared high-frequency prior available in the source contrast to preserve high-spatial-frequency details, low-frequency prior available in the undersampled target contrast to prevent feature leakage/loss, and perceptual prior to improve recovery of high-level features. Demonstrations on brain MRI datasets from healthy subjects and patients indicate the superior performance of the proposed method compared to pure reconstruction and synthesis methods. The proposed method can help improve the quality and scan efficiency of multi-contrast MRI exams.",
    "citationCount": 154,
    "pdf_filename": "2020_Prior_Guided_Image_Reconstruction_for_Ac_67e3e885.pdf"
  },
  "afdf89219bd4fa2e590d4aa3f28d9194f66b3fcf": {
    "paperId": "afdf89219bd4fa2e590d4aa3f28d9194f66b3fcf",
    "title": "DOA-GAN: Dual-Order Attentive Generative Adversarial Network for Image Copy-Move Forgery Detection and Localization",
    "year": 2020,
    "authors": "Ashraful Islam, Chengjiang Long, Arslan Basharat, A. Hoogs",
    "abstract": "Images can be manipulated for nefarious purposes to hide content or to duplicate certain objects through copy-move operations. Discovering a well-crafted copy-move forgery in images can be very challenging for both humans and machines; for example, an object on a uniform background can be replaced by an image patch of the same background. In this paper, we propose a Generative Adversarial Network with a dual-order attention model to detect and localize copy-move forgeries. In the generator, the first-order attention is designed to capture copy-move location information, and the second-order attention exploits more discriminative features for the patch co-occurrence. Both attention maps are extracted from the affinity matrix and are used to fuse location-aware and co-occurrence features for the final detection and localization branches of the network. The discriminator network is designed to further ensure more accurate localization results. To the best of our knowledge, we are the first to propose such a network architecture with the 1st-order attention mechanism from the affinity matrix. We have performed extensive experimental validation and our state-of-the-art results strongly demonstrate the efficacy of the proposed approach.",
    "citationCount": 141,
    "pdf_filename": "2020_DOA_GAN__Dual_Order_Attentive_Generative_afdf8921.pdf"
  },
  "d8e3f41428691a450cb6b27bf02fc3cb3c539f11": {
    "paperId": "d8e3f41428691a450cb6b27bf02fc3cb3c539f11",
    "title": "SynSigGAN: Generative Adversarial Networks for Synthetic Biomedical Signal Generation",
    "year": 2020,
    "authors": "Debapriya Hazra, Y. Byun",
    "abstract": "Simple Summary This paper proposes a novel generative adversarial networks model, SynSigGAN, to generate any kind of synthetic biomedical signals. The generation of synthetic signals eliminates confidentiality concerns and accessibility problem of medical data. Synthetic data can be utilized for training medical students and machine learning models for the advancement and automation of healthcare systems. Our proposed model performs significantly better than existing models with a high correlation coefficient that measures the generated synthetic signals’ similarity with the original signals. Abstract Automating medical diagnosis and training medical students with real-life situations requires the accumulation of large dataset variants covering all aspects of a patient’s condition. For preventing the misuse of patient’s private information, datasets are not always publicly available. There is a need to generate synthetic data that can be trained for the advancement of public healthcare without intruding on patient’s confidentiality. Currently, rules for generating synthetic data are predefined and they require expert intervention, which limits the types and amount of synthetic data. In this paper, we propose a novel generative adversarial networks (GAN) model, named SynSigGAN, for automating the generation of any kind of synthetic biomedical signals. We have used bidirectional grid long short-term memory for the generator network and convolutional neural network for the discriminator network of the GAN model. Our model can be applied in order to create new biomedical synthetic signals while using a small size of the original signal dataset. We have experimented with our model for generating synthetic signals for four kinds of biomedical signals (electrocardiogram (ECG), electroencephalogram (EEG), electromyography (EMG), photoplethysmography (PPG)). The performance of our model is superior wheen compared to other traditional models and GAN models, as depicted by the evaluation metric. Synthetic biomedical signals generated by our approach have been tested while using other models that could classify each signal significantly with high accuracy.",
    "citationCount": 140,
    "pdf_filename": "2020_SynSigGAN__Generative_Adversarial_Networ_d8e3f414.pdf"
  },
  "f800a355cb58c003bfd80ffe0a10c5df70013674": {
    "paperId": "f800a355cb58c003bfd80ffe0a10c5df70013674",
    "title": "A Systematic Survey on Deep Generative Models for Graph Generation",
    "year": 2020,
    "authors": "Xiaojie Guo, Liang Zhao",
    "abstract": "Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to their wide range of applications, generative models for graphs, which have a rich history, however, are traditionally hand-crafted and only capable of modeling a few statistical properties of graphs. Recent advances in deep generative models for graph generation is an important step towards improving the fidelity of generated graphs and paves the way for new kinds of applications. This article provides an extensive overview of the literature in the field of deep generative models for graph generation. First, the formal definition of deep generative models for the graph generation and the preliminary knowledge are provided. Second, taxonomies of deep generative models for both unconditional and conditional graph generation are proposed respectively; the existing works of each are compared and analyzed. After that, an overview of the evaluation metrics in this specific domain is provided. Finally, the applications that deep graph generation enables are summarized and five promising future research directions are highlighted.",
    "citationCount": 174,
    "pdf_filename": "2020_A_Systematic_Survey_on_Deep_Generative_M_f800a355.pdf"
  },
  "e157b90ab9c50907f76aa22558ee1c04749728a3": {
    "paperId": "e157b90ab9c50907f76aa22558ee1c04749728a3",
    "title": "Generative Adversarial Networks and Its Applications in Biomedical Informatics",
    "year": 2020,
    "authors": "L. Lan, Lei You, Zeyang Zhang, Zhiwei Fan, Weiling Zhao",
    "abstract": "The basic Generative Adversarial Networks (GAN) model is composed of the input vector, generator, and discriminator. Among them, the generator and discriminator are implicit function expressions, usually implemented by deep neural networks. GAN can learn the generative model of any data distribution through adversarial methods with excellent performance. It has been widely applied to different areas since it was proposed in 2014. In this review, we introduced the origin, specific working principle, and development history of GAN, various applications of GAN in digital image processing, Cycle-GAN, and its application in medical imaging analysis, as well as the latest applications of GAN in medical informatics and bioinformatics.",
    "citationCount": 190,
    "pdf_filename": "2020_Generative_Adversarial_Networks_and_Its__e157b90a.pdf"
  },
  "237729237fde44eb7ab8f35aafb82c9b8a816e44": {
    "paperId": "237729237fde44eb7ab8f35aafb82c9b8a816e44",
    "title": "Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications",
    "year": 2020,
    "authors": "Ming-Yu Liu, Xun Huang, Jiahui Yu, Ting-Chun Wang, Arun Mallya",
    "abstract": "The generative adversarial network (GAN) framework has emerged as a powerful tool for various image and video synthesis tasks, allowing the synthesis of visual content in an unconditional or input-conditional manner. It has enabled the generation of high-resolution photorealistic images and videos, a task that was challenging or impossible with prior methods. It has also led to the creation of many new applications in content creation. In this article, we provide an overview of GANs with a special focus on algorithms and applications for visual synthesis. We cover several important techniques to stabilize GAN training, which has a reputation for being notoriously difficult. We also discuss its applications to image translation, image processing, video synthesis, and neural rendering.",
    "citationCount": 175,
    "pdf_filename": "2020_Generative_Adversarial_Networks_for_Imag_23772923.pdf"
  },
  "824d7f06c640c1c7f2d2905e29795f2b700247ce": {
    "paperId": "824d7f06c640c1c7f2d2905e29795f2b700247ce",
    "title": "DE-GAN: A Conditional Generative Adversarial Network for Document Enhancement",
    "year": 2020,
    "authors": "Mohamed Ali Souibgui, Yousri Kessentini",
    "abstract": "Documents often exhibit various forms of degradation, which make it hard to be read and substantially deteriorate the performance of an OCR system. In this paper, we propose an effective end-to-end framework named document enhancement generative adversarial networks (DE-GAN) that uses the conditional GANs (cGANs) to restore severely degraded document images. To the best of our knowledge, this practice has not been studied within the context of generative adversarial deep networks. We demonstrate that, in different tasks (document clean up, binarization, deblurring and watermark removal), DE-GAN can produce an enhanced version of the degraded document with a high quality. In addition, our approach provides consistent improvements compared to state-of-the-art methods over the widely used DIBCO 2013, DIBCO 2017, and H-DIBCO 2018 datasets, proving its ability to restore a degraded document image to its ideal condition. The obtained results on a wide variety of degradation reveal the flexibility of the proposed model to be exploited in other document enhancement problems.",
    "citationCount": 135,
    "pdf_filename": "2020_DE_GAN__A_Conditional_Generative_Adversa_824d7f06.pdf"
  },
  "778d9d77ce1ba5a553b49407b543120523d22702": {
    "paperId": "778d9d77ce1ba5a553b49407b543120523d22702",
    "title": "Data augmentation for enhancing EEG-based emotion recognition with deep generative models",
    "year": 2020,
    "authors": "Yun Luo, Li-Zhen Zhu, Zi-Yu Wan, Bao-Liang Lu",
    "abstract": "Objective. The data scarcity problem in emotion recognition from electroencephalography (EEG) leads to difficulty in building an affective model with high accuracy using machine learning algorithms or deep neural networks. Inspired by emerging deep generative models, we propose three methods for augmenting EEG training data to enhance the performance of emotion recognition models. Approach. Our proposed methods are based on two deep generative models, variational autoencoder (VAE) and generative adversarial network (GAN), and two data augmentation ways, full and partial usage strategies. For the full usage strategy, all of the generated data are augmented to the training dataset without judging the quality of the generated data, while for the partial usage, only high-quality data are selected and appended to the training dataset. These three methods are called conditional Wasserstein GAN (cWGAN), selective VAE (sVAE), and selective WGAN (sWGAN). Main results. To evaluate the effectiveness of these proposed methods, we perform a systematic experimental study on two public EEG datasets for emotion recognition, namely, SEED and DEAP. We first generate realistic-like EEG training data in two forms: power spectral density and differential entropy. Then, we augment the original training datasets with a different number of generated realistic-like EEG data. Finally, we train support vector machines and deep neural networks with shortcut layers to build affective models using the original and augmented training datasets. The experimental results demonstrate that our proposed data augmentation methods based on generative models outperform the existing data augmentation approaches such as conditional VAE, Gaussian noise, and rotational data augmentation. We also observe that the number of generated data should be less than 10 times of the original training dataset to achieve the best performance. Significance. The augmented training datasets produced by our proposed sWGAN method significantly enhance the performance of EEG-based emotion recognition models.",
    "citationCount": 135,
    "pdf_filename": "2020_Data_augmentation_for_enhancing_EEG_base_778d9d77.pdf"
  },
  "021642baa03c61c687805364d10420d108bbbf8a": {
    "paperId": "021642baa03c61c687805364d10420d108bbbf8a",
    "title": "Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (STONED) algorithm for molecules using SELFIES",
    "year": 2020,
    "authors": "AkshatKumar Nigam, R. Pollice, Mario Krenn, Gabriel dos Passos Gomes, Alán Aspuru-Guzik",
    "abstract": "Inverse design allows the generation of molecules with desirable physical quantities using property optimization. Deep generative models have recently been applied to tackle inverse design, as they possess the ability to optimize molecular properties directly through structure modification using gradients. While the ability to carry out direct property optimizations is promising, the use of generative deep learning models to solve practical problems requires large amounts of data and is very time-consuming. In this work, we propose STONED – a simple and efficient algorithm to perform interpolation and exploration in the chemical space, comparable to deep generative models. STONED bypasses the need for large amounts of data and training times by using string modifications in the SELFIES molecular representation. First, we achieve non-trivial performance on typical benchmarks for generative models without any training. Additionally, we demonstrate applications in high-throughput virtual screening for the design of drugs, photovoltaics, and the construction of chemical paths, allowing for both property and structure-based interpolation in the chemical space. Overall, we anticipate our results to be a stepping stone for developing more sophisticated inverse design models and benchmarking tools, ultimately helping generative models achieve wider adoption.",
    "citationCount": 134,
    "pdf_filename": "2020_Beyond_generative_models__superfast_trav_021642ba.pdf"
  },
  "e37daeaa20bc8cd68db07641201faf1db3b8c31d": {
    "paperId": "e37daeaa20bc8cd68db07641201faf1db3b8c31d",
    "title": "Dual Discriminator Generative Adversarial Network for Video Anomaly Detection",
    "year": 2020,
    "authors": "Fei Dong, Yu Zhang, Xiushan Nie",
    "abstract": "Video anomaly detection is an essential task because of its numerous applications in various areas. Because of the rarity of abnormal events and the complicated characteristic of videos, video anomaly detection is challenging and has been studied for a long time. In this paper, we propose a semi-supervised approach with a dual discriminator-based generative adversarial network structure. Our method considers more motion information in video clips compared with previous approaches. Specifically, in the training phase, we predict future frames for normal events via a generator and attempt to force the predicted frames to be similar to their ground truths. In addition, we utilize both a frame discriminator and motion discriminator to adverse the generator to generate more realistic and consecutive frames. The frame discriminator attempts to determine whether the input frames are generated or original frames sampled from the normal video. The motion discriminator attempts to determine whether the given optical flows are real or fake. Fake optical flows are estimated from generated frames and adjacent frames, and real optical flows are estimated from the real frames sampled from original videos. Then, in the testing phase, we evaluate the quality of predicted frames to obtain the regular score, and we consider those frames with lower prediction qualities as abnormal frames. The results of experiments on three publicly available datasets demonstrate the effectiveness of our proposed method.",
    "citationCount": 126,
    "pdf_filename": "2020_Dual_Discriminator_Generative_Adversaria_e37daeaa.pdf"
  },
  "7f327e86fdd1e5aafe362ad8053bf94c56cab245": {
    "paperId": "7f327e86fdd1e5aafe362ad8053bf94c56cab245",
    "title": "ARShadowGAN: Shadow Generative Adversarial Network for Augmented Reality in Single Light Scenes",
    "year": 2020,
    "authors": "Daquan Liu, Chengjiang Long, Hongpan Zhang, Hanning Yu, Xinzhi Dong",
    "abstract": "Generating virtual object shadows consistent with the real-world environment shading effects is important but challenging in computer vision and augmented reality applications. To address this problem, we propose an end-to-end Generative Adversarial Network for shadow generation named ARShadowGAN for augmented reality in single light scenes. Our ARShadowGAN makes full use of attention mechanism and is able to directly model the mapping relation between the virtual object shadow and the real-world environment without any explicit estimation of the illumination and 3D geometric information. In addition, we collect an image set which provides rich clues for shadow generation and construct a dataset for training and evaluating our proposed ARShadowGAN. The extensive experimental results show that our proposed ARShadowGAN is capable of directly generating plausible virtual object shadows in single light scenes. Our source code is available at https://github.com/ldq9526/ARShadowGAN.",
    "citationCount": 119,
    "pdf_filename": "2020_ARShadowGAN__Shadow_Generative_Adversari_7f327e86.pdf"
  },
  "12ff6fba7f6ec5c5d9b5a2ab77c27fc0e9b5df8e": {
    "paperId": "12ff6fba7f6ec5c5d9b5a2ab77c27fc0e9b5df8e",
    "title": "Quantum State Tomography with Conditional Generative Adversarial Networks",
    "year": 2020,
    "authors": "Shahnawaz Ahmed, C. Munoz, F. Nori, A. F. Kockum",
    "abstract": "Quantum state tomography (QST) is a challenging task in intermediate-scale quantum devices. Here, we apply conditional generative adversarial networks (CGANs) to QST. In the CGAN framework, two dueling neural networks, a generator and a discriminator, learn multimodal models from data. We augment a CGAN with custom neural-network layers that enable conversion of output from any standard neural network into a physical density matrix. To reconstruct the density matrix, the generator and discriminator networks train each other on data using standard gradient-based methods. We demonstrate that our QST-CGAN reconstructs optical quantum states with high fidelity, using orders of magnitude fewer iterative steps, and less data, than both accelerated projected-gradient-based and iterative maximum-likelihood estimation. We also show that the QST-CGAN can reconstruct a quantum state in a single evaluation of the generator network if it has been pretrained on similar quantum states.",
    "citationCount": 152,
    "pdf_filename": "2020_Quantum_State_Tomography_with_Conditiona_12ff6fba.pdf"
  },
  "c292508f593f5ad2618fbb27abcb0166caeb847b": {
    "paperId": "c292508f593f5ad2618fbb27abcb0166caeb847b",
    "title": "Modeling Human Driving Behavior Through Generative Adversarial Imitation Learning",
    "year": 2020,
    "authors": "Raunak P. Bhattacharyya, Blake Wulfe, Derek J. Phillips, Alex Kuefler, Jeremy Morton",
    "abstract": "An open problem in autonomous vehicle safety validation is building reliable models of human driving behavior in simulation. This work presents an approach to learn neural driving policies from real world driving demonstration data. We model human driving as a sequential decision making problem that is characterized by non-linearity and stochasticity, and unknown underlying cost functions. Imitation learning is an approach for generating intelligent behavior when the cost function is unknown or difficult to specify. Building upon work in inverse reinforcement learning (IRL), Generative Adversarial Imitation Learning (GAIL) aims to provide effective imitation even for problems with large or continuous state and action spaces, such as modeling human driving. This article describes the use of GAIL for learning-based driver modeling. Because driver modeling is inherently a multi-agent problem, where the interaction between agents needs to be modeled, this paper describes a parameter-sharing extension of GAIL called PS-GAIL to tackle multi-agent driver modeling. In addition, GAIL is domain agnostic, making it difficult to encode specific knowledge relevant to driving in the learning process. This paper describes Reward Augmented Imitation Learning (RAIL), which modifies the reward signal to provide domain-specific knowledge to the agent. Finally, human demonstrations are dependent upon latent factors that may not be captured by GAIL. This paper describes Burn-InfoGAIL, which allows for disentanglement of latent variability in demonstrations. Imitation learning experiments are performed using NGSIM, a real-world highway driving dataset. Experiments show that these modifications to GAIL can successfully model highway driving behavior, accurately replicating human demonstrations and generating realistic, emergent behavior in the traffic flow arising from the interaction between driving agents.",
    "citationCount": 124,
    "pdf_filename": "2020_Modeling_Human_Driving_Behavior_Through__c292508f.pdf"
  },
  "5a64123f1564401dabf5db45d6f1c27d7b0c6c6c": {
    "paperId": "5a64123f1564401dabf5db45d6f1c27d7b0c6c6c",
    "title": "Responsible Disclosure of Generative Models Using Scalable Fingerprinting",
    "year": 2020,
    "authors": "Ning Yu, Vladislav Skripniuk, Dingfan Chen, Larry S. Davis, Mario Fritz",
    "abstract": "Over the past five years, deep generative models have achieved a qualitative new level of performance. Generated data has become difficult, if not impossible, to be distinguished from real data. While there are plenty of use cases that benefit from this technology, there are also strong concerns on how this new technology can be misused to spoof sensors, generate deep fakes, and enable misinformation at scale. Unfortunately, current deep fake detection methods are not sustainable, as the gap between real and fake continues to close. In contrast, our work enables a responsible disclosure of such state-of-the-art generative models, that allows researchers and companies to fingerprint their models, so that the generated samples containing a fingerprint can be accurately detected and attributed to a source. Our technique achieves this by an efficient and scalable ad-hoc generation of a large population of models with distinct fingerprints. Our recommended operation point uses a 128-bit fingerprint which in principle results in more than $10^{36}$ identifiable models. Experimental results show that our method fulfills key properties of a fingerprinting mechanism and achieves effectiveness in deep fake detection and attribution.",
    "citationCount": 105,
    "pdf_filename": "2020_Responsible_Disclosure_of_Generative_Mod_5a64123f.pdf"
  },
  "30263af82c044310fac1736a363dd1cf1c7f6530": {
    "paperId": "30263af82c044310fac1736a363dd1cf1c7f6530",
    "title": "Constrained crystals deep convolutional generative adversarial network for the inverse design of crystal structures",
    "year": 2020,
    "authors": "Teng Long, N. Fortunato, I. Opahle, Yixuan Zhang, I. Samathrakis",
    "abstract": "Autonomous materials discovery with desired properties is one of the ultimate goals for materials science, and the current studies have been focusing mostly on high-throughput screening based on density functional theory calculations and forward modeling of physical properties using machine learning. Applying the deep learning techniques, we have developed a generative model, which can predict distinct stable crystal structures by optimizing the formation energy in the latent space. It is demonstrated that the optimization of physical properties can be integrated into the generative model as on-top screening or backward propagator, both with their own advantages. Applying the generative models on the binary Bi-Se system reveals that distinct crystal structures can be obtained covering the whole composition range, and the phases on the convex hull can be reproduced after the generated structures are fully relaxed to the equilibrium. The method can be extended to multicomponent systems for multi-objective optimization, which paves the way to achieve the inverse design of materials with optimal properties.",
    "citationCount": 121,
    "pdf_filename": "2020_Constrained_crystals_deep_convolutional__30263af8.pdf"
  },
  "cb03cff85876b3719fc9843f5bcf77f38dfa4f4a": {
    "paperId": "cb03cff85876b3719fc9843f5bcf77f38dfa4f4a",
    "title": "A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks",
    "year": 2020,
    "authors": "Lei Wang, Wei Chen, Wenjia Yang, Fangming Bi, Fei Yu",
    "abstract": "Generative Adversarial Networks (GANs) have achieved impressive results in various image synthesis tasks, and are becoming a hot topic in computer vision research because of the impressive performance they achieved in various applications. In this paper, we introduce the recent research on GANs in the field of image processing, including image synthesis, image generation, image semantic editing, image-to-image translation, image super-resolution, image inpainting, and cartoon generation. We analyze and summarize the methods used in these applications which have improved the generated results. Then, we discuss the challenges faced by GANs and introduce some methods to deal with these problems. We also preview some likely future research directions in the field of GANs, such as video generation, facial animation synthesis and 3D face reconstruction. The purpose of this review is to provide insights into the research on GANs and to present the various applications based on GANs in different scenarios.",
    "citationCount": 139,
    "pdf_filename": "2020_A_State_of_the_Art_Review_on_Image_Synth_cb03cff8.pdf"
  },
  "557ed446503524c111d3c0d661672001d559b3c2": {
    "paperId": "557ed446503524c111d3c0d661672001d559b3c2",
    "title": "Generative chemistry: drug discovery with deep learning generative models",
    "year": 2020,
    "authors": "Yuemin Bian, X. Xie",
    "abstract": "The de novo design of molecular structures using deep learning generative models introduces an encouraging solution to drug discovery in the face of the continuously increased cost of new drug development. From the generation of original texts, images, and videos, to the scratching of novel molecular structures the creativity of deep learning generative models exhibits the height machine intelligence can achieve. The purpose of this paper is to review the latest advances in generative chemistry which relies on generative modeling to expedite the drug discovery process. This review starts with a brief history of artificial intelligence in drug discovery to outline this emerging paradigm. Commonly used chemical databases, molecular representations, and tools in cheminformatics and machine learning are covered as the infrastructure for generative chemistry. The detailed discussions on utilizing cutting-edge generative architectures, including recurrent neural network, variational autoencoder, adversarial autoencoder, and generative adversarial network for compound generation are focused. Challenges and future perspectives follow.",
    "citationCount": 126,
    "pdf_filename": "2020_Generative_chemistry__drug_discovery_wit_557ed446.pdf"
  },
  "3ee3794b25304f21d364b7389d91a37c989a35d5": {
    "paperId": "3ee3794b25304f21d364b7389d91a37c989a35d5",
    "title": "Generative Adversarial Networks for Spatio-temporal Data: A Survey",
    "year": 2020,
    "authors": "Nan Gao, Hao Xue, Wei Shao, Sichen Zhao, K. K. Qin",
    "abstract": "Generative Adversarial Networks (GANs) have shown remarkable success in producing realistic-looking images in the computer vision area. Recently, GAN-based techniques are shown to be promising for spatio-temporal-based applications such as trajectory prediction, events generation, and time-series data imputation. While several reviews for GANs in computer vision have been presented, no one has considered addressing the practical applications and challenges relevant to spatio-temporal data. In this article, we have conducted a comprehensive review of the recent developments of GANs for spatio-temporal data. We summarise the application of popular GAN architectures for spatio-temporal data and the common practices for evaluating the performance of spatio-temporal applications with GANs. Finally, we point out future research directions to benefit researchers in this area.",
    "citationCount": 121,
    "pdf_filename": "2020_Generative_Adversarial_Networks_for_Spat_3ee3794b.pdf"
  },
  "1ed76faa66589b7e853b2ab629805915231e576a": {
    "paperId": "1ed76faa66589b7e853b2ab629805915231e576a",
    "title": "Pores for thought: generative adversarial networks for stochastic reconstruction of 3D multi-phase electrode microstructures with periodic boundaries",
    "year": 2020,
    "authors": "Andrea Gayon-Lombardo, L. Mosser, N. Brandon, S. J. Cooper",
    "abstract": "The generation of multiphase porous electrode microstructures is a critical step in the optimisation of electrochemical energy storage devices. This work implements a deep convolutional generative adversarial network (DC-GAN) for generating realistic n-phase microstructural data. The same network architecture is successfully applied to two very different three-phase microstructures: A lithium-ion battery cathode and a solid oxide fuel cell anode. A comparison between the real and synthetic data is performed in terms of the morphological properties (volume fraction, specific surface area, triple-phase boundary) and transport properties (relative diffusivity), as well as the two-point correlation function. The results show excellent agreement between datasets and they are also visually indistinguishable. By modifying the input to the generator, we show that it is possible to generate microstructure with periodic boundaries in all three directions. This has the potential to significantly reduce the simulated volume required to be considered “representative” and therefore massively reduce the computational cost of the electrochemical simulations necessary to predict the performance of a particular microstructure during optimisation.",
    "citationCount": 131,
    "pdf_filename": "2020_Pores_for_thought__generative_adversaria_1ed76faa.pdf"
  },
  "cd5bd706bc9c4114454deb4006ffbd2e4922327e": {
    "paperId": "cd5bd706bc9c4114454deb4006ffbd2e4922327e",
    "title": "Intrusion Detection for Cyber–Physical Systems Using Generative Adversarial Networks in Fog Environment",
    "year": 2020,
    "authors": "Paulo Freitas de Araujo-Filho, Georges Kaddoum, Divanilson R. Campelo, Aline Gondim Santos, David Macêdo",
    "abstract": "Cyber-attacks cyber–physical systems (CPSs) can lead to sensing and actuation misbehavior, severe damages to physical objects, and safety risks. Machine learning algorithms have been proposed for hindering cyber-attacks on CPSs, but the absence of labeled data from novel attacks makes their detection quite challenging. In this context, generative adversarial networks (GANs) are a promising unsupervised approach to detect cyber-attacks by implicitly modeling the system. However, the detection of cyber-attacks on CPSs has strict latency requirements, since the attacks need to be stopped before the system is compromised. In this article, we propose FID-GAN, a novel fog-based, unsupervised intrusion detection system (IDS) for CPSs using GANs. The IDS is proposed for a fog architecture, which brings computation resources closer to the end nodes and thus contributes to meeting low-latency requirements. In order to achieve higher detection rates, the proposed architecture computes a reconstruction loss based on the reconstruction of data samples mapped to the latent space. Other works that follow a similar approach struggle with the time required to compute the reconstruction loss, which renders them impractical for latency constrained applications. We address this problem by training an encoder that accelerates the reconstruction loss computation. Experiments show that the proposed solution achieves higher detection rates and is at least 5.5 times faster than a baseline approach in the three studied data sets.",
    "citationCount": 116,
    "pdf_filename": "2020_Intrusion_Detection_for_Cyber_Physical_S_cd5bd706.pdf"
  },
  "5c305ea1e3b6c4eb6cbed3f6e040a177414d6b0e": {
    "paperId": "5c305ea1e3b6c4eb6cbed3f6e040a177414d6b0e",
    "title": "Combining generative artificial intelligence and on-chip synthesis for de novo drug design",
    "year": 2020,
    "authors": "F. Grisoni, Berend J. H. Huisman, Alexander L. Button, Michael Moret, Kenneth Atz",
    "abstract": "Generative deep learning and miniaturized bench-top synthesis were combined to automate the design of novel LXR agonists. Automating the molecular design-make-test-analyze cycle accelerates hit and lead finding for drug discovery. Using deep learning for molecular design and a microfluidics platform for on-chip chemical synthesis, liver X receptor (LXR) agonists were generated from scratch. The computational pipeline was tuned to explore the chemical space of known LXRα agonists and generate novel molecular candidates. To ensure compatibility with automated on-chip synthesis, the chemical space was confined to the virtual products obtainable from 17 one-step reactions. Twenty-five de novo designs were successfully synthesized in flow. In vitro screening of the crude reaction products revealed 17 (68%) hits, with up to 60-fold LXR activation. The batch resynthesis, purification, and retesting of 14 of these compounds confirmed that 12 of them were potent LXR agonists. These results support the suitability of the proposed design-make-test-analyze framework as a blueprint for automated drug design with artificial intelligence and miniaturized bench-top synthesis.",
    "citationCount": 123,
    "pdf_filename": "2020_Combining_generative_artificial_intellig_5c305ea1.pdf"
  },
  "8050826d4765fa5aa6237690c65eabd5b91cc796": {
    "paperId": "8050826d4765fa5aa6237690c65eabd5b91cc796",
    "title": "Fault-Attention Generative Probabilistic Adversarial Autoencoder for Machine Anomaly Detection",
    "year": 2020,
    "authors": "Jingyao Wu, Zhibin Zhao, Chuang Sun, Ruqiang Yan, Xuefeng Chen",
    "abstract": "Anomaly detection is one of the most fundamental and indispensable components in predictive maintenance. In this article, anomaly detection is modeled as a one-class classification problem. Based on the scenario that the training data only include healthy state data, a fault-attention generative probabilistic adversarial autoencoder (FGPAA) is proposed to automatically find low-dimensional manifold embedded in high-dimensional space of the signal. Benefited from the characteristics of autoencoder, the signal information loss in feature extraction is reduced. Then, the fault-attention abnormal state indictor can be constructed with the distribution probability of low-dimensional feature and reconstruction error. Effectiveness of the model is verified with fault classification datasets and run-to-failure experimental datasets. The results show that FGPAA outperforms both GPAA and other traditional methods and can be processed in real time. It not only can obtain high accuracy for both classification data and run-to-failure data, but also achieve a certain trend index for run-to-failure data.",
    "citationCount": 106,
    "pdf_filename": "2020_Fault_Attention_Generative_Probabilistic_8050826d.pdf"
  },
  "becfcaa3284985ee29d99acbaea404446fe41ebe": {
    "paperId": "becfcaa3284985ee29d99acbaea404446fe41ebe",
    "title": "A Generative Machine Learning-Based Approach for Inverse Design of Multilayer Metasurfaces",
    "year": 2020,
    "authors": "Parinaz Naseri, S. Hum",
    "abstract": "The synthesis of a metasurface exhibiting a specific set of desired scattering properties is a time-consuming and resource-demanding process, which conventionally relies on many cycles of full-wave simulations. It requires an experienced designer to choose the number of metallic layers, the scatterer shapes and dimensions, and the type and the thickness of the separating substrates. In this article, we propose a generative machine learning (ML)-based approach to solve this one-to-many mapping and automate the inverse design of dual- and triple-layer metasurfaces. Using this approach, it is possible to solve optimization problems with single or more constraints by synthesizing thin structures composed of potentially brand-new scatterer designs, in cases where the interlayer coupling between the layers is nonnegligible and synthesis by traditional methods becomes cumbersome. Various examples to provide specific magnitude and phase responses of <inline-formula> <tex-math notation=\"LaTeX\">$x$ </tex-math></inline-formula>- and <inline-formula> <tex-math notation=\"LaTeX\">$y$ </tex-math></inline-formula>-polarized scattering coefficients across a frequency range as well as bounded responses for different metasurface applications are presented to verify the practicality of the proposed method.",
    "citationCount": 109,
    "pdf_filename": "2020_A_Generative_Machine_Learning_Based_Appr_becfcaa3.pdf"
  },
  "a179ba78290dd252f2b0d377400a9092b46ea8db": {
    "paperId": "a179ba78290dd252f2b0d377400a9092b46ea8db",
    "title": "The Third AI Summer: AAAI Robert S. Engelmore Memorial Lecture",
    "year": 2022,
    "authors": "Henry A. Kautz",
    "abstract": "This article summarizes the author's Robert S. Englemore Memorial Lecture presented at the Thirty-Fourth AAAI Conference on Artificial Intelligence on February 10, 2020. It explores recurring themes in the history of AI, real and imagined dangers from AI, and the future of the field.",
    "citationCount": 132,
    "pdf_filename": "2022_The_Third_AI_Summer__AAAI_Robert_S__Enge_a179ba78.pdf"
  },
  "785b350274dabe7449106c861ca9030e6792bc98": {
    "paperId": "785b350274dabe7449106c861ca9030e6792bc98",
    "title": "Minding the gap(s): public perceptions of AI and socio-technical imaginaries",
    "year": 2022,
    "authors": "L. Sartori, Giulia Bocca",
    "abstract": "Deepening and digging into the social side of AI is a novel but emerging requirement within the AI community. Future research should invest in an “AI for people”, going beyond the undoubtedly much-needed efforts into ethics, explainability and responsible AI. The article addresses this challenge by problematizing the discussion around AI shifting the attention to individuals and their awareness, knowledge and emotional response to AI. First, we outline our main argument relative to the need for a socio-technical perspective in the study of AI social implications. Then, we illustrate the main existing narratives of hopes and fears associated with AI and robots. As building blocks of broader “sociotechnical imaginaries”, narratives are powerful tools that shape how society sees, interprets and organizes technology. An original empirical study within the University of Bologna collects the data to examine the levels of awareness, knowledge and emotional response towards AI, revealing interesting insights to be carried on in future research. Replete with exaggerations, both utopian and dystopian narratives are analysed with respect to some relevant socio-demographic variables (gender, generation and competence). Finally, focusing on two issues—the state of AI anxiety and the point of view of non-experts—opens the floor to problematizing the discourse around AI, sustaining the need for a sociological perspective in the field of AI and discussing future comparative research.",
    "citationCount": 133,
    "pdf_filename": "2022_Minding_the_gap_s___public_perceptions_o_785b3502.pdf"
  },
  "5d4bf95028b301bc277f6fb5f7c673934c6312b1": {
    "paperId": "5d4bf95028b301bc277f6fb5f7c673934c6312b1",
    "title": "Redefining Creativity in the Era of AI? Perspectives of Computer Scientists and New Media Artists",
    "year": 2022,
    "authors": "Roosa Wingström, Johanna Hautala, Riina Lundman",
    "abstract": "ABSTRACT Artificial intelligence (AI) has breached creativity research. The advancements of creative AI systems dispute the common definitions of creativity that have traditionally focused on five elements: actor, process, outcome, domain, and space. Moreover, creative workers, such as scientists and artists, increasingly use AI in their creative processes, and the concept of co-creativity has emerged to describe blended human–AI creativity. These issues evoke the question of whether creativity requires redefinition in the era of AI. Currently, co-creativity is mostly studied within the framework of computer science in pre-organized laboratory settings. This study contributes from a human scientific perspective with 52 interviews of Finland-based computer scientists and new media artists who use AI in their work. The results suggest scientists and artists use similar elements to define creativity. However, the role of AI differs between the scientific and artistic creative processes. Scientists need AI to produce accurate and trustworthy outcomes, whereas artists use AI to explore and play. Unlike the scientists, some artists also considered their work with AI co-creative. We suggest that co-creativity can explain the contemporary creative processes in the era of AI and should be the focal point of future creativity research.",
    "citationCount": 132,
    "pdf_filename": "2022_Redefining_Creativity_in_the_Era_of_AI___5d4bf950.pdf"
  },
  "c253ab3e988d996b9253f8437cbdc37c415a2f0b": {
    "paperId": "c253ab3e988d996b9253f8437cbdc37c415a2f0b",
    "title": "Outsider Oversight: Designing a Third Party Audit Ecosystem for AI Governance",
    "year": 2022,
    "authors": "Inioluwa Deborah Raji, Peggy Xu, Colleen Honigsberg, Daniel E. Ho",
    "abstract": "Much attention has focused on algorithmic audits and impact assessments to hold developers and users of algorithmic systems accountable. But existing algorithmic accountability policy approaches have neglected the lessons from non-algorithmic domains: notably, the importance of third parties. Our paper synthesizes lessons from other fields on how to craft effective systems of external oversight for algorithmic deployments. First, we discuss the challenges of third party oversight in the current AI landscape. Second, we survey audit systems across domains - e.g., financial, environmental, and health regulation - and show that the institutional design of such audits are far from monolithic. Finally, we survey the evidence base around these design components and spell out the implications for algorithmic auditing. We conclude that the turn toward audits alone is unlikely to achieve actual algorithmic accountability, and sustained focus on institutional design will be required for meaningful third party involvement.",
    "citationCount": 129,
    "pdf_filename": "2022_Outsider_Oversight__Designing_a_Third_Pa_c253ab3e.pdf"
  },
  "5d8896396860d2b98af5dbaeb242cf66fe607c2a": {
    "paperId": "5d8896396860d2b98af5dbaeb242cf66fe607c2a",
    "title": "Defining organizational AI governance",
    "year": 2022,
    "authors": "Matti Mäntymäki, Matti Minkkinen, Teemu Birkstedt, M. Viljanen",
    "abstract": "Artificial intelligence (AI) governance is required to reap the benefits and manage the risks brought by AI systems. This means that ethical principles, such as fairness, need to be translated into practicable AI governance processes. A concise AI governance definition would allow researchers and practitioners to identify the constituent parts of the complex problem of translating AI ethics into practice. However, there have been few efforts to define AI governance thus far. To bridge this gap, this paper defines AI governance at the organizational level. Moreover, we delineate how AI governance enters into a governance landscape with numerous governance areas, such as corporate governance, information technology (IT) governance, and data governance. Therefore, we position AI governance as part of an organization’s governance structure in relation to these existing governance areas. Our definition and positioning of organizational AI governance paves the way for crafting AI governance frameworks and offers a stepping stone on the pathway toward governed AI.",
    "citationCount": 117,
    "pdf_filename": "2022_Defining_organizational_AI_governance_5d889639.pdf"
  },
  "ec31364e266ac691da29be7d2309fc2a4f8e0ee6": {
    "paperId": "ec31364e266ac691da29be7d2309fc2a4f8e0ee6",
    "title": "Creative Writing with an AI-Powered Writing Assistant: Perspectives from Professional Writers",
    "year": 2022,
    "authors": "Daphne Ippolito, Ann Yuan, Andy Coenen, Sehmon Burnam",
    "abstract": "Recent developments in natural language generation (NLG) using neural language models have brought us closer than ever to the goal of building AI-powered creative writing tools. However, most prior work on human-AI collaboration in the creative writing domain has evaluated new systems with amateur writers, typically in contrived user studies of limited scope. In this work, we commissioned 13 professional, published writers from a diverse set of creative writing backgrounds to craft stories using Wordcraft, a text editor with built-in AI-powered writing assistance tools. Using interviews and participant journals, we discuss the potential of NLG to have significant impact in the creative writing domain--especially with respect to brainstorming, generation of story details, world-building, and research assistance. Experienced writers, more so than amateurs, typically have well-developed systems and methodologies for writing, as well as distinctive voices and target audiences. Our work highlights the challenges in building for these writers; NLG technologies struggle to preserve style and authorial voice, and they lack deep understanding of story contents. In order for AI-powered writing assistants to realize their full potential, it is essential that they take into account the diverse goals and expertise of human writers.",
    "citationCount": 118,
    "pdf_filename": "2022_Creative_Writing_with_an_AI_Powered_Writ_ec31364e.pdf"
  },
  "b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5": {
    "paperId": "b41daf07f4cb04f494a0c7ce420afc68b3e6dbf5",
    "title": "Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms",
    "year": 2022,
    "authors": "B. Giovanola, S. Tiribelli",
    "abstract": "The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored. Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals. Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.",
    "citationCount": 113,
    "pdf_filename": "2022_Beyond_bias_and_discrimination__redefini_b41daf07.pdf"
  },
  "754c6ab1ba9edb06e3925f9235f6e53aa3ef5e4a": {
    "paperId": "754c6ab1ba9edb06e3925f9235f6e53aa3ef5e4a",
    "title": "Rethinking creativity: creative industries, AI and everyday creativity",
    "year": 2022,
    "authors": "H. Lee",
    "abstract": "This commentary reflects on how creativity is dehumanised (and rehumanised) and how its labour aspects are hindered (and highlighted) in the three recent developments in our understanding of arts, culture and creativity: the creative industries; AI creativity; and creativity in everyday life. The creative industries discourse instrumentalises and dehumanises creativity by hiding labour perspectives and treating creativity as human capital and a generator of IP. Meanwhile, contemplating AI creativity helps us to look beyond the economic paradigm and consider key traits of human creativity and the creation process, some aspects of which are successfully emulated by AI. Yet, we also observe how AI dissociates creativity from human agency and how its cost-cutting effect can challenge human creators in many sectors. Finally, the idea of everyday creativity effectively rehumanises and democratises creativity; however, it not only lacks labour perspectives but also hinders them.",
    "citationCount": 105,
    "pdf_filename": "2022_Rethinking_creativity__creative_industri_754c6ab1.pdf"
  },
  "5c26c7684845876b30a7a16ccdbb5fa7e59d3c27": {
    "paperId": "5c26c7684845876b30a7a16ccdbb5fa7e59d3c27",
    "title": "Multimodal Deep Generative Models for Trajectory Prediction: A Conditional Variational Autoencoder Approach",
    "year": 2020,
    "authors": "B. Ivanovic, Karen Leung, E. Schmerling, M. Pavone",
    "abstract": "Human behavior prediction models enable robots to anticipate how humans may react to their actions, and hence are instrumental to devising safe and proactive robot planning algorithms. However, modeling complex interaction dynamics and capturing the possibility of many possible outcomes in such interactive settings is very challenging, which has recently prompted the study of several different approaches. In this work, we provide a self-contained tutorial on a conditional variational autoencoder (CVAE) approach to human behavior prediction which, at its core, can produce a multimodal probability distribution over future human trajectories conditioned on past interactions and candidate robot future actions. Specifically, the goals of this tutorial paper are to review and build a taxonomy of state-of-the-art methods in human behavior prediction, from physics-based to purely data-driven methods, provide a rigorous yet easily accessible description of a data-driven, CVAE-based approach, highlight important design characteristics that make this an attractive model to use in the context of model-based planning for human-robot interactions, and provide important design considerations when using this class of models.",
    "citationCount": 118,
    "pdf_filename": "2020_Multimodal_Deep_Generative_Models_for_Tr_5c26c768.pdf"
  },
  "a0ae0261ed05b02736be59e7b0201ef0b60988fb": {
    "paperId": "a0ae0261ed05b02736be59e7b0201ef0b60988fb",
    "title": "GANterfactual—Counterfactual Explanations for Medical Non-experts Using Generative Adversarial Learning",
    "year": 2020,
    "authors": "Silvan Mertes, Tobias Huber, Katharina Weitz, Alexander Heimerl, Elisabeth Andr'e",
    "abstract": "With the ongoing rise of machine learning, the need for methods for explaining decisions made by artificial intelligence systems is becoming a more and more important topic. Especially for image classification tasks, many state-of-the-art tools to explain such classifiers rely on visual highlighting of important areas of the input data. Contrary, counterfactual explanation systems try to enable a counterfactual reasoning by modifying the input image in a way such that the classifier would have made a different prediction. By doing so, the users of counterfactual explanation systems are equipped with a completely different kind of explanatory information. However, methods for generating realistic counterfactual explanations for image classifiers are still rare. Especially in medical contexts, where relevant information often consists of textural and structural information, high-quality counterfactual images have the potential to give meaningful insights into decision processes. In this work, we present GANterfactual, an approach to generate such counterfactual image explanations based on adversarial image-to-image translation techniques. Additionally, we conduct a user study to evaluate our approach in an exemplary medical use case. Our results show that, in the chosen medical use-case, counterfactual explanations lead to significantly better results regarding mental models, explanation satisfaction, trust, emotions, and self-efficacy than two state-of-the art systems that work with saliency maps, namely LIME and LRP.",
    "citationCount": 100,
    "pdf_filename": "2020_GANterfactual_Counterfactual_Explanation_a0ae0261.pdf"
  },
  "2db0876940068279e829854a498337ddff796432": {
    "paperId": "2db0876940068279e829854a498337ddff796432",
    "title": "AI bias: exploring discriminatory algorithmic decision-making models and the application of possible machine-centric solutions adapted from the pharmaceutical industry",
    "year": 2022,
    "authors": "L. Belenguer",
    "abstract": "A new and unorthodox approach to deal with discriminatory bias in Artificial Intelligence is needed. As it is explored in detail, the current literature is a dichotomy with studies originating from the contrasting fields of study of either philosophy and sociology or data science and programming. It is suggested that there is a need instead for an integration of both academic approaches, and needs to be machine-centric rather than human-centric applied with a deep understanding of societal and individual prejudices. This article is a novel approach developed into a framework of action: a bias impact assessment to raise awareness of bias and why, a clear set of methodologies as shown in a table comparing with the four stages of pharmaceutical trials, and a summary flowchart. Finally, this study concludes the need for a transnational independent body with enough power to guarantee the implementation of those solutions.",
    "citationCount": 100,
    "pdf_filename": "2022_AI_bias__exploring_discriminatory_algori_2db08769.pdf"
  },
  "489abbb6e3afc7c8a378b6bc15e3cd4a13f8d5f5": {
    "paperId": "489abbb6e3afc7c8a378b6bc15e3cd4a13f8d5f5",
    "title": "Mapping value sensitive design onto AI for social good principles",
    "year": 2021,
    "authors": "Steven Umbrello, I. van de Poel",
    "abstract": "Value sensitive design (VSD) is an established method for integrating values into technical design. It has been applied to different technologies and, more recently, to artificial intelligence (AI). We argue that AI poses a number of challenges specific to VSD that require a somewhat modified VSD approach. Machine learning (ML), in particular, poses two challenges. First, humans may not understand how an AI system learns certain things. This requires paying attention to values such as transparency, explicability, and accountability. Second, ML may lead to AI systems adapting in ways that ‘disembody’ the values embedded in them. To address this, we propose a threefold modified VSD approach: (1) integrating a known set of VSD principles (AI4SG) as design norms from which more specific design requirements can be derived; (2) distinguishing between values that are promoted and respected by the design to ensure outcomes that not only do no harm but also contribute to good, and (3) extending the VSD process to encompass the whole life cycle of an AI technology to monitor unintended value consequences and redesign as needed. We illustrate our VSD for AI approach with an example use case of a SARS-CoV-2 contact tracing app.",
    "citationCount": 179,
    "pdf_filename": "2021_Mapping_value_sensitive_design_onto_AI_f_489abbb6.pdf"
  },
  "1b1109ed7549c009738caccb4405a04373c82e51": {
    "paperId": "1b1109ed7549c009738caccb4405a04373c82e51",
    "title": "Operationalising AI ethics: barriers, enablers and next steps",
    "year": 2021,
    "authors": "J. Morley, Libby Kinsey, Anat Elhalal, Francesca Garcia, M. Ziosi",
    "abstract": "By mid-2019 there were more than 80 AI ethics guides available in the public domain. Despite this, 2020 saw numerous news stories break related to ethically questionable uses of AI. In part, this is because AI ethics theory remains highly abstract, and of limited practical applicability to those actually responsible for designing algorithms and AI systems. Our previous research sought to start closing this gap between the ‘what’ and the ‘how’ of AI ethics through the creation of a searchable typology of tools and methods designed to translate between the five most common AI ethics principles and implementable design practices. Whilst a useful starting point, that research rested on the assumption that all AI practitioners are aware of the ethical implications of AI, understand their importance, and are actively seeking to respond to them. In reality, it is unclear whether this is the case. It is this limitation that we seek to overcome here by conducting a mixed-methods qualitative analysis to answer the following four questions: what do AI practitioners understand about the need to translate ethical principles into practice? What motivates AI practitioners to embed ethical principles into design practices? What barriers do AI practitioners face when attempting to translate ethical principles into practice? And finally, what assistance do AI practitioners want and need when translating ethical principles into practice?",
    "citationCount": 150,
    "pdf_filename": "2021_Operationalising_AI_ethics__barriers__en_1b1109ed.pdf"
  },
  "dd5a6c9ebde898e89e2d3db8153de774dce53c1a": {
    "paperId": "dd5a6c9ebde898e89e2d3db8153de774dce53c1a",
    "title": "Putting AI ethics to work: are the tools fit for purpose?",
    "year": 2021,
    "authors": "Jacqui Ayling, Adriane P. Chapman",
    "abstract": "Bias, unfairness and lack of transparency and accountability in Artificial Intelligence (AI) systems, and the potential for the misuse of predictive models for decision-making have raised concerns about the ethical impact and unintended consequences of new technologies for society across every sector where data-driven innovation is taking place. This paper reviews the landscape of suggested ethical frameworks with a focus on those which go beyond high-level statements of principles and offer practical tools for application of these principles in the production and deployment of systems. This work provides an assessment of these practical frameworks with the lens of known best practices for impact assessment and audit of technology. We review other historical uses of risk assessments and audits and create a typology that allows us to compare current AI ethics tools to Best Practices found in previous methodologies from technology, environment, privacy, finance and engineering. We analyse current AI ethics tools and their support for diverse stakeholders and components of the AI development and deployment lifecycle as well as the types of tools used to facilitate use. From this, we identify gaps in current AI ethics tools in auditing and risk assessment that should be considered going forward.",
    "citationCount": 157,
    "pdf_filename": "2021_Putting_AI_ethics_to_work__are_the_tools_dd5a6c9e.pdf"
  },
  "61b265b5a07bb563c2072e20ba22d3b9cdb95bc0": {
    "paperId": "61b265b5a07bb563c2072e20ba22d3b9cdb95bc0",
    "title": "In principle obstacles for empathic AI: why we can’t replace human empathy in healthcare",
    "year": 2021,
    "authors": "Carlos Montemayor, J. Halpern, A. Fairweather",
    "abstract": "What are the limits of the use of artificial intelligence (AI) in the relational aspects of medical and nursing care? There has been a lot of recent work and applications showing the promise and efficiency of AI in clinical medicine, both at the research and treatment levels. Many of the obstacles discussed in the literature are technical in character, regarding how to improve and optimize current practices in clinical medicine and also how to develop better data bases for optimal parameter adjustments and predictive algorithms. This paper argues that there are also in principle obstacles to the application of AI in clinical medicine and care where empathy is important, and that these problems cannot be solved with any of the technical and theoretical approaches that shape the current application of AI in specific areas of clinical medicine in which care for patients is fundamental. This is important, because it generates specific risks that may be overlooked otherwise, and it justifies the necessity of human monitoring and emotional intervention in clinical medicine. Consequently, difficult issues concerning moral and legal responsibility may ensue if these in principle problems are ignored.",
    "citationCount": 151,
    "pdf_filename": "2021_In_principle_obstacles_for_empathic_AI___61b265b5.pdf"
  },
  "1d2790cf793a3638470ffc8a712f5ae1a50c3b79": {
    "paperId": "1d2790cf793a3638470ffc8a712f5ae1a50c3b79",
    "title": "DARPA’s Explainable AI (XAI) program: A retrospective",
    "year": 2021,
    "authors": "David Gunning, E. Vorm, Jennifer Yunyan Wang, Matt Turek",
    "abstract": "DARPA formulated the Explainable Artificial Intelligence (XAI) program\nin 2015 with the goal to enable end users to better understand, trust,\nand effectively manage artificially intelligent systems. In 2017, the\nfour-year XAI research program began. Now, as XAI comes to an end in\n2021, it is time to reflect on what succeeded, what failed, and what was\nlearned. This article summarizes the goals, organization, and research\nprogress of the XAI Program.",
    "citationCount": 190,
    "pdf_filename": "2021_DARPA_s_Explainable_AI__XAI__program__A__1d2790cf.pdf"
  },
  "625821d95514db99e1d55342802aa8cfb372fcfb": {
    "paperId": "625821d95514db99e1d55342802aa8cfb372fcfb",
    "title": "You Can't Sit With Us: Exclusionary Pedagogy in AI Ethics Education",
    "year": 2021,
    "authors": "Inioluwa Deborah Raji, M. Scheuerman, Razvan Amironesei",
    "abstract": "Given a growing concern about the lack of ethical consideration in the Artificial Intelligence (AI) field, many have begun to question how dominant approaches to the disciplinary education of computer science (CS)---and its implications for AI---has led to the current \"ethics crisis\". However, we claim that the current AI ethics education space relies on a form of \"exclusionary pedagogy,\" where ethics is distilled for computational approaches, but there is no deeper epistemological engagement with other ways of knowing that would benefit ethical thinking or an acknowledgement of the limitations of uni-vocal computational thinking. This results in indifference, devaluation, and a lack of mutual support between CS and humanistic social science (HSS), elevating the myth of technologists as \"ethical unicorns\" that can do it all, though their disciplinary tools are ultimately limited. Through an analysis of computer science education literature and a review of college-level course syllabi in AI ethics, we discuss the limitations of the epistemological assumptions and hierarchies of knowledge which dictate current attempts at including ethics education in CS training and explore evidence for the practical mechanisms through which this exclusion occurs. We then propose a shift towards a substantively collaborative, holistic, and ethically generative pedagogy in AI education.",
    "citationCount": 125,
    "pdf_filename": "2021_You_Can_t_Sit_With_Us__Exclusionary_Peda_625821d9.pdf"
  },
  "5b3eb959cd98a29603c1d81acfe2ffb0df2d93cc": {
    "paperId": "5b3eb959cd98a29603c1d81acfe2ffb0df2d93cc",
    "title": "Speeding up to keep up: exploring the use of AI in the research process",
    "year": 2021,
    "authors": "J. Chubb, P. Cowling, D. Reed",
    "abstract": "There is a long history of the science of intelligent machines and its potential to provide scientific insights have been debated since the dawn of AI. In particular, there is renewed interest in the role of AI in research and research policy as an enabler of new methods, processes, management and evaluation which is still relatively under-explored. This empirical paper explores interviews with leading scholars on the potential impact of AI on research practice and culture through deductive, thematic analysis to show the issues affecting academics and universities today. Our interviewees identify positive and negative consequences for research and researchers with respect to collective and individual use. AI is perceived as helpful with respect to information gathering and other narrow tasks, and in support of impact and interdisciplinarity. However, using AI as a way of ‘speeding up—to keep up’ with bureaucratic and metricised processes, may proliferate negative aspects of academic culture in that the expansion of AI in research should assist and not replace human creativity. Research into the future role of AI in the research process needs to go further to address these challenges, and ask fundamental questions about how AI might assist in providing new tools able to question the values and principles driving institutions and research processes. We argue that to do this an explicit movement of meta-research on the role of AI in research should consider the effects for research and researcher creativity. Anticipatory approaches and engagement of diverse and critical voices at policy level and across disciplines should also be considered.",
    "citationCount": 116,
    "pdf_filename": "2021_Speeding_up_to_keep_up__exploring_the_us_5b3eb959.pdf"
  },
  "535c50a84e9652b1c94da85c1a0eeef31892dd86": {
    "paperId": "535c50a84e9652b1c94da85c1a0eeef31892dd86",
    "title": "Bosses without a heart: socio-demographic and cross-cultural determinants of attitude toward Emotional AI in the workplace",
    "year": 2021,
    "authors": "Peter Mantello, Manh-Tung Ho, Minh-Hoang Nguyen, Q. Vuong",
    "abstract": "Biometric technologies are becoming more pervasive in the workplace, augmenting managerial processes such as hiring, monitoring and terminating employees. Until recently, these devices consisted mainly of GPS tools that track location, software that scrutinizes browser activity and keyboard strokes, and heat/motion sensors that monitor workstation presence. Today, however, a new generation of biometric devices has emerged that can sense, read, monitor and evaluate the affective state of a worker. More popularly known by its commercial moniker, Emotional AI, the technology stems from advancements in affective computing. But whereas previous generations of biometric monitoring targeted the exterior physical body of the worker, concurrent with the writings of Foucault and Hardt, we argue that emotion-recognition tools signal a far more invasive disciplinary gaze that exposes and makes vulnerable the inner regions of the worker-self. Our paper explores attitudes towards empathic surveillance by analyzing a survey of 1015 responses of future job-seekers from 48 countries with Bayesian statistics. Our findings reveal affect tools, left unregulated in the workplace, may lead to heightened stress and anxiety among disadvantaged ethnicities, gender and income class. We also discuss a stark cross-cultural discrepancy whereby East Asians, compared to Western subjects, are more likely to profess a trusting attitude toward EAI-enabled automated management. While this emerging technology is driven by neoliberal incentives to optimize the worksite and increase productivity, ultimately, empathic surveillance may create more problems in terms of algorithmic bias, opaque decisionism, and the erosion of employment relations. Thus, this paper nuances and extends emerging literature on emotion-sensing technologies in the workplace, particularly through its highly original cross-cultural study.",
    "citationCount": 114,
    "pdf_filename": "2021_Bosses_without_a_heart__socio_demographi_535c50a8.pdf"
  },
  "0e97f8694c65f5e28f17de6004dd4ef33db88014": {
    "paperId": "0e97f8694c65f5e28f17de6004dd4ef33db88014",
    "title": "Envisioning Communities: A Participatory Approach Towards AI for Social Good",
    "year": 2021,
    "authors": "Elizabeth Bondi-Kelly, Lily Xu, Diana Acosta-Navas, J. Killian",
    "abstract": "Research in artificial intelligence (AI) for social good presupposes some definition of social good, but potential definitions have been seldom suggested and never agreed upon. The normative question of what AI for social good research should be \"for\" is not thoughtfully elaborated, or is frequently addressed with a utilitarian outlook that prioritizes the needs of the majority over those who have been historically marginalized, brushing aside realities of injustice and inequity. We argue that AI for social good ought to be assessed by the communities that the AI system will impact, using as a guide the capabilities approach, a framework to measure the ability of different policies to improve human welfare equity. Furthermore, we lay out how AI research has the potential to catalyze social progress by expanding and equalizing capabilities. We show how the capabilities approach aligns with a participatory approach for the design and implementation of AI for social good research in a framework we introduce called PACT, in which community members affected should be brought in as partners and their input prioritized throughout the project. We conclude by providing an incomplete set of guiding questions for carrying out such participatory AI research in a way that elicits and respects a community's own definition of social good.",
    "citationCount": 102,
    "pdf_filename": "2021_Envisioning_Communities__A_Participatory_0e97f869.pdf"
  },
  "7a7b6b7499107eb4043d8a88b2880319c17c2c18": {
    "paperId": "7a7b6b7499107eb4043d8a88b2880319c17c2c18",
    "title": "AI in the headlines: the portrayal of the ethical issues of artificial intelligence in the media",
    "year": 2020,
    "authors": "Leila Ouchchy, Allen Coin, Veljko Dubljević",
    "abstract": "As artificial intelligence (AI) technologies become increasingly prominent in our daily lives, media coverage of the ethical considerations of these technologies has followed suit. Since previous research has shown that media coverage can drive public discourse about novel technologies, studying how the ethical issues of AI are portrayed in the media may lead to greater insight into the potential ramifications of this public discourse, particularly with regard to development and regulation of AI. This paper expands upon previous research by systematically analyzing and categorizing the media portrayal of the ethical issues of AI to better understand how media coverage of these issues may shape public debate about AI. Our results suggest that the media has a fairly realistic and practical focus in its coverage of the ethics of AI, but that the coverage is still shallow. A multifaceted approach to handling the social, ethical and policy issues of AI technology is needed, including increasing the accessibility of correct information to the public in the form of fact sheets and ethical value statements on trusted webpages (e.g., government agencies), collaboration and inclusion of ethics and AI experts in both research and public debate, and consistent government policies or regulatory frameworks for AI technology.",
    "citationCount": 182,
    "pdf_filename": "2020_AI_in_the_headlines__the_portrayal_of_th_7a7b6b74.pdf"
  },
  "0a7109502e7fe91f4decc3dd3515e1fecbc02da7": {
    "paperId": "0a7109502e7fe91f4decc3dd3515e1fecbc02da7",
    "title": "Beyond the promise: implementing ethical AI",
    "year": 2020,
    "authors": "Ray Eitel-Porter",
    "abstract": "Artificial Intelligence (AI) applications can and do have unintended negative consequences for businesses if not implemented with care. Specifically, faulty or biased AI applications risk compliance and governance breaches and damage to the corporate brand. These issues commonly arise from a number of pitfalls associated with AI development, which include rushed development, a lack of technical understanding, and improper quality assurance, among other factors. To mitigate these risks, a growing number of organisations are working on ethical AI principles and frameworks. However, ethical AI principles alone are not sufficient for ensuring responsible AI use in enterprises. Businesses also require strong, mandated governance controls including tools for managing processes and creating associated audit trails to enforce their principles. Businesses that implement strong governance frameworks, overseen by an ethics board and strengthened with appropriate training, will reduce the risks associated with AI. When applied to AI modelling, the governance will also make it easier for businesses to bring their AI deployments to scale.",
    "citationCount": 162,
    "pdf_filename": "2020_Beyond_the_promise__implementing_ethical_0a710950.pdf"
  },
  "3fb4e0af816525a226d41ceae4b3299fbc3b9977": {
    "paperId": "3fb4e0af816525a226d41ceae4b3299fbc3b9977",
    "title": "Conversational AI: Dialogue Systems, Conversational Agents, and Chatbots",
    "year": 2020,
    "authors": "M. McTear",
    "abstract": "Abstract This book provides a comprehensive introduction to Conversational AI. While the idea of interacting with a computer using voice or text goes back a long way, it is only in recent years tha...",
    "citationCount": 146,
    "pdf_filename": "2020_Conversational_AI__Dialogue_Systems__Con_3fb4e0af.pdf"
  },
  "3862698833e74d527b66a57901004092b26b11d1": {
    "paperId": "3862698833e74d527b66a57901004092b26b11d1",
    "title": "More Than \"If Time Allows\": The Role of Ethics in AI Education",
    "year": 2020,
    "authors": "Natalie Garrett, Nathan Beard, Casey Fiesler",
    "abstract": "Even as public pressure mounts for technology companies to consider societal impacts of products, industries and governments in the AI race are demanding technical talent. To meet this demand, universities clamor to add technical artificial intelligence (AI) and machine learning (ML) courses into computing curriculum-but how are societal and ethical considerations part of this landscape? We explore two pathways for ethics content in AI education: (1) standalone AI ethics courses, and (2) integrating ethics into technical AI courses. For both pathways, we ask: What is being taught? As we train computer scientists who will build and deploy AI tools, how are we training them to consider the consequences of their work? In this exploratory work, we qualitatively analyzed 31 standalone AI ethics classes from 22 U.S. universities and 20 AI/ML technical courses from 12 U.S. universities to understand which ethics-related topics instructors include in courses. We identify and categorize topics in AI ethics education, share notable practices, and note omissions. Our analysis will help AI educators identify what topics should be taught and create scaffolding for developing future AI ethics education.",
    "citationCount": 141,
    "pdf_filename": "2020_More_Than__If_Time_Allows___The_Role_of__38626988.pdf"
  },
  "e92b81d6cb49cedcc98c2175377450dd6505673e": {
    "paperId": "e92b81d6cb49cedcc98c2175377450dd6505673e",
    "title": "Conceptual Metaphors Impact Perceptions of Human-AI Collaboration",
    "year": 2020,
    "authors": "Pranav Khadpe, Ranjay Krishna, Fei-Fei Li, Jeffrey T. Hancock, Michael S. Bernstein",
    "abstract": "With the emergence of conversational artificial intelligence (AI) agents, it is important to understand the mechanisms that influence users' experiences of these agents. In this paper, we study one of the most common tools in the designer's toolkit: conceptual metaphors. Metaphors can present an agent as akin to a wry teenager, a toddler, or an experienced butler. How might a choice of metaphor influence our experience of the AI agent? Sampling a set of metaphors along the dimensions of warmth and competence---defined by psychological theories as the primary axes of variation for human social perception---we perform a study $(N=260)$ where we manipulate the metaphor, but not the behavior, of a Wizard-of-Oz conversational agent. Following the experience, participants are surveyed about their intention to use the agent, their desire to cooperate with the agent, and the agent's usability. Contrary to the current tendency of designers to use high competence metaphors to describe AI products, we find that metaphors that signal low competence lead to better evaluations of the agent than metaphors that signal high competence. This effect persists despite both high and low competence agents featuring identical, human-level performance and the wizards being blind to condition. A second study confirms that intention to adopt decreases rapidly as competence projected by the metaphor increases. In a third study, we assess effects of metaphor choices on potential users' desire to try out the system and find that users are drawn to systems that project higher competence and warmth. These results suggest that projecting competence may help attract new users, but those users may discard the agent unless it can quickly correct with a lower competence metaphor. We close with a retrospective analysis that finds similar patterns between metaphors and user attitudes towards past conversational agents such as Xiaoice, Replika, Woebot, Mitsuku, and Tay.",
    "citationCount": 131,
    "pdf_filename": "2020_Conceptual_Metaphors_Impact_Perceptions__e92b81d6.pdf"
  },
  "89664effe9311a20a609d3a2cb514e5ef57cb9ce": {
    "paperId": "89664effe9311a20a609d3a2cb514e5ef57cb9ce",
    "title": "Clinical AI: opacity, accountability, responsibility and liability",
    "year": 2020,
    "authors": "Helen Smith",
    "abstract": "The aim of this literature review was to compose a narrative review supported by a systematic approach to critically identify and examine concerns about accountability and the allocation of responsibility and legal liability as applied to the clinician and the technologist as applied the use of opaque AI-powered systems in clinical decision making. This review questions (a) if it is permissible for a clinician to use an opaque AI system (AIS) in clinical decision making and (b) if a patient was harmed as a result of using a clinician using an AIS’s suggestion, how would responsibility and legal liability be allocated? Literature was systematically searched, retrieved, and reviewed from nine databases, which also included items from three clinical professional regulators, as well as relevant grey literature from governmental and non-governmental organisations. This literature was subjected to inclusion/exclusion criteria; those items found relevant to this review underwent data extraction. This review found that there are multiple concerns about opacity, accountability, responsibility and liability when considering the stakeholders of technologists and clinicians in the creation and use of AIS in clinical decision making. Accountability is challenged when the AIS used is opaque, and allocation of responsibility is somewhat unclear. Legal analysis would help stakeholders to understand their obligations and prepare should an undesirable scenario of patient harm eventuate when AIS were used.",
    "citationCount": 137,
    "pdf_filename": "2020_Clinical_AI__opacity__accountability__re_89664eff.pdf"
  },
  "553aac3ab3cbf05cc4a92e6cf4e177433da9d3a9": {
    "paperId": "553aac3ab3cbf05cc4a92e6cf4e177433da9d3a9",
    "title": "Simulating 500 million years of evolution with a language model.",
    "year": 2025,
    "authors": "Thomas Hayes, Roshan Rao, Halil Akin, Nicholas J Sofroniew, Deniz Oktay",
    "abstract": "More than three billion years of evolution have produced an image of biology encoded into the space of natural proteins. Here we show that language models trained at scale on evolutionary data can generate functional proteins that are far away from known proteins. We present ESM3, a frontier multimodal generative language model that reasons over the sequence, structure, and function of proteins. ESM3 can follow complex prompts combining its modalities and is highly responsive to alignment to improve its fidelity. We have prompted ESM3 to generate fluorescent proteins. Among the generations that we synthesized, we found a bright fluorescent protein at a far distance (58% sequence identity) from known fluorescent proteins, which we estimate is equivalent to simulating five hundred million years of evolution.",
    "citationCount": 134,
    "pdf_filename": "2025_Simulating_500_million_years_of_evolutio_553aac3a.pdf"
  },
  "856e055369b0216c928c66d964aeda8817fe822e": {
    "paperId": "856e055369b0216c928c66d964aeda8817fe822e",
    "title": "A small-molecule TNIK inhibitor targets fibrosis in preclinical and clinical models",
    "year": 2024,
    "authors": "Fengzhi Ren, Alex Aliper, Jian Chen, Heng Zhao, Sujata Rao",
    "abstract": "Idiopathic pulmonary fibrosis (IPF) is an aggressive interstitial lung disease with a high mortality rate. Putative drug targets in IPF have failed to translate into effective therapies at the clinical level. We identify TRAF2- and NCK-interacting kinase (TNIK) as an anti-fibrotic target using a predictive artificial intelligence (AI) approach. Using AI-driven methodology, we generated INS018_055, a small-molecule TNIK inhibitor, which exhibits desirable drug-like properties and anti-fibrotic activity across different organs in vivo through oral, inhaled or topical administration. INS018_055 possesses anti-inflammatory effects in addition to its anti-fibrotic profile, validated in multiple in vivo studies. Its safety and tolerability as well as pharmacokinetics were validated in a randomized, double-blinded, placebo-controlled phase I clinical trial (NCT05154240) involving 78 healthy participants. A separate phase I trial in China, CTR20221542, also demonstrated comparable safety and pharmacokinetic profiles. This work was completed in roughly 18 months from target discovery to preclinical candidate nomination and demonstrates the capabilities of our generative AI-driven drug-discovery pipeline. An AI-generated small-molecule inhibitor treats fibrosis in vivo and in phase I clinical trials.",
    "citationCount": 167,
    "pdf_filename": "2024_A_small_molecule_TNIK_inhibitor_targets__856e0553.pdf"
  },
  "402303ecf9fe73d152543a4e78d4014f1c7e2df2": {
    "paperId": "402303ecf9fe73d152543a4e78d4014f1c7e2df2",
    "title": "Artificial Intelligence for Predictive Maintenance Applications: Key Components, Trustworthiness, and Future Trends",
    "year": 2024,
    "authors": "Aysegul Ucar, Mehmet Karakose, Necim Kırımça",
    "abstract": "Predictive maintenance (PdM) is a policy applying data and analytics to predict when one of the components in a real system has been destroyed, and some anomalies appear so that maintenance can be performed before a breakdown takes place. Using cutting-edge technologies like data analytics and artificial intelligence (AI) enhances the performance and accuracy of predictive maintenance systems and increases their autonomy and adaptability in complex and dynamic working environments. This paper reviews the recent developments in AI-based PdM, focusing on key components, trustworthiness, and future trends. The state-of-the-art (SOTA) techniques, challenges, and opportunities associated with AI-based PdM are first analyzed. The integration of AI technologies into PdM in real-world applications, the human–robot interaction, the ethical issues emerging from using AI, and the testing and validation abilities of the developed policies are later discussed. This study exhibits the potential working areas for future research, such as digital twin, metaverse, generative AI, collaborative robots (cobots), blockchain technology, trustworthy AI, and Industrial Internet of Things (IIoT), utilizing a comprehensive survey of the current SOTA techniques, opportunities, and challenges allied with AI-based PdM.",
    "citationCount": 178,
    "pdf_filename": "2024_Artificial_Intelligence_for_Predictive_M_402303ec.pdf"
  },
  "9dfd2248d66f7227eb8a2b5d29064acf66174c9a": {
    "paperId": "9dfd2248d66f7227eb8a2b5d29064acf66174c9a",
    "title": "Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis",
    "year": 2023,
    "authors": "Hubert Siuzdak",
    "abstract": "Recent advancements in neural vocoding are predominantly driven by Generative Adversarial Networks (GANs) operating in the time-domain. While effective, this approach neglects the inductive bias offered by time-frequency representations, resulting in reduntant and computionally-intensive upsampling operations. Fourier-based time-frequency representation is an appealing alternative, aligning more accurately with human auditory perception, and benefitting from well-established fast algorithms for its computation. Nevertheless, direct reconstruction of complex-valued spectrograms has been historically problematic, primarily due to phase recovery issues. This study seeks to close this gap by presenting Vocos, a new model that directly generates Fourier spectral coefficients. Vocos not only matches the state-of-the-art in audio quality, as demonstrated in our evaluations, but it also substantially improves computational efficiency, achieving an order of magnitude increase in speed compared to prevailing time-domain neural vocoding approaches. The source code and model weights have been open-sourced at https://github.com/gemelo-ai/vocos.",
    "citationCount": 174,
    "pdf_filename": "2023_Vocos__Closing_the_gap_between_time_doma_9dfd2248.pdf"
  },
  "a677b65bf1e1f9881bccc90fe08261e11f79fab3": {
    "paperId": "a677b65bf1e1f9881bccc90fe08261e11f79fab3",
    "title": "Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation",
    "year": 2023,
    "authors": "Michal Stypulkowski, Konstantinos Vougioukas, Sen He, Maciej Ziȩba, Stavros Petridis",
    "abstract": "Talking face generation has historically struggled to produce head movements and natural facial expressions without guidance from additional reference videos. Recent developments in diffusion-based generative models allow for more realistic and stable data synthesis and their performance on image and video generation has surpassed that of other generative models. In this work, we present an autoregressive diffusion model that requires only one identity image and audio sequence to generate a video of a realistic talking head. Our solution is capable of hallucinating head movements, facial expressions, such as blinks, and preserving a given background. We evaluate our model on two different datasets, achieving state-of-the-art results in expressiveness and smoothness on both of them.1",
    "citationCount": 174,
    "pdf_filename": "2023_Diffused_Heads__Diffusion_Models_Beat_GA_a677b65b.pdf"
  },
  "07f07d4d59fdbc3596284f51057cb006779d42c1": {
    "paperId": "07f07d4d59fdbc3596284f51057cb006779d42c1",
    "title": "A Bibliometric Review of Large Language Models Research from 2017 to 2023",
    "year": 2023,
    "authors": "Lizhou Fan, Lingyao Li, Zihui Ma, Sanggyu Lee, Huizi Yu",
    "abstract": "Large language models (LLMs), such as OpenAI's Generative Pre-trained Transformer (GPT), are a class of language models that have demonstrated outstanding performance across a range of natural language processing (NLP) tasks. LLMs have become a highly sought-after research area because of their ability to generate human-like language and their potential to revolutionize science and technology. In this study, we conduct bibliometric and discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000 publications, this article serves as a roadmap for researchers, practitioners, and policymakers to navigate the current landscape of LLMs research. We present the research trends from 2017 to early 2023, identifying patterns in research paradigms and collaborations. We start with analyzing the core algorithm developments and NLP tasks that are fundamental in LLMs research. We then investigate the applications of LLMs in various fields and domains, including medicine, engineering, social science, and humanities. Our review also reveals the dynamic, fast-paced evolution of LLMs research. Overall, this article offers valuable insights into the current state, impact, and potential of LLMs research and its applications.",
    "citationCount": 194,
    "pdf_filename": "2023_A_Bibliometric_Review_of_Large_Language__07f07d4d.pdf"
  },
  "421a3f9355c83e30f9b6fd0df2f295430fc1766d": {
    "paperId": "421a3f9355c83e30f9b6fd0df2f295430fc1766d",
    "title": "Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models",
    "year": 2023,
    "authors": "Stephen Brade, Bryan Wang, Maurício Sousa, Sageev Oore, Tovi Grossman",
    "abstract": "Text-to-image generative models have demonstrated remarkable capabilities in generating high-quality images based on textual prompts. However, crafting prompts that accurately capture the user’s creative intent remains challenging. It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user’s intention. To address these challenges, we present Promptify, an interactive system that supports prompt exploration and refinement for text-to-image generative models. Promptify utilizes a suggestion engine powered by large language models to help users quickly explore and craft diverse prompts. Our interface allows users to organize the generated images flexibly, and based on their preferences, Promptify suggests potential changes to the original prompt. This feedback loop enables users to iteratively refine their prompts and enhance desired features while avoiding unwanted ones. Our user study shows that Promptify effectively facilitates the text-to-image workflow, allowing users to create visually appealing images on their first attempt while requiring significantly less cognitive load than a widely-used baseline tool.",
    "citationCount": 140,
    "pdf_filename": "2023_Promptify__Text_to_Image_Generation_thro_421a3f93.pdf"
  },
  "93be625e495c685301023774647d4446beeabc33": {
    "paperId": "93be625e495c685301023774647d4446beeabc33",
    "title": "Inverse design of nonlinear mechanical metamaterials via video denoising diffusion models",
    "year": 2023,
    "authors": "Jan-Hendrik Bastek, D. Kochmann",
    "abstract": "The accelerated inverse design of complex material properties—such as identifying a material with a given stress–strain response over a nonlinear deformation path—holds great potential for addressing challenges from soft robotics to biomedical implants and impact mitigation. Although machine learning models have provided such inverse mappings, they are typically restricted to linear target properties such as stiffness. Here, to tailor the nonlinear response, we show that video diffusion generative models trained on full-field data of periodic stochastic cellular structures can successfully predict and tune their nonlinear deformation and stress response under compression in the large-strain regime, including buckling and contact. Key to success is to break from the common strategy of directly learning a map from property to design and to extend the framework to intrinsically estimate the expected deformation path and the full-field internal stress distribution, which closely agree with finite element simulations. This work thus has the potential to simplify and accelerate the identification of materials with complex target performance. Machine learning models have been widely used in the inverse design of new materials, but typically only linear properties could be targeted. Bastek and Kochmann show that video diffusion generative models can produce the nonlinear deformation and stress response of cellular materials under large-scale compression.",
    "citationCount": 144,
    "pdf_filename": "2023_Inverse_design_of_nonlinear_mechanical_m_93be625e.pdf"
  },
  "901dfc3f07e8cb0cb74666429c67fedf30af87e8": {
    "paperId": "901dfc3f07e8cb0cb74666429c67fedf30af87e8",
    "title": "Students’ perceptions of using ChatGPT in a physics class as a virtual tutor",
    "year": 2023,
    "authors": "Lu Ding, Tong Li, Shiyan Jiang, Albert Gapud",
    "abstract": "The latest development of Generative Artificial Intelligence (GenAI), particularly ChatGPT, has drawn the attention of educational researchers and practitioners. We have witnessed many innovative uses of ChatGPT in STEM classrooms. However, studies regarding students’ perceptions of ChatGPT as a virtual tutoring tool in STEM education are rare. The current study investigated undergraduate students’ perceptions of using ChatGPT in a physics class as an assistant tool for addressing physics questions. Specifically, the study examined the accuracy of ChatGPT in answering physics questions, the relationship between students’ ChatGPT trust levels and answer accuracy, and the influence of trust on students’ perceptions of ChatGPT. Our finding indicates that despite the inaccuracy of GenAI in question answering, most students trust its ability to provide correct answers. Trust in GenAI is also associated with students’ perceptions of GenAI. In addition, this study sheds light on students’ misconceptions toward GenAI and provides suggestions for future considerations in AI literacy teaching and research.",
    "citationCount": 136,
    "pdf_filename": "2023_Students__perceptions_of_using_ChatGPT_i_901dfc3f.pdf"
  },
  "a25b5802f10a3d036afc0f8264e0bdd4618cf01d": {
    "paperId": "a25b5802f10a3d036afc0f8264e0bdd4618cf01d",
    "title": "Game of algorithms: ChatGPT implications for the future of tourism education and research",
    "year": 2023,
    "authors": "Stanislav Ivanov, Mohammad Soliman",
    "abstract": "PurposeThe paper aims to evaluate the ways ChatGPT is going to disrupt tourism education and research.Design/methodology/approachThis is a conceptual paper.FindingsChatGPT has the potential to revolutionize tourism education and research because it can do what students and researchers should do, namely, generate text (assignments and research papers). Universities will need to reevaluate their teaching and assessment strategies and incorporate generative language models in teaching. Publishers will need to be more receptive toward manuscripts that are partially generated by artificial intelligence. In the future, digital teachers and research assistants will take over many of the cognitive tasks of tourism educators and researchers.Originality/valueTo the authors’ best knowledge, this is one of the first academic papers that investigates the implications of ChatGPT to tourism education and research.",
    "citationCount": 131,
    "pdf_filename": "2023_Game_of_algorithms__ChatGPT_implications_a25b5802.pdf"
  },
  "17d648a0a8ec8a9b30c7bedccbc38b3ed0a5cdda": {
    "paperId": "17d648a0a8ec8a9b30c7bedccbc38b3ed0a5cdda",
    "title": "From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought",
    "year": 2023,
    "authors": "L. Wong, Gabriel Grand, Alexander K. Lew, Noah D. Goodman, Vikash K. Mansinghka",
    "abstract": "How does language inform our downstream thinking? In particular, how do humans make meaning from language--and how can we leverage a theory of linguistic meaning to build machines that think in more human-like ways? In this paper, we propose rational meaning construction, a computational framework for language-informed thinking that combines neural language models with probabilistic models for rational inference. We frame linguistic meaning as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT)--a general-purpose symbolic substrate for generative world modeling. Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language. We illustrate our framework through examples covering four core domains from cognitive science: probabilistic reasoning, logical and relational reasoning, visual and physical reasoning, and social reasoning. In each, we show that LLMs can generate context-sensitive translations that capture pragmatically-appropriate linguistic meanings, while Bayesian inference with the generated programs supports coherent and robust commonsense reasoning. We extend our framework to integrate cognitively-motivated symbolic modules (physics simulators, graphics engines, and planning algorithms) to provide a unified commonsense thinking interface from language. Finally, we explore how language can drive the construction of world models themselves. We hope this work will provide a roadmap towards cognitive models and AI systems that synthesize the insights of both modern and classical computational perspectives.",
    "citationCount": 125,
    "pdf_filename": "2023_From_Word_Models_to_World_Models__Transl_17d648a0.pdf"
  },
  "0302438b3656971ea3741b71d0da6e4c417c74cf": {
    "paperId": "0302438b3656971ea3741b71d0da6e4c417c74cf",
    "title": "A Comprehensive Study of ChatGPT: Advancements, Limitations, and Ethical Considerations in Natural Language Processing and Cybersecurity",
    "year": 2023,
    "authors": "Moatsum Alawida, S. Mejri, Abid Mehmood, B. Chikhaoui, Oludare Isaac Abiodun",
    "abstract": "This paper presents an in-depth study of ChatGPT, a state-of-the-art language model that is revolutionizing generative text. We provide a comprehensive analysis of its architecture, training data, and evaluation metrics and explore its advancements and enhancements over time. Additionally, we examine the capabilities and limitations of ChatGPT in natural language processing (NLP) tasks, including language translation, text summarization, and dialogue generation. Furthermore, we compare ChatGPT to other language generation models and discuss its applicability in various tasks. Our study also addresses the ethical and privacy considerations associated with ChatGPT and provides insights into mitigation strategies. Moreover, we investigate the role of ChatGPT in cyberattacks, highlighting potential security risks. Lastly, we showcase the diverse applications of ChatGPT in different industries and evaluate its performance across languages and domains. This paper offers a comprehensive exploration of ChatGPT’s impact on the NLP field.",
    "citationCount": 125,
    "pdf_filename": "2023_A_Comprehensive_Study_of_ChatGPT__Advanc_0302438b.pdf"
  },
  "f0bfec5397cd46cb0c192f798c6789ff259a5528": {
    "paperId": "f0bfec5397cd46cb0c192f798c6789ff259a5528",
    "title": "A Survey on Deep Learning for Symbolic Music Generation: Representations, Algorithms, Evaluations, and Challenges",
    "year": 2023,
    "authors": "Shulei Ji, Xinyu Yang, Jing Luo",
    "abstract": "Significant progress has been made in symbolic music generation with the help of deep learning techniques. However, the tasks covered by symbolic music generation have not been well summarized, and the evolution of generative models for the specific music generation task has not been illustrated systematically. This paper attempts to provide a task-oriented survey of symbolic music generation based on deep learning techniques, covering most of the currently popular music generation tasks. The distinct models under the same task are set forth briefly and strung according to their motivations, basically in chronological order. Moreover, we summarize the common datasets suitable for various tasks, discuss the music representations and the evaluation methods, highlight current challenges in symbolic music generation, and finally point out potential future research directions.",
    "citationCount": 106,
    "pdf_filename": "2023_A_Survey_on_Deep_Learning_for_Symbolic_M_f0bfec53.pdf"
  },
  "9e93ab728e3e174ec1492009055885a9123d434f": {
    "paperId": "9e93ab728e3e174ec1492009055885a9123d434f",
    "title": "Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing",
    "year": 2023,
    "authors": "Walid Hariri",
    "abstract": "Large language models, pivotal in artificial intelligence, find diverse applications. ChatGPT (Chat Generative Pre-trained Transformer), an OpenAI creation, stands out as a widely adopted, powerful tool. It excels in chatbots, content generation, language translation, recommendations, and medical applications, due to its ability to generate human-like responses, comprehend natural language, and adapt contextually. Its versatility and accuracy make it a potent force in natural language processing (NLP). Despite successes, ChatGPT has limitations, including biased responses and potential reinforcement of harmful language patterns. This article offers a comprehensive overview of ChatGPT, detailing its applications, advantages, and limitations. It also describes the main advancements from GPT-3 to GPT-4 Omni, comparing them with other LLMs like LLaMA 3, Gemini and Deepseek. The paper underscores the ethical imperative when utilizing this robust tool in practical settings. Furthermore, it contributes to ongoing discussions on artificial intelligence's impact on vision and NLP domains, providing insights into prompt engineering techniques.",
    "citationCount": 115,
    "pdf_filename": "2023_Unlocking_the_Potential_of_ChatGPT__A_Co_9e93ab72.pdf"
  },
  "416248cae7fd843e73f37141fad9fe25dfb9a08b": {
    "paperId": "416248cae7fd843e73f37141fad9fe25dfb9a08b",
    "title": "A Mathematical Investigation of Hallucination and Creativity in GPT Models",
    "year": 2023,
    "authors": "Minhyeok Lee",
    "abstract": "In this paper, we present a comprehensive mathematical analysis of the hallucination phenomenon in generative pretrained transformer (GPT) models. We rigorously define and measure hallucination and creativity using concepts from probability theory and information theory. By introducing a parametric family of GPT models, we characterize the trade-off between hallucination and creativity and identify an optimal balance that maximizes model performance across various tasks. Our work offers a novel mathematical framework for understanding the origins and implications of hallucination in GPT models and paves the way for future research and development in the field of large language models (LLMs).",
    "citationCount": 120,
    "pdf_filename": "2023_A_Mathematical_Investigation_of_Hallucin_416248ca.pdf"
  },
  "c83af97a9489f38611182c49d699f80c15ed9b65": {
    "paperId": "c83af97a9489f38611182c49d699f80c15ed9b65",
    "title": "Aligning Distillation For Cold-start Item Recommendation",
    "year": 2023,
    "authors": "Feiran Huang, Zefan Wang, Xiao Huang, Yu-hong Qian, Zhetao Li",
    "abstract": "Recommending cold items in recommendation systems is a longstanding challenge due to the inherent differences between warm items, which are recommended based on user behavior, and cold items, which are recommended based on content features. To tackle this, generative models generate synthetic embeddings from content features, while dropout models enhance the robustness of the recommendation system by randomly dropping behavioral embeddings during training. However, these models primarily focus on handling the recommendation of cold items, but do not effectively address the differences between warm and cold recommendations. As a result, generative models may over-recommend either warm or cold items, neglecting the other type, and dropout models may negatively impact warm item recommendations. To address this, we propose the Aligning Distillation (ALDI) framework, which leverages warm items as \"teachers\" to transfer their behavioral information to cold items, referred to as \"students\". ALDI aligns the students with the teachers by comparing the differences in their recommendation characters, using tailored rating distribution aligning, ranking aligning, and identification aligning losses to narrow these differences. Furthermore, ALDI incorporates a teacher-qualifying weighting structure to prevent students from learning inaccurate information from unreliable teachers. Experiments on three datasets show that our approach outperforms state-of-the-art baselines in terms of overall, warm, and cold recommendation performance with three different recommendation backbones.",
    "citationCount": 108,
    "pdf_filename": "2023_Aligning_Distillation_For_Cold_start_Ite_c83af97a.pdf"
  },
  "806d58b835800815d9d6ad0e5731b85c5956c69b": {
    "paperId": "806d58b835800815d9d6ad0e5731b85c5956c69b",
    "title": "Leveraging molecular structure and bioactivity with chemical language models for de novo drug design",
    "year": 2023,
    "authors": "Michael Moret, Irene Pachon Angona, Leandro Cotos, Shen Yan, Kenneth Atz",
    "abstract": "Generative Deep Learning holds promise for mining the unexplored “chemical universe” for new drugs. Here, the authors demonstrate the de novo design of phosphoinositide 3-kinase gamma (PI3Kγ) inhibitors for the PI3K/Akt pathway in human tumor cells. Generative chemical language models (CLMs) can be used for de novo molecular structure generation by learning from a textual representation of molecules. Here, we show that hybrid CLMs can additionally leverage the bioactivity information available for the training compounds. To computationally design ligands of phosphoinositide 3-kinase gamma (PI3Kγ), a collection of virtual molecules was created with a generative CLM. This virtual compound library was refined using a CLM-based classifier for bioactivity prediction. This second hybrid CLM was pretrained with patented molecular structures and fine-tuned with known PI3Kγ ligands. Several of the computer-generated molecular designs were commercially available, enabling fast prescreening and preliminary experimental validation. A new PI3Kγ ligand with sub-micromolar activity was identified, highlighting the method’s scaffold-hopping potential. Chemical synthesis and biochemical testing of two of the top-ranked de novo designed molecules and their derivatives corroborated the model’s ability to generate PI3Kγ ligands with medium to low nanomolar activity for hit-to-lead expansion. The most potent compounds led to pronounced inhibition of PI3K-dependent Akt phosphorylation in a medulloblastoma cell model, demonstrating efficacy of PI3Kγ ligands in PI3K/Akt pathway repression in human tumor cells. The results positively advocate hybrid CLMs for virtual compound screening and activity-focused molecular design.",
    "citationCount": 120,
    "pdf_filename": "2023_Leveraging_molecular_structure_and_bioac_806d58b8.pdf"
  },
  "321160254c3b059ec7aed0bcbd7d7c6d1be17372": {
    "paperId": "321160254c3b059ec7aed0bcbd7d7c6d1be17372",
    "title": "Large Language Models in Law: A Survey",
    "year": 2023,
    "authors": "Jinqi Lai, Wensheng Gan, Jiayang Wu, Zhenlian Qi, Philip S. Yu",
    "abstract": "The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs, but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementation presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges.",
    "citationCount": 149,
    "pdf_filename": "2023_Large_Language_Models_in_Law__A_Survey_32116025.pdf"
  },
  "4032c638728e155bb2d5d5b676ce7c99ccbf7db9": {
    "paperId": "4032c638728e155bb2d5d5b676ce7c99ccbf7db9",
    "title": "Use of GPT-4 to Diagnose Complex Clinical Cases",
    "year": 2023,
    "authors": "A. V. Eriksen, Sören Möller, J. Ryg",
    "abstract": "We assessed the performance of the newly released AI GPT-4 in diagnosing complex medical case challenges and compared the success rate to that of medical-journal readers. GPT-4 correctly diagnosed 57% of cases, outperforming 99.98% of simulated human readers generated from online answers. We highlight the potential for AI to be a powerful supportive tool for diagnosis; however, further improvements, validation, and addressing of ethical considerations are needed before clinical implementation. (No funding was obtained for this study.)",
    "citationCount": 136,
    "pdf_filename": "2023_Use_of_GPT_4_to_Diagnose_Complex_Clinica_4032c638.pdf"
  },
  "84055f6939af6750efab2e54688a3361a412ccbb": {
    "paperId": "84055f6939af6750efab2e54688a3361a412ccbb",
    "title": "Chatbots for future docs: exploring medical students’ attitudes and knowledge towards artificial intelligence and medical chatbots",
    "year": 2023,
    "authors": "Julia-Astrid Moldt, T. Festl-Wietek, Amir Madany Mamlouk, K. Nieselt, Wolfgang Fuhl",
    "abstract": "ABSTRACT Artificial intelligence (AI) in medicine and digital assistance systems such as chatbots will play an increasingly important role in future doctor – patient communication. To benefit from the potential of this technical innovation and ensure optimal patient care, future physicians should be equipped with the appropriate skills. Accordingly, a suitable place for the management and adaptation of digital assistance systems must be found in the medical education curriculum. To determine the existing levels of knowledge of medical students about AI chatbots in particular in the healthcare setting, this study surveyed medical students of the University of Luebeck and the University Hospital of Tuebingen. Using standardized quantitative questionnaires and qualitative analysis of group discussions, the attitudes of medical students toward AI and chatbots in medicine were investigated. From this, relevant requirements for the future integration of AI into the medical curriculum could be identified. The aim was to establish a basic understanding of the opportunities, limitations, and risks, as well as potential areas of application of the technology. The participants (N = 12) were able to develop an understanding of how AI and chatbots will affect their future daily work. Although basic attitudes toward the use of AI were positive, the students also expressed concerns. There were high levels of agreement regarding the use of AI in administrative settings (83.3%) and research with health-related data (91.7%). However, participants expressed concerns that data protection may be insufficiently guaranteed (33.3%) and that they might be increasingly monitored at work in the future (58.3%). The evaluations indicated that future physicians want to engage more intensively with AI in medicine. In view of future developments, AI and data competencies should be taught in a structured way during the medical curriculum and integrated into curricular teaching.",
    "citationCount": 132,
    "pdf_filename": "2023_Chatbots_for_future_docs__exploring_medi_84055f69.pdf"
  },
  "0d140d405916137cf5d91fbc8174f3aedc8239e9": {
    "paperId": "0d140d405916137cf5d91fbc8174f3aedc8239e9",
    "title": "The ethics of disclosing the use of artificial intelligence tools in writing scholarly manuscripts",
    "year": 2023,
    "authors": "Mohammad Hosseini, D. Resnik, Kristi L. Holmes",
    "abstract": "In this article, we discuss ethical issues related to using and disclosing artificial intelligence (AI) tools, such as ChatGPT and other systems based on large language models (LLMs), to write or edit scholarly manuscripts. Some journals, such as Science, have banned the use of LLMs because of the ethical problems they raise concerning responsible authorship. We argue that this is not a reasonable response to the moral conundrums created by the use of LLMs because bans are unenforceable and would encourage undisclosed use of LLMs. Furthermore, LLMs can be useful in writing, reviewing and editing text, and promote equity in science. Others have argued that LLMs should be mentioned in the acknowledgments since they do not meet all the authorship criteria. We argue that naming LLMs as authors or mentioning them in the acknowledgments are both inappropriate forms of recognition because LLMs do not have free will and therefore cannot be held morally or legally responsible for what they do. Tools in general, and software in particular, are usually cited in-text, followed by being mentioned in the references. We provide suggestions to improve APA Style for referencing ChatGPT to specifically indicate the contributor who used LLMs (because interactions are stored on personal user accounts), the used version and model (because the same version could use different language models and generate dissimilar responses, e.g., ChatGPT May 12 Version GPT3.5 or GPT4), and the time of usage (because LLMs evolve fast and generate dissimilar responses over time). We recommend that researchers who use LLMs: (1) disclose their use in the introduction or methods section to transparently describe details such as used prompts and note which parts of the text are affected, (2) use in-text citations and references (to recognize their used applications and improve findability and indexing), and (3) record and submit their relevant interactions with LLMs as supplementary material or appendices.",
    "citationCount": 128,
    "pdf_filename": "2023_The_ethics_of_disclosing_the_use_of_arti_0d140d40.pdf"
  },
  "37f5484e4ec6dbab9a022273e260a225a7ff71b6": {
    "paperId": "37f5484e4ec6dbab9a022273e260a225a7ff71b6",
    "title": "Fine_Denseiganet: Automatic Medical Image Classification in Chest CT Scan Using Hybrid Deep Learning Framework",
    "year": 2023,
    "authors": "Hemlata Sahu, R. Kashyap",
    "abstract": "Medical image classification is one of the most significant tasks in computer-aided diagnosis. In the era of modern healthcare, the progress of digitalized medical images has led to a crucial role in analyzing medical image analysis. Recently, accurate disease recognition from medical Computed Tomography (CT) images remains a challenging scenario which is important in rendering effective treatment to patients. The infectious COVID-19 disease is highly contagious and leads to a rapid increase in infected individuals. Some drawbacks noticed with RT-PCR kits are high false negative rate (FNR) and a shortage in the number of test kits. Hence, a Chest CT scan is introduced instead of RT-PCR which plays an important role in diagnosing and screening COVID-19 infections. However, manual examination of CT scans performed by radiologists can be time-consuming, and a manual review of each individual CT image may not be feasible in emergencies. Therefore, there is a need to perform automated COVID-19 detection with the advances in AI-based models. This work presents effective and automatic Deep Learning (DL)-based COVID-19 detection using Chest CT images. Initially, the data is gathered and pre-processed through Spatial Weighted Bilateral Filter (SWBF) to eradicate unwanted distortions. The extraction of deep features is processed using Fine_Dense Convolutional Network (Fine_DenseNet). For classification, the Softmax layer of Fine_DenseNet is replaced using Improved Generative Adversarial Network_Artificial Hummingbird (IGAN_AHb) model in order to train the data on the labeled and unlabeled dataset. The loss in the network model is optimized using Artificial Hummingbird (AHb) optimization algorithm. Here, the proposed DL model (Fine_DenseIGANet) is used to perform automated multi-class classification of COVID-19 using CT scan images and attained a superior classification accuracy of 95.73% over other DL models.",
    "citationCount": 121,
    "pdf_filename": "2023_Fine_Denseiganet__Automatic_Medical_Imag_37f5484e.pdf"
  },
  "8bfb1b701c801fc8fa470379c4a86341a9ea36e0": {
    "paperId": "8bfb1b701c801fc8fa470379c4a86341a9ea36e0",
    "title": "Protein Structure and Sequence Generation with Equivariant Denoising Diffusion Probabilistic Models",
    "year": 2022,
    "authors": "N. Anand, Tudor Achim",
    "abstract": "Proteins are macromolecules that mediate a significant fraction of the cellular processes that underlie life. An important task in bioengineering is designing proteins with specific 3D structures and chemical properties which enable targeted functions. To this end, we introduce a generative model of both protein structure and sequence that can operate at significantly larger scales than previous molecular generative modeling approaches. The model is learned entirely from experimental data and conditions its generation on a compact specification of protein topology to produce a full-atom backbone configuration as well as sequence and side-chain predictions. We demonstrate the quality of the model via qualitative and quantitative analysis of its samples. Videos of sampling trajectories are available at https://nanand2.github.io/proteins .",
    "citationCount": 198,
    "pdf_filename": "2022_Protein_Structure_and_Sequence_Generatio_8bfb1b70.pdf"
  },
  "34f1ff785af21f1531e1d31f3e260a30198cd6d4": {
    "paperId": "34f1ff785af21f1531e1d31f3e260a30198cd6d4",
    "title": "Towards the Detection of Diffusion Model Deepfakes",
    "year": 2022,
    "authors": "Jonas Ricker, Simon Damm, Thorsten Holz, Asja Fischer",
    "abstract": "In the course of the past few years, diffusion models (DMs) have reached an unprecedented level of visual quality. However, relatively little attention has been paid to the detection of DM-generated images, which is critical to prevent adverse impacts on our society. In contrast, generative adversarial networks (GANs), have been extensively studied from a forensic perspective. In this work, we therefore take the natural next step to evaluate whether previous methods can be used to detect images generated by DMs. Our experiments yield two key findings: (1) state-of-the-art GAN detectors are unable to reliably distinguish real from DM-generated images, but (2) re-training them on DM-generated images allows for almost perfect detection, which remarkably even generalizes to GANs. Together with a feature space analysis, our results lead to the hypothesis that DMs produce fewer detectable artifacts and are thus more difficult to detect compared to GANs. One possible reason for this is the absence of grid-like frequency artifacts in DM-generated images, which are a known weakness of GANs. However, we make the interesting observation that diffusion models tend to underestimate high frequencies, which we attribute to the learning objective.",
    "citationCount": 133,
    "pdf_filename": "2022_Towards_the_Detection_of_Diffusion_Model_34f1ff78.pdf"
  },
  "9ab5c6644082b6fdbd6a2b0e6ae3527668244424": {
    "paperId": "9ab5c6644082b6fdbd6a2b0e6ae3527668244424",
    "title": "Machine-Generated Text: A Comprehensive Survey of Threat Models and Detection Methods",
    "year": 2022,
    "authors": "Evan Crothers, N. Japkowicz, H. Viktor",
    "abstract": "Machine-generated text is increasingly difficult to distinguish from text authored by humans. Powerful open-source models are freely available, and user-friendly tools that democratize access to generative models are proliferating. ChatGPT, which was released shortly after the first edition of this survey, epitomizes these trends. The great potential of state-of-the-art natural language generation (NLG) systems is tempered by the multitude of avenues for abuse. Detection of machine-generated text is a key countermeasure for reducing the abuse of NLG models, and presents significant technical challenges and numerous open problems. We provide a survey that includes 1) an extensive analysis of threat models posed by contemporary NLG systems and 2) the most complete review of machine-generated text detection methods to date. This survey places machine-generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models. While doing so, we highlight the importance that detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability.",
    "citationCount": 148,
    "pdf_filename": "2022_Machine_Generated_Text__A_Comprehensive__9ab5c664.pdf"
  },
  "9e33460168097cca50a0b955b1b6b44bf82f0ea8": {
    "paperId": "9e33460168097cca50a0b955b1b6b44bf82f0ea8",
    "title": "Generated Faces in the Wild: Quantitative Comparison of Stable Diffusion, Midjourney and DALL-E 2",
    "year": 2022,
    "authors": "A. Borji",
    "abstract": "The field of image synthesis has made great strides in the last couple of years. Recent models are capable of generating images with astonishing quality. Fine-grained evaluation of these models on some interesting categories such as faces is still missing. Here, we conduct a quantitative comparison of three popular systems including Stable Diffusion, Midjourney, and DALL-E 2 in their ability to generate photorealistic faces in the wild. We find that Stable Diffusion generates better faces than the other systems, according to the FID score. We also introduce a dataset of generated faces in the wild dubbed GFW, including a total of 15,076 faces. Furthermore, we hope that our study spurs follow-up research in assessing the generative models and improving them. Data and code are available at data and code, respectively.",
    "citationCount": 157,
    "pdf_filename": "2022_Generated_Faces_in_the_Wild__Quantitativ_9e334601.pdf"
  },
  "09797949fc70fbad8f3fed4f6cf4a91a9c709652": {
    "paperId": "09797949fc70fbad8f3fed4f6cf4a91a9c709652",
    "title": "New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology",
    "year": 2022,
    "authors": "Siddharth Nath, Abdullah Marie, S. Ellershaw, Edward Korot, P. Keane",
    "abstract": "Natural language processing (NLP) is a subfield of machine intelligence focused on the interaction of human language with computer systems. NLP has recently been discussed in the mainstream media and the literature with the advent of Generative Pre-trained Transformer 3 (GPT-3), a language model capable of producing human-like text. The release of GPT-3 has also sparked renewed interest on the applicability of NLP to contemporary healthcare problems. This article provides an overview of NLP models, with a focus on GPT-3, as well as discussion of applications specific to ophthalmology. We also outline the limitations of GPT-3 and the challenges with its integration into routine ophthalmic care.",
    "citationCount": 103,
    "pdf_filename": "2022_New_meaning_for_NLP__the_trials_and_trib_09797949.pdf"
  },
  "7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb": {
    "paperId": "7faff5b4f3fd3cbcc9b9ce61a0a371e13be1c9bb",
    "title": "The ethical issues of the application of artificial intelligence in healthcare: a systematic scoping review",
    "year": 2022,
    "authors": "Golnar Karimian, Elena Petelos, S. Evers",
    "abstract": "Artificial intelligence (AI) is being increasingly applied in healthcare. The expansion of AI in healthcare necessitates AI-related ethical issues to be studied and addressed. This systematic scoping review was conducted to identify the ethical issues of AI application in healthcare, to highlight gaps, and to propose steps to move towards an evidence-informed approach for addressing them. A systematic search was conducted to retrieve all articles examining the ethical aspects of AI application in healthcare from Medline (PubMed) and Embase (OVID), published between 2010 and July 21, 2020. The search terms were “artificial intelligence” or “machine learning” or “deep learning” in combination with “ethics” or “bioethics”. The studies were selected utilizing a PRISMA flowchart and predefined inclusion criteria. Ethical principles of respect for human autonomy, prevention of harm, fairness, explicability, and privacy were charted. The search yielded 2166 articles, of which 18 articles were selected for data charting on the basis of the predefined inclusion criteria. The focus of many articles was a general discussion about ethics and AI. Nevertheless, there was limited examination of ethical principles in terms of consideration for design or deployment of AI in most retrieved studies. In the few instances where ethical principles were considered, fairness, preservation of human autonomy, explicability and privacy were equally discussed. The principle of prevention of harm was the least explored topic. Practical tools for testing and upholding ethical requirements across the lifecycle of AI-based technologies are largely absent from the body of reported evidence. In addition, the perspective of different stakeholders is largely missing.",
    "citationCount": 149,
    "pdf_filename": "2022_The_ethical_issues_of_the_application_of_7faff5b4.pdf"
  },
  "8e19265e4e20575c292c89a2d9faa85780498709": {
    "paperId": "8e19265e4e20575c292c89a2d9faa85780498709",
    "title": "A Unified Deep Learning Anomaly Detection and Classification Approach for Smart Grid Environments",
    "year": 2021,
    "authors": "Ilias Siniosoglou, Panagiotis I. Radoglou-Grammatikis, G. Efstathopoulos, Panagiotis E. Fouliras, Panos Sarigiannidis",
    "abstract": "The interconnected and heterogeneous nature of the next-generation Electrical Grid (EG), widely known as Smart Grid (SG), bring severe cybersecurity and privacy risks that can also raise domino effects against other Critical Infrastructures (CIs). In this paper, we present an Intrusion Detection System (IDS) specially designed for the SG environments that use Modbus/Transmission Control Protocol (TCP) and Distributed Network Protocol 3 (DNP3) protocols. The proposed IDS called MENSA (anoMaly dEtection aNd claSsificAtion) adopts a novel Autoencoder-Generative Adversarial Network (GAN) architecture for (a) detecting operational anomalies and (b) classifying Modbus/TCP and DNP3 cyberattacks. In particular, MENSA combines the aforementioned Deep Neural Networks (DNNs) in a common architecture, taking into account the adversarial loss and the reconstruction difference. The proposed IDS is validated in four real SG evaluation environments, namely (a) SG lab, (b) substation, (c) hydropower plant and (d) power plant, solving successfully an outlier detection (i.e., anomaly detection) problem as well as a challenging multiclass classification problem consisting of 14 classes (13 Modbus/TCP cyberattacks and normal instances). Furthermore, MENSA can discriminate five cyberattacks against DNP3. The evaluation results demonstrate the efficiency of MENSA compared to other Machine Learning (ML) and Deep Learning (DL) methods in terms of Accuracy, False Positive Rate (FPR), True Positive Rate (TPR) and the F1 score.",
    "citationCount": 186,
    "pdf_filename": "2021_A_Unified_Deep_Learning_Anomaly_Detectio_8e19265e.pdf"
  },
  "0f1c956f84a68ea4d6f5ebcf3c4d1d4e1f41d8f3": {
    "paperId": "0f1c956f84a68ea4d6f5ebcf3c4d1d4e1f41d8f3",
    "title": "Language models can learn complex molecular distributions",
    "year": 2021,
    "authors": "Daniel Flam-Shepherd, Kevin Zhu, A. Aspuru‐Guzik",
    "abstract": "Deep generative models of molecules have grown immensely in popularity, trained on relevant datasets, these models are used to search through chemical space. The downstream utility of generative models for the inverse design of novel functional compounds, depends on their ability to learn a training distribution of molecules. The most simple example is a language model that takes the form of a recurrent neural network and generates molecules using a string representation. Since their initial use, subsequent work has shown that language models are very capable, in particular, recent research has demonstrated their utility in the low data regime. In this work, we investigate the capacity of simple language models to learn more complex distributions of molecules. For this purpose, we introduce several challenging generative modeling tasks by compiling larger, more complex distributions of molecules and we evaluate the ability of language models on each task. The results demonstrate that language models are powerful generative models, capable of adeptly learning complex molecular distributions. Language models can accurately generate: distributions of the highest scoring penalized LogP molecules in ZINC15, multi-modal molecular distributions as well as the largest molecules in PubChem. The results highlight the limitations of some of the most popular and recent graph generative models– many of which cannot scale to these molecular distributions. Generative models for the novo molecular design attract enormous interest for exploring the chemical space. Here the authors investigate the application of chemical language models to challenging modeling tasks demonstrating their capability of learning complex molecular distributions.",
    "citationCount": 169,
    "pdf_filename": "2021_Language_models_can_learn_complex_molecu_0f1c956f.pdf"
  },
  "5b7916ad1672695dc8c6fc422274bfcd1968a25e": {
    "paperId": "5b7916ad1672695dc8c6fc422274bfcd1968a25e",
    "title": "How Cognitive Biases Affect XAI-assisted Decision-making: A Systematic Review",
    "year": 2022,
    "authors": "Astrid Bertrand, Rafik Belloum, Winston Maxwell, James R. Eagan",
    "abstract": "The field of eXplainable Artificial Intelligence (XAI) aims to bring transparency to complex AI systems. Although it is usually considered an essentially technical field, effort has been made recently to better understand users' human explanation methods and cognitive constraints. Despite these advances, the community lacks a general vision of what and how cognitive biases affect explainability systems. To address this gap, we present a heuristic map which matches human cognitive biases with explainability techniques from the XAI literature, structured around XAI-aided decision-making. We identify four main ways cognitive biases affect or are affected by XAI systems: 1) cognitive biases affect how XAI methods are designed, 2) they can distort how XAI techniques are evaluated in user studies, 3) some cognitive biases can be successfully mitigated by XAI techniques, and, on the contrary, 4) some cognitive biases can be exacerbated by XAI techniques. We construct this heuristic map through the systematic review of 37 papers-drawn from a corpus of 285-that reveal cognitive biases in XAI systems, including the explainability method and the user and task types in which they arise. We use the findings from our review to structure directions for future XAI systems to better align with people's cognitive processes.",
    "citationCount": 127,
    "pdf_filename": "2022_How_Cognitive_Biases_Affect_XAI_assisted_5b7916ad.pdf"
  },
  "2a3e997957a023ae7c4f43a92ad57a63edfc9ca1": {
    "paperId": "2a3e997957a023ae7c4f43a92ad57a63edfc9ca1",
    "title": "Opal: Multimodal Image Generation for News Illustration",
    "year": 2022,
    "authors": "Vivian Liu, Han Qiao, Lydia B. Chilton",
    "abstract": "Advances in multimodal AI have presented people with powerful ways to create images from text. Recent work has shown that text-to-image generations are able to represent a broad range of subjects and artistic styles. However, finding the right visual language for text prompts is difficult. In this paper, we address this challenge with Opal, a system that produces text-to-image generations for news illustration. Given an article, Opal guides users through a structured search for visual concepts and provides a pipeline allowing users to generate illustrations based on an article’s tone, keywords, and related artistic styles. Our evaluation shows that Opal efficiently generates diverse sets of news illustrations, visual assets, and concept ideas. Users with Opal generated two times more usable results than users without. We discuss how structured exploration can help users better understand the capabilities of human AI co-creative systems.",
    "citationCount": 120,
    "pdf_filename": "2022_Opal__Multimodal_Image_Generation_for_Ne_2a3e9979.pdf"
  },
  "722ae1415e102ff258d5cbf31cfaacd6fd31d99f": {
    "paperId": "722ae1415e102ff258d5cbf31cfaacd6fd31d99f",
    "title": "Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers",
    "year": 2024,
    "authors": "Peng Gao, Le Zhuo, Ziyi Lin, Chris Liu, Junsong Chen",
    "abstract": "Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details. In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions. By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions. This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference. Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens. This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions. We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community.",
    "citationCount": 118,
    "pdf_filename": "2024_Lumina_T2X__Transforming_Text_into_Any_M_722ae141.pdf"
  },
  "495dd58b86ccee51f1a7011dbf3c4e4f55219597": {
    "paperId": "495dd58b86ccee51f1a7011dbf3c4e4f55219597",
    "title": "The news framing of artificial intelligence: a critical exploration of how media discourses make sense of automation",
    "year": 2022,
    "authors": "Dennis Nguyen, Erik Hekman",
    "abstract": "Analysing how news media portray A.I. reveals what interpretative frameworks around the technology circulate in public discourses. This allows for critical reflections on the making of meaning in prevalent narratives about A.I. and its impact. While research on the public perception of datafication and automation is growing, only a few studies investigate news framing practices. The present study connects to this nascent research area by charting A.I. news frames in four internationally renowned media outlets: The New York Times, The Guardian, Wired, and Gizmodo. The main goals are to identify dominant emphasis frames in AI news reporting over the past decade, to explore whether certain A.I. frames are associated with specific data risks (surveillance, data bias, cyber-war/cyber-crime, and information disorder), and what journalists and experts contribute to the media discourse. An automated content analysis serves for inductive frame detection (N = 3098), identification of risk references (dictionary-based), and network analysis of news writers. The results show how A.I.’s ubiquity emerged rapidly in the mid-2010s, and that the news discourse became more critical over time. It is further argued that A.I. news reporting is an important factor in building critical data literacy among lay audiences.",
    "citationCount": 112,
    "pdf_filename": "2022_The_news_framing_of_artificial_intellige_495dd58b.pdf"
  },
  "fb8d5b02bc61eb3b8ee746704893e799b969e961": {
    "paperId": "fb8d5b02bc61eb3b8ee746704893e799b969e961",
    "title": "Explaining the Black-box Smoothly- A Counterfactual Approach",
    "year": 2021,
    "authors": "Junyu Chen, Yong Du, Yufan He, W. Paul Segars, Ye Li",
    "abstract": "We propose a BlackBox Counterfactual Explainer, designed to explain image classification models for medical applications. Classical approaches (e.g., , saliency maps) that assess feature importance do not explain how imaging features in important anatomical regions are relevant to the classification decision. Such reasoning is crucial for transparent decision-making in healthcare applications. Our framework explains the decision for a target class by gradually exaggerating the semantic effect of the class in a query image. We adopted a Generative Adversarial Network (GAN) to generate a progressive set of perturbations to a query image, such that the classification decision changes from its original class to its negation. Our proposed loss function preserves essential details (e.g., support devices) in the generated images. We used counterfactual explanations from our framework to audit a classifier trained on a chest X-ray dataset with multiple labels. Clinical evaluation of model explanations is a challenging task. We proposed clinically-relevant quantitative metrics such as cardiothoracic ratio and the score of a healthy costophrenic recess to evaluate our explanations. We used these metrics to quantify the counterfactual changes between the populations with negative and positive decisions for a diagnosis by the given classifier. We conducted a human-grounded experiment with diagnostic radiology residents to compare different styles of explanations (no explanation, saliency map, cycleGAN explanation, and our counterfactual explanation) by evaluating different aspects of explanations: (1) understandability, (2) classifier's decision justification, (3) visual quality, (d) identity preservation, and (5) overall helpfulness of an explanation to the users. Our results show that our counterfactual explanation was the only explanation method that significantly improved the users' understanding of the classifier's decision compared to the no-explanation baseline. Our metrics established a benchmark for evaluating model explanation methods in medical images. Our explanations revealed that the classifier relied on clinically relevant radiographic features for its diagnostic decisions, thus making its decision-making process more transparent to the end-user.",
    "citationCount": 122,
    "pdf_filename": "2021_Explaining_the_Black_box_Smoothly__A_Cou_fb8d5b02.pdf"
  },
  "1f85e686d848db4d8797aab4a67ba5838c6cffed": {
    "paperId": "1f85e686d848db4d8797aab4a67ba5838c6cffed",
    "title": "Deep Learning-Based Image Semantic Coding for Semantic Communications",
    "year": 2021,
    "authors": "Danlan Huang, Xiaoming Tao, F. Gao, Jianhua Lu",
    "abstract": "This paper presents the Generative Adversarial Networks (GANs)-based image semantic coding, the goal of which is semantic exchange rather than symbol transmission. State-of-the-art visually pleasing reconstruction and semantic preserving performance are obtained in extreme low bitrate via a rate-perception-distortion optimization framework. In particular, we investigate convolutional encoder, quantizer, conditional SPADE generator, residual coding as well as perceptual losses. In contrast to previous work, we designed a coarse-to-fine image semantic coding model for multimedia semantic communication system. The base layer of the image is fully generated and preserves semantic information while the enhancement layer restores the fine details. We explore the perception and distortion performance trade-off by tuning the rate of base layer and enhancement layer. Different from the existing methods that adopt pixel accuracy as distortion metric, we train and evaluate the proposed image semantic coding model with multiple perception metrics, in line with the purpose of semantic communications. Experimental results demonstrate that our model could achieve visually pleasant and semantic consistent reconstruction, as well as saving times of bitrate, compared to BPG, WebP, JPEG2000, JPEG, and other deep learning-based image codecs.",
    "citationCount": 118,
    "pdf_filename": "2021_Deep_Learning_Based_Image_Semantic_Codin_1f85e686.pdf"
  },
  "419100bc2f2035198e1ed55ffa632a535c16a2fa": {
    "paperId": "419100bc2f2035198e1ed55ffa632a535c16a2fa",
    "title": "SinGAN-Seg: Synthetic training data generation for medical image segmentation",
    "year": 2021,
    "authors": "Vajira Lasantha Thambawita, Pegah Salehi, Sajad Amouei Sheshkal, Steven Hicks, Hugo L.Hammer",
    "abstract": "Analyzing medical data to find abnormalities is a time-consuming and costly task, particularly for rare abnormalities, requiring tremendous efforts from medical experts. Therefore, artificial intelligence has become a popular tool for the automatic processing of medical data, acting as a supportive tool for doctors. However, the machine learning models used to build these tools are highly dependent on the data used to train them. Large amounts of data can be difficult to obtain in medicine due to privacy reasons, expensive and time-consuming annotations, and a general lack of data samples for infrequent lesions. In this study, we present a novel synthetic data generation pipeline, called SinGAN-Seg, to produce synthetic medical images with corresponding masks using a single training image. Our method is different from the traditional generative adversarial networks (GANs) because our model needs only a single image and the corresponding ground truth to train. We also show that the synthetic data generation pipeline can be used to produce alternative artificial segmentation datasets with corresponding ground truth masks when real datasets are not allowed to share. The pipeline is evaluated using qualitative and quantitative comparisons between real data and synthetic data to show that the style transfer technique used in our pipeline significantly improves the quality of the generated data and our method is better than other state-of-the-art GANs to prepare synthetic images when the size of training datasets are limited. By training UNet++ using both real data and the synthetic data generated from the SinGAN-Seg pipeline, we show that the models trained on synthetic data have very close performances to those trained on real data when both datasets have a considerable amount of training data. In contrast, we show that synthetic data generated from the SinGAN-Seg pipeline improves the performance of segmentation models when training datasets do not have a considerable amount of data. All experiments were performed using an open dataset and the code is publicly available on GitHub.",
    "citationCount": 103,
    "pdf_filename": "2021_SinGAN_Seg__Synthetic_training_data_gene_419100bc.pdf"
  },
  "3c6f7ec37cedd2d487c42ce58a6da2c9293cbdd9": {
    "paperId": "3c6f7ec37cedd2d487c42ce58a6da2c9293cbdd9",
    "title": "Federated Learning for Privacy Preservation in Smart Healthcare Systems: A Comprehensive Survey",
    "year": 2022,
    "authors": "Mansoor Ali, Faisal Naeem, M. Tariq, Georges Kaddoum",
    "abstract": "Recent advances in electronic devices and communication infrastructure have revolutionized the traditional healthcare system into a smart healthcare system by using internet of medical things (IoMT) devices. However, due to the centralized training approach of artificial intelligence (AI), mobile and wearable IoMT devices raise privacy issues concerning the information communicated between hospitals and end-users. The information conveyed by the IoMT devices is highly confidential and can be exposed to adversaries. In this regard, federated learning (FL), a distributive AI paradigm, has opened up new opportunities for privacy preservation in IoMT without accessing the confidential data of the participants. Further, FL provides privacy to end-users as only gradients are shared during training. For these specific properties of FL, in this paper, we present privacy-related issues in IoMT. Afterwards, we present the role of FL in IoMT networks for privacy preservation and introduce some advanced FL architectures by incorporating deep reinforcement learning (DRL), digital twin, and generative adversarial networks (GANs) for detecting privacy threats. Moreover, we present some practical opportunities for FL in IoMT. In the end, we conclude this survey by discussing open research issues and challenges while using FL in future smart healthcare systems.",
    "citationCount": 177,
    "pdf_filename": "2022_Federated_Learning_for_Privacy_Preservat_3c6f7ec3.pdf"
  },
  "b9c4ec6e99dd57ff3b4f04d324a22e6c48dc2064": {
    "paperId": "b9c4ec6e99dd57ff3b4f04d324a22e6c48dc2064",
    "title": "Graph networks for molecular design",
    "year": 2020,
    "authors": "Rocío Mercado, T. Rastemo, Edvard Lindelöf, G. Klambauer, O. Engkvist",
    "abstract": "Deep learning methods applied to chemistry can be used to accelerate the discovery of new molecules. This work introduces GraphINVENT, a platform developed for graph-based molecular design using graph neural networks (GNNs). GraphINVENT uses a tiered deep neural network architecture to probabilistically generate new molecules a single bond at a time. All models implemented in GraphINVENT can quickly learn to build molecules resembling the training set molecules without any explicit programming of chemical rules. The models have been benchmarked using the MOSES distribution-based metrics, showing how GraphINVENT models compare well with state-of-the-art generative models. This work compares six different GNN-based generative models in GraphINVENT, and shows that ultimately the gated-graph neural network performs best against the metrics considered here.",
    "citationCount": 181,
    "pdf_filename": "2020_Graph_networks_for_molecular_design_b9c4ec6e.pdf"
  },
  "266db595c4a77f4bbef941369be31b691428f55a": {
    "paperId": "266db595c4a77f4bbef941369be31b691428f55a",
    "title": "Accelerating antibiotic discovery through artificial intelligence",
    "year": 2021,
    "authors": "Marcelo C. R. Melo, Jacqueline R. M. A. Maasch, César de la Fuente-Nunez",
    "abstract": "By targeting invasive organisms, antibiotics insert themselves into the ancient struggle of the host-pathogen evolutionary arms race. As pathogens evolve tactics for evading antibiotics, therapies decline in efficacy and must be replaced, distinguishing antibiotics from most other forms of drug development. Together with a slow and expensive antibiotic development pipeline, the proliferation of drug-resistant pathogens drives urgent interest in computational methods that promise to expedite candidate discovery. Strides in artificial intelligence (AI) have encouraged its application to multiple dimensions of computer-aided drug design, with increasing application to antibiotic discovery. This review describes AI-facilitated advances in the discovery of both small molecule antibiotics and antimicrobial peptides. Beyond the essential prediction of antimicrobial activity, emphasis is also given to antimicrobial compound representation, determination of drug-likeness traits, antimicrobial resistance, and de novo molecular design. Given the urgency of the antimicrobial resistance crisis, we analyze uptake of open science best practices in AI-driven antibiotic discovery and argue for openness and reproducibility as a means of accelerating preclinical research. Finally, trends in the literature and areas for future inquiry are discussed, as artificially intelligent enhancements to drug discovery at large offer many opportunities for future applications in antibiotic development. Melo, Maasch and de la Fuente-Nunez review the current practices in use of artificial intelligence in the discovery of antibiotics and antimicrobials. They also provide details about the best-practices that should be engaged with during computational drug discovery, including open science and reproducibility.",
    "citationCount": 148,
    "pdf_filename": "2021_Accelerating_antibiotic_discovery_throug_266db595.pdf"
  },
  "638c10d215125ade7b79b9813657db4413074d2c": {
    "paperId": "638c10d215125ade7b79b9813657db4413074d2c",
    "title": "Machine Learning Algorithms for Urban Land Use Planning: A Review",
    "year": 2021,
    "authors": "V. Chaturvedi, W. D. de Vries",
    "abstract": "Urbanization is persistent globally and has increasingly significant spatial and environmental consequences. It is especially challenging in developing countries due to the increasing pressure on the limited resources, and damage to the bio-physical environment. Traditional analytical methods of studying the urban land use dynamics associated with urbanization are static and tend to rely on top-down approaches, such as linear and mathematical modeling. These traditional approaches do not capture the nonlinear properties of land use change. New technologies, such as artificial intelligence (AI) and machine learning (ML) have made it possible to model and predict the nonlinear aspects of urban land dynamics. AI and ML are programmed to recognize patterns and carry out predictions, decision making and perform operations with speed and accuracy. Classification, analysis and modeling using earth observation-based data forms the basis for the geospatial support for land use planning. In the process of achieving higher accuracies in the classification of spatial data, ML algorithms are being developed and being improved to enhance the decision-making process. The purpose of the research is to bring out the various ML algorithms and statistical models that have been applied to study aspects of land use planning using earth observation-based data (EO). It intends to review their performance, functional requirements, interoperability requirements and for which research problems can they be applied best. The literature review revealed that random forest (RF), deep learning like convolutional neural network (CNN) and support vector machine (SVM) algorithms are best suited for classification and pattern analysis of earth observation-based data. GANs (generative adversarial networks) have been used to simulate urban patterns. Algorithms like cellular automata, spatial logistic regression and agent-based modeling have been used for studying urban growth, land use change and settlement pattern analysis. Most of the papers reviewed applied ML algorithms for classification of EO data and to study urban growth and land use change. It is observed that hybrid approaches have better performance in terms of accuracies, efficiency and computational cost.",
    "citationCount": 129,
    "pdf_filename": "2021_Machine_Learning_Algorithms_for_Urban_La_638c10d2.pdf"
  },
  "97a4ece721913de47a13246da8fc241229afde14": {
    "paperId": "97a4ece721913de47a13246da8fc241229afde14",
    "title": "Organisational responses to the ethical issues of artificial intelligence",
    "year": 2021,
    "authors": "B. Stahl, Josephina Antoniou, M. Ryan, Kevin Macnish, Tilimbe Jiya",
    "abstract": "The ethics of artificial intelligence (AI) is a widely discussed topic. There are numerous initiatives that aim to develop the principles and guidance to ensure that the development, deployment and use of AI are ethically acceptable. What is generally unclear is how organisations that make use of AI understand and address these ethical issues in practice. While there is an abundance of conceptual work on AI ethics, empirical insights are rare and often anecdotal. This paper fills the gap in our current understanding of how organisations deal with AI ethics by presenting empirical findings collected using a set of ten case studies and providing an account of the cross-case analysis. The paper reviews the discussion of ethical issues of AI as well as mitigation strategies that have been proposed in the literature. Using this background, the cross-case analysis categorises the organisational responses that were observed in practice. The discussion shows that organisations are highly aware of the AI ethics debate and keen to engage with ethical issues proactively. However, they make use of only a relatively small subsection of the mitigation strategies proposed in the literature. These insights are of importance to organisations deploying or using AI, to the academic AI ethics debate, but maybe most valuable to policymakers involved in the current debate about suitable policy developments to address the ethical issues raised by AI.",
    "citationCount": 101,
    "pdf_filename": "2021_Organisational_responses_to_the_ethical__97a4ece7.pdf"
  },
  "31e7099ba50ce27d2f0a0cf6a9b864b4ec6a5cc3": {
    "paperId": "31e7099ba50ce27d2f0a0cf6a9b864b4ec6a5cc3",
    "title": "Theorizing artificial intelligence acceptance and digital entrepreneurship model",
    "year": 2021,
    "authors": "Nitin Upadhyay, S. Upadhyay, Yogesh K. Dwivedi",
    "abstract": "PurposeThis paper aims to determine the entrepreneur's intention to accept artificial intelligence (AI) and provide advancement in the domain of digital entrepreneurship.Design/methodology/approachExtensive literature review and theories have been considered in the area of technology adoption/acceptance and digital entrepreneurship to identify the factors affecting the intention of entrepreneurs with respect to accept AI for digital entrepreneurship. Further, a model, artificial intelligence acceptance and digital entrepreneurship (AIADE) is theorized after formulating some hypotheses. The theorized model has been validated with 476 useable responses.FindingsThe findings revealed that performance expectancy, openness, social influence, hedonic motivations and generativity have a positive impact on entrepreneur's acceptance intention of AI. Additionally, affordance has no direct relationship with AI acceptance intention, but it affects AI acceptance intention through attitude. Inconvenience has a significant negative relationship with the intention to accept AI, while uncertainty was found to be positively affecting the AI acceptance intention. Effort expectancy did not confirm any significant relationship.Research limitations/implicationsBy considering existing theoretical models and concepts the authors contribute to the AI's theoretical progress, specifically in the domain of entrepreneurship. The authors complement and extend existing technology adoption/acceptance theories and digital entrepreneurship theories by developing a theoretical model, AIADE, explaining the entrepreneur's intention to accept AI.Practical implicationsThe practical implications of the study show that performance expectancy (positive), openness (positive), social influence (positive), hedonic motivations (positive), generativity (positive), affordance through attitude (positive), uncertainty (positive), effort expectancy (negative) and inconvenience (negative) are the antecedents for the entrepreneurs to accept AI for digital entrepreneurship. The authors suggest that intentional improvement planning is developed by increasing entrepreneur's positive perceptions of AI affordance and explanation of its generativity and openness, and improving their attitude of using AI for digital entrepreneurship.Originality/valueThis is the first study that reveals the critical antecedents of entrepreneur's intention to accept AI for digital entrepreneurship. Relevant theoretical background, discussion, implications, limitations and future research recommendations are discussed.",
    "citationCount": 101,
    "pdf_filename": "2021_Theorizing_artificial_intelligence_accep_31e7099b.pdf"
  },
  "08f846974649390cf3834a1c2b99a86fafca84c0": {
    "paperId": "08f846974649390cf3834a1c2b99a86fafca84c0",
    "title": "The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of US, EU, and UK regulatory frameworks",
    "year": 2021,
    "authors": "D. Almeida, Konstantin Shmarko, Elizabeth Lomas",
    "abstract": "The rapid development of facial recognition technologies (FRT) has led to complex ethical choices in terms of balancing individual privacy rights versus delivering societal safety. Within this space, increasingly commonplace use of these technologies by law enforcement agencies has presented a particular lens for probing this complex landscape, its application, and the acceptable extent of citizen surveillance. This analysis focuses on the regulatory contexts and recent case law in the United States (USA), United Kingdom (UK), and European Union (EU) in terms of the use and misuse of FRT by law enforcement agencies. In the case of the USA, it is one of the main global regions in which the technology is being rapidly evolved, and yet, it has a patchwork of legislation with less emphasis on data protection and privacy. Within the context of the EU and the UK, there has been a critical focus on the development of accountability requirements particularly when considered in the context of the EU’s General Data Protection Regulation (GDPR) and the legal focus on Privacy by Design (PbD). However, globally, there is no standardised human rights framework and regulatory requirements that can be easily applied to FRT rollout. This article contains a discursive discussion considering the complexity of the ethical and regulatory dimensions at play in these spaces including considering data protection and human rights frameworks. It concludes that data protection impact assessments (DPIA) and human rights impact assessments together with greater transparency, regulation, audit and explanation of FRT use, and application in individual contexts would improve FRT deployments. In addition, it sets out ten critical questions which it suggests need to be answered for the successful development and deployment of FRT and AI more broadly. It is suggested that these should be answered by lawmakers, policy makers, AI developers, and adopters.",
    "citationCount": 130,
    "pdf_filename": "2021_The_ethics_of_facial_recognition_technol_08f84697.pdf"
  },
  "ac1d3d1b2f04b292bad4d58cad03c3d62738a52c": {
    "paperId": "ac1d3d1b2f04b292bad4d58cad03c3d62738a52c",
    "title": "Prompt Engineering",
    "year": 2024,
    "authors": "Sandra Breitenberger",
    "abstract": "Seit Ende 2022 haben ChatGPT und Co. mehrere Millionen Nutzer*innen gewinnen können – zu diesem Zeitpunkt bekam die breite Masse Zugang zu künstlicher Intelligenz, vor allem aber zu generativer KI. Expert*innen erklärten sich den Hype um die App vor allem durch die einfache Nutzbarkeit: Auch ohne Computer-Kenntnisse zu besitzen, konnten Laien nun einfach mit KI interagieren. Für eine effiziente Nutzung ist es jedoch notwendig, die richtige Handhabung für die Verwendung der großen Sprachmodelle zu finden.",
    "citationCount": 171,
    "pdf_filename": "2024_Prompt_Engineering_ac1d3d1b.pdf"
  },
  "8119d4c29aad808671b219f86c117ec5e8f87160": {
    "paperId": "8119d4c29aad808671b219f86c117ec5e8f87160",
    "title": "How to conduct a bibliometric content analysis: Guidelines and contributions of content co‐occurrence or co‐word literature reviews",
    "year": 2024,
    "authors": "Anton Klarin",
    "abstract": "Literature reviews summarize existing literature, uncover research gaps, and offer future research directions, thus aiding in theoretical and methodological development. Informetric research including bibliometric, scientometric, webometric, cybermetric, patentometric, and altmetric methods are becoming increasingly prevalent in conducting literature review studies. Looking at the common informetric literature review methods—citation, co‐citation, co‐author, bibliographic coupling, and content co‐occurrence analyses, this study aims to serve as a guide in using content co‐occurrence also known as co‐word analysis to conduct literature reviews. This study outlines a variety of informetric research methods and how they are utilized to conduct review and evidence‐based conceptual studies. In addition to the analyses, the study highlights different informetric software packages like Bibliometrix, Biblioshiny, Leximancer, NVivo, and CiteSpace including their comparison. The study further discusses contributions of algorithm‐based content analyses including offering taxonomies, definitions, classifications, typologies, comparisons, and theoretical development to constitute integrative literature reviews. Finally, this study offers step‐by‐step guidelines for conducting a review study using VOSviewer content co‐occurrence analysis while providing a systems view of informetric research in social science. The study also notes the emergence of generative artificial intelligence (AI) like Open AI's ChatGPT, Google's Bard, Elicit, Scite, Research Rabbit, and ChatPDF among others, and its potential in contributing to the literature review methods and, as such, being an interesting direction for future research.",
    "citationCount": 120,
    "pdf_filename": "2024_How_to_conduct_a_bibliometric_content_an_8119d4c2.pdf"
  }
}